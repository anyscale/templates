# UNDER CONSTRUCTION: we in the process of adding template definitions
# into this file. This file does not contain all the templates yet.

# job-intro template is to be removed and replaced by
# https://github.com/anyscale/first-job
# owner: matthew owen
- name: job-intro
  emoji: üî∞
  title: Intro to Jobs
  description: Introduction on how to use Anyscale Jobs
  dir: templates/intro-jobs
  cluster_env:
    build_id: anyscaleray2501-py311
  compute_config:
    GCP: configs/basic-single-node/gce.yaml
    AWS: configs/basic-single-node/aws.yaml

# owner: huaiwei
- name: workspace-intro
  emoji: üî∞
  title: Intro to Workspaces
  description: Introduction on how to use Anyscale Workspaces
  dir: templates/intro-workspaces
  cluster_env:
    build_id: anyscaleray2501-py311
  compute_config:
    GCP: configs/basic-single-node/gce.yaml
    AWS: configs/basic-single-node/aws.yaml

# owner: edward
- name: service-intro
  emoji: üî∞
  title: Intro to Services
  description: Introduction on how to use Anyscale Services
  dir: templates/intro-services
  cluster_env:
    build_id: anyscaleray2501-py311
  compute_config:
    GCP: configs/basic-serverless-config/gce.yaml
    AWS: configs/basic-serverless-config/aws.yaml

### summit 2025 templates

- name: summit25-deploy-and-finetune-llm
  emoji: üöÄü§ñ
  title: Deploy and fine-tune LLMs with vLLM and Llama-Factory
  description: Deploy gpt-oss 20B with Ray Serve LLM and fine-tune popular open-source LLMs using Llama-Factory on Anyscale.
  dir: templates/summit25-deploy-and-finetune-llm
  cluster_env:
    byod:
      docker_image: anyscale/ray-llm:2.50.1-py311-cu128
      ray_version: 2.50.1
  compute_config:
    AWS: configs/summit25-deploy-and-finetune-llm/aws.yaml
    GCP: configs/summit25-deploy-and-finetune-llm/gce.yaml

- name: ray-data-pipelines
  emoji: ‚ö°üß†
  title: Building pipelines with Ray Data
  description: Building scalable, multi-modal data processing pipelines with Ray Data, including batch inference optimization, ETL processing & optimization, and unstructured data ingestion.
  dir: templates/ray-data-pipelines
  cluster_env:
    byod:
      docker_image: us-docker.pkg.dev/anyscale-workspace-templates/workspace-templates/ray-data-pipelines:2.50.1
      ray_version: 2.50.1
  compute_config:
    AWS: configs/ray-data-pipelines/aws.yaml
    GCP: configs/ray-data-pipelines/gce.yaml

- name: summit25-raytrain-training
  emoji: üöÄüí™
  title: Easy scalable training with Ray Train
  description: Train PyTorch models efficiently with Ray Train. This guide covers data migration, checkpointing, fault tolerance, Ray Data integration, and observability.
  dir: templates/summit25-raytrain-training
  cluster_env:
    byod:
      docker_image: us-docker.pkg.dev/anyscale-workspace-templates/workspace-templates/summit25-ai-libs:2
      ray_version: 2.49.2
  compute_config:
    AWS: configs/summit25-raytrain-training/aws.yaml
    GCP: configs/summit25-raytrain-training/gce.yaml

- name: summit25-distributed-ml-systems
  emoji: ‚öôÔ∏èüìà
  title: Building distributed ML systems with Ray Core
  description: Hands-on tasks, actors, and streaming patterns to build scalable ML pipelines and distributed training.
  cluster_env:
    byod:
      docker_image: us-docker.pkg.dev/anyscale-workspace-templates/workspace-templates/ray-core-summit:2.50.0
      ray_version: 2.50.0
  compute_config:
    AWS: configs/summit25-distributed-ml-systems/aws.yaml
    GCP: configs/summit25-distributed-ml-systems/gce.yaml

- name: summit25-ml-ray-serve
  emoji: ‚öôÔ∏èüìà
  title: Serving ML models with Ray Serve
  description: Best practices and scalable production patterns for serving ML models with Ray Serve.
  dir: templates/summit25-ml-ray-serve
  cluster_env:
    byod:
      docker_image: us-docker.pkg.dev/anyscale-workspace-templates/workspace-templates/ray-serve-summit:2.50.0
      ray_version: 2.50.0
  compute_config:
    AWS: configs/summit25-ml-ray-serve/aws.yaml
    GCP: configs/summit25-ml-ray-serve/gce.yaml
