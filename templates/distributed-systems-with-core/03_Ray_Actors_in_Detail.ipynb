{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "998e35b4",
   "metadata": {},
   "source": [
    "# Ray Actors in Detail\n",
    "\n",
    "Â© 2025, Anyscale. All Rights Reserved\n",
    "\n",
    "This document provides an introduction to Ray Actors, which extend the Ray API from functions (tasks) to classes.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b> Here is the roadmap for this notebook </b>\n",
    "\n",
    "<ol>\n",
    "  <li>Overview and setup</li>\n",
    "  <li>Simple actor submission (creating, executing, and getting results)</li>\n",
    "  <li>Actor resource fulfillment and scheduling</li>\n",
    "  <li>Fault tolerance with Actors</li>\n",
    "  <li>Multi-threading with Actors</li>\n",
    "  <li>Asyncio with Actors</li>\n",
    "  <li>Placement groups</li>\n",
    "  <li>Actor pool abstraction</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60dfd80",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc2dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "\n",
    "\n",
    "import ray\n",
    "from ray.util import ActorPool\n",
    "from ray.util.scheduling_strategies import NodeAffinitySchedulingStrategy\n",
    "from ray.util.placement_group import placement_group, remove_placement_group\n",
    "from ray.util.scheduling_strategies import PlacementGroupSchedulingStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaf81dd",
   "metadata": {},
   "source": [
    "## Simple actor submission (creating, executing, and getting results)\n",
    "\n",
    "Actors extend the Ray API from functions (tasks) to classes.\n",
    "\n",
    "An actor is a stateful worker. When a new actor is instantiated, a new worker is created, and methods of the actor are scheduled on that specific worker and can access and mutate the state of that worker. Similarly to Ray Tasks, actors support CPU and GPU compute as well as fractional resources.\n",
    "\n",
    "Let's look at an example of an actor which maintains a running balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Accounting:\n",
    "    def __init__(self):\n",
    "        self.total = 0\n",
    "    \n",
    "    def add(self, amount):\n",
    "        self.total += amount\n",
    "        \n",
    "    def remove(self, amount):\n",
    "        self.total -= amount\n",
    "        \n",
    "    def total(self):\n",
    "        return self.total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53d64fa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "  <strong><a href=\"https://docs.ray.io/en/latest/ray-core/key-concepts.html#actors\" target=\"_blank\">Actor</a></strong> is a remote, stateful Python class.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "The most common use case for actors is with state that is not mutated but is large enough that we may want to load it only once and ensure we can route calls to it over time, such as a large AI model.\n",
    "\n",
    "</div>\n",
    "\n",
    "Define an actor with the `@ray.remote` decorator and then use `<class_name>.remote()` ask Ray to construct and instance of this actor somewhere in the cluster.\n",
    "\n",
    "We get an actor handle which we can use to communicate with that actor, pass to other code, tasks, or actors, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2b8e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = Accounting.remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f36904",
   "metadata": {},
   "source": [
    "We can send a message to an actor -- with RPC semantics -- by using `<handle>.<method_name>.remote()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478b7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc.total.remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b93c30",
   "metadata": {},
   "source": [
    "Not surprisingly, we get an object ref back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84bb88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.get(acc.total.remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e617bbf8",
   "metadata": {},
   "source": [
    "We can mutate the state inside this actor instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758ceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc.add.remote(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc.remove.remote(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98425e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.get(acc.total.remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f369b8",
   "metadata": {},
   "source": [
    "### Activity: Linear Model Inference\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "__Activity: linear model inference__\n",
    "\n",
    "* Create an actor which applies a model to convert Celsius temperatures to Fahrenheit\n",
    "* The constructor should take model weights (w1 and w0) and store them as instance state\n",
    "* A convert method should take a scalar, multiply it by w1 then add w0 (weights retrieved from instance state) and then return the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb2ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: define the below as a remote actor\n",
    "class LinearModel:\n",
    "    def __init__(self, w0, w1):\n",
    "        \"\"\"Hint: store the weights\"\"\"\n",
    "\n",
    "    def convert(self, celsius):\n",
    "        \"\"\"Hint: convert the celsius temperature to Fahrenheit.\"\"\"\n",
    "\n",
    "# Hint: create an instance of the LinearModel actor\n",
    "\n",
    "# Hint: convert 100 Celsius to Fahrenheit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019cced5",
   "metadata": {},
   "source": [
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba447e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfdfcae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary> Click to see solution </summary>\n",
    "\n",
    "```python\n",
    "@ray.remote\n",
    "class LinearModel:\n",
    "    def __init__(self, w0, w1):\n",
    "        self.w0 = w0\n",
    "        self.w1 = w1\n",
    "\n",
    "    def convert(self, celsius):\n",
    "        return self.w1 * celsius + self.w0\n",
    "\n",
    "model = LinearModel.remote(w1=9/5, w0=32)\n",
    "ray.get(model.convert.remote(100))\n",
    "``` \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb35fe70",
   "metadata": {},
   "source": [
    "</details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12424ff",
   "metadata": {},
   "source": [
    "## Actor resource fulfillment and scheduling\n",
    "\n",
    "Actors reserve resources for their entire lifetime. Method calls (actor tasks) execute on the same worker process that hosts the actor.\n",
    "\n",
    "- An actor's resource shape is specified on the class via `@ray.remote(...)` or with `.options(...)` at construction time.\n",
    "- Actor methods run on that dedicated worker; they do not request additional resources beyond what the actor already holds.\n",
    "- Calls to the same actor are queued and executed according to its concurrency settings (default: one at a time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=2, num_gpus=0.5, resources={\"db\": 1})\n",
    "class ModelServer:\n",
    "    def __init__(self):\n",
    "        self.ready = True\n",
    "\n",
    "    def infer(self, x):\n",
    "        return x * 2\n",
    "\n",
    "# Placement: let Ray decide (default)\n",
    "srv = ModelServer.remote()\n",
    "\n",
    "# Placement: spread actors across nodes\n",
    "srv_spread = ModelServer.options(scheduling_strategy=\"SPREAD\").remote()\n",
    "\n",
    "# Placement: node affinity\n",
    "node_id = ray.get_runtime_context().get_node_id()\n",
    "affinity = NodeAffinitySchedulingStrategy(node_id=node_id, soft=True)\n",
    "srv_aff = ModelServer.options(scheduling_strategy=affinity).remote()\n",
    "\n",
    "ray.get(srv.infer.remote(21))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc91a85f",
   "metadata": {},
   "source": [
    "### How actor placement is chosen\n",
    "\n",
    "| Rule | When | Behavior |\n",
    "| --- | --- | --- |\n",
    "| Data locality | Actor args include large `ObjectRef`s | Prefer node with most bytes local |\n",
    "| Node affinity | `scheduling_strategy=NodeAffinitySchedulingStrategy(...)` | Try preferred node; fallback if `soft=True` |\n",
    "| Default | No preferences | Use caller's local raylet if resources fit |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c82ef",
   "metadata": {},
   "source": [
    "### Execution model\n",
    "- Actor creation is a placement decision; resources are leased to the actor's worker for its full lifetime.\n",
    "- Actor method calls reuse that worker (no per-call placement), honoring FIFO and concurrency limits.\n",
    "- To scale throughput, create multiple actors or increase `max_concurrency` (see Multithreaded/Async actors).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <b>Tip:</b> Use fractional resources (e.g., <code>num_cpus=0.5</code>) for I/O-heavy actors to pack more per node.\n",
    "  Inspect <code>ray.available_resources()</code> and <code>ray.cluster_resources()</code> to reason about placement capacity.\n",
    "  Consider <code>SPREAD</code> to avoid hotspots when launching many actors.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2e719",
   "metadata": {},
   "source": [
    "## Fault tolerance with Actors\n",
    "\n",
    "Actors can automatically restart on failure. Configure restart behavior on the class or at construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(max_restarts=2, max_task_retries=5)\n",
    "class Unstable:\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "\n",
    "    def bump(self):\n",
    "        self.n += 1\n",
    "        return self.n\n",
    "\n",
    "    def crash(self):\n",
    "        os._exit(1)  # simulate hard failure\n",
    "\n",
    "a = Unstable.remote()\n",
    "try:\n",
    "    ray.get(a.crash.remote())  # triggers restart (up to 2x)\n",
    "except Exception:\n",
    "    pass\n",
    "ray.get(a.bump.remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237a3e88",
   "metadata": {},
   "source": [
    "### Key behaviors\n",
    "- max_restarts: How many times to recreate the actor after process/node failures.\n",
    "- max_task_retries: How many times to retry a failed actor method due to system errors.\n",
    "- Application exceptions from methods propagate as `RayTaskError` to the caller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8849a08b",
   "metadata": {},
   "source": [
    "### Preserving state across restarts\n",
    "Actor memory is process-local. After a restart, you must restore state explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e28054",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(max_restarts=3)\n",
    "class Checkpointed:\n",
    "    def __init__(self, ckpt_ref=None):\n",
    "        self.state = {\"sum\": 0}\n",
    "        if ckpt_ref is not None:\n",
    "            self.state = ray.get(ckpt_ref)\n",
    "\n",
    "    def add(self, x):\n",
    "        self.state[\"sum\"] += x\n",
    "        return self.state[\"sum\"]\n",
    "\n",
    "    def checkpoint(self):\n",
    "        return ray.put(self.state)\n",
    "\n",
    "ckpt_actor = Checkpointed.remote()\n",
    "ray.get([ckpt_actor.add.remote(i) for i in range(10)])\n",
    "ckpt_ref = ray.get(ckpt_actor.checkpoint.remote())\n",
    "\n",
    "# Recreate using checkpoint (e.g., after failure)\n",
    "ckpt_actor2 = Checkpointed.options(args=(ckpt_ref,)).remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46a91f1",
   "metadata": {},
   "source": [
    "### Detached actors\n",
    "Make long-lived, globally named services resilient to driver exits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b5d7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = ModelServer.options(lifetime=\"detached\", name=\"global_model\").remote()\n",
    "# Later (or from another driver):\n",
    "svc = ray.get_actor(\"global_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6bc90",
   "metadata": {},
   "source": [
    "### Killing actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc792a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent restart on kill\n",
    "ray.kill(a, no_restart=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67100ed8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Note:</b> Restarted actors run <code>__init__</code> again. Implement idempotent initialization and explicit restore paths.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61df781",
   "metadata": {},
   "source": [
    "## Multithreaded actors\n",
    "\n",
    "By default, an actor runs one method at a time. Increase parallelism with `max_concurrency` and ensure thread-safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501cea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(max_concurrency=8)\n",
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.value = 0\n",
    "        self._lock = threading.Lock()\n",
    "\n",
    "    def add(self, x):\n",
    "        time.sleep(0.1)  # simulate work\n",
    "        with self._lock:\n",
    "            self.value += x\n",
    "            return self.value\n",
    "\n",
    "c = Counter.remote()\n",
    "refs = [c.add.remote(1) for _ in range(32)]\n",
    "ray.get(refs)  # up to 8 run concurrently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd36202",
   "metadata": {},
   "source": [
    "Guidelines:\n",
    "- Protect shared mutable state with locks or use immutable updates.\n",
    "- Use higher `max_concurrency` for I/O-bound actors; keep modest for CPU-bound to avoid oversubscription.\n",
    "- For CPU-heavy parallelism, prefer multiple actors to scale across cores/nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68c0d4",
   "metadata": {},
   "source": [
    "## Async actors\n",
    "\n",
    "Async actors run an asyncio event loop; methods declared with `async def` can interleave via `await` points. Concurrency is bounded by `max_concurrency`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(max_concurrency=16)\n",
    "class AsyncWorker:\n",
    "    async def work(self, i):\n",
    "        await asyncio.sleep(0.2)\n",
    "        return i * i\n",
    "\n",
    "aw = AsyncWorker.remote()\n",
    "results = ray.get([aw.work.remote(i) for i in range(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52267c9",
   "metadata": {},
   "source": [
    "Patterns:\n",
    "- Prefer async actors for network-bound or timer-based workflows; use `await` to yield.\n",
    "- Combine async with backpressure at the caller (e.g., submit N calls, `ray.wait`, then submit more).\n",
    "- You can mix sync and async methods in the same actor.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "  <b>Tip:</b> Async actors avoid Python thread contention and can scale high-concurrency I/O. Set <code>max_concurrency</code> to the target in-flight operations.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f72e074",
   "metadata": {},
   "source": [
    "## Placement groups (bundle-aware placement)\n",
    "\n",
    "Placement groups co-locate a set of resources into one or more bundles and schedule them atomically. They are useful when you need:\n",
    "- Multiple actors/tasks to be co-located on the same node (e.g., pipeline stages sharing data)\n",
    "- Gang scheduling for tightly coupled components (e.g., parameter server + workers)\n",
    "- Reserved capacity before launching a topology of actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2f1597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a placement group with two bundles on the same node (PACK)\n",
    "pg = placement_group(\n",
    "    [\n",
    "        {\"CPU\": 2},  # bundle 0\n",
    "        {\"CPU\": 2},  # bundle 1\n",
    "    ],\n",
    "    strategy=\"PACK\",\n",
    "    name=\"actors_pg\",\n",
    ")\n",
    "ray.get(pg.ready())\n",
    "\n",
    "\n",
    "# Schedule an actor in bundle 0\n",
    "@ray.remote(num_cpus=2)\n",
    "class StageA:\n",
    "    def run(self, x):\n",
    "        return x + 1\n",
    "\n",
    "\n",
    "# Schedule an actor in bundle 1\n",
    "@ray.remote(num_cpus=2)\n",
    "class StageB:\n",
    "    def run(self, x):\n",
    "        return x * 2\n",
    "\n",
    "\n",
    "bundle0 = PlacementGroupSchedulingStrategy(\n",
    "    placement_group=pg, placement_group_bundle_index=0\n",
    ")\n",
    "bundle1 = PlacementGroupSchedulingStrategy(\n",
    "    placement_group=pg, placement_group_bundle_index=1\n",
    ")\n",
    "\n",
    "a = StageA.options(scheduling_strategy=bundle0).remote()\n",
    "b = StageB.options(scheduling_strategy=bundle1).remote()\n",
    "\n",
    "res = ray.get(b.run.remote(ray.get(a.run.remote(10))))\n",
    "\n",
    "# Cleanup when done\n",
    "remove_placement_group(pg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e911805",
   "metadata": {},
   "source": [
    "### Strategies\n",
    "- PACK: Prefer to place all bundles on as few nodes as possible (good for locality).\n",
    "- SPREAD: Spread bundles across nodes (fault isolation, bandwidth).\n",
    "- STRICT_PACK / STRICT_SPREAD: Hard constraints; fail if not possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f6f77",
   "metadata": {},
   "source": [
    "### Best practices\n",
    "- Create the placement group first, wait for `pg.ready()` before launching actors to avoid queuing delays.\n",
    "- Use `PlacementGroupSchedulingStrategy` on each actor/task that must reserve from the group.\n",
    "- Right-size bundles to the actors/tasks that will occupy them (avoid internal fragmentation).\n",
    "- For elastic topologies, prefer multiple smaller placement groups over a single monolith.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>Note:</b> Placement groups reserve capacity; they can increase pending time if the cluster is busy. Use them when co-placement matters.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b326485",
   "metadata": {},
   "source": [
    "## ActorPool (simple worker pool over actors)\n",
    "\n",
    "`ray.util.ActorPool` provides a lightweight way to manage a pool of homogeneous actors and submit many small jobs with automatic load balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b5fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Worker:\n",
    "    def process(self, x):\n",
    "        return x * x\n",
    "\n",
    "# Create N actors\n",
    "workers = [Worker.remote() for _ in range(4)]\n",
    "pool = ActorPool(workers)\n",
    "\n",
    "# Map over inputs (unordered completion)\n",
    "inputs = range(10)\n",
    "results = list(pool.map(lambda a, x: a.process.remote(x), inputs))\n",
    "\n",
    "# Or submit tasks incrementally and consume as ready\n",
    "for x in range(10, 20):\n",
    "    pool.submit(lambda a, v: a.process.remote(v), x)\n",
    "\n",
    "ready = [pool.get_next() for _ in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849d083d",
   "metadata": {},
   "source": [
    "When to use:\n",
    "- Many short, similar actor method calls; you want automatic fair scheduling across a fixed set of actors.\n",
    "- Simple replacement for manual round-robin over actor handles.\n",
    "\n",
    "Prefer alternatives when:\n",
    "- You need heterogeneous actors or topology (use multiple actor types or placement groups).\n",
    "- You need backpressure/windowed submission (combine with `ray.wait` or use async actors with queues)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "ray-core-deep-dive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
