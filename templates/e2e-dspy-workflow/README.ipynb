{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Efficient LLM Pipeline with DSPy and Anyscale\n",
    "\n",
    "Time to complete: 1.5 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this guide, we'll show how you can build an efficient pipeline covering synthetic data generation, data processing, fine-tuning, evaluation and serving with DSPy and Anyscale.\n",
    "\n",
    "**What is DSPy?**\n",
    "\n",
    "DSPy is a framework for building and optimizing programs involving language models.\n",
    "\n",
    "It allows you to define a complex pipeline with simple Python code, and then optimize the pipeline for better performance on whatever your task is.\n",
    "\n",
    "See the [DSPy Documentation](https://dspy-docs.vercel.app/intro/) for more information.\n",
    "\n",
    "## Why DSPy and Anyscale?\n",
    "DSPy simplifies the complex workflow of:\n",
    "- Data Collection/Labeling\n",
    "- Fine-tuning\n",
    "- Prompt Optimization\n",
    "- Evaluation\n",
    "  \n",
    "We'll use Anyscale for scalable infrastructure for training and serving/deploying models.\n",
    "\n",
    "## Scenario: Cost-Effective Customer Support Query Classification\n",
    "\n",
    "Consider an example of classification with limited labelled data. The specific dataset we'll be working with is the [PolyAI/banking77](https://huggingface.co/datasets/PolyAI/banking77) dataset, which consists of customer support queries for a bank. We'll simulate a scenario with low labelled data: let's say we have a dataset has limited labeled data (100 queries) and 4,000 unlabeled customer queries. We'll build a solution that leverages DSPy on Anyscale to distill knowledge from a 70B model into a more cost-effective 1B model, making it practical for production deployment.\n",
    "\n",
    "- DSPy enables easy creation of a pipeline for knowledge distillation from a 70B model to a 1B model in a low data environment\n",
    "- Anyscale's infrastructure supports efficient fine-tuning and deployment\n",
    "- Result: A cost-effective, accurate classification system for 25 categories\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. Setup\n",
    "2. Data Processing and Labeling\n",
    "3. Model Fine-tuning\n",
    "4. Evaluation and Optimization\n",
    "5. Production Deployment\n",
    "6. Future Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be running everything on A100-80GB GPUs. This is not necessary, especially for running a 1B model. You can edit the serving configuration files used throughout the notebook to use different GPUs if you do not have access to A100s.\n",
    "\n",
    "We use Anyscale's Auto-select worker node feature to launch and manage child nodes that are running our LLM. You can also set your own compute configuration to autoscale different types of GPUs at different ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dspy is already installed\n",
      "Requirement already satisfied: matplotlib in /home/ray/anaconda3/lib/python3.9/site-packages (3.9.2)\n",
      "Requirement already satisfied: python-dotenv in /home/ray/anaconda3/lib/python3.9/site-packages (1.0.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from matplotlib) (6.4.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/ray/anaconda3/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ray/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "\n",
    "if importlib.util.find_spec(\"dspy\") is None:\n",
    "    print(\"Installing dspy\")\n",
    "    !pip install git+https://github.com/stanfordnlp/dspy.git@main\n",
    "\n",
    "else:\n",
    "    print(\"dspy is already installed\")\n",
    "\n",
    "!pip install matplotlib python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "dspy.settings.configure(experimental=True)\n",
    "\n",
    "import ujson\n",
    "\n",
    "from src import set_dspy_cache_location\n",
    "set_dspy_cache_location(\"/home/ray/default/dspy/cache\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this notebook, you need to have the following environment variables set:\n",
    "- HF_HOME\n",
    "- HF_TOKEN\n",
    "- (optional) WANDB_API_KEY\n",
    "\n",
    "You can get a HF_TOKEN [here](https://huggingface.co/settings/tokens). You will need to request access to the Meta-Llama-3.1-70B-Instruct model and the Llama-3.2-1B-Instruct model.\n",
    "\n",
    "You can get a WANDB_API_KEY [here](https://wandb.ai/authorize)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"background-color: yellow;\">&nbsp;ðŸ”„ REPLACE&nbsp;</b>: Set the HF_TOKEN, HF_HOME, and optionally the WANDB_API_KEY environment variables in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import ray \n",
    "# By default, the cache directory used by HuggingFace is in the home directory -`/home/ray`\n",
    "# We'll use `/mnt/local_storage` here for downloading large model weight files\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"/mnt/local_storage/huggingface\"\n",
    "os.environ[\"HF_TOKEN\"] = \"Add your HF token here\"\n",
    "# Optional: Add your Wandb token\n",
    "# os.environ[\"WANDB_API_KEY\"] = \"12345\"\n",
    "\n",
    "# You can also use a .env file to store your HF_TOKEN and WANDB_API_KEY\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of a random number generator in this notebook to ensure that our notebook is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import set_random_seed\n",
    "rng = set_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import check_env_vars\n",
    "\n",
    "# Check if env vars are set correctly\n",
    "check_env_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 00:37:29,643\tINFO worker.py:1601 -- Connecting to existing Ray cluster at address: 10.0.0.28:6379...\n",
      "2024-10-23 00:37:29,654\tINFO worker.py:1777 -- Connected to Ray cluster. View the dashboard at https://session-6frbgpfbuzs27m75xhz3c8vnde.i.anyscaleuserdata.com \n",
      "2024-10-23 00:37:29,686\tINFO packaging.py:531 -- Creating a file package for local directory '/home/ray/anaconda3/lib/python3.9/site-packages/dspy'.\n",
      "2024-10-23 00:37:29,730\tINFO packaging.py:359 -- Pushing file package 'gcs://_ray_pkg_3456a89b1fcd9948.zip' (1.17MiB) to Ray cluster...\n",
      "2024-10-23 00:37:29,744\tINFO packaging.py:372 -- Successfully pushed file package 'gcs://_ray_pkg_3456a89b1fcd9948.zip'.\n",
      "2024-10-23 00:37:29,759\tINFO packaging.py:531 -- Creating a file package for local directory '/home/ray/anaconda3/lib/python3.9/site-packages/dsp'.\n",
      "2024-10-23 00:37:29,779\tINFO packaging.py:359 -- Pushing file package 'gcs://_ray_pkg_eac1031112d62b99.zip' (0.55MiB) to Ray cluster...\n",
      "2024-10-23 00:37:29,787\tINFO packaging.py:372 -- Successfully pushed file package 'gcs://_ray_pkg_eac1031112d62b99.zip'.\n",
      "2024-10-23 00:37:29,790\tINFO packaging.py:359 -- Pushing file package 'gcs://_ray_pkg_c62d21a49b226e4a53a17f9d7aa3bed4b56a5efb.zip' (0.83MiB) to Ray cluster...\n",
      "2024-10-23 00:37:29,798\tINFO packaging.py:372 -- Successfully pushed file package 'gcs://_ray_pkg_c62d21a49b226e4a53a17f9d7aa3bed4b56a5efb.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +1m53s) Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "(autoscaler +1m53s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +3m32s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launched 1 instances.\n",
      "(autoscaler +17m6s) [autoscaler] Downscaling node g-f69c56902ddd40001 (node IP: 10.0.0.57) due to node idle termination.\n",
      "(autoscaler +31m41s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +32m27s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launched 1 instances.\n",
      "(autoscaler +40m35s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 3 node(s).\n",
      "(autoscaler +40m36s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:3;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +40m39s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +40m39s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +40m39s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +40m40s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +40m41s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +40m42s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +40m43s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +40m44s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +40m46s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +40m46s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +40m48s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +40m48s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +40m50s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +40m50s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +40m51s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 3 node(s).\n",
      "(autoscaler +40m53s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:3;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +40m54s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +40m56s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +40m57s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +40m57s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +40m58s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +40m58s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +40m58s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +40m59s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m0s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m1s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m2s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m2s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m5s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m6s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m7s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +41m9s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m10s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 3 node(s).\n",
      "(autoscaler +41m10s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:3;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m13s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m13s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m14s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m14s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m15s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m16s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m18s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +41m19s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-c] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:true]: googleapi: Error 400: Invalid value for field 'resource.instanceProperties.machineType': 'a2-ultragpu-1g'. Machine type with name 'a2-ultragpu-1g' does not exist in zone 'us-east5-c'.\n",
      "(autoscaler +41m19s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-c] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 400: Invalid value for field 'resource.instanceProperties.machineType': 'a2-ultragpu-1g'. Machine type with name 'a2-ultragpu-1g' does not exist in zone 'us-east5-c'.\n",
      "(autoscaler +41m22s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 3 node(s).\n",
      "(autoscaler +41m23s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:3;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m25s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +41m25s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m27s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m27s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m28s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m28s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m31s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m32s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m33s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +41m33s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m34s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m34s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m34s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m35s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m38s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m39s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m40s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 3 node(s).\n",
      "(autoscaler +41m41s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:3;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m44s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m44s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m44s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m44s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m46s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +41m48s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m49s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m49s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m50s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m50s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m50s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m51s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m52s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m54s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m57s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 3 node(s).\n",
      "(autoscaler +41m58s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:3;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +41m59s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +41m59s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m0s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m0s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m2s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +42m4s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m6s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m7s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m8s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m8s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m9s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m9s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m12s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +42m12s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m15s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m16s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m17s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m17s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m17s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m18s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m19s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m21s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m23s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 3 node(s).\n",
      "(autoscaler +42m24s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:3;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m25s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +42m25s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m26s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m26s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m27s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m27s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m30s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m30s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m31s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 3 node(s).\n",
      "(autoscaler +42m33s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:3;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m34s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m34s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m35s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m35s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m37s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m39s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m40s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +42m41s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m42s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m42s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m42s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m42s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m44s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m44s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m47s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +42m48s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m49s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m49s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m50s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m51s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m51s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m53s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m54s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 3 node(s).\n",
      "(autoscaler +42m56s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:3;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m57s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +42m58s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +42m59s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +42m59s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m0s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m0s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m2s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m2s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m5s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m5s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m5s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m6s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m8s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +43m8s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m10s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m12s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m13s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m13s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m14s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m14s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m16s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +43m16s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m18s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m19s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m22s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 3 node(s).\n",
      "(autoscaler +43m23s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:3;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m25s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m25s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m25s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m25s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m27s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m29s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m31s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +43m31s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-c] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:true]: googleapi: Error 400: Invalid value for field 'resource.instanceProperties.machineType': 'a2-ultragpu-1g'. Machine type with name 'a2-ultragpu-1g' does not exist in zone 'us-east5-c'.\n",
      "(autoscaler +43m32s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-c] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 400: Invalid value for field 'resource.instanceProperties.machineType': 'a2-ultragpu-1g'. Machine type with name 'a2-ultragpu-1g' does not exist in zone 'us-east5-c'.\n",
      "(autoscaler +43m33s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +43m34s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m35s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m35s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m36s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m36s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m39s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m40s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m41s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 6 node(s).\n",
      "(autoscaler +43m43s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:6;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m44s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 3 node(s).\n",
      "(autoscaler +43m46s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:3;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m48s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m48s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m49s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m49s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m50s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m51s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m53s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m53s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +43m53s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m55s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m57s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 3 node(s).\n",
      "(autoscaler +43m58s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:3;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +43m59s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +44m1s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +44m1s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +44m2s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +44m5s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +44m5s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +44m55s) [autoscaler] Downscaling node g-754bab5ac3b0b0002 (node IP: 10.0.0.46) due to node idle termination.\n",
      "(autoscaler +44m55s) [autoscaler] Downscaling node g-754bab5ac3b0b0001 (node IP: 10.0.0.41) due to node idle termination.\n",
      "(autoscaler +44m55s) [autoscaler] Downscaling node g-754bab5ac3b0b0003 (node IP: 10.0.0.45) due to node idle termination.\n",
      "(autoscaler +44m57s) [autoscaler] Cluster resized to {12 CPU, 1 GPU}.\n",
      "(autoscaler +1h1m41s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h1m41s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h1m43s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h1m43s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h1m44s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h1m45s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h1m48s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h1m48s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h1m48s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h1m48s) [autoscaler] Cluster upscaled to {48 CPU, 4 GPU}.\n",
      "(autoscaler +1h1m48s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h1m50s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h1m51s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h1m52s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h1m53s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h1m53s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h1m53s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h1m57s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h1m57s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h1m57s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h1m57s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h1m59s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h1m59s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m0s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h2m0s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m1s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m1s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m4s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m4s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m5s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m5s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m7s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m7s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m9s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h2m9s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m10s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m10s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m11s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m11s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m13s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m13s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m15s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m16s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m16s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h2m16s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m17s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m17s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m18s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m18s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m19s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m19s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m23s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m24s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m24s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h2m25s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m26s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m26s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m28s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m28s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m28s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m30s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m31s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m32s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m34s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m34s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h2m35s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m35s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m37s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m37s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m37s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m39s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m40s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m41s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m41s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h2m41s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m42s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m43s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m44s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m44s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m45s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m45s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m49s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m49s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m50s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m50s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h2m50s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m50s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m52s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m52s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m53s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m53s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m56s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h2m57s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h2m58s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h2m58s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m0s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m0s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m2s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m2s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m2s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m2s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m5s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m6s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m6s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h3m7s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m8s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m8s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m9s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m9s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m11s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m11s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m14s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m14s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m16s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m16s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h3m16s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m16s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m17s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m17s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m18s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m18s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m21s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m22s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m23s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h3m23s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m25s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m25s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m27s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m27s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m27s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m27s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m30s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m30s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m32s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m32s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h3m32s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m33s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m33s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m33s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m34s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m35s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m36s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m39s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m41s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h3m41s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m41s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m41s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m42s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m42s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m42s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m42s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m43s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m44s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m47s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h3m47s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m48s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m48s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m50s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m50s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m51s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m51s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m53s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m53s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m55s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h3m55s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m56s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m57s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m58s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m58s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h3m59s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h3m59s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m0s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m2s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m4s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m4s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h4m5s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m5s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m6s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m6s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m7s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m7s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m9s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m9s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m11s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m11s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h4m11s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m13s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m15s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m15s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m15s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m15s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m16s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m17s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m18s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h4m18s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m19s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m21s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m22s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m22s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m24s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m24s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m25s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m25s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m27s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h4m27s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m28s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m28s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m31s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m31s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m31s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m31s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m32s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m32s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m35s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h4m35s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m35s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m35s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m38s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m38s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m39s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m40s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m41s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m41s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m43s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m43s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h4m43s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m45s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m46s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m46s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m47s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m47s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m49s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m50s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m51s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h4m51s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m52s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m52s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m53s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m53s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m53s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m55s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m57s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m57s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m58s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h4m58s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h4m59s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h4m59s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m0s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m0s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m1s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m1s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m3s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m4s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m5s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h5m5s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m6s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m6s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m8s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m8s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m8s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m9s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m12s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m13s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m14s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h5m14s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m15s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m15s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m16s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m16s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m17s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m17s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m19s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m21s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m22s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h5m22s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m24s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m24s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m25s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m25s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m25s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m26s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m28s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m28s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m30s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h5m31s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m31s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m31s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m32s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m33s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m33s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m33s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m35s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m35s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m36s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h5m36s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m38s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m38s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m41s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m41s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m41s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m41s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m43s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m44s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m45s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h5m45s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m47s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m47s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m48s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m49s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m49s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m49s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m52s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m52s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m52s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h5m52s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m53s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m53s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m57s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m57s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m58s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m58s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h5m59s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h5m59s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m1s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h6m1s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m2s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m2s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m5s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m5s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m5s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m5s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m7s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m8s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m10s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m10s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h6m10s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m10s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m11s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m11s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m13s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m14s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m16s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m16s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m17s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m17s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h6m18s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m18s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m21s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m21s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m21s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m22s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m22s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m24s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m25s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m25s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h6m26s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m27s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m28s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m28s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m30s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m30s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m32s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m33s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m36s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m36s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h6m36s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m36s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m38s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m38s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m38s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m38s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m40s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m40s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m41s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h6m41s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m42s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m42s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m44s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m44s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m47s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m47s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m48s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m48s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m50s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h6m50s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m50s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m50s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m52s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m52s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m52s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m52s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m54s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m56s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m57s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 2 node(s).\n",
      "(autoscaler +1h6m57s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h6m58s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:2;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h6m58s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h7m0s) [autoscaler] [4xA100-80GB:48CPU-680GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h7m0s) [autoscaler] [1xA100-80GB:12CPU-170GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h7m1s) [autoscaler] [4xA100-80GB:48CPU-680GB|a2-ultragpu-4g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-4g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h7m1s) [autoscaler] [1xA100-80GB:12CPU-170GB|a2-ultragpu-1g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-1g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h7m5s) [autoscaler] [8xA100-80GB:96CPU-1360GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h7m5s) [autoscaler] [8xA100-80GB:96CPU-1360GB|a2-ultragpu-8g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-8g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h7m7s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h7m7s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h7m8s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h7m8s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h7m9s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h7m11s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h7m11s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h7m13s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h7m15s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h7m15s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h7m16s) [autoscaler] [2xA100-80GB:24CPU-340GB] Upscaling 1 node(s).\n",
      "(autoscaler +1h7m17s) [autoscaler] [2xA100-80GB:24CPU-340GB|a2-ultragpu-2g] [us-east5-b] [on-demand] Launching instances failed: NewInstances[a2-ultragpu-2g;num:1;all:false]: googleapi: Error 403: Quota 'NVIDIA_A100_80GB_GPUS' exceeded. Limit: 16.0 in region us-east5.\n",
      "(autoscaler +1h8m4s) [autoscaler] Downscaling node g-93baa4121b79f0001 (node IP: 10.0.0.53) due to node idle termination.\n",
      "(autoscaler +1h8m5s) [autoscaler] Cluster resized to {36 CPU, 3 GPU}.\n",
      "(autoscaler +1h11m36s) [autoscaler] Downscaling node g-73bd411113f590001 (node IP: 10.0.0.22) due to node idle termination.\n",
      "(autoscaler +1h11m37s) [autoscaler] Cluster resized to {12 CPU, 1 GPU}.\n"
     ]
    }
   ],
   "source": [
    "from src import init_ray\n",
    "init_ray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "We will be using the `PolyAI/banking77` dataset for this tutorial. We use the built in dspy DataLoader to load the dataset from Huggingface as a list of dspy.Example objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "from src import load_data_from_huggingface, convert_int_label_to_string\n",
    "full_trainset, full_testset = load_data_from_huggingface()\n",
    "\n",
    "full_trainset_processed, full_testset_processed = convert_int_label_to_string(full_trainset, full_testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is originally called \"banking77\" because there are 77 labels. We will be reducing this to the top 25 most frequent labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset filtered to top 25 labels. New sizes:\n",
      "Training set size: 4171; Test set size: 1000\n",
      "Top 25 labels: card_payment_fee_charged, direct_debit_payment_not_recognised, balance_not_updated_after_cheque_or_cash_deposit, wrong_amount_of_cash_received, cash_withdrawal_charge, transaction_charged_twice, declined_cash_withdrawal, transfer_fee_charged, balance_not_updated_after_bank_transfer, transfer_not_received_by_recipient, request_refund, card_payment_not_recognised, card_payment_wrong_exchange_rate, extra_charge_on_statement, wrong_exchange_rate_for_cash_withdrawal, refund_not_showing_up, reverted_card_payment, cash_withdrawal_not_recognised, activate_my_card, pending_card_payment, cancel_transfer, beneficiary_not_allowed, card_arrival, declined_card_payment, pending_top_up\n",
      "Example training set: Example({'label': 'card_arrival', 'text': 'I am still waiting on my card?'}) (input_keys={'text'})\n",
      "Example test set: Example({'label': 'card_arrival', 'text': 'How do I locate my card?'}) (input_keys={'text'})\n"
     ]
    }
   ],
   "source": [
    "from src import filter_to_top_n_labels\n",
    "full_trainset_filtered, full_testset_filtered, top_25_labels = filter_to_top_n_labels(full_trainset_processed, full_testset_processed, n=25)\n",
    "labels_in_use = top_25_labels\n",
    "print(f\"Dataset filtered to top 25 labels. New sizes:\")\n",
    "print(f\"Training set size: {len(full_trainset_filtered)}; Test set size: {len(full_testset_filtered)}\")\n",
    "print(f\"Top 25 labels: {', '.join(str(label) for label in top_25_labels)}\")\n",
    "print(f\"Example training set: {full_trainset_filtered[0]}\")\n",
    "print(f\"Example test set: {full_testset_filtered[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will shuffle our training set and split it into a training and labeled set.\n",
    "\n",
    "The scenario we are emulating is that we only trust our 70B model to do a good job at classifying the queries, but don't want to serve a 70B parameter model for classification. We are saying that we have 4K (length of the training set) unlabeled examples we can then label using an oracle model, and then distill the knowledge from the oracle model into our 1B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import adjusted_exact_match, delete_labels, NUM_THREADS\n",
    "\n",
    "\n",
    "shuffled_trainset = [d for d in full_trainset_filtered]\n",
    "rng.shuffle(shuffled_trainset)\n",
    "ft_trainset = shuffled_trainset\n",
    "# For realism of this scenario, we are going to delete all our labels except for our test set\n",
    "ft_trainset_to_label = delete_labels(ft_trainset)\n",
    "\n",
    "testset = full_testset_filtered\n",
    "\n",
    "common_kwargs = dict(metric=adjusted_exact_match, num_threads=NUM_THREADS, display_progress=True, max_errors=10000)\n",
    "# evaluate_testset is our \"eval harness for this program\"\n",
    "evaluate_testset = dspy.Evaluate(devset=testset, **common_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Simple Chain of Thought Program in DSPy\n",
    "\n",
    "## Defining the Signature\n",
    "\n",
    "At the heart of our DSPy program is the `Signature` class. This class serves as a blueprint, outlining the inputs and outputs of our language model task. Here's how we structure it:\n",
    "\n",
    "1. **Docstring for Context**: We utilize the docstring to provide context to the LLM. In this case, we're passing our fixed set of 25 labels directly in the docstring. This approach is ideal when dealing with a static set of options.\n",
    "\n",
    "2. **Input Field**: We define an `intent` field as the input to our program. This will contain the natural language query we want to classify.\n",
    "\n",
    "3. **Output Field**: The `label` field represents our desired output - the classified intent.\n",
    "\n",
    "Both input and output fields are accompanied by concise descriptions, just to help the LLM understand the task.\n",
    "\n",
    "By structuring our program this way, we utilize DSPy's capabilities to create a clear, modular design that's both powerful and easy to maintain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentClassification(dspy.Signature):\n",
    "    \"\"\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
    "    The intent should exactly match one of the following:\n",
    "    ['card_payment_fee_charged', 'direct_debit_payment_not_recognised', 'balance_not_updated_after_cheque_or_cash_deposit', 'wrong_amount_of_cash_received', 'cash_withdrawal_charge', 'transaction_charged_twice', 'declined_cash_withdrawal', 'transfer_fee_charged', 'balance_not_updated_after_bank_transfer', 'transfer_not_received_by_recipient', 'request_refund', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'extra_charge_on_statement', 'wrong_exchange_rate_for_cash_withdrawal', 'refund_not_showing_up', 'reverted_card_payment', 'cash_withdrawal_not_recognised', 'activate_my_card', 'pending_card_payment', 'cancel_transfer', 'beneficiary_not_allowed', 'card_arrival', 'declined_card_payment', 'pending_top_up']\n",
    "    \"\"\"\n",
    "\n",
    "    intent = dspy.InputField(desc=\"Intent of the query\")\n",
    "    label = dspy.OutputField(desc=\"Type of the intent; Should just be one of the 25 labels with no other text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the module, we create a dspy.Module class that contains the Chain of Thought predictor using the signature we defined above.\n",
    "We also pass in the valid labels to the module.\n",
    "\n",
    "Inside the forward method, we pass the text to the predictor, do a little cleaning, and return the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentClassificationModule(dspy.Module):\n",
    "    def __init__(self, labels_in_use):\n",
    "        self.intent_classifier = dspy.ChainOfThought(IntentClassification)\n",
    "        self.valid_labels = set(labels_in_use)\n",
    "\n",
    "    def forward(self, text):\n",
    "        prediction = self.intent_classifier(intent=text)\n",
    "        sanitized_prediction = dspy.Prediction(label=prediction.label.lower().strip().replace(\" \", \"_\"), reasoning=prediction.reasoning)\n",
    "        return sanitized_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we set up some the vanilla program we will use throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import MODEL_PARAMETERS, LOCAL_API_PARAMETERS\n",
    "vanilla_program = IntentClassificationModule(labels_in_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying and Utilizing a 70B Language Model\n",
    "\n",
    "This section outlines the process of deploying and utilizing a 70B parameter language model for data gathering and training. Key steps include:\n",
    "\n",
    "1. Infrastructure: Leverage Anyscale's [RayLLM](https://docs.anyscale.com/llms/serving/intro) with \"Auto-select worker nodes\" for dynamically allocating GPUs.\n",
    "2. Configuration: Use a pre-generated serve config file (created via `rayllm gen-config`) to configure the RayLLM instance.\n",
    "\n",
    "Below we show the contents of the serve config and its corresponding model config file.\n",
    "\n",
    "`serve_70B.yaml` is a file that we created using rayllm gen-config for the purposes of this notebook. A serve config needs to have access to your HF_TOKEN so that it can correctly download the model from hugging face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">serve_config:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "serve_config:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'applications'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'args'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'llm_configs'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'./model_config/meta-llama--Meta-Llama-3_1-70B-Instruct.yaml'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'import_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'rayllm:app'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'llm-endpoint'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'route_prefix'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'query_auth_token_enabled'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'applications'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'llm_configs'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'./model_config/meta-llama--Meta-Llama-3_1-70B-Instruct.yaml'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'import_path'\u001b[0m: \u001b[32m'rayllm:app'\u001b[0m,\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'llm-endpoint'\u001b[0m,\n",
       "            \u001b[32m'route_prefix'\u001b[0m: \u001b[32m'/'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'query_auth_token_enabled'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "==================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_config:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "model_config:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'accelerator_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'A100-80G'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'deployment_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'autoscaling_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'initial_replicas'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'max_replicas'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'min_replicas'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'target_ongoing_requests'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'max_ongoing_requests'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'engine_kwargs'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'enable_chunked_prefill'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'max_num_batched_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'max_num_seqs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'tokenizer_pool_extra_config'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'runtime_env'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'pip'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'tokenizer_pool_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'trust_remote_code'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generation_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_format'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\\n{instruction}&lt;|eot_id|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'bos'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|begin_of_text|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'default_system_message'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\\n\\n{instruction}&lt;|eot_id|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'system_in_user'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'trailing_assistant'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'user'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\n{instruction}&lt;|eot_id|&gt;'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stopping_sequences'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stopping_tokens'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128001</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128009</span><span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'input_modality'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'json_mode'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'enabled'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'llm_engine'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'VLLMEngine'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'lora_config'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'max_request_context_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_loading_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'meta-llama/Meta-Llama-3.1-70B-Instruct'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'meta-llama/Meta-Llama-3.1-70B-Instruct'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'runtime_env'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'env_vars'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'HUGGING_FACE_HUB_TOKEN'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'REDACTED'</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tensor_parallelism'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'degree'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'accelerator_type'\u001b[0m: \u001b[32m'A100-80G'\u001b[0m,\n",
       "    \u001b[32m'deployment_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'autoscaling_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'initial_replicas'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "            \u001b[32m'max_replicas'\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
       "            \u001b[32m'min_replicas'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m'target_ongoing_requests'\u001b[0m: \u001b[1;36m128\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'max_ongoing_requests'\u001b[0m: \u001b[1;36m300\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'engine_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'enable_chunked_prefill'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[32m'max_num_batched_tokens'\u001b[0m: \u001b[1;36m8192\u001b[0m,\n",
       "        \u001b[32m'max_num_seqs'\u001b[0m: \u001b[1;36m256\u001b[0m,\n",
       "        \u001b[32m'tokenizer_pool_extra_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'runtime_env'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'pip'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'tokenizer_pool_size'\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
       "        \u001b[32m'trust_remote_code'\u001b[0m: \u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'generation_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'prompt_format'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'assistant'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32m|start_header_id|\u001b[0m\u001b[32m>assistant<|end_header_id|>\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32minstruction\u001b[0m\u001b[32m}\u001b[0m\u001b[32m<|eot_id|>'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'bos'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<|begin_of_text|>'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'default_system_message'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m''\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'system'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<|start_header_id|>system<|end_header_id|>\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32minstruction\u001b[0m\u001b[32m}\u001b[0m\u001b[32m<|eot_id|>'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'system_in_user'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'trailing_assistant'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<|start_header_id|>assistant<|end_header_id|>\\n\\n'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'user'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<|start_header_id|>user<|end_header_id|>\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32minstruction\u001b[0m\u001b[32m}\u001b[0m\u001b[32m<|eot_id|\u001b[0m\u001b[32m>\u001b[0m\u001b[32m'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'stopping_sequences'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'stopping_tokens'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m128001\u001b[0m, \u001b[1;36m128009\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'input_modality'\u001b[0m: \u001b[32m'text'\u001b[0m,\n",
       "    \u001b[32m'json_mode'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'enabled'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'llm_engine'\u001b[0m: \u001b[32m'VLLMEngine'\u001b[0m,\n",
       "    \u001b[32m'lora_config'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "    \u001b[32m'max_request_context_length'\u001b[0m: \u001b[1;36m8192\u001b[0m,\n",
       "    \u001b[32m'model_loading_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'model_id'\u001b[0m: \u001b[32m'meta-llama/Meta-Llama-3.1-70B-Instruct'\u001b[0m,\n",
       "        \u001b[32m'model_source'\u001b[0m: \u001b[32m'meta-llama/Meta-Llama-3.1-70B-Instruct'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'runtime_env'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'env_vars'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'HUGGING_FACE_HUB_TOKEN'\u001b[0m: \u001b[32m'REDACTED'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'tensor_parallelism'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'degree'\u001b[0m: \u001b[1;36m4\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src import print_serve_and_model_config, update_serve_config_hf_token\n",
    "\n",
    "# First we update the config to contain your actual HF_TOKEN to get access to the Meta-LLama huggingface repositories\n",
    "update_serve_config_hf_token(\"serve_70B.yaml\")\n",
    "\n",
    "print_serve_and_model_config(\"serve_70B.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `serve run [file]` command is used in order to launch any ray serve deployments. For RayLLM specifically, that will allow us to query `localhost:8000` as an OpenAI compatible API with whatever model is served."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-23 00:38:50,089\tINFO scripts.py:489 -- Running config file: 'serve_70B.yaml'.\n",
      "2024-10-23 00:38:50,418\tINFO worker.py:1601 -- Connecting to existing Ray cluster at address: 10.0.0.28:6379...\n",
      "2024-10-23 00:38:50,426\tINFO worker.py:1777 -- Connected to Ray cluster. View the dashboard at https://session-6frbgpfbuzs27m75xhz3c8vnde.i.anyscaleuserdata.com \n",
      "2024-10-23 00:38:50,430\tINFO packaging.py:359 -- Pushing file package 'gcs://_ray_pkg_fd90c1638cd32bfadef22fb05da8f982b8bee1ed.zip' (0.83MiB) to Ray cluster...\n",
      "2024-10-23 00:38:50,439\tINFO packaging.py:372 -- Successfully pushed file package 'gcs://_ray_pkg_fd90c1638cd32bfadef22fb05da8f982b8bee1ed.zip'.\n",
      "(ProxyActor pid=143530) INFO 2024-10-23 00:38:54,251 proxy 10.0.0.28 proxy.py:1235 - Proxy starting on node 76e2eab0a833e02208d948f67f54806e64e4d0b26f1a49507548855a (HTTP port: 8000).\n",
      "INFO 2024-10-23 00:38:54,280 serve 143394 api.py:277 - Started Serve in namespace \"serve\".\n",
      "2024-10-23 00:38:54,288\tSUCC scripts.py:540 -- Submitted deploy config successfully.\n",
      "(ServeController pid=143461) INFO 2024-10-23 00:38:54,283 controller 143461 application_state.py:881 - Deploying new app 'llm-endpoint'.\n",
      "(ServeController pid=143461) INFO 2024-10-23 00:38:54,284 controller 143461 application_state.py:457 - Importing and building app 'llm-endpoint'.\n"
     ]
    }
   ],
   "source": [
    "!serve run --non-blocking serve_70B.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we instantiate a `dspy.LM` object pointing at our RayLLM deployment. This will allow us to query it inside of DSPy programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters: {'max_tokens': 1000, 'temperature': 0}\n",
      "Local API Parameters: {'api_base': 'http://localhost:8000/v1', 'api_key': 'fake-key-doesnt-matter'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Parameters:\", MODEL_PARAMETERS)\n",
    "print(\"Local API Parameters:\", LOCAL_API_PARAMETERS)\n",
    "llama_70b = dspy.LM(model=\"openai/meta-llama/Meta-Llama-3.1-70B-Instruct\", **MODEL_PARAMETERS, **LOCAL_API_PARAMETERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a sanity check to make sure that our program is running properly.\n",
    "\n",
    "All it is doing is passing a single request to the DSPy program.\n",
    "\n",
    "The request will wait until the server starts up before it finishes.\n",
    "\n",
    "When the server starts up, it may need to recruit a worker node and also download the 70B model weights. Once that returns, our server is good to go, and we can use it like any other endpoint.\n",
    "\n",
    "You can expect the cell below to take around 8-10 minutes to run, as it waits for a worker node and to download the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program input: Example({'text': \"I was just giving the wrong amount by the ATM. How do I request cash back at this point? The app is showing the amount that I actually requested even though that's not what I got.\"}) (input_keys={'text'})\n",
      "Program output label: wrong_amount_of_cash_received\n"
     ]
    }
   ],
   "source": [
    "from src import sanity_check_program\n",
    "\n",
    "sanity_check_program(llama_70b, vanilla_program, ft_trainset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Data\n",
    "\n",
    "In this section, we bootstrap and prepare data for fine-tuning.\n",
    "\n",
    "Recall that our dataset only contains 100 labelled examples. Using DSPy, we will now \"bootstrap\" our training dataset with these labelled examples and generate synthetic labels using the Llama 70B model.\n",
    "\n",
    "As a part of data validation (\"Is this a correct label?\"), we will use a simple metric: we returns True if the prediction is in the desired set of labels, else we return False. Entries for which the metric is False are filtered out.\n",
    "\n",
    "Finally, we convert the filtered dataset into the OpenAI conversational format for use in fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4162 / 4171  (99.8): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4171/4171 [06:24<00:00, 10.85it/s]  \n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt.finetune_teleprompter import bootstrap_data, convert_to_module_level_message_data\n",
    "from src import NUM_THREADS, get_valid_label_metric_fn\n",
    "\n",
    "with dspy.context(lm=llama_70b):\n",
    "    bootstrap_data_kwargs = {\n",
    "        \"program\": vanilla_program, \n",
    "        \"dataset\": ft_trainset_to_label, \n",
    "        \"num_threads\": NUM_THREADS, \n",
    "        \"max_errors\": 10000, \n",
    "        \"metric\": get_valid_label_metric_fn(labels_in_use)\n",
    "    }\n",
    "    collected_data = bootstrap_data(**bootstrap_data_kwargs)\n",
    "    # Make sure to only include the labels we are actively using or that arent hallucinated by the oracle\n",
    "    collected_data_filtered = [x for x in collected_data if x[\"prediction\"][\"label\"] in labels_in_use]\n",
    "\n",
    "dataset = convert_to_module_level_message_data(collected_data_filtered, program=vanilla_program, exclude_demos=True)\n",
    "\n",
    "dataset_formatted = [{\"messages\": item} for item in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'messages'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Your input fields are:\\n1. `intent` (str): Intent of the query\\n\\nYour output fields </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">are:\\n1. `reasoning` (str): ${produce the output fields}. We ...\\n2. `label` (str): Type of the intent; Should just</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">be one of the 25 labels with no other text\\n\\nAll interactions will be structured in the following way, with the </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">appropriate values filled in.\\n\\n[[ ## intent ## ]]\\n{intent}\\n\\n[[ ## reasoning ## ]]\\n{reasoning}\\n\\n[[ ## label </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">## ]]\\n{label}\\n\\n[[ ## completed ## ]]\\n\\nIn adhering to this structure, your objective is: \\n        As a part of</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\\n      </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">The intent should exactly match one of the following:\\n        ['card_payment_fee_charged', </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'direct_debit_payment_not_recognised', 'balance_not_updated_after_cheque_or_cash_deposit', </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'wrong_amount_of_cash_received', 'cash_withdrawal_charge', 'transaction_charged_twice', 'declined_cash_withdrawal',</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'transfer_fee_charged', 'balance_not_updated_after_bank_transfer', 'transfer_not_received_by_recipient', </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'request_refund', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'extra_charge_on_statement', </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'wrong_exchange_rate_for_cash_withdrawal', 'refund_not_showing_up', 'reverted_card_payment', </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'cash_withdrawal_not_recognised', 'activate_my_card', 'pending_card_payment', 'cancel_transfer', </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'beneficiary_not_allowed', 'card_arrival', 'declined_card_payment', 'pending_top_up']\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'user'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"[[ ## intent ## ]]\\nI was just giving the wrong amount by the ATM. How do I request cash </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">back at this point? The app is showing the amount that I actually requested even though that's not what I </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">got.\\n\\nRespond with the corresponding output fields, starting with the field `reasoning`, then `label`, and then </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ending with the marker for `completed`.\"</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'role'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'content'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'[[ ## reasoning ## ]]\\nThe user is reporting that they received the wrong amount of cash </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">from an ATM, and the amount shown on the app is different from what they actually received. They are asking how to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">request cash back in this situation.\\n\\n[[ ## label ## ]]\\nwrong_amount_of_cash_received\\n\\n[[ ## completed ## ]]'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'messages'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'system'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"Your input fields are:\\n1. `intent` \u001b[0m\u001b[32m(\u001b[0m\u001b[32mstr\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: Intent of the query\\n\\nYour output fields \u001b[0m\n",
       "\u001b[32mare:\\n1. `reasoning` \u001b[0m\u001b[32m(\u001b[0m\u001b[32mstr\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: $\u001b[0m\u001b[32m{\u001b[0m\u001b[32mproduce the output fields\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. We ...\\n2. `label` \u001b[0m\u001b[32m(\u001b[0m\u001b[32mstr\u001b[0m\u001b[32m)\u001b[0m\u001b[32m: Type of the intent; Should just\u001b[0m\n",
       "\u001b[32mbe one of the 25 labels with no other text\\n\\nAll interactions will be structured in the following way, with the \u001b[0m\n",
       "\u001b[32mappropriate values filled in.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m[\u001b[0m\u001b[32m ## intent ## \u001b[0m\u001b[32m]\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mintent\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m[\u001b[0m\u001b[32m ## reasoning ## \u001b[0m\u001b[32m]\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mreasoning\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m[\u001b[0m\u001b[32m ## label \u001b[0m\n",
       "\u001b[32m## \u001b[0m\u001b[32m]\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mlabel\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m[\u001b[0m\u001b[32m ## completed ## \u001b[0m\u001b[32m]\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\\nIn adhering to this structure, your objective is: \\n        As a part of\u001b[0m\n",
       "\u001b[32ma banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\\n      \u001b[0m\n",
       "\u001b[32mThe intent should exactly match one of the following:\\n        \u001b[0m\u001b[32m[\u001b[0m\u001b[32m'card_payment_fee_charged', \u001b[0m\n",
       "\u001b[32m'direct_debit_payment_not_recognised', 'balance_not_updated_after_cheque_or_cash_deposit', \u001b[0m\n",
       "\u001b[32m'wrong_amount_of_cash_received', 'cash_withdrawal_charge', 'transaction_charged_twice', 'declined_cash_withdrawal',\u001b[0m\n",
       "\u001b[32m'transfer_fee_charged', 'balance_not_updated_after_bank_transfer', 'transfer_not_received_by_recipient', \u001b[0m\n",
       "\u001b[32m'request_refund', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'extra_charge_on_statement', \u001b[0m\n",
       "\u001b[32m'wrong_exchange_rate_for_cash_withdrawal', 'refund_not_showing_up', 'reverted_card_payment', \u001b[0m\n",
       "\u001b[32m'cash_withdrawal_not_recognised', 'activate_my_card', 'pending_card_payment', 'cancel_transfer', \u001b[0m\n",
       "\u001b[32m'beneficiary_not_allowed', 'card_arrival', 'declined_card_payment', 'pending_top_up'\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'user'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m\"\u001b[0m\u001b[32m[\u001b[0m\u001b[32m[\u001b[0m\u001b[32m ## intent ## \u001b[0m\u001b[32m]\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\nI was just giving the wrong amount by the ATM. How do I request cash \u001b[0m\n",
       "\u001b[32mback at this point? The app is showing the amount that I actually requested even though that's not what I \u001b[0m\n",
       "\u001b[32mgot.\\n\\nRespond with the corresponding output fields, starting with the field `reasoning`, then `label`, and then \u001b[0m\n",
       "\u001b[32mending with the marker for `completed`.\"\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'role'\u001b[0m: \u001b[32m'assistant'\u001b[0m,\n",
       "            \u001b[32m'content'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m[\u001b[0m\u001b[32m ## reasoning ## \u001b[0m\u001b[32m]\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\nThe user is reporting that they received the wrong amount of cash \u001b[0m\n",
       "\u001b[32mfrom an ATM, and the amount shown on the app is different from what they actually received. They are asking how to \u001b[0m\n",
       "\u001b[32mrequest cash back in this situation.\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m[\u001b[0m\u001b[32m ## label ## \u001b[0m\u001b[32m]\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\nwrong_amount_of_cash_received\\n\\n\u001b[0m\u001b[32m[\u001b[0m\u001b[32m[\u001b[0m\u001b[32m ## completed ## \u001b[0m\u001b[32m]\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset:\t 4162\n"
     ]
    }
   ],
   "source": [
    "import rich\n",
    "\n",
    "rich.print(dataset_formatted[0])\n",
    "print(\"Length of dataset:\\t\", len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-23 00:50:14,214\tWARN scripts.py:132 -- The `RAY_AGENT_ADDRESS` env var has been deprecated in favor of the `RAY_DASHBOARD_ADDRESS` env var. The `RAY_AGENT_ADDRESS` is ignored.\n",
      "2024-10-23 00:50:16,880\tSUCC scripts.py:747 -- Sent shutdown request; applications will be deleted asynchronously.\n"
     ]
    }
   ],
   "source": [
    "# Now we are done with the 70B model, so we can kill the server\n",
    "!serve shutdown -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning\n",
    "\n",
    "We will use Anyscale's [LLMForge](https://docs.anyscale.com/llms/finetuning/intro) to fine-tune the 1B model.\n",
    "\n",
    "To fine-tune with LLMForge, we will make use of DSPy's native integration with Anyscale. We can simply pass the desired Anyscale job configuration and DSPy will handle the rest.\n",
    "\n",
    "Be sure to checkout the fine-tuning documentation for the latest on how to use our [API](https://docs.anyscale.com/llms/finetuning/intro) and additional [capabilities](https://www.anyscale.com/library/llmforge).\n",
    "\n",
    "\n",
    "We will be starting out by fine-tuning using LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.clients.lm import TrainingMethod\n",
    "\n",
    "train_data = dataset_formatted\n",
    "method = TrainingMethod.SFT\n",
    "\n",
    "# There are a few important files that we are providing for you in this template in order to finetune + serve using LLMForge and RayLLM\n",
    "job_config_path = \"configs/job.yaml\"\n",
    "llmforge_config_path = \"configs/training/lora/llama-3-8b.yaml\"\n",
    "# Optional: DSPY supports passing a serve config for serving the fine-tuned model. This particular config is generated\n",
    "serve_config_path = \"serve_1B.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you want to launch a finetuning run, you run the command `llmforge anyscale finetune [config file]`. You can do this locally if you are on a GPU head node, but because you generally run on a CPU head node, we will launch it as a job on the Anyscale platform.\n",
    "\n",
    "In order to interface properly with DSPy, there are new abstractions that were introduced in order to lower the complexity of combining a finetuning platform and DSPy.\n",
    "\n",
    "DSPy will verify and format your data, submit your finetuning job using the **Job Config** and **LLMForge Config** files, then update your **Serve Config** so that your serve config knows where the finetuned weights are stored.\n",
    "\n",
    "There are 4 important files here, and we will go through them one by one:\n",
    "1. **Job Config**: job config points to a yaml file that will launch the LLMForge finetuning run as a job on the Anyscale platform.\n",
    "    All that a job config contains are the image to use, any environment variables, and an entrypoint that is the command to run, in this case `llmforge anyscale finetune [config file]`. [Job Config Documentation](https://docs.anyscale.com/reference/job-api/#jobconfig)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dspy-llmforge-fine-tuning-job'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'entrypoint'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'llmforge anyscale finetune configs/training/lora/llama-3-8b.yaml'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'working_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'image_uri'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'localhost:5555/anyscale/llm-forge:0.5.7'</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'name'\u001b[0m: \u001b[32m'dspy-llmforge-fine-tuning-job'\u001b[0m,\n",
       "    \u001b[32m'entrypoint'\u001b[0m: \u001b[32m'llmforge anyscale finetune configs/training/lora/llama-3-8b.yaml'\u001b[0m,\n",
       "    \u001b[32m'working_dir'\u001b[0m: \u001b[32m'.'\u001b[0m,\n",
       "    \u001b[32m'image_uri'\u001b[0m: \u001b[32m'localhost:5555/anyscale/llm-forge:0.5.7'\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yaml\n",
    "rich.print(yaml.safe_load(open(job_config_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **LLMForge Config**:\n",
    "The LLMForge config contains the relevant details for how to actually finetune the model. This contains every parameter you might expect for doing the actual finetuning: model, training data, epochs to run, batch size, LoRA parameters, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'context_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2048</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'num_devices'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'num_epochs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'train_batch_size_per_device'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'eval_batch_size_per_device'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'learning_rate'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3e-05</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'padding'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'longest'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'num_checkpoints_to_keep'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'dataset_size_scaling_factor'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10000</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'output_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/mnt/local_storage'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'deepspeed'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'config_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'configs/deepspeed/zero_3.json'</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'flash_attention_2'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'worker_resources'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'accelerator_type:A100-80G'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.001</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generation_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_format'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\\n\\n{instruction}&lt;|eot_id|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'user'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n{instruction}&lt;|eot_id|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\\n{instruction}&lt;|eot_id|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'trailing_assistant'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'bos'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|begin_of_text|&gt;'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'system_in_user'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'default_system_message'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'lora_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'r'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'lora_alpha'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'lora_dropout'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'target_modules'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'q_proj'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'v_proj'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'k_proj'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'o_proj'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'gate_proj'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'up_proj'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'down_proj'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'embed_tokens'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'lm_head'</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'task_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'CAUSAL_LM'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'modules_to_save'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'bias'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'none'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'fan_in_fan_out'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'init_lora_weights'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "    <span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'context_length'\u001b[0m: \u001b[1;36m2048\u001b[0m,\n",
       "    \u001b[32m'num_devices'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
       "    \u001b[32m'num_epochs'\u001b[0m: \u001b[1;36m6\u001b[0m,\n",
       "    \u001b[32m'train_batch_size_per_device'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "    \u001b[32m'eval_batch_size_per_device'\u001b[0m: \u001b[1;36m16\u001b[0m,\n",
       "    \u001b[32m'learning_rate'\u001b[0m: \u001b[1;36m3e-05\u001b[0m,\n",
       "    \u001b[32m'padding'\u001b[0m: \u001b[32m'longest'\u001b[0m,\n",
       "    \u001b[32m'num_checkpoints_to_keep'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
       "    \u001b[32m'dataset_size_scaling_factor'\u001b[0m: \u001b[1;36m10000\u001b[0m,\n",
       "    \u001b[32m'output_dir'\u001b[0m: \u001b[32m'/mnt/local_storage'\u001b[0m,\n",
       "    \u001b[32m'deepspeed'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'config_path'\u001b[0m: \u001b[32m'configs/deepspeed/zero_3.json'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'flash_attention_2'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "    \u001b[32m'worker_resources'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'accelerator_type:A100-80G'\u001b[0m: \u001b[1;36m0.001\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'generation_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'prompt_format'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'system'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32m|start_header_id|\u001b[0m\u001b[32m>system<|end_header_id|>\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32minstruction\u001b[0m\u001b[32m}\u001b[0m\u001b[32m<|eot_id|>'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'user'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<|start_header_id|>user<|end_header_id|>\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32minstruction\u001b[0m\u001b[32m}\u001b[0m\u001b[32m<|eot_id|>'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'assistant'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<|start_header_id|>assistant<|end_header_id|>\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32minstruction\u001b[0m\u001b[32m}\u001b[0m\u001b[32m<|eot_id|>'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'trailing_assistant'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<|start_header_id|>assistant<|end_header_id|>\\n\\n'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'bos'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<|begin_of_text|\u001b[0m\u001b[32m>\u001b[0m\u001b[32m'\u001b[0m,\n",
       "            \u001b[32m'system_in_user'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "            \u001b[32m'default_system_message'\u001b[0m: \u001b[32m''\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'lora_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'r'\u001b[0m: \u001b[1;36m8\u001b[0m,\n",
       "        \u001b[32m'lora_alpha'\u001b[0m: \u001b[1;36m16\u001b[0m,\n",
       "        \u001b[32m'lora_dropout'\u001b[0m: \u001b[1;36m0.05\u001b[0m,\n",
       "        \u001b[32m'target_modules'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "            \u001b[32m'q_proj'\u001b[0m,\n",
       "            \u001b[32m'v_proj'\u001b[0m,\n",
       "            \u001b[32m'k_proj'\u001b[0m,\n",
       "            \u001b[32m'o_proj'\u001b[0m,\n",
       "            \u001b[32m'gate_proj'\u001b[0m,\n",
       "            \u001b[32m'up_proj'\u001b[0m,\n",
       "            \u001b[32m'down_proj'\u001b[0m,\n",
       "            \u001b[32m'embed_tokens'\u001b[0m,\n",
       "            \u001b[32m'lm_head'\u001b[0m\n",
       "        \u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'task_type'\u001b[0m: \u001b[32m'CAUSAL_LM'\u001b[0m,\n",
       "        \u001b[32m'modules_to_save'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'bias'\u001b[0m: \u001b[32m'none'\u001b[0m,\n",
       "        \u001b[32m'fan_in_fan_out'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[32m'init_lora_weights'\u001b[0m: \u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(yaml.safe_load(open(llmforge_config_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Serve Config**: This is a RayLLM serving configuration file that points to the model config file we want to serve.\n",
    "For what Job Config is to the LLMForge config, Serve Config is to the model config.\n",
    "\n",
    "Serve config just points to the model config file that we want to serve.\n",
    "\n",
    "4. **Model Config**: This is the file that contains the details of the model we want to finetune. It contains parameters like where to read in LoRA weights from, what model to serve, what resources to use to serve the model, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">serve_config:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "serve_config:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'applications'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'args'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'llm_configs'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'./model_config/meta-llama--Llama-3_2-1B-Instruct.yaml'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'import_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'rayllm:app'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'llm-endpoint'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'route_prefix'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'query_auth_token_enabled'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'applications'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'llm_configs'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'./model_config/meta-llama--Llama-3_2-1B-Instruct.yaml'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'import_path'\u001b[0m: \u001b[32m'rayllm:app'\u001b[0m,\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'llm-endpoint'\u001b[0m,\n",
       "            \u001b[32m'route_prefix'\u001b[0m: \u001b[32m'/'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'query_auth_token_enabled'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "==================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">model_config:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "model_config:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'accelerator_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'A100-80G'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'deployment_config'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'autoscaling_config'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'target_ongoing_requests'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'max_ongoing_requests'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'engine_kwargs'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'enable_chunked_prefill'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'enable_lora'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'max_lora_rank'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'max_loras'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'max_num_batched_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'max_num_seqs'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'tokenizer_pool_extra_config'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'runtime_env'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'pip'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'tokenizer_pool_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'trust_remote_code'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'generation_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_format'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\\n{instruction}&lt;|eot_id|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'bos'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|begin_of_text|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'default_system_message'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'system'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\\n\\n{instruction}&lt;|eot_id|&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'system_in_user'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'trailing_assistant'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">            </span><span style=\"color: #008000; text-decoration-color: #008000\">'user'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\n{instruction}&lt;|eot_id|&gt;'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stopping_sequences'</span>: <span style=\"font-weight: bold\">[]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stopping_tokens'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128001</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128009</span><span style=\"font-weight: bold\">]</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'input_modality'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'json_mode'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'enabled'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'llm_engine'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'VLLMEngine'</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'lora_config'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'dynamic_lora_loading_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'none'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'max_num_adapters_per_replica'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span><span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'max_request_context_length'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8192</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_loading_config'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'meta-llama/Llama-3.2-1B-Instruct'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'meta-llama/Llama-3.2-1B-Instruct'</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'runtime_env'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'env_vars'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'HUGGING_FACE_HUB_TOKEN'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'REDACTED'</span><span style=\"font-weight: bold\">}}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'tensor_parallelism'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'degree'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'accelerator_type'\u001b[0m: \u001b[32m'A100-80G'\u001b[0m,\n",
       "    \u001b[32m'deployment_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'autoscaling_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'target_ongoing_requests'\u001b[0m: \u001b[1;36m32\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'max_ongoing_requests'\u001b[0m: \u001b[1;36m64\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'engine_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'enable_chunked_prefill'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "        \u001b[32m'enable_lora'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "        \u001b[32m'max_lora_rank'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "        \u001b[32m'max_loras'\u001b[0m: \u001b[1;36m16\u001b[0m,\n",
       "        \u001b[32m'max_num_batched_tokens'\u001b[0m: \u001b[1;36m8192\u001b[0m,\n",
       "        \u001b[32m'max_num_seqs'\u001b[0m: \u001b[1;36m64\u001b[0m,\n",
       "        \u001b[32m'tokenizer_pool_extra_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'runtime_env'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'pip'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'tokenizer_pool_size'\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
       "        \u001b[32m'trust_remote_code'\u001b[0m: \u001b[3;92mTrue\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'generation_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'prompt_format'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'assistant'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32m|start_header_id|\u001b[0m\u001b[32m>assistant<|end_header_id|>\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32minstruction\u001b[0m\u001b[32m}\u001b[0m\u001b[32m<|eot_id|>'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'bos'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<|begin_of_text|>'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'default_system_message'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m''\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'system'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<|start_header_id|>system<|end_header_id|>\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32minstruction\u001b[0m\u001b[32m}\u001b[0m\u001b[32m<|eot_id|>'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'system_in_user'\u001b[0m\u001b[39m: \u001b[0m\u001b[3;91mFalse\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'trailing_assistant'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<|start_header_id|>assistant<|end_header_id|>\\n\\n'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m            \u001b[0m\u001b[32m'user'\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<|start_header_id|>user<|end_header_id|>\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32minstruction\u001b[0m\u001b[32m}\u001b[0m\u001b[32m<|eot_id|\u001b[0m\u001b[32m>\u001b[0m\u001b[32m'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'stopping_sequences'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[32m'stopping_tokens'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1;36m128001\u001b[0m, \u001b[1;36m128009\u001b[0m\u001b[1m]\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'input_modality'\u001b[0m: \u001b[32m'text'\u001b[0m,\n",
       "    \u001b[32m'json_mode'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'enabled'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'llm_engine'\u001b[0m: \u001b[32m'VLLMEngine'\u001b[0m,\n",
       "    \u001b[32m'lora_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'dynamic_lora_loading_path'\u001b[0m: \u001b[32m'none'\u001b[0m, \u001b[32m'max_num_adapters_per_replica'\u001b[0m: \u001b[1;36m32\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'max_request_context_length'\u001b[0m: \u001b[1;36m8192\u001b[0m,\n",
       "    \u001b[32m'model_loading_config'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "        \u001b[32m'model_id'\u001b[0m: \u001b[32m'meta-llama/Llama-3.2-1B-Instruct'\u001b[0m,\n",
       "        \u001b[32m'model_source'\u001b[0m: \u001b[32m'meta-llama/Llama-3.2-1B-Instruct'\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'runtime_env'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'env_vars'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'HUGGING_FACE_HUB_TOKEN'\u001b[0m: \u001b[32m'REDACTED'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[32m'tensor_parallelism'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'degree'\u001b[0m: \u001b[1;36m1\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_serve_and_model_config(serve_config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSPy has an abstraction around LLMForge finetuning in order to allow you to pass in your configuration files and not have to worry about the details of how to interface with LLMForge.\n",
    "\n",
    "What we do is we create a `dspy.LM` object that points to the model we want to finetune.\n",
    "\n",
    "Part of the new behavior added in order to support better finetuning flows, is that `dspy.LM` objects now have a `.finetune()` method that will take in the train data, training arguments, a method, and a provider. Each provider can individually handle the finetuning process differently, but will return a `dspy.FinetuningJob` object that you can use to access your finetuned model.\n",
    "\n",
    "The end of this process is the `dspy.FinetuningJob` object, which contains a `.result()` method that will return the finetuned `dspy.LM` object.\n",
    "\n",
    "Note that `dspy.LM` objects do not manage the weights themselves, and can be considered essentially immutable. The returned `dspy.LM` object has a `.model` attribute that points to the finetuned model, in this example, `meta-llama/Llama-3.2-1B-Instruct:name:suffix`, where name and suffix come from LLMForge.\n",
    "\n",
    "When you call `LM.finetune()`, DSPy will:\n",
    "1. Verify your data is formatted correctly\n",
    "2. Upload your data to the cloud using the Anyscale Datasets API\n",
    "3. Update your LLMForge config to point to the data that has been uploaded\n",
    "4. Launch a LLMForge job using the provided job config, LLMForge config, and the data you uploaded\n",
    "5. Update the serve config to point to the finetuned model\n",
    "6. Wait for the finetuning job to complete\n",
    "7. Return the finetuned `dspy.LM` object\n",
    "\n",
    "You can see what DSPy is doing under the hood [here](https://github.com/stanfordnlp/dspy/blob/main/dspy/clients/anyscale.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3fc68dad2b438ead84e045363e032f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Upload complete!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32mUpload complete!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(anyscale +13m39.4s) Uploading local dir '.' to cloud storage.\n",
      "(anyscale +13m41.8s) Including workspace-managed pip dependencies.\n",
      "(anyscale +13m42.5s) Job 'dspy-llmforge-fine-tuning-job' submitted, ID: 'prodjob_r4nwu2mlijl1ag7heb755cjw8x'.\n",
      "(anyscale +13m42.5s) View the job in the UI: https://console.anyscale.com/jobs/prodjob_r4nwu2mlijl1ag7heb755cjw8x\n",
      "(anyscale +13m42.7s) Waiting for job 'prodjob_r4nwu2mlijl1ag7heb755cjw8x' to reach target state SUCCEEDED, currently in state: STARTING\n",
      "(anyscale +16m7.5s) Job 'prodjob_r4nwu2mlijl1ag7heb755cjw8x' transitioned from STARTING to RUNNING\n",
      "(anyscale +29m42.0s) Job 'prodjob_r4nwu2mlijl1ag7heb755cjw8x' transitioned from RUNNING to SUCCEEDED\n",
      "(anyscale +29m42.0s) Job 'prodjob_r4nwu2mlijl1ag7heb755cjw8x' reached target state, exiting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned Model ID: openai/meta-llama/Llama-3.2-1B-Instruct:isaac:ngffk\n"
     ]
    }
   ],
   "source": [
    "finetuneable_lm = dspy.LM(model=\"meta-llama/Llama-3.2-1B-Instruct\", **MODEL_PARAMETERS, **LOCAL_API_PARAMETERS)\n",
    "\n",
    "try:\n",
    "    finetuning_kwargs = {\n",
    "        \"train_data\": train_data, \n",
    "        \"train_kwargs\": {\n",
    "            \"job_config_path\": job_config_path, \n",
    "            \"llmforge_config_path\": llmforge_config_path, \n",
    "            \"serve_config_path\": serve_config_path\n",
    "        }, \n",
    "        \"train_method\": method, \n",
    "        \"provider\": \"anyscale\"\n",
    "    }\n",
    "\n",
    "    finetuning_job = finetuneable_lm.finetune(**finetuning_kwargs)\n",
    "    finetuned_llama = finetuning_job.result()\n",
    "    print(\"Finetuned Model ID:\", finetuned_llama.model)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "## Performance comparisons\n",
    "\n",
    "**Datasets:**\n",
    "- Synthetic Devset - we care about how well a model does on the dataset, as it is our closest thing to ground truth in our scenario with a lot of unlabeled data.\n",
    "- Real Testset - in this case, we do actually have a test set, so we can see how well a model does on a representative dataset of unseen user queries.\n",
    "\n",
    "**LM Comparison:**\n",
    "We will compare the finetuned model to the non-finetuned model, both with and without prompt optimization. We expect to see that the finetuned model does better on the synthetic devset compared to the testset, as it was trained on exactly that data.\n",
    "- 1B Non-finetuned\n",
    "- 1B Non-finetuned + Prompt Optimization\n",
    "- 1B Finetuned (last checkpoint)\n",
    "- 1B Finetuned (last checkpoint) + Prompt Optimization\n",
    "\n",
    "Note that we do not provide an eval set when finetuning, as the eval loss of a checkpoint isn't necessarily predictive of the downstream performance of the program. We use the last checkpoint by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai/meta-llama/Llama-3.2-1B-Instruct:isaac:ngffk\n"
     ]
    }
   ],
   "source": [
    "print(finetuned_llama.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run a local RayLLM instance that serves the model.\n",
    "\n",
    "Provided with this template is are two files, `serve_1B.yaml` and `model_configs/meta-llama--Llama-3_2-1B-Instruct.yaml`. \n",
    "\n",
    "The first file, `serve_1B.yaml`, contains the serve configuration to load the model with RayLLM.\n",
    "\n",
    "The second file, `model_configs/meta-llama--Llama-3_2-1B-Instruct.yaml`, contains the necessary configurations to run the 1B model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import update_serve_config_hf_token\n",
    "\n",
    "update_serve_config_hf_token(\"serve_1B.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this command to start the 1B RayLLM server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-23 01:08:39,710\tINFO scripts.py:489 -- Running config file: 'serve_1B.yaml'.\n",
      "2024-10-23 01:08:40,027\tINFO worker.py:1601 -- Connecting to existing Ray cluster at address: 10.0.0.28:6379...\n",
      "2024-10-23 01:08:40,035\tINFO worker.py:1777 -- Connected to Ray cluster. View the dashboard at https://session-6frbgpfbuzs27m75xhz3c8vnde.i.anyscaleuserdata.com \n",
      "2024-10-23 01:08:40,039\tINFO packaging.py:359 -- Pushing file package 'gcs://_ray_pkg_65f953c7794f5c3fb3b91d46cb1f7888057a961d.zip' (0.85MiB) to Ray cluster...\n",
      "2024-10-23 01:08:40,048\tINFO packaging.py:372 -- Successfully pushed file package 'gcs://_ray_pkg_65f953c7794f5c3fb3b91d46cb1f7888057a961d.zip'.\n",
      "INFO 2024-10-23 01:08:43,956 serve 157622 api.py:277 - Started Serve in namespace \"serve\".\n",
      "2024-10-23 01:08:43,965\tSUCC scripts.py:540 -- Submitted deploy config successfully.\n",
      "(ServeController pid=157685) INFO 2024-10-23 01:08:43,959 controller 157685 application_state.py:881 - Deploying new app 'llm-endpoint'.\n",
      "(ServeController pid=157685) INFO 2024-10-23 01:08:43,960 controller 157685 application_state.py:457 - Importing and building app 'llm-endpoint'.\n",
      "(ProxyActor pid=157763) INFO 2024-10-23 01:08:43,926 proxy 10.0.0.28 proxy.py:1235 - Proxy starting on node 76e2eab0a833e02208d948f67f54806e64e4d0b26f1a49507548855a (HTTP port: 8000).\n"
     ]
    }
   ],
   "source": [
    "!serve run --non-blocking serve_1B.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import MODEL_PARAMETERS, LOCAL_API_PARAMETERS\n",
    "\n",
    "non_ft_llama = dspy.LM(model=\"openai/meta-llama/Llama-3.2-1B-Instruct\", **MODEL_PARAMETERS, **LOCAL_API_PARAMETERS)\n",
    "\n",
    "all_llamas = {\"base\": non_ft_llama, finetuned_llama.model: finetuned_llama}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program input: Example({'text': \"I was just giving the wrong amount by the ATM. How do I request cash back at this point? The app is showing the amount that I actually requested even though that's not what I got.\"}) (input_keys={'text'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non fine-tuned model returned invalid output out and errored out with Expected dict_keys(['reasoning', 'label']) but got dict_keys([])\n",
      "Program input: Example({'text': \"I was just giving the wrong amount by the ATM. How do I request cash back at this point? The app is showing the amount that I actually requested even though that's not what I got.\"}) (input_keys={'text'})\n",
      "Program output label: wrong_amount_of_cash_received\n"
     ]
    }
   ],
   "source": [
    "# Sanity check that the finetuned models are working\n",
    "\n",
    "try:\n",
    "    sanity_check_program(non_ft_llama, vanilla_program, ft_trainset[0])\n",
    "except ValueError as e:\n",
    "    # Sometimes the 1B model isn't capable of correctly outputting the label before prompt optimization, so we can just ignore this error.\n",
    "    print(\"Non fine-tuned model returned invalid output out and errored out with\", e)\n",
    "\n",
    "try:\n",
    "    sanity_check_program(finetuned_llama, vanilla_program, ft_trainset[0])\n",
    "except ValueError as e:\n",
    "    print(\"Fine-tuned model returned invalid output out and errored out with\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Optimization with DSPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to be doing prompt optimization using DSPy's `BootstrapFewShotWithRandomSearch (BFRS)` function.\n",
    "\n",
    "BootstrapFewShotWithRandomSearch will:\n",
    "- Collect a set of chains of thought from the model\n",
    "- Use these examples that lead to a correct prediction to \"bootstrap\" the program\n",
    "- See which set of examples lead to the most correct predictions across your evaluation metric\n",
    "- Continue this process for a set number of iterations, using the best performing programs to bootstrap the next iteration\n",
    "- Return the best program\n",
    "\n",
    "Let's go over what the hyperparameters mean:\n",
    "- **max_bootstrapped_demos**: DSPy will \"bootstrap\" the program by collecting examples at each step that are successful and reusing those in the pipeline. This means that it will automatically collect and add chains of thought to the pipeline.\n",
    "- **max_labeled_demos**: DSPy will also insert some labeled demonstrations from the training set. These would be unmodified examples from the training set that are just using the given answer.\n",
    "- **num_candidate_programs**: This is the number of candidate programs that the optimizer will generate. The actual number of programs that are created is this plus three, as DSPy will also try a program with no examples, a program with just the labeled demonstrations, and a bootstrapped program with the first few examples.\n",
    "\n",
    "Learn more about the BFRS optimizer [here](https://dspy-docs.vercel.app/deep-dive/optimizers/bootstrap-fewshot/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:\n",
      "max_bootstrapped_demos: 3\n",
      "max_labeled_demos: 3\n",
      "num_candidate_programs: 6\n"
     ]
    }
   ],
   "source": [
    "from src import bootstrap_fewshot_random_search_parameters, adjusted_exact_match\n",
    "\n",
    "print(\"Parameters:\")\n",
    "for k, v in bootstrap_fewshot_random_search_parameters.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths:\n",
      "Synthetic Devset:\t 1000\n",
      "Optimizer Trainset:\t 2862\n",
      "Optimizer Devset:\t 300\n",
      "Example from synthetic devset:\n",
      "Example({'text': \"I was just giving the wrong amount by the ATM. How do I request cash back at this point? The app is showing the amount that I actually requested even though that's not what I got.\", 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'})\n"
     ]
    }
   ],
   "source": [
    "from src import split_into_devset_and_optimizer_sets\n",
    "\n",
    "def collected_data_to_example(data):\n",
    "    return dspy.Example(text=data[\"example\"][\"text\"], label=data[\"prediction\"][\"label\"]).with_inputs(\"text\")\n",
    "\n",
    "collected_data_examples = [collected_data_to_example(x) for x in collected_data_filtered]\n",
    "\n",
    "devset_synthetic, ft_optimizer_trainset, ft_optimizer_devset = split_into_devset_and_optimizer_sets(collected_data_examples, dev_size=1000, optimizer_num_val=300)\n",
    "print(\"Lengths:\")\n",
    "print(\"Synthetic Devset:\\t\", len(devset_synthetic))\n",
    "print(\"Optimizer Trainset:\\t\", len(ft_optimizer_trainset))\n",
    "print(\"Optimizer Devset:\\t\", len(ft_optimizer_devset))\n",
    "print(\"Example from synthetic devset:\")\n",
    "print(devset_synthetic[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will evaluate our finetuned model and the base model, prompt optimize them, and evaluate them on the synthetic devset.\n",
    "\n",
    "Note that there is a `%%capture` below. This is to suppress the output of the evaluation and prompt optimization because it is quite long and will slow down the notebook. We will graph the results in the cell after. You can remove the tag in order to see the output.\n",
    "\n",
    "You can expect this to take around 15-20 minutes to run.\n",
    "\n",
    "If you remove the `%%capture` tag, you will see that the output is quite long and full of errors. This is because the base LLama 1B model is not capable of formatting the outputs correctly in the way that DSPy expects, so it will throw errors. Our finetuned model is much better at this, and throws significantly less errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from src import evaluate_and_prompt_optimize\n",
    "\n",
    "evaluation_kwargs = {\n",
    "    \"models\": all_llamas,\n",
    "    \"module_class\": IntentClassificationModule,\n",
    "    \"optimizer_trainset\": ft_optimizer_trainset,\n",
    "    \"optimizer_valset\": ft_optimizer_devset,\n",
    "    \"devset\": devset_synthetic,\n",
    "    \"metric\": adjusted_exact_match,\n",
    "    \"labels_in_use\": labels_in_use\n",
    "}\n",
    "\n",
    "ft_results = evaluate_and_prompt_optimize(**evaluation_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base': {'vanilla': {'devset': 0.3}, 'bfrs': {'devset': 23.5}}, 'openai/meta-llama/Llama-3.2-1B-Instruct:isaac:ngffk': {'vanilla': {'devset': 56.3}, 'bfrs': {'devset': 56.3}}}\n"
     ]
    }
   ],
   "source": [
    "print(ft_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Dev Set Score: 56.3, Model: Fine-tuned\n"
     ]
    }
   ],
   "source": [
    "from src import graph_devset_results, graph_testset_results\n",
    "\n",
    "graph_devset_results(ft_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the our finetuned model significantly outperforms the base model on the synthetic devset, and prompt optimization isn't enough to bring 1B all the way up to FT performance.\n",
    "\n",
    "We will now evaluate both the finetuned and base models on the real test set to see if we have improved performance. We will use the prompt optimized versions of the models that we created using the synthetic devset as our in context examples.\n",
    "\n",
    "This should take around 10 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Now we need to evaluate the test set\n",
    "from src import run_testset_evaluation\n",
    "\n",
    "testset_evaluation_kwargs = {\n",
    "    \"ft_results\": ft_results,\n",
    "    \"all_llamas\": all_llamas,\n",
    "    \"labels_in_use\": labels_in_use,\n",
    "    \"testset\": testset,\n",
    "    \"metric\": adjusted_exact_match,\n",
    "    \"module_class\": IntentClassificationModule\n",
    "}\n",
    "\n",
    "ft_results_testset, (best_program_path, best_model, best_score) = run_testset_evaluation(**testset_evaluation_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_testset_results(ft_results_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best testset result: \n",
      "openai/meta-llama/Llama-3.2-1B-Instruct:isaac:ngffk with score: 53.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best testset result: \\n{best_model} with score: {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that on the true test set, the prompt optimized pipeline using the finetuned model outperforms the prompt optimized pipeline using the non-finetuned model by approximately 12% in overall dataset accuracy. This is a relative performance improvement of almost 40%!\n",
    "\n",
    "This is one small example of where DSPy finetuning can be useful in terms of increasing task specific performance and helping you to get the most out of your LLM.\n",
    "\n",
    "This pipeline is very simple, but you can imagine that data collection would be much harder for longer pipelines, and DSPy can optimize it just as easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The typical usecase for DSPy is for optimizing prompts and weights programmatically. DSPy allows you to define a complex pipeline with different components like a retriever and one or more LLMs. Often, we're interested in taking the same system we optimized during training to inference. \n",
    "\n",
    "To deploy, you can serve the optimized DSPy program directly: This is the simplest option to take your program to production. Since DSPy simply relies on a deployed inference endpoint for LLM calls, we can use it in conjunction with optimized serving libraries like RayLLM. We can leverage Ray Serve with our DSPy pipeline being our custom business logic while serving.\n",
    "\n",
    "NOTE: As of DSPy 2.5, there are scalability limitations for high throughput scenarios with DSPy. DSPy compiled programs currently use threading for handling multiple queries in parallel, which might not scale as well as a native `async` implementation. A native `async` implementation is in the immediate roadmap for DSPy. If this is a concern, you can always try to stitch together the saved program from DSPy in native Python code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving a DSPy Pipeline as a Multi-App Serve Application\n",
    "\n",
    "We can break down our program into two distinct parts: 1) Fine-tuned LLM served behind an OpenAI compatible endpoint and 2) The DSPy program (our business logic tying all components together)\n",
    "\n",
    "These two different parts can be served as two separate applications with different deployment configurations. There are two ways this can be done:\n",
    "- Separate Ray Serve deployments: In this case, you would be managing two separate services for your DSPy program. One scenario where this is helpful is if you expect changes/updates to just one component (say the DSPy program) happening at a different cadence to the other. \n",
    "- Single multi-app deployment: This is the simpler way for managing your DSPy program in production by deploying one service with two applications. This is recommended when all your Ray Serve logic lies in one repository.\n",
    "\n",
    "\n",
    "In this guide, we will deploy our DSPy program as a single Ray Serve deployment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's save some important state for the compiled program into a JSON file for use in serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "# Note: there are some caveats to how `best_program_path` can look like. All files for use in serving should be in the working directory passed to the serve config. \n",
    "# By default the working directory  is the current directory\n",
    "my_state = {\"best_model\": best_model, \"best_program_path\": best_program_path, \"labels_in_use\": labels_in_use}\n",
    "with open(\"configs/deploy_params.json\", \"w\") as f:\n",
    "    json.dump(my_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of serving, it is recommended to place all the application logic in a python script. We've provided a script `deploy.py` which contains the DSPy application logic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> dspy</span><span style=\"background-color: #272822\">                                                                                                        </span>\n",
       "<span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">from</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> ray </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> serve</span><span style=\"background-color: #272822\">                                                                                              </span>\n",
       "<span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">from</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> fastapi </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> FastAPI</span><span style=\"background-color: #272822\">                                                                                        </span>\n",
       "<span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">from</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> src </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> MODEL_PARAMETERS</span><span style=\"background-color: #272822\">                                                                                   </span>\n",
       "<span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> json </span><span style=\"background-color: #272822\">                                                                                                       </span>\n",
       "<span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">from</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> starlette.requests </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> Request</span><span style=\"background-color: #272822\">                                                                             </span>\n",
       "<span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">from</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> urllib.parse </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">import</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> urlparse</span><span style=\"background-color: #272822\">                                                                                  </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">app </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> FastAPI()</span><span style=\"background-color: #272822\">                                                                                                    </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">read_params</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(file_path: str):</span><span style=\"background-color: #272822\">                                                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"\"\"Simple helper for reading dspy program parameters\"\"\"</span><span style=\"background-color: #272822\">                                                        </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">with</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> open(file_path, </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"r\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">as</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> f:</span><span style=\"background-color: #272822\">                                                                                </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        params </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> json</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">load(f)</span><span style=\"background-color: #272822\">                                                                                      </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">return</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> params</span><span style=\"background-color: #272822\">                                                                                                  </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">class</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">IntentClassification</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(dspy</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Signature):</span><span style=\"background-color: #272822\">                                                                        </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"\"\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of th</span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    intent </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> dspy</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">InputField(desc</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Intent of the query\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                           </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    label </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> dspy</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">OutputField(desc</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"Type of the intent; Should just be one of the 25 labels with no other text\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">    </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">class</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">IntentClassificationModule</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(dspy</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Module):</span><span style=\"background-color: #272822\">                                                                     </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">__init__</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(self, labels_in_use):</span><span style=\"background-color: #272822\">                                                                             </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">intent_classifier </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> dspy</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">ChainOfThought(IntentClassification)</span><span style=\"background-color: #272822\">                                         </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">valid_labels </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> set(labels_in_use)</span><span style=\"background-color: #272822\">                                                                     </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">forward</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(self, text, </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">**</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">predictor_kwargs):</span><span style=\"background-color: #272822\">                                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        prediction </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">intent_classifier(intent</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">text, </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">**</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">predictor_kwargs)</span><span style=\"background-color: #272822\">                                       </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        sanitized_prediction </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> dspy</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Prediction(label</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">prediction</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">label</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">lower()</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">strip()</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">replace(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\" \"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"_\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">), reasoning</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">if</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> sanitized_prediction</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">label </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">not</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">in</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">valid_labels:</span><span style=\"background-color: #272822\">                                                    </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            sanitized_prediction </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> dspy</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">Prediction(label</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"INVALID MODEL OUTPUT\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">return</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> sanitized_prediction</span><span style=\"background-color: #272822\">                                                                                </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">@serve</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">deployment(</span><span style=\"background-color: #272822\">                                                                                                 </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    ray_actor_options</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">{</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"num_cpus\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">0.1</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">},</span><span style=\"background-color: #272822\">                                                                           </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    autoscaling_config</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">dict(min_replicas</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">1</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, max_replicas</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #ae81ff; text-decoration-color: #ae81ff; background-color: #272822\">5</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                        </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                                                                  </span>\n",
       "<span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">class</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">LLMClient</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">:</span><span style=\"background-color: #272822\">                                                                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">__init__</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(self, param_path, serve_args):</span><span style=\"background-color: #272822\">                                                                    </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        params </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> read_params(param_path)</span><span style=\"background-color: #272822\">                                                                           </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">params </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> params</span><span style=\"background-color: #272822\">                                                                                       </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        base_url </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> serve_args[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"api_base\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"background-color: #272822\">                                                                          </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        prefix </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> serve_args[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"route_prefix\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"background-color: #272822\">                                                                        </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        full_url </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> base_url </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">+</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> prefix</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">lstrip(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'/'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">) </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">if</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> len(prefix</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">lstrip(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">'/'</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)) </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">else</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> base_url</span><span style=\"background-color: #272822\">                          </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        api_parameters </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> {</span><span style=\"background-color: #272822\">                                                                                         </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"api_base\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">f\"{</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">full_url</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">}/v1\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">,</span><span style=\"background-color: #272822\">                                                                          </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"api_key\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">: serve_args[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"api_key\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">]</span><span style=\"background-color: #272822\">                                                                       </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        }</span><span style=\"background-color: #272822\">                                                                                                          </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        print(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"API parameters\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, api_parameters)</span><span style=\"background-color: #272822\">                                                                    </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">llm </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> dspy</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">LM(model</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"openai/\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">+</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">params[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"best_model\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">], </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">**</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">MODEL_PARAMETERS, </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">**</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">api_parameters)</span><span style=\"background-color: #272822\">      </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">program </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> IntentClassificationModule(params[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"labels_in_use\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">])</span><span style=\"background-color: #272822\">                                         </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">program</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">load(params[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"best_program_path\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">])</span><span style=\"background-color: #272822\">                                                             </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">async</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">__call__</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(self, query: str):</span><span style=\"background-color: #272822\">                                                                          </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"\"\"Answer the given question and provide sources.\"\"\"</span><span style=\"background-color: #272822\">                                                       </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">with</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> dspy</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">context(lm</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">llm):</span><span style=\"background-color: #272822\">                                                                            </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">            retrieval_response </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> self</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">program(query)</span><span style=\"background-color: #272822\">                                                               </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">        </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">return</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> retrieval_response</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">label</span><span style=\"background-color: #272822\">                                                                            </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"background-color: #272822\">                                                                                                                   </span>\n",
       "<span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">def</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #a6e22e; text-decoration-color: #a6e22e; background-color: #272822\">construct_app</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">(args):</span><span style=\"background-color: #272822\">                                                                                           </span>\n",
       "<span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">    </span><span style=\"color: #66d9ef; text-decoration-color: #66d9ef; background-color: #272822\">return</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> LLMClient</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">.</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">bind(args[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"program_param_path\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">], args[</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"rayllm_args\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">])</span><span style=\"background-color: #272822\">                                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdspy\u001b[0m\u001b[48;2;39;40;34m                                                                                                        \u001b[0m\n",
       "\u001b[38;2;255;70;137;48;2;39;40;34mfrom\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mray\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mserve\u001b[0m\u001b[48;2;39;40;34m                                                                                              \u001b[0m\n",
       "\u001b[38;2;255;70;137;48;2;39;40;34mfrom\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfastapi\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mFastAPI\u001b[0m\u001b[48;2;39;40;34m                                                                                        \u001b[0m\n",
       "\u001b[38;2;255;70;137;48;2;39;40;34mfrom\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msrc\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mMODEL_PARAMETERS\u001b[0m\u001b[48;2;39;40;34m                                                                                   \u001b[0m\n",
       "\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mjson\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[48;2;39;40;34m                                                                                                       \u001b[0m\n",
       "\u001b[38;2;255;70;137;48;2;39;40;34mfrom\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstarlette\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mrequests\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mRequest\u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m\n",
       "\u001b[38;2;255;70;137;48;2;39;40;34mfrom\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34murllib\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mparse\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mimport\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34murlparse\u001b[0m\u001b[48;2;39;40;34m                                                                                  \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34mapp\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mFastAPI\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                    \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mread_params\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfile_path\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstr\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\"\"Simple helper for reading dspy program parameters\"\"\"\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mwith\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mopen\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfile_path\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mr\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mas\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mf\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mparams\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mjson\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mload\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mf\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                      \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mreturn\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mparams\u001b[0m\u001b[48;2;39;40;34m                                                                                                  \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;102;217;239;48;2;39;40;34mclass\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mIntentClassification\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdspy\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mSignature\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\"\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of th\u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mintent\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdspy\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mInputField\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdesc\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mIntent of the query\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                           \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlabel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdspy\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mOutputField\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdesc\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mType of the intent; Should just be one of the 25 labels with no other text\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m    \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;102;217;239;48;2;39;40;34mclass\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mIntentClassificationModule\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdspy\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mModule\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                     \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34m__init__\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlabels_in_use\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                             \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mintent_classifier\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdspy\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mChainOfThought\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mIntentClassification\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                         \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mvalid_labels\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mset\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlabels_in_use\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                     \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mforward\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtext\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpredictor_kwargs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprediction\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mintent_classifier\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mintent\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mtext\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mpredictor_kwargs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                       \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msanitized_prediction\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdspy\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mPrediction\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlabel\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprediction\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlabel\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlower\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstrip\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mreplace\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m_\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mreasoning\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mif\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msanitized_prediction\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlabel\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34mnot\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34min\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mvalid_labels\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                    \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m            \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msanitized_prediction\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdspy\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mPrediction\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlabel\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mINVALID MODEL OUTPUT\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mreturn\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msanitized_prediction\u001b[0m\u001b[48;2;39;40;34m                                                                                \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;166;226;46;48;2;39;40;34m@serve\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdeployment\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[48;2;39;40;34m                                                                                                 \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mray_actor_options\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m{\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mnum_cpus\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m0.1\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m}\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mautoscaling_config\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdict\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmin_replicas\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m1\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmax_replicas\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;174;129;255;48;2;39;40;34m5\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                        \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                                  \u001b[0m\n",
       "\u001b[38;2;102;217;239;48;2;39;40;34mclass\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mLLMClient\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34m__init__\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mparam_path\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mserve_args\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                    \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mparams\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mread_params\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mparam_path\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                           \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mparams\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mparams\u001b[0m\u001b[48;2;39;40;34m                                                                                       \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mbase_url\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mserve_args\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mapi_base\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                                          \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprefix\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mserve_args\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mroute_prefix\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                                        \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfull_url\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mbase_url\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m+\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprefix\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlstrip\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m/\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mif\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlen\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprefix\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlstrip\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m/\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m'\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34melse\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mbase_url\u001b[0m\u001b[48;2;39;40;34m                          \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mapi_parameters\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m{\u001b[0m\u001b[48;2;39;40;34m                                                                                         \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m            \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mapi_base\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mf\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m{\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfull_url\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m}\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m/v1\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[48;2;39;40;34m                                                                          \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m            \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mapi_key\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mserve_args\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mapi_key\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[48;2;39;40;34m                                                                       \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m}\u001b[0m\u001b[48;2;39;40;34m                                                                                                          \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mAPI parameters\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mapi_parameters\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                    \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mllm\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdspy\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mLM\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mmodel\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mopenai/\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m+\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mparams\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mbest_model\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mMODEL_PARAMETERS\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m*\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mapi_parameters\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m      \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprogram\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mIntentClassificationModule\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mparams\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mlabels_in_use\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                         \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprogram\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mload\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mparams\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mbest_program_path\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                             \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34masync\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34m__call__\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mstr\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                          \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\"\"Answer the given question and provide sources.\"\"\"\u001b[0m\u001b[48;2;39;40;34m                                                       \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mwith\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mdspy\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcontext\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlm\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mllm\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                            \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m            \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretrieval_response\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mself\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprogram\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                               \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m        \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mreturn\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mretrieval_response\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mlabel\u001b[0m\u001b[48;2;39;40;34m                                                                            \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m\n",
       "\u001b[38;2;102;217;239;48;2;39;40;34mdef\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;166;226;46;48;2;39;40;34mconstruct_app\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34margs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m:\u001b[0m\u001b[48;2;39;40;34m                                                                                           \u001b[0m\n",
       "\u001b[38;2;248;248;242;48;2;39;40;34m    \u001b[0m\u001b[38;2;102;217;239;48;2;39;40;34mreturn\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mLLMClient\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m.\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mbind\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34margs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mprogram_param_path\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34margs\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m[\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mrayllm_args\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m]\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print out deploy.py \n",
    "\n",
    "from rich import print_json\n",
    "from rich.syntax import Syntax\n",
    "from rich import print as rprint \n",
    "\n",
    "\n",
    "def pretty_print_py(file_path):\n",
    "    with open(file_path) as f:\n",
    "        code = f.read()\n",
    "    syntax = Syntax(code, \"python\", theme=\"monokai\")\n",
    "    rprint(syntax)\n",
    "\n",
    "pretty_print_py(\"deploy.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, we've put our DSPy application logic in the `LLMClient` class. We've also passed in some basic configuration for resources and an autoscaling config. At initialization, each replica of `LLMClient` will run a copy of the DSPy program after reading in the saved parameters from `param_path` (`configs/deploy_params.json` here).\n",
    "\n",
    "The main entrypoint for the app is `construct_app`. \n",
    "\n",
    "Our DSPy code will read in the API parameters for the RayLLM service through `args`.\n",
    "\n",
    "Let's now go over the Ray Serve config for our DSPy deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'applications'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'dspy_client'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'args'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'program_param_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'configs/deploy_params.json'</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'rayllm_args'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'route_prefix'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'api_base'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://localhost:8000'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'api_key'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fake-key'</span><span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'import_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'deploy:construct_app'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'route_prefix'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/classify_intent'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'runtime_env'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'pip'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'dspy'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'matplotlib'</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'working_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'llm-endpoint'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'args'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'llm_configs'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'./model_config/meta-llama--Llama-3_2-1B-Instruct.yaml'</span><span style=\"font-weight: bold\">]}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'import_path'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'rayllm:app'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'route_prefix'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'/'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'runtime_env'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'working_dir'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'.'</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'query_auth_token_enabled'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'applications'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'dspy_client'\u001b[0m,\n",
       "            \u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "                \u001b[32m'program_param_path'\u001b[0m: \u001b[32m'configs/deploy_params.json'\u001b[0m,\n",
       "                \u001b[32m'rayllm_args'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'route_prefix'\u001b[0m: \u001b[32m'/'\u001b[0m, \u001b[32m'api_base'\u001b[0m: \u001b[32m'https://localhost:8000'\u001b[0m, \u001b[32m'api_key'\u001b[0m: \u001b[32m'fake-key'\u001b[0m\u001b[1m}\u001b[0m\n",
       "            \u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'import_path'\u001b[0m: \u001b[32m'deploy:construct_app'\u001b[0m,\n",
       "            \u001b[32m'route_prefix'\u001b[0m: \u001b[32m'/classify_intent'\u001b[0m,\n",
       "            \u001b[32m'runtime_env'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'pip'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'dspy'\u001b[0m, \u001b[32m'matplotlib'\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'working_dir'\u001b[0m: \u001b[32m'.'\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'llm-endpoint'\u001b[0m,\n",
       "            \u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'llm_configs'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'./model_config/meta-llama--Llama-3_2-1B-Instruct.yaml'\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'import_path'\u001b[0m: \u001b[32m'rayllm:app'\u001b[0m,\n",
       "            \u001b[32m'route_prefix'\u001b[0m: \u001b[32m'/'\u001b[0m,\n",
       "            \u001b[32m'runtime_env'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'working_dir'\u001b[0m: \u001b[32m'.'\u001b[0m\u001b[1m}\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[32m'query_auth_token_enabled'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yaml \n",
    "\n",
    "deploy_config_path = \"configs/local_deploy_dspy.yaml\"\n",
    "with open(deploy_config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "rprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make use of [application args](https://docs.ray.io/en/latest/serve/advanced-guides/app-builder-guide.html) to provide the path to the program state json and the RayLLM API parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now deploy the apps locally with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-23 04:32:53,288\tINFO scripts.py:489 -- Running config file: 'local_deploy_dspy.yaml'.\n",
      "2024-10-23 04:32:53,643\tINFO worker.py:1601 -- Connecting to existing Ray cluster at address: 10.0.0.25:6379...\n",
      "2024-10-23 04:32:53,652\tINFO worker.py:1777 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-czqbf1bhvhp98gnjubkguupgc2.i.anyscaleuserdata.com \u001b[39m\u001b[22m\n",
      "2024-10-23 04:32:53,657\tINFO packaging.py:359 -- Pushing file package 'gcs://_ray_pkg_1ceac2efe61277e59cd1273bb531c4dfe845e103.zip' (1.39MiB) to Ray cluster...\n",
      "2024-10-23 04:32:53,674\tINFO packaging.py:372 -- Successfully pushed file package 'gcs://_ray_pkg_1ceac2efe61277e59cd1273bb531c4dfe845e103.zip'.\n",
      "INFO 2024-10-23 04:32:57,859 serve 249754 api.py:277 - Started Serve in namespace \"serve\".\n",
      "2024-10-23 04:32:57,871\tSUCC scripts.py:540 -- \u001b[32mSubmitted deploy config successfully.\u001b[39m\n",
      "\u001b[0m\u001b[36m(ServeController pid=249826)\u001b[0m INFO 2024-10-23 04:32:57,862 controller 249826 application_state.py:881 - Deploying new app 'dspy_client'.\n",
      "\u001b[36m(ServeController pid=249826)\u001b[0m INFO 2024-10-23 04:32:57,863 controller 249826 application_state.py:457 - Importing and building app 'dspy_client'.\n",
      "\u001b[36m(ServeController pid=249826)\u001b[0m INFO 2024-10-23 04:32:57,867 controller 249826 application_state.py:881 - Deploying new app 'llm-endpoint'.\n",
      "\u001b[36m(ServeController pid=249826)\u001b[0m INFO 2024-10-23 04:32:57,869 controller 249826 application_state.py:457 - Importing and building app 'llm-endpoint'.\n",
      "\u001b[36m(ProxyActor pid=249884)\u001b[0m INFO 2024-10-23 04:32:57,827 proxy 10.0.0.25 proxy.py:1235 - Proxy starting on node 9085971e2ef1cdf0cd5515d8cb45a7cb716afef38ea4a1ed736c820d (HTTP port: 8000).\n"
     ]
    }
   ],
   "source": [
    "!serve run local_deploy_dspy.yaml --non-blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the deployed DSPy service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query our app directly using HTTP requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got response:  <Response [500]>\n",
      "Reason:  Internal Server Error\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "response = requests.post(\"http://localhost:8000/classify_intent\", json={\"query\": example_query})\n",
    "\n",
    "if not response.ok:\n",
    "    print(\"Got response: \", response)\n",
    "    print(\"Reason: \", response.reason)\n",
    "else:\n",
    "    print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: Deploy DSPy program as an Anyscale Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can optionally deploy your program to Anyscale in order to use it in production. We will repeat the same steps as above, but this time deploy the two applications as separate Anyscale services for convenience.\n",
    "\n",
    "## Step 1: Deploy RayLLM as a Anyscale Service\n",
    "\n",
    "<b style=\"background-color: blue;\">&nbsp;ðŸ”„ RUN (optional)&nbsp;</b>:\n",
    "To deploy the fine-tuned model as an Anyscale Service, run the following command:\n",
    "\n",
    "```\n",
    "!anyscale service deploy -f serve_1B.yaml\n",
    "```\n",
    "\n",
    "Follow the URL in order to find your service URL and API key for your deployed service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you want to deploy an Anyscale service\n",
    "!anyscale service deploy -f serve_1B.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"background-color: yellow;\">&nbsp;ðŸ”„ REPLACE&nbsp;</b>:\n",
    "Replace the following variables with your Anyscale service URL and API key.\n",
    "\n",
    "\n",
    "You can find them by clicking the query button on the Anyscale dashboard for your service.\n",
    "\n",
    "<!-- <img src=\"files/service-query.png\" alt=\"Service Query\" width=\"500\"> -->\n",
    "![Service Query](README_files/service-query.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANYSCALE_RAYLLM_SERVICE_BASE_URL = None\n",
    "ANYSCALE_RAYLLM_API_KEY = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Deploy the DSPy program as a Anyscale Service\n",
    "\n",
    "To deploy our DSPy program, we first need to make sure we point to the Anyscale Service running RayLLM for the API parameters used. To do this, we should update the `rayllm_args` section of our config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def update_rayllm_config(yaml_path, new_api_base=None, new_api_key=None, new_route_prefix=None):\n",
    "    \"\"\"\n",
    "    Update the RayLLM configuration in the YAML file.\n",
    "    \n",
    "    Args:\n",
    "        yaml_path (str): Path to the YAML file\n",
    "        new_api_base (str, Optional): New API base URL\n",
    "        new_api_key (str, Optional): New API key\n",
    "        new_route_prefix (str, Optional): New route prefix\n",
    "    \"\"\"\n",
    "    with open(yaml_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    rayllm_args = config['applications'][0]['args']['rayllm_args']\n",
    "    \n",
    "    if new_api_base:\n",
    "        rayllm_args['api_base'] = new_api_base\n",
    "    if new_api_key:\n",
    "        rayllm_args['api_key'] = new_api_key\n",
    "    if new_route_prefix:\n",
    "        rayllm_args['route_prefix'] = new_route_prefix\n",
    "    \n",
    "    with open(yaml_path, 'w') as f:\n",
    "        yaml.safe_dump(config, f, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you deployed an Anyscale Service with RayLLM\n",
    "\n",
    "update_rayllm_config(\"configs/deploy_dspy.yaml\", new_api_base=ANYSCALE_RAYLLM_SERVICE_BASE_URL, new_api_key=ANYSCALE_RAYLLM_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We should now have a service which runs the compiled DSPy program. Let's query this new service. Make sure to enter the details here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANYSCALE_DSPY_SERVICE_BASE_URL = None\n",
    "ANYSCALE_DSPY_API_KEY = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {ANYSCALE_DSPY_API_KEY}\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{ANYSCALE_DSPY_SERVICE_BASE_URL}/classify_intent?query={example_query}\", headers=headers)\n",
    "    print(response.json())\n",
    "except Exception as e:\n",
    "    print(\"Error:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"background-color: yellow;\">&nbsp;ðŸ›‘ IMPORTANT&nbsp;</b>: Please `Terminate` your service from the Service page to avoid depleting your credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "!python src/clear_cell_nums.py\n",
    "!find . | grep -E \".ipynb_checkpoints\" | xargs rm -rf\n",
    "!find . | grep -E \"(__pycache__|\\.pyc|\\.pyo)\" | xargs rm -rf\n",
    "!rm -rf __pycache__ data .HF_TOKEN deploy/services"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
