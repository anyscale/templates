{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end DSPy Workflows Guide "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Motivation - have this problem and going to solve it with dspy and that is why we believe ti is the right solution\n",
    "\n",
    "This guide will cover the following topics:\n",
    "\n",
    "## Creating a Multi-stage LLM Pipeline\n",
    "- Building a pipeline with an untuned model in DSPy\n",
    "- Implementing batch inference (using Ray data)\n",
    "\n",
    "## Improving the Pipeline\n",
    "1. Prompt optimization\n",
    "2. Fine-tuning\n",
    "    - How to make an 8B model perform almost as well as a 70B model in your pipeline\n",
    "3. Combining fine-tuning with prompt optimization\n",
    "\n",
    "## Deployment\n",
    "- Steps to deploy the optimized pipeline and fine-tuned model to production\n",
    "\n",
    "## Future Work and Open Questions\n",
    "- Efficient batch inference with a DSPy pipeline\n",
    "- Exploring different fine-tuning methods and hyperparameter sweeps\n",
    "\n",
    "This guide aims to provide a comprehensive overview of building, optimizing, and deploying LLM pipelines using DSPy and Anyscale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node Set up:\n",
    "\n",
    "We will be running everything on a head node that uses 4xA100-80GB GPUs. I find that L4s are usually available and suitable for this usecase. You can also use any more powerful node.\n",
    "\n",
    "To change to use A100 GPUs, click the \"1 active node\" in the top right corner, then for workspace node, click the pencil icon and navigate to the A100 tab and select the 4xA100 option. If you do not see A100 in the list of GPUs, they may not be available on your cloud. Choose another kind of GPU (This notebook has been tested on X, and Y as alternatives) (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(work): DSPy installation cell\n",
    "\n",
    "# TODO: look at my own init file to see all the stupid extra pip installs\n",
    "\n",
    "# !pip install -e dspy\n",
    "\n",
    "# ignore future warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import dsp\n",
    "import os\n",
    "import ujson\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# TODO: include cache in notebook\n",
    "cache_dir = \"/home/ray/default/dspy/cache\"\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "# I have included a .env.example with the necessary environment variables to be set\n",
    "# You can also set them manually if you prefer\n",
    "\n",
    "os.environ[\"DSP_CACHEDIR\"] = cache_dir\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "dspy.settings.configure(experimental=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "\n",
    "litellm.set_verbose=False\n",
    "litellm.suppress_debug_info=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "necessary_env_vars = [\n",
    "    \"DSP_CACHEDIR\",\n",
    "    \"HF_TOKEN\",\n",
    "    \"HF_HOME\"\n",
    "]\n",
    "\n",
    "for var in necessary_env_vars:\n",
    "    assert os.environ[var], f\"{var} is not set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 01:34:41,494\tINFO worker.py:1601 -- Connecting to existing Ray cluster at address: 10.0.0.2:6379...\n",
      "2024-10-14 01:34:41,503\tINFO worker.py:1777 -- Connected to Ray cluster. View the dashboard at https://session-fkvdirx4bzefi53sjl55m7asad.i.anyscaleuserdata.com \n",
      "2024-10-14 01:34:41,530\tINFO packaging.py:531 -- Creating a file package for local directory '/home/ray/default/dspy-1/dspy'.\n",
      "2024-10-14 01:34:41,566\tINFO packaging.py:359 -- Pushing file package 'gcs://_ray_pkg_f6f649a9144f3c6b.zip' (0.97MiB) to Ray cluster...\n",
      "2024-10-14 01:34:41,577\tINFO packaging.py:372 -- Successfully pushed file package 'gcs://_ray_pkg_f6f649a9144f3c6b.zip'.\n",
      "2024-10-14 01:34:41,590\tINFO packaging.py:531 -- Creating a file package for local directory '/home/ray/default/dspy-1/dsp'.\n",
      "2024-10-14 01:34:41,611\tINFO packaging.py:359 -- Pushing file package 'gcs://_ray_pkg_4796df1b082f04ee.zip' (0.54MiB) to Ray cluster...\n",
      "2024-10-14 01:34:41,614\tINFO packaging.py:372 -- Successfully pushed file package 'gcs://_ray_pkg_4796df1b082f04ee.zip'.\n",
      "2024-10-14 01:34:41,637\tINFO packaging.py:359 -- Pushing file package 'gcs://_ray_pkg_569127ca115768e9e386f590cdb74cd9f5b69451.zip' (10.95MiB) to Ray cluster...\n",
      "2024-10-14 01:34:41,774\tINFO packaging.py:372 -- Successfully pushed file package 'gcs://_ray_pkg_569127ca115768e9e386f590cdb74cd9f5b69451.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +1m0s) Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "if not ray.is_initialized():\n",
    "    ray.init(runtime_env={\"env_vars\": os.environ, \"py_modules\": [dspy, dsp]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of a random number generator in this notebook. We are creating a Random object here to ensure that our notebook is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rng = random.Random(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating your multi-stage LLM pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.datasets import HotPotQA\n",
    "from dspy.evaluate import Evaluate\n",
    "from dsp.utils.utils import deduplicate\n",
    "\n",
    "\n",
    "# We are setting the experimental flag to True to make use of the fine-tuning\n",
    "# features that are still in development.\n",
    "dspy.settings.configure(experimental=True)\n",
    "\n",
    "class IntentClassification(dspy.Signature):\n",
    "    \"\"\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
    "    The intent should exactly match one of the following:\n",
    "    ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
    "    \"\"\"\n",
    "\n",
    "    intent = dspy.InputField(desc=\"Intent of the query\")\n",
    "    label = dspy.OutputField(desc=\"Type of the intent; Should just be one of the 25 labels with no other text\")\n",
    "\n",
    "class IntentClassificationModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.intent_classifier = dspy.ChainOfThought(IntentClassification)\n",
    "        self.valid_labels = set([\"activate_my_card\", \"cancel_transfer\", \"cash_withdrawal_charge\", \"declined_card_payment\", \"declined_cash_withdrawal\", \"direct_debit_payment_not_recognised\", \"extra_charge_on_statement\", \"pending_card_payment\", \"pending_top_up\", \"Refund_not_showing_up\", \"request_refund\", \"reverted_card_payment\", \"transaction_charged_twice\", \"transfer_fee_charged\", \"transfer_not_received_by_recipient\", \"wrong_amount_of_cash_received\", \"wrong_exchange_rate_for_cash_withdrawal\"])\n",
    "\n",
    "    def forward(self, text):\n",
    "        prediction = self.intent_classifier(intent=text)\n",
    "        sanitized_prediction = dspy.Prediction(label=prediction.label.lower().strip().replace(\" \", \"_\"), reasoning=prediction.reasoning)\n",
    "        # if sanitized_prediction.label not in self.valid_labels:\n",
    "        #     for label in self.valid_labels:\n",
    "        #         if label in sanitized_prediction.label:\n",
    "        #             sanitized_prediction.label = label\n",
    "        #             break\n",
    "        #     # this means that the prediction was not in the valid labels\n",
    "        #     # Could do edit distance or something more sophisticated here\n",
    "        #     # but for now just take the first\n",
    "        #     sanitized_prediction.label = self.valid_labels[0]\n",
    "        return sanitized_prediction\n",
    "\n",
    "class IntentClassificationPredictModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.intent_classifier = dspy.Predict(IntentClassification)\n",
    "        self.valid_labels = set([\"activate_my_card\", \"cancel_transfer\", \"cash_withdrawal_charge\", \"declined_card_payment\", \"declined_cash_withdrawal\", \"direct_debit_payment_not_recognised\", \"extra_charge_on_statement\", \"pending_card_payment\", \"pending_top_up\", \"Refund_not_showing_up\", \"request_refund\", \"reverted_card_payment\", \"transaction_charged_twice\", \"transfer_fee_charged\", \"transfer_not_received_by_recipient\", \"wrong_amount_of_cash_received\", \"wrong_exchange_rate_for_cash_withdrawal\"])\n",
    "\n",
    "    def forward(self, text):\n",
    "        prediction = self.intent_classifier(intent=text)\n",
    "        sanitized_prediction = dspy.Prediction(label=prediction.label.lower().strip().replace(\" \", \"_\"), reasoning=prediction.reasoning)\n",
    "        # if sanitized_prediction.label not in self.valid_labels:\n",
    "        #     for label in self.valid_labels:\n",
    "        #         if label in sanitized_prediction.label:\n",
    "        #             sanitized_prediction.label = label\n",
    "        #             break\n",
    "        #     # this means that the prediction was not in the valid labels\n",
    "        #     # Could do edit distance or something more sophisticated here\n",
    "        #     # but for now just take the first\n",
    "        #     sanitized_prediction.label = self.valid_labels[0]\n",
    "        return sanitized_prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's break down the Text to SQL program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we load the dataset using a built in `HotPotQA` dataset class from DSPy.\n",
    "\n",
    "We set the `train_seed` and `eval_seed` to `0` for reproducibility and the `test_size` to `0` because we do not need a test set for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({15: 187, 28: 182, 6: 181, 75: 180, 19: 177, 63: 175, 26: 173, 64: 172, 66: 171, 5: 171, 52: 169, 16: 168, 17: 167, 34: 166, 76: 163, 51: 162, 53: 161, 20: 160, 45: 159, 0: 159, 8: 157, 7: 156, 11: 153, 25: 153, 47: 149, 48: 148, 61: 146, 59: 145, 46: 143, 13: 139, 35: 137, 73: 135, 27: 133, 54: 129, 39: 129, 9: 129, 24: 129, 67: 128, 4: 127, 36: 126, 71: 126, 2: 126, 21: 122, 30: 121, 74: 121, 29: 121, 42: 121, 31: 121, 43: 120, 33: 118, 49: 115, 58: 114, 57: 114, 70: 113, 65: 113, 32: 112, 12: 112, 14: 112, 56: 111, 1: 110, 55: 108, 38: 106, 44: 105, 69: 104, 62: 103, 68: 102, 40: 98, 60: 97, 37: 97, 50: 95, 3: 87, 22: 86, 41: 82, 18: 61, 10: 59, 72: 41, 23: 35})\n",
      "Dataset filtered to top 25 labels. New sizes:\n",
      "Training set: 4171\n",
      "Test set: 1000\n",
      "Top 25 labels: 0, 5, 6, 7, 8, 11, 15, 16, 17, 19, 20, 25, 26, 28, 34, 45, 47, 51, 52, 53, 63, 64, 66, 75, 76\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset\n",
    "from dspy.datasets import DataLoader\n",
    "\n",
    "dl = DataLoader()\n",
    "full_trainset = dl.from_huggingface(\n",
    "    dataset_name=\"PolyAI/banking77\", # Dataset name from Huggingface\n",
    "    fields=(\"label\", \"text\"), # Fields needed\n",
    "    input_keys=(\"text\",), # What our model expects to recieve to generate an output\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "full_testset = dl.from_huggingface(\n",
    "    dataset_name=\"PolyAI/banking77\", # Dataset name from Huggingface\n",
    "    fields=(\"label\", \"text\"), # Fields needed\n",
    "    input_keys=(\"text\",), # What our model expects to recieve to generate an output\n",
    "    split=\"test\"\n",
    ")\n",
    "\n",
    "# Find the 15 most common class labels\n",
    "from collections import Counter\n",
    "\n",
    "# Count occurrences of each label\n",
    "label_counts = Counter(example['label'] for example in full_trainset)\n",
    "print(label_counts)\n",
    "\n",
    "# Get the 15 most common labels\n",
    "top_25_labels = set([label for label, _ in label_counts.most_common(25)])\n",
    "\n",
    "# Filter the datasets to only include examples with the top 15 labels\n",
    "full_trainset_filtered = [example for example in full_trainset if example['label'] in top_25_labels]\n",
    "full_testset_filtered = [example for example in full_testset if example['label'] in top_25_labels]\n",
    "\n",
    "# Replace the original datasets with the filtered versions\n",
    "full_trainset = full_trainset_filtered\n",
    "full_testset = full_testset_filtered\n",
    "\n",
    "print(f\"Dataset filtered to top 25 labels. New sizes:\")\n",
    "print(f\"Training set: {len(full_trainset)}\")\n",
    "print(f\"Test set: {len(full_testset)}\")\n",
    "print(f\"Top 25 labels: {', '.join(str(label) for label in top_25_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_label_dict = {\n",
    "    0: \"activate_my_card\",\n",
    "    1: \"age_limit\",\n",
    "    2: \"apple_pay_or_google_pay\",\n",
    "    3: \"atm_support\",\n",
    "    4: \"automatic_top_up\",\n",
    "    5: \"balance_not_updated_after_bank_transfer\",\n",
    "    6: \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "    7: \"beneficiary_not_allowed\",\n",
    "    8: \"cancel_transfer\",\n",
    "    9: \"card_about_to_expire\",\n",
    "    10: \"card_acceptance\",\n",
    "    11: \"card_arrival\",\n",
    "    12: \"card_delivery_estimate\",\n",
    "    13: \"card_linking\",\n",
    "    14: \"card_not_working\",\n",
    "    15: \"card_payment_fee_charged\",\n",
    "    16: \"card_payment_not_recognised\",\n",
    "    17: \"card_payment_wrong_exchange_rate\",\n",
    "    18: \"card_swallowed\",\n",
    "    19: \"cash_withdrawal_charge\",\n",
    "    20: \"cash_withdrawal_not_recognised\",\n",
    "    21: \"change_pin\",\n",
    "    22: \"compromised_card\",\n",
    "    23: \"contactless_not_working\",\n",
    "    24: \"country_support\",\n",
    "    25: \"declined_card_payment\",\n",
    "    26: \"declined_cash_withdrawal\",\n",
    "    27: \"declined_transfer\",\n",
    "    28: \"direct_debit_payment_not_recognised\",\n",
    "    29: \"disposable_card_limits\",\n",
    "    30: \"edit_personal_details\",\n",
    "    31: \"exchange_charge\",\n",
    "    32: \"exchange_rate\",\n",
    "    33: \"exchange_via_app\",\n",
    "    34: \"extra_charge_on_statement\",\n",
    "    35: \"failed_transfer\",\n",
    "    36: \"fiat_currency_support\",\n",
    "    37: \"get_disposable_virtual_card\",\n",
    "    38: \"get_physical_card\",\n",
    "    39: \"getting_spare_card\",\n",
    "    40: \"getting_virtual_card\",\n",
    "    41: \"lost_or_stolen_card\",\n",
    "    42: \"lost_or_stolen_phone\",\n",
    "    43: \"order_physical_card\",\n",
    "    44: \"passcode_forgotten\",\n",
    "    45: \"pending_card_payment\",\n",
    "    46: \"pending_cash_withdrawal\",\n",
    "    47: \"pending_top_up\",\n",
    "    48: \"pending_transfer\",\n",
    "    49: \"pin_blocked\",\n",
    "    50: \"receiving_money\",\n",
    "    51: \"refund_not_showing_up\",\n",
    "    52: \"request_refund\",\n",
    "    53: \"reverted_card_payment\",\n",
    "    54: \"supported_cards_and_currencies\",\n",
    "    55: \"terminate_account\",\n",
    "    56: \"top_up_by_bank_transfer_charge\",\n",
    "    57: \"top_up_by_card_charge\",\n",
    "    58: \"top_up_by_cash_or_cheque\",\n",
    "    59: \"top_up_failed\",\n",
    "    60: \"top_up_limits\",\n",
    "    61: \"top_up_reverted\",\n",
    "    62: \"topping_up_by_card\",\n",
    "    63: \"transaction_charged_twice\",\n",
    "    64: \"transfer_fee_charged\",\n",
    "    65: \"transfer_into_account\",\n",
    "    66: \"transfer_not_received_by_recipient\",\n",
    "    67: \"transfer_timing\",\n",
    "    68: \"unable_to_verify_identity\",\n",
    "    69: \"verify_my_identity\",\n",
    "    70: \"verify_source_of_funds\",\n",
    "    71: \"verify_top_up\",\n",
    "    72: \"virtual_card_not_working\",\n",
    "    73: \"visa_or_mastercard\",\n",
    "    74: \"why_verify_identity\",\n",
    "    75: \"wrong_amount_of_cash_received\",\n",
    "    76: \"wrong_exchange_rate_for_cash_withdrawal\"\n",
    "}\n",
    "\n",
    "label_to_int_dict = {v: k for k, v in int_to_label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "Example({'label': 'card_arrival', 'text': 'I am still waiting on my card?'}) (input_keys={'text'})\n"
     ]
    }
   ],
   "source": [
    "labels_in_use = [int_to_label_dict[label] for label in top_25_labels]\n",
    "\n",
    "print(labels_in_use)\n",
    "\n",
    "def convert_int_to_label(example):\n",
    "    example[\"label\"] = int_to_label_dict[example[\"label\"]]\n",
    "    return example\n",
    "\n",
    "full_trainset = [convert_int_to_label(example) for example in full_trainset]\n",
    "full_testset = [convert_int_to_label(example) for example in full_testset]\n",
    "\n",
    "print(full_trainset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_trainset = [d for d in full_trainset]\n",
    "rng.shuffle(shuffled_trainset)\n",
    "\n",
    "# The devset shouldn't overlap\n",
    "ft_trainset = shuffled_trainset[:-100]\n",
    "labeled_trainset = shuffled_trainset[-100:]\n",
    "\n",
    "testset = full_testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set up the metric and evaluator. We will be using the answer exact match metric.\n",
    "\n",
    "The evaluator is what we will consider as our test set.\n",
    "\n",
    "We choose `num_threads=90` because we are bottlenecked by the retrieval server, and through testing this is the maximum number of concurrent threads that can be run without causing issues for other people using the retrieval server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the metric and evaluator\n",
    "from dspy.evaluate import answer_exact_match\n",
    "\n",
    "NUM_THREADS = 50\n",
    "\n",
    "def adjusted_exact_match(example, pred, trace=None, frac=1.0):\n",
    "    example.answer = example.label\n",
    "    pred.answer = pred.label\n",
    "    return answer_exact_match(example, pred, trace, frac)\n",
    "\n",
    "metric = adjusted_exact_match\n",
    "common_kwargs = dict(metric=metric, num_threads=NUM_THREADS, display_progress=True, max_errors=10000)\n",
    "\n",
    "evaluate_testset = Evaluate(devset=testset, **common_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return [ujson.loads(line) for line in f]\n",
    "\n",
    "def write_jsonl(filename, data):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for item in data:\n",
    "            f.write(ujson.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering baseline performance\n",
    "\n",
    "run evaluate on a base pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 1000\n",
    "MODEL_PARAMETERS = {\n",
    "  \"max_tokens\": MAX_TOKENS,\n",
    "  \"temperature\": 0,\n",
    "}\n",
    "\n",
    "LOCAL_API_PARAMETERS = {\n",
    "  \"api_base\": \"http://localhost:8000/v1\",\n",
    "  \"api_key\": \"fake-key-doesnt-matter\"\n",
    "}\n",
    "vanilla_program = IntentClassificationModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Run above this to do all setup without launching any models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a local VLLM instance to run the initial benchmarks and data collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering training data and running the 70B Model\n",
    "\n",
    "Now that we have a baseline for the 8B model, let's run the 70B model and compare its performance.\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Before running the 70B model:\n",
    "1. Kill the 8B server (use `Ctrl+C`) to free up memory.\n",
    "2. Remember to set your HF_TOKEN and HF_HOME environment variables\n",
    "3. Use the following command to start the 70B server:\n",
    "\n",
    "   ```\n",
    "   vllm serve meta-llama/Meta-Llama-3.1-70B-Instruct --port 8000 --pipeline_parallel_size 2 --enable_prefix_caching --tensor_parallel_size 2\n",
    "   ```\n",
    "\n",
    "## Parallelism Configuration\n",
    "\n",
    "We've chosen pipeline parallelism and tensor parallelism of 2 for the 70B model based on our current setup. Here's the reasoning:\n",
    "\n",
    "1. Model size: The 70B model has 30 parts of ~5 GB each (based on [HuggingFace documentation](https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct/tree/main)).\n",
    "   - Total size: 30 * 5 GB = 150 GB\n",
    "\n",
    "2. Available VRAM:\n",
    "   - Our GPUs: 80 GB VRAM x 4 = 320 GB\n",
    "   - Tensor parallelism: floor(320/150) = 2\n",
    "   - Pipeline parallelism: floor(num_gpus/2) = 2\n",
    "   - To use all 4 GPUs efficiently:\n",
    "     - Pipeline parallel size: 2\n",
    "     - Tensor parallelism: 2\n",
    "\n",
    "3. Alternative setup (8x24GB GPUs):\n",
    "   - Pipeline parallel size: 1\n",
    "   - Tensor parallelism: ceil(150/24) = 7\n",
    "\n",
    "This configuration allows us to run the 70B model efficiently across our available GPU resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I needed to add the HF_HOME var to my serve config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command for easy copying: \n",
    "# `export HF_HOME=/mnt/local_storage/huggingface`\n",
    "# `vllm serve meta-llama/Meta-Llama-3.1-70B-Instruct --port 8000 --pipeline_parallel_size 2 --enable_prefix_caching --tensor_parallel_size 2`\n",
    "\n",
    "# input(\"Press Enter once you have the vllm server running...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_70b = dspy.LM(model=\"openai/meta-llama/Meta-Llama-3.1-70B-Instruct\", **MODEL_PARAMETERS, **LOCAL_API_PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example({'label': 'card_arrival', 'text': 'I have been waiting longer than expected for my bank card, could you provide information on when it will arrive?'}) (input_keys={'text'})\n",
      "card_arrival\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "test_predictor = IntentClassificationModule()\n",
    "with dspy.context(lm=llama_70b):\n",
    "    sample_input = testset[15]\n",
    "    print(sample_input)\n",
    "    print(test_predictor(**sample_input.inputs()).label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see how the vanilla program performs on our small labeled dataset\n",
    "# vanilla_program = IntentClassificationModule()\n",
    "# with dspy.context(lm=llama_70b):\n",
    "#     print(\"Evaluating the vanilla program on the devset using llama 70B...\")\n",
    "#     true_labeled_eval = evaluate_devset(vanilla_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the LLaMa 70B pipeline\n",
    "\n",
    "Now we are ready to optimize the pipeline. We want to optimize the 70B pipeline in order to get the best possible data to then train our 8B model.\n",
    "\n",
    "We will use Bootstrap Few Shot with Random Search (BFRS) to optimize the pipeline.\n",
    "\n",
    "The essence of BFRS is to try out different configurations of few shot demonstrations per step and see which one works best on the validation set.\n",
    "\n",
    "The cool part about BFRs is that it will automatically collect the \"good\" chains of thought for us and add them to the examples at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how well the base pipeline performs, let's run prompt optimization on the pipeline in order to juice up the performance.\n",
    "\n",
    "Let's go over what the hyperparameters mean:\n",
    "- MAX_BOOTSTRAPPED_DEMOS: DSPy will \"bootstrap\" the program by collecting examples at each step that are successful and reusing those in the pipeline. This means that it will automatically collect and add chains of thought to the pipeline.\n",
    "- MAX_LABELED_DEMOS: DSPy will also insert some labeled demonstrations from the training set. These would be unmodified examples from the training set that are just using the gold answer.\n",
    "- NUM_CANDIDATE_PROGRAMS: This is the number of candidate programs that the optimizer will generate. The actual number of programs that are created is this plus three, as DSPy will also try a program with no examples, a program with TODO (check)\n",
    "- OPTIMIZER_NUM_TRAIN and OPTIMIZER_NUM_VAL: These are the number of examples that the optimizer will use for training and validation. Note that we will be taking the \"validation\" set from the trainset so as the actual validation set is untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization hyperparameters\n",
    "from dspy.teleprompt.random_search import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# Define the hyperparameters for prompt optimization\n",
    "MAX_BOOTSTRAPPED_DEMOS = 3\n",
    "MAX_LABELED_DEMOS = 3\n",
    "NUM_CANDIDATE_PROGRAMS = 6\n",
    "OPTIMIZER_NUM_TRAIN = 100\n",
    "OPTIMIZER_NUM_VAL = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 3 traces per predictor.\n",
      "Will attempt to bootstrap 6 candidate sets.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the optimizer\n",
    "bfrs_optimizer = BootstrapFewShotWithRandomSearch(\n",
    "    metric=metric,\n",
    "    max_bootstrapped_demos=MAX_BOOTSTRAPPED_DEMOS,\n",
    "    max_labeled_demos=MAX_LABELED_DEMOS,\n",
    "    num_candidate_programs=NUM_CANDIDATE_PROGRAMS,\n",
    "    num_threads=NUM_THREADS,\n",
    "    max_errors=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have added this flag to save you some compute and time while running the notebook\n",
    "# TODO: do prompt optimization on the 100 labeled examples\n",
    "# COMPILE_PROGRAM = False\n",
    "# EVAL_PROGRAM = True\n",
    "\n",
    "# # Compile the optimizer and evaluate\n",
    "# with dspy.context(lm=llama_70b):\n",
    "#     vanilla_program = IntentClassificationModule()\n",
    "#     if COMPILE_PROGRAM:\n",
    "#         bfrs_base_program = bfrs_optimizer.compile(vanilla_program, trainset=po_trainset, valset=po_devset)\n",
    "#         bfrs_base_program.save(f\"b25_70b_31_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}.json\")\n",
    "#     else:\n",
    "#         bfrs_base_program = IntentClassificationModule()\n",
    "#         bfrs_base_program.load(f\"b25_70b_31_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}.json\")\n",
    "#     if EVAL_PROGRAM:\n",
    "#         llama_70b_bfrs_eval = evaluate_devset(bfrs_base_program)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do some data analysis and cleaning\n",
    "# First we will convert the data to a pandas dataframe\n",
    "import pandas as pd\n",
    "from dspy.teleprompt.finetune_teleprompter import bootstrap_data, convert_to_module_level_message_data\n",
    "\n",
    "# TODO: WORKING HERE\n",
    "\n",
    "# For realism of this scenario, we are going to delete all our labels except for our test set(which is cheating and we wouldn't have in production) and our 100 true labeled examples\n",
    "def delete_labels(dataset):\n",
    "    for example in dataset:\n",
    "        if \"label\" in example:\n",
    "            del example[\"label\"]\n",
    "    return dataset\n",
    "\n",
    "ft_trainset_to_label = delete_labels(ft_trainset)\n",
    "with dspy.context(lm=llama_70b):\n",
    "    collected_data = bootstrap_data(vanilla_program, ft_trainset_to_label, num_threads=NUM_THREADS, max_errors=10000)\n",
    "    print(collected_data[0])\n",
    "    collected_data_filtered = [x for x in collected_data if x[\"prediction\"][\"label\"] in labels_in_use]\n",
    "\n",
    "    # Convert collected_data to a pandas DataFrame\n",
    "    dataset = convert_to_module_level_message_data(collected_data_filtered, program=vanilla_program, exclude_demos=True)\n",
    "    \n",
    "print(dataset[0])\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data points removed:\", len(collected_data) - len(collected_data_filtered))\n",
    "# look at all the data that was removed to see if any can be cleaned\n",
    "filtered_data = [x for x in collected_data if x[\"prediction\"][\"label\"] not in labels_in_use]\n",
    "bad_labels = [x[\"prediction\"][\"label\"] for x in filtered_data]\n",
    "print(bad_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(\"collected_data_filtered.jsonl\", \"w\") as f:\n",
    "        for item in collected_data_filtered:\n",
    "            f.write(ujson.dumps({\"example\": item[\"example\"], \"prediction\": item[\"prediction\"]}) + \"\\n\")\n",
    "else:\n",
    "    with open(\"collected_data_filtered.jsonl\", \"r\") as f:\n",
    "        collected_data_filtered = [ujson.loads(line) for line in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_formatted = [{\"messages\": x} for x in dataset]\n",
    "\n",
    "# Note: Maybe dont use devset here\n",
    "dataset_filenames = {f\"trainset_data_banking.jsonl\": dataset}\n",
    "\n",
    "for filename, data in dataset_filenames.items():\n",
    "    # we first need to convert the data to be only the messages and to be in proper messages format\n",
    "    messages_format = [{\"messages\": item} for item in data]\n",
    "    # print(messages_format[0])\n",
    "\n",
    "    write_jsonl(filename, messages_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dspy.teleprompt.finetune_teleprompter import bootstrap_data, convert_to_module_level_message_data, bootstrap_data_for_round\n",
    "# import ujson\n",
    "\n",
    "# # This should be moved inside the finetune_teleprompter class\n",
    "# def write_data(program, data, filename):\n",
    "#     print(\"Bootstrapping and writing data to\", filename)\n",
    "#     correct_data = bootstrap_data(program, data, metric=metric, num_threads=NUM_THREADS, max_errors=10000)\n",
    "#     correct_data_round = [x for x in correct_data if x[\"score\"]]\n",
    "\n",
    "#     # Convert the data to prompt completion format\n",
    "#     dataset = convert_to_module_level_message_data(correct_data_round, program=program, exclude_demos=True)\n",
    "    \n",
    "#     dataset_formatted = [{\"messages\": x} for x in dataset]\n",
    "#     # Format the data for finetuning using the LM\n",
    "#     print(\"Writing dataset with length\", len(dataset), \"to\", filename)\n",
    "#     write_jsonl(filename, dataset_formatted)\n",
    "\n",
    "# dataset_filenames = {f\"ft_trainset_data_{len(ft_trainset)}.jsonl\": ft_trainset, f\"ft_valset_data_{len(devset)}.jsonl\": devset}\n",
    "\n",
    "\n",
    "# WRITE_DATA = True\n",
    "# if WRITE_DATA:\n",
    "#     for filename, data in dataset_filenames.items():\n",
    "#         bootstrap_program = IntentClassificationModule()\n",
    "#         with dspy.context(lm=llama_70b):\n",
    "#             write_data(bootstrap_program, data, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at an example prompt completion pair!\n",
    "# with open(f\"trainset_data_banking_{TRAIN_SIZE}.json\", \"r\") as f:\n",
    "#     data_example = ujson.load(f)\n",
    "from pprint import pprint\n",
    "data_example = read_jsonl(f\"trainset_data_banking.jsonl\")[0]\n",
    "\n",
    "print(\"Example prompt:\")\n",
    "pprint(data_example[\"messages\"][:-1])\n",
    "print(\"<end prompt>\\n\"+\"-\"*50)\n",
    "print(\"Example completion:\")\n",
    "pprint(data_example[\"messages\"][-1])\n",
    "print(\"<end completion>\\n\"+\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning\n",
    "\n",
    "We will use LLM Forge to fine-tune the 8B model.\n",
    "\n",
    "In order to do this, we need to format our data into the correct format (Follows OpenAI messaging format placed in a jsonl file).\n",
    "\n",
    "We initially saved the data into a json file in prompt-completion format.\n",
    "\n",
    "In order to prepare for finetuning, we need to do three steps:\n",
    "1. Format the data into the correct format and verify that the data is valid\n",
    "2. Upload the data to GCP\n",
    "3. Generate the compute configuration file\n",
    "\n",
    "After the compute configuration file is generated, we can submit the job to LLM Forge, using either the command line or using the anyscale jobs sdk.\n",
    "TODO: Add the anyscale jobs sdk submit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.modules.lm import TrainingMethod\n",
    "# from dsp.modules.trainable_anyscale import TrainableAnyscale\n",
    "import asyncio\n",
    "from dspy.clients.lm import LM\n",
    "from dspy.clients.anyscale import FinetuneJobAnyScale\n",
    "\n",
    "# TODO: This is the only section that really needs to be changed in the merge\n",
    "# NOTE: Working here\n",
    "train_path = f\"trainset_data_banking.jsonl\"\n",
    "# eval_path = f\"valset_data_banking.jsonl\"\n",
    "eval_path = None\n",
    "method = TrainingMethod.SFT\n",
    "\n",
    "kwargs = {\n",
    "    \"hyperparameters\": {\n",
    "        \"num_devices\": 4,\n",
    "        \"trainer_resources\": None,\n",
    "        \"worker_resources\": None,\n",
    "        \"generation_config\": {\n",
    "            \"prompt_format\": {\n",
    "                \"system\": \"<|start_header_id|>system<|end_header_id|>\\n\\n{instruction}<|eot_id|>\",\n",
    "                \"user\": \"<|start_header_id|>user<|end_header_id|>\\n{instruction}<|eot_id|>\",\n",
    "                \"assistant\": \"<|start_header_id|>assistant<|end_header_id|>\\n\\n{instruction}<|eot_id|>\",\n",
    "                \"trailing_assistant\": \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    "                \"bos\": \"<|begin_of_text|>\",\n",
    "                \"system_in_user\": False,\n",
    "                \"default_system_message\": \"\"\n",
    "            },\n",
    "        },\n",
    "        \"learning_rate\": 3e-5,\n",
    "        \"num_epochs\": 6,\n",
    "        \"train_batch_size_per_device\": 32\n",
    "    },\n",
    "    \"use_lora\": True,\n",
    "    # TODO: I think this needs to be set dynamically\n",
    "    # \"lora_dynamic_folder\": \"dspy/lora_weights/prodjob_qmulcjw4x8z599m8hkyja8tbmi/meta-llama/Llama-3.2-1B-Instruct\"\n",
    "}\n",
    "\n",
    "\n",
    "SKIP_FT = False\n",
    "if not SKIP_FT:\n",
    "\n",
    "    finetuneable_lm = dspy.LM(model=\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "    finetuning_job = await finetuneable_lm.finetune(method, train_path, eval_path, provider=\"anyscale\", train_kwargs=kwargs)\n",
    "    model_names = []\n",
    "    async for model_name in finetuning_job:\n",
    "        model_names.append(model_name)\n",
    "    print(model_names)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODODODODODOO: Currently I am manually updating HF_TOKEN\n",
    "# Also copying the prodjob into the serving file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Throughout this section, anything using 8B model (or technically 70B too) should use the new evaluate with ray data batch offline(or technically online) inference.\n",
    "\n",
    "Probably worth testing offline with 8x8 threads vs just 64 threads to see if it makes a meaningful difference.\n",
    "\n",
    "## Performance comparisons\n",
    "\n",
    "- 70B\n",
    "- 70B BSFS\n",
    "- 8B\n",
    "- 8B BSFT\n",
    "- 8B BSFT + BSFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model to run is the 8B model in order to collect a baseline of performance.\n",
    "\n",
    "You can run the local VLLM instance with the following command:\n",
    "\n",
    "Make sure to set your HF_TOKEN and HF_HOME environment variables\n",
    "\n",
    "For Anyscale, putting models into /mnt/local_storage is a typical pattern.\n",
    "\n",
    "\n",
    "`vllm serve meta-llama/Meta-Llama-3.1-8B-Instruct --port 8000 --pipeline_parallel_size 4 --enable_prefix_caching`\n",
    "\n",
    "Lets break down what this command does:\n",
    "- `vllm serve` is the command to run the VLLM server\n",
    "- `meta-llama/Meta-Llama-3.1-8B-Instruct` is the model to run\n",
    "- `--port 8000` is the port to run the server on\n",
    "- `--pipeline_parallel_size 4` is the number of pipeline parallel size to run the server with. We are using 4 because we have 4 GPUs all of which can hold an instance of the model.\n",
    "- `--enable_prefix_caching` is the flag to enable the prefix caching. This will store and reuse the beginnings of prompts to avoid repeating the same computation. This is especially useful for DSPy since we are almost always using prompts with the same beginning parts in the form of few shot demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO IMPORTANT IMPORTANT IMPORTANT\n",
    "import json\n",
    "if False:\n",
    "    if model_names is not None:\n",
    "        with open(\"model_names.json\", \"w\") as f:\n",
    "            json.dump(model_names, f)\n",
    "else:\n",
    "    with open(\"model_names.json\", \"r\") as f:\n",
    "        model_names = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command for easy copying: \n",
    "llama_1b = dspy.LM(model=\"openai/meta-llama/Llama-3.2-1B-Instruct\", **LOCAL_API_PARAMETERS, **MODEL_PARAMETERS)\n",
    "finetuned_llamas_1b = {f: dspy.LM(model=\"openai/\" + f, **LOCAL_API_PARAMETERS, **MODEL_PARAMETERS) for f in model_names}\n",
    "all_llamas = {**finetuned_llamas_1b, \"base\": llama_1b}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving things above this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope to bring the 8B performance up to at least 70B level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Data\n",
    "\n",
    "\n",
    "In this section, we bootstrap data for fine-tuning. In the code block below, we are deciding which program should be used to collect the bootstraps. We are setting this to the prompt optimized program, but one could also set this to the vanilla program, though doing so would lead to lower quality bootstraps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to checkout the fine-tuning documentation for the latest on how to use our [API](https://docs.anyscale.com/llms/finetuning/intro) and additional [capabilities](https://docs.anyscale.com/category/fine-tuning-beta/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fine-tune our LLM by choosing a set of configurations. We have created recipes for different LLMs in the [`training configs`](configs/training/lora/llama-3-8b.yaml) folder which can be used as is or modified for experiments. These configurations provide flexibility over a broad range of parameters such as model, data paths, compute to use for training, number of training epochs, how often to save checkpoints, padding, loss, etc. We also include several [DeepSpeed](https://github.com/microsoft/DeepSpeed) [configurations](configs/deepspeed/zero_3_offload_optim+param.json) to choose from for further optimizations around data/model parallelism, mixed precision, checkpointing, etc.\n",
    "\n",
    "We also have recipes for [LoRA](https://arxiv.org/abs/2106.09685) (where we train a set of small low ranked matrices instead of the original attention and feed forward layers) or full parameter fine-tuning. We recommend starting with LoRA as it's less resource intensive and quicker to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to serve the base model and tell VLLM where to find the LoRA weights\n",
    "\n",
    "Run the following command:\n",
    "\n",
    "```\n",
    "vllm serve meta-llama/Meta-Llama-3.1-8B-Instruct --port 8000 --pipeline_parallel_size 4 --enable_prefix_caching --enable_lora --lora_modules mhqa-lora=/mnt/local_storage/dspy/mhqa-lora\n",
    "```\n",
    "\n",
    "# Explanation:\n",
    "This command starts a VLLM server to serve the Meta-Llama-3-8B-Instruct model with LoRA fine-tuning.\n",
    "Here's a breakdown of the command:\n",
    "- 'vllm serve': Starts the VLLM server\n",
    "- 'meta-llama/Meta-Llama-3.1-8B-Instruct': Specifies the base model to use\n",
    "- '--port 8000': Sets the server port to 8000\n",
    "- '--pipeline_parallel_size 4': Enables pipeline parallelism with 4 stages\n",
    "- '--enable_prefix_caching': Enables caching of prefixes for faster inference\n",
    "- '--enable_lora': Enables LoRA (Low-Rank Adaptation) for fine-tuning\n",
    "- '--lora_modules mhqa-lora=/mnt/local_storage/dspy/mhqa-lora': Specifies the name of the LoRA module and the path to the LoRA weights. We use the name instead of the base model name when trying to use the LoRA weights. If we just use the base model name, the server will ignore the LoRA weights.\n",
    "\n",
    "This setup allows us to serve a fine-tuned version of the 8B model, which we'll use for subsequent evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sanity check that the finetuned models are working\n",
    "llama1 = list(finetuned_llamas_1b.values())[3]\n",
    "with dspy.context(lm=llama1):\n",
    "    print(llama1.model)\n",
    "    test_predictor = IntentClassificationModule()\n",
    "    sample_input = ft_trainset[11]\n",
    "    print(sample_input)\n",
    "    print(test_predictor(**sample_input.inputs()).label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try optimizing the program with the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 2758 300\n",
      "Example({'text': 'I still have not received an answer as to why I was charged $1.00 in a transaction?', 'label': 'extra_charge_on_statement'}) (input_keys={'text'})\n"
     ]
    }
   ],
   "source": [
    "def collected_data_to_example(data):\n",
    "    return dspy.Example(text=data[\"example\"][\"text\"], label=data[\"prediction\"][\"label\"]).with_inputs(\"text\")\n",
    "\n",
    "collected_data_examples = [collected_data_to_example(x) for x in collected_data_filtered]\n",
    "# collected_data_examples[0]\n",
    "\n",
    "devset_synthetic = collected_data_examples[:DEV_SIZE]\n",
    "ft_optimizer_devset = collected_data_examples[DEV_SIZE:DEV_SIZE+OPTIMIZER_NUM_VAL]\n",
    "ft_optimizer_trainset = collected_data_examples[DEV_SIZE+OPTIMIZER_NUM_VAL:]\n",
    "\n",
    "\n",
    "print(len(devset_synthetic), len(ft_optimizer_trainset), len(ft_optimizer_devset))\n",
    "print(devset_synthetic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repro bug\n",
    "import dspy\n",
    "import dsp\n",
    "COMPILE_PROGRAM = True\n",
    "\n",
    "ft_results = {}\n",
    "for folder, llama in list(all_llamas.items())[0:1]:\n",
    "    print(\"Evaluating\", llama.model)\n",
    "    ft_results[folder] = {}\n",
    "    with dspy.context(lm=llama):\n",
    "        evaluate_devset = Evaluate(devset=devset_synthetic, metric=metric, num_threads=NUM_THREADS, display_progress=True, max_errors=10000)\n",
    "\n",
    "        # print(\"llama model\", llama.model)\n",
    "        # print(\"settings\", dspy.settings.lm.model)\n",
    "        # print(\"dsp settings\", dsp.settings.lm.model)\n",
    "        vanilla_program = IntentClassificationModule()\n",
    "        devset_result = evaluate_devset(vanilla_program)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating openai/meta-llama/Llama-3.2-1B-Instruct:epochs-4-total-trained-steps-160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 179 / 1000  (17.9): 100%|██████████| 1000/1000 [01:07<00:00, 14.88it/s]\n",
      "Average Metric: 63 / 300  (21.0): 100%|██████████| 300/300 [00:26<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 21.0 for seed -3\n",
      "Scores so far: [21.0]\n",
      "Best score so far: 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 63 / 300  (21.0): 100%|██████████| 300/300 [00:00<00:00, 1205.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [21.0, 21.0]\n",
      "Best score so far: 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2758 [00:04<25:26,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:17:21.387538Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<04:40,  1.07it/s]2024-10-14T00:17:21.429109Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 58  (53.4):  19%|█▉        | 58/300 [00:04<00:18, 13.41it/s]2024-10-14T00:17:25.444475Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 68  (51.5):  23%|██▎       | 68/300 [00:05<00:20, 11.05it/s]2024-10-14T00:17:26.417738Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 111  (45.0):  37%|███▋      | 110/300 [00:08<00:12, 15.38it/s]2024-10-14T00:17:28.856226Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 73.0 / 160  (45.6):  53%|█████▎    | 159/300 [00:11<00:09, 14.38it/s]2024-10-14T00:17:32.391369Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 90.0 / 199  (45.2):  66%|██████▌   | 198/300 [00:14<00:07, 13.37it/s]2024-10-14T00:17:35.377887Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 92.0 / 202  (45.5):  67%|██████▋   | 201/300 [00:15<00:06, 14.27it/s]2024-10-14T00:17:35.698863Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 113.0 / 242  (46.7):  80%|████████  | 241/300 [00:17<00:03, 16.52it/s]2024-10-14T00:17:38.100289Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 144.0 / 300  (48.0): 100%|██████████| 300/300 [00:21<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 48.0 for seed -1\n",
      "Scores so far: [21.0, 21.0, 48.0]\n",
      "Best score so far: 48.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2758 [00:02<25:04,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:17:45.845165Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<04:23,  1.14it/s]2024-10-14T00:17:46.242751Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 53  (50.9):  18%|█▊        | 53/300 [00:04<00:27,  8.90it/s]2024-10-14T00:17:49.432299Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 92.0 / 228  (40.4):  76%|███████▌  | 227/300 [00:15<00:04, 15.27it/s]2024-10-14T00:18:00.735645Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 93.0 / 232  (40.1):  77%|███████▋  | 231/300 [00:16<00:04, 14.03it/s]]024-10-14T00:18:01.005519Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 130.0 / 300  (43.3): 100%|██████████| 300/300 [00:18<00:00, 16.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [21.0, 21.0, 48.0, 43.33]\n",
      "Best score so far: 48.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2758 [00:04<27:45,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 74 / 300  (24.7): 100%|██████████| 300/300 [00:16<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [21.0, 21.0, 48.0, 43.33, 24.67]\n",
      "Best score so far: 48.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2758 [00:01<26:28,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 47 / 207  (22.7):  69%|██████▊   | 206/300 [00:14<00:04, 20.83it/s]2024-10-14T00:18:41.811745Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 70.0 / 300  (23.3): 100%|██████████| 300/300 [00:19<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [21.0, 21.0, 48.0, 43.33, 24.67, 23.33]\n",
      "Best score so far: 48.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2758 [00:05<32:14,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 93 / 300  (31.0): 100%|██████████| 300/300 [00:15<00:00, 19.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [21.0, 21.0, 48.0, 43.33, 24.67, 23.33, 31.0]\n",
      "Best score so far: 48.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2758 [00:01<31:10,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 31 / 300  (10.3): 100%|██████████| 300/300 [00:18<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [21.0, 21.0, 48.0, 43.33, 24.67, 23.33, 31.0, 10.33]\n",
      "Best score so far: 48.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2758 [00:06<31:35,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:19:36.006771Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:01<05:08,  1.03s/it]2024-10-14T00:19:36.227743Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 54  (37.0):  18%|█▊        | 53/300 [00:03<00:12, 19.12it/s]evaluate.py00:19:38.675973Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename= lineno=198\n",
      "Average Metric: 44.0 / 114  (38.6):  38%|███▊      | 113/300 [00:07<00:12, 14.72it/s]2024-10-14T00:19:42.001026Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 164  (36.0):  54%|█████▍    | 163/300 [00:10<00:09, 14.94it/s]1984-10-14T00:19:45.074214Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 72.0 / 192  (37.5):  64%|██████▎   | 191/300 [00:12<00:09, 11.11it/s]linenome14T00:19:47.033593Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py =198\n",
      "Average Metric: 98.0 / 243  (40.3):  81%|████████  | 243/300 [00:15<00:03, 17.95it/s]2024-10-14T00:19:50.008187Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 129.0 / 300  (43.0): 100%|██████████| 300/300 [00:16<00:00, 18.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [21.0, 21.0, 48.0, 43.33, 24.67, 23.33, 31.0, 10.33, 43.0]\n",
      "Best score so far: 48.0\n",
      "9 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]2024-10-14T00:19:53.175489Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 50  (46.0):   5%|▌         | 50/1000 [00:04<00:52, 17.99it/s]2024-10-14T00:19:56.354947Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 153  (52.3):  15%|█▌        | 153/1000 [00:11<01:03, 13.39it/s]2024-10-14T00:20:03.183372Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 157  (51.6):  16%|█▌        | 157/1000 [00:11<00:53, 15.85it/s]2024-10-14T00:20:03.558682Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 89.0 / 178  (50.0):  18%|█▊        | 177/1000 [00:12<00:44, 18.66it/s]2024-10-14T00:20:04.765212Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 140.0 / 290  (48.3):  29%|██▉       | 289/1000 [00:20<00:42, 16.81it/s] rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 156.0 / 328  (47.6):  33%|███▎      | 328/1000 [00:23<00:47, 14.07it/s]2024-10-14T00:20:15.291929Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 199.0 / 411  (48.4):  41%|████      | 410/1000 [00:28<00:53, 10.93it/s] [24-10-14T00:20:20.746149Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 204.0 / 419  (48.7):  42%|████▏     | 418/1000 [00:29<00:46, 12.41it/s]2024-10-14T00:20:21.201744Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 210.0 / 442  (47.5):  44%|████▍     | 441/1000 [00:30<00:33, 16.89it/s]2024-10-14T00:20:22.687416Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 214.0 / 450  (47.6):  45%|████▌     | 450/1000 [00:31<00:50, 10.83it/s]2024-10-14T00:20:23.425556Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 221.0 / 463  (47.7):  46%|████▌     | 462/1000 [00:32<00:54,  9.88it/s]2024-10-14T00:20:24.574613Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 260.0 / 538  (48.3):  54%|█████▍    | 538/1000 [00:38<00:33, 13.95it/s]=ilename14T00:20:29.975033Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] evaluate.py lineno=198\n",
      "Average Metric: 266.0 / 559  (47.6):  56%|█████▌    | 558/1000 [00:39<00:24, 17.95it/s]2024-10-14T00:20:31.229702Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 307.0 / 640  (48.0):  64%|██████▍   | 639/1000 [00:44<00:21, 16.42it/s]2024-10-14T00:20:36.212704Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 317.0 / 655  (48.4):  65%|██████▌   | 654/1000 [00:45<00:18, 18.50it/s]2024-10-14T00:20:37.610992Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 330.0 / 682  (48.4):  68%|██████▊   | 682/1000 [00:47<00:18, 16.75it/s]1984-10-14T00:20:39.449584Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 342.0 / 708  (48.3):  71%|███████   | 708/1000 [00:49<00:22, 12.94it/s]2024-10-14T00:20:41.338709Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 345.0 / 716  (48.2):  72%|███████▏  | 715/1000 [00:49<00:23, 11.89it/s]2024-10-14T00:20:41.819556Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 368.0 / 779  (47.2):  78%|███████▊  | 779/1000 [00:53<00:13, 16.11it/s]2024-10-14T00:20:45.931738Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 384.0 / 814  (47.2):  81%|████████▏ | 814/1000 [00:56<00:12, 14.77it/s]2024-10-14T00:20:48.419486Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 388.0 / 822  (47.2):  82%|████████▏ | 821/1000 [00:56<00:12, 14.84it/s]2024-10-14T00:20:49.160869Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 399.0 / 845  (47.2):  84%|████████▍ | 844/1000 [00:58<00:08, 17.94it/s]2024-10-14T00:20:50.714067Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 426.0 / 901  (47.3):  90%|█████████ | 900/1000 [01:02<00:06, 14.74it/s] ilenameluate.evaluate3218Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] =evaluate.pylineno=198\n",
      "Average Metric: 437.0 / 929  (47.0):  93%|█████████▎| 928/1000 [01:04<00:03, 20.52it/s]2024-10-14T00:20:56.209519Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 455.0 / 963  (47.2):  96%|█████████▌| 962/1000 [01:06<00:01, 24.06it/s]2024-10-14T00:20:58.055904Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 475.0 / 1000  (47.5): 100%|██████████| 1000/1000 [01:06<00:00, 15.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for meta-llama/Llama-3.2-1B-Instruct:epochs-4-total-trained-steps-160: 47.5, None, None\n",
      "Evaluating openai/meta-llama/Llama-3.2-1B-Instruct:epochs-5-total-trained-steps-192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 164 / 819  (20.0):  82%|████████▏ | 818/1000 [01:17<00:15, 11.90it/s]2024-10-14T00:22:16.303204Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 190.0 / 1000  (19.0): 100%|██████████| 1000/1000 [01:32<00:00, 10.80it/s]\n",
      "Average Metric: 66 / 300  (22.0): 100%|██████████| 300/300 [00:25<00:00, 11.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 22.0 for seed -3\n",
      "Scores so far: [22.0]\n",
      "Best score so far: 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 66 / 300  (22.0): 100%|██████████| 300/300 [00:00<00:00, 1145.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [22.0, 22.0]\n",
      "Best score so far: 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 17/2758 [00:10<27:36,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 18 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:23:09.356007Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:01<05:40,  1.14s/it]2024-10-14T00:23:09.516471Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 50  (64.0):  16%|█▋        | 49/300 [00:04<00:11, 21.50it/s]2024-10-14T00:23:12.434852Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 96  (55.2):  32%|███▏      | 95/300 [00:06<00:13, 15.07it/s]2024-10-14T00:23:15.137852Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 55.0 / 103  (53.4):  34%|███▍      | 102/300 [00:07<00:12, 16.40it/s]2024-10-14T00:23:15.606756Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 101.0 / 199  (50.8):  66%|██████▌   | 198/300 [00:14<00:09, 10.33it/s]2024-10-14T00:23:22.475523Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 122.0 / 238  (51.3):  79%|███████▉  | 238/300 [00:16<00:03, 15.92it/s]2024-10-14T00:23:25.044090Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 163.0 / 300  (54.3): 100%|██████████| 300/300 [00:18<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 54.33 for seed -1\n",
      "Scores so far: [22.0, 22.0, 54.33]\n",
      "Best score so far: 54.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2758 [00:02<25:43,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:23:31.203993Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:01<06:08,  1.23s/it]2024-10-14T00:23:31.596362Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 50  (50.0):  17%|█▋        | 50/300 [00:03<00:16, 15.51it/s]2024-10-14T00:23:33.897815Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 104.0 / 249  (41.8):  83%|████████▎ | 248/300 [00:15<00:02, 18.56it/s]2024-10-14T00:23:45.307386Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 130.0 / 300  (43.3): 100%|██████████| 300/300 [00:16<00:00, 18.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [22.0, 22.0, 54.33, 43.33]\n",
      "Best score so far: 54.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2758 [00:06<32:42,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 83 / 300  (27.7): 100%|██████████| 300/300 [00:19<00:00, 15.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [22.0, 22.0, 54.33, 43.33, 27.67]\n",
      "Best score so far: 54.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2758 [00:00<22:01,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 72 / 300  (24.0): 100%|██████████| 300/300 [00:20<00:00, 14.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [22.0, 22.0, 54.33, 43.33, 27.67, 24.0]\n",
      "Best score so far: 54.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2758 [00:05<32:08,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 94 / 300  (31.3): 100%|██████████| 300/300 [00:14<00:00, 20.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [22.0, 22.0, 54.33, 43.33, 27.67, 24.0, 31.33]\n",
      "Best score so far: 54.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2758 [00:01<25:02,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29 / 300  (9.7): 100%|██████████| 300/300 [00:18<00:00, 15.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [22.0, 22.0, 54.33, 43.33, 27.67, 24.0, 31.33, 9.67]\n",
      "Best score so far: 54.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2758 [00:06<29:20,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:25:22.603005Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<04:47,  1.04it/s]2024-10-14T00:25:22.803124Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 50  (42.0):  17%|█▋        | 50/300 [00:03<00:13, 17.90it/s]2024-10-14T00:25:25.031923Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 41.0 / 102  (40.2):  34%|███▍      | 102/300 [00:06<00:12, 15.30it/s]2024-10-14T00:25:27.921415Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 152  (35.5):  50%|█████     | 151/300 [00:09<00:11, 13.33it/s]2024-10-14T00:25:30.722153Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 193  (38.9):  64%|██████▍   | 192/300 [00:10<00:05, 18.23it/s]dspy.evaluate.evaluate1071Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 102.0 / 244  (41.8):  81%|████████  | 243/300 [00:13<00:03, 18.54it/s]2024-10-14T00:25:35.255390Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 134.0 / 300  (44.7): 100%|██████████| 300/300 [00:14<00:00, 20.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [22.0, 22.0, 54.33, 43.33, 27.67, 24.0, 31.33, 9.67, 44.67]\n",
      "Best score so far: 54.33\n",
      "9 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]2024-10-14T00:25:38.052995Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 154  (51.3):  15%|█▌        | 153/1000 [00:11<01:01, 13.83it/s]2024-10-14T00:25:48.243043Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 84.0 / 164  (51.2):  16%|█▋        | 164/1000 [00:11<00:52, 16.02it/s]2024-10-14T00:25:48.680122Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 88.0 / 182  (48.4):  18%|█▊        | 181/1000 [00:12<00:55, 14.66it/s]2024-10-14T00:25:49.836098Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 136.0 / 266  (51.1):  27%|██▋       | 266/1000 [00:19<00:53, 13.81it/s]2024-10-14T00:25:56.500783Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 140.0 / 282  (49.6):  28%|██▊       | 281/1000 [00:20<00:38, 18.59it/s]2024-10-14T00:25:57.493349Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 141.0 / 287  (49.1):  29%|██▊       | 286/1000 [00:20<00:57, 12.37it/s]2024-10-14T00:25:57.887023Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 157.0 / 318  (49.4):  32%|███▏      | 317/1000 [00:23<00:46, 14.79it/s]2024-10-14T00:26:00.055713Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 183.0 / 370  (49.5):  37%|███▋      | 370/1000 [00:27<01:25,  7.39it/s]2024-10-14T00:26:04.818996Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 195.0 / 391  (49.9):  39%|███▉      | 390/1000 [00:29<00:43, 14.10it/s]2024-10-14T00:26:06.190298Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 204.0 / 414  (49.3):  41%|████▏     | 414/1000 [00:30<00:36, 16.16it/s]2024-10-14T00:26:07.907514Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 268.0 / 536  (50.0):  54%|█████▎    | 535/1000 [00:40<00:36, 12.69it/s]2024-10-14T00:26:17.214297Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 291.0 / 574  (50.7):  57%|█████▋    | 573/1000 [00:42<00:35, 12.12it/s]2024-10-14T00:26:19.896268Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 327.0 / 635  (51.5):  63%|██████▎   | 634/1000 [00:47<00:27, 13.51it/s]2024-10-14T00:26:24.253209Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 332.0 / 648  (51.2):  65%|██████▍   | 647/1000 [00:48<00:29, 12.02it/s]dspy.evaluate.evaluate7577Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 357.0 / 704  (50.7):  70%|███████   | 703/1000 [00:52<00:35,  8.47it/s]2024-10-14T00:26:29.790339Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 357.0 / 709  (50.4):  71%|███████   | 708/1000 [00:53<00:27, 10.46it/s]2024-10-14T00:26:30.127730Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 382.0 / 771  (49.5):  77%|███████▋  | 771/1000 [00:57<00:18, 12.06it/s]2024-10-14T00:26:34.949182Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 400.0 / 806  (49.6):  81%|████████  | 806/1000 [01:00<00:14, 13.18it/s]2024-10-14T00:26:37.268246Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 411.0 / 821  (50.1):  82%|████████▏ | 820/1000 [01:01<00:10, 17.91it/s]2024-10-14T00:26:38.165587Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 431.0 / 864  (49.9):  86%|████████▋ | 863/1000 [01:04<00:14,  9.66it/s]filename14T00:26:41.199123Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 442.0 / 889  (49.7):  89%|████████▉ | 889/1000 [01:05<00:06, 16.79it/s]2024-10-14T00:26:42.978587Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 478.0 / 955  (50.1):  95%|█████████▌| 954/1000 [01:08<00:00, 50.40it/s]2024-10-14T00:26:48.568408Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 478.0 / 956  (50.0):  96%|█████████▌| 955/1000 [01:11<00:00, 50.40it/s]2024-10-14T00:26:48.641347Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 502.0 / 1000  (50.2): 100%|██████████| 1000/1000 [01:12<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for meta-llama/Llama-3.2-1B-Instruct:epochs-5-total-trained-steps-192: 50.2, None, None\n",
      "Evaluating openai/meta-llama/Llama-3.2-1B-Instruct:epochs-2-total-trained-steps-96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 3  (66.7):   0%|          | 2/1000 [00:04<30:34,  1.84s/it]   2024-10-14T00:26:54.116298Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 91.0 / 550  (16.5):  55%|█████▌    | 550/1000 [00:53<00:44, 10.12it/s]2024-10-14T00:27:43.566253Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 114.0 / 695  (16.4):  69%|██████▉   | 694/1000 [01:07<00:27, 11.24it/s]2024-10-14T00:27:57.226431Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 125.0 / 784  (15.9):  78%|███████▊  | 784/1000 [01:16<00:21,  9.87it/s]2024-10-14T00:28:05.894534Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 144.0 / 929  (15.5):  93%|█████████▎| 929/1000 [01:30<00:05, 13.03it/s]2024-10-14T00:28:19.928702Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 152.0 / 1000  (15.2): 100%|██████████| 1000/1000 [01:35<00:00, 10.42it/s]\n",
      "Average Metric: 20 / 138  (14.5):  46%|████▌     | 137/300 [00:14<00:16,  9.63it/s]2024-10-14T00:28:40.316580Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 300  (14.7): 100%|██████████| 300/300 [00:28<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 14.67 for seed -3\n",
      "Scores so far: [14.67]\n",
      "Best score so far: 14.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 2  (0.0):   0%|          | 1/300 [00:00<00:00, 480.56it/s]ted ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno=198\n",
      "Average Metric: 44.0 / 300  (14.7): 100%|██████████| 300/300 [00:00<00:00, 1134.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.67, 14.67]\n",
      "Best score so far: 14.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2758 [00:05<30:32,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:29:01.642238Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:01<05:04,  1.02s/it]2024-10-14T00:29:01.811205Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 54  (44.4):  18%|█▊        | 53/300 [00:03<00:12, 19.32it/s]2024-10-14T00:29:04.379489Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 64  (43.8):  21%|██▏       | 64/300 [00:04<00:16, 14.42it/s]2024-10-14T00:29:05.044164Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 37.0 / 86  (43.0):  28%|██▊       | 85/300 [00:05<00:13, 16.47it/s]filename14T00:29:06.417430Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 43.0 / 108  (39.8):  36%|███▌      | 107/300 [00:06<00:12, 16.03it/s]2024-10-14T00:29:07.889393Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 66.0 / 165  (40.0):  55%|█████▍    | 164/300 [00:10<00:08, 15.32it/s]=spy.evaluate.evaluate5176Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno198\n",
      "Average Metric: 84.0 / 206  (40.8):  69%|██████▊   | 206/300 [00:13<00:05, 17.22it/s]2024-10-14T00:29:13.701836Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 221  (38.9):  73%|███████▎  | 220/300 [00:14<00:05, 15.56it/s]2024-10-14T00:29:14.732085Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 103.0 / 246  (41.9):  82%|████████▏ | 245/300 [00:15<00:03, 16.36it/s]2024-10-14T00:29:16.131796Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 128.0 / 300  (42.7): 100%|██████████| 300/300 [00:18<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 42.67 for seed -1\n",
      "Scores so far: [14.67, 14.67, 42.67]\n",
      "Best score so far: 42.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2758 [00:04<32:23,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:29:25.079548Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 122.0 / 300  (40.7): 100%|██████████| 300/300 [00:18<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.67, 14.67, 42.67, 40.67]\n",
      "Best score so far: 42.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2758 [00:05<33:42,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 66 / 300  (22.0): 100%|██████████| 300/300 [00:13<00:00, 21.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.67, 14.67, 42.67, 40.67, 22.0]\n",
      "Best score so far: 42.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2758 [00:01<24:22,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 78 / 300  (26.0): 100%|██████████| 300/300 [00:17<00:00, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.67, 14.67, 42.67, 40.67, 22.0, 26.0]\n",
      "Best score so far: 42.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2758 [00:09<56:36,  1.24s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 74 / 300  (24.7): 100%|██████████| 300/300 [00:15<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.67, 14.67, 42.67, 40.67, 22.0, 26.0, 24.67]\n",
      "Best score so far: 42.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2758 [00:00<21:30,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 34 / 300  (11.3): 100%|██████████| 300/300 [00:17<00:00, 17.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.67, 14.67, 42.67, 40.67, 22.0, 26.0, 24.67, 11.33]\n",
      "Best score so far: 42.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2758 [00:06<27:43,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:31:13.606367Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<02:01,  2.45it/s]2024-10-14T00:31:14.396260Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 56  (39.3):  18%|█▊        | 55/300 [00:04<00:17, 14.22it/s]2024-10-14T00:31:17.434711Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 37.0 / 105  (35.2):  35%|███▌      | 105/300 [00:06<00:10, 18.31it/s]1984-10-14T00:31:19.856578Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 54.0 / 161  (33.5):  53%|█████▎    | 160/300 [00:09<00:08, 16.28it/s]2024-10-14T00:31:22.920775Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 70.0 / 196  (35.7):  65%|██████▌   | 196/300 [00:11<00:04, 24.01it/s]2024-10-14T00:31:24.786014Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 120.0 / 300  (40.0): 100%|██████████| 300/300 [00:15<00:00, 19.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.67, 14.67, 42.67, 40.67, 22.0, 26.0, 24.67, 11.33, 40.0]\n",
      "Best score so far: 42.67\n",
      "9 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]2024-10-14T00:31:30.547148Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/1000 [00:01<18:35,  1.12s/it]14T00:31:30.560911Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/1000 [00:01<18:35,  1.12s/it]2024-10-14T00:31:30.921104Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 47  (31.9):   5%|▍         | 47/1000 [00:03<00:35, 26.79it/s]2024-10-14T00:31:32.552942Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 52  (32.7):   5%|▌         | 51/1000 [00:03<00:52, 17.93it/s]2024-10-14T00:31:33.004027Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 150  (42.7):  15%|█▍        | 149/1000 [00:09<00:49, 17.20it/s]2024-10-14T00:31:38.772282Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 153  (42.5):  15%|█▌        | 153/1000 [00:09<00:59, 14.18it/s]2024-10-14T00:31:38.970404Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 69.0 / 163  (42.3):  16%|█▌        | 162/1000 [00:10<01:03, 13.25it/s]]024-10-14T00:31:39.402891Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 192  (39.1):  19%|█▉        | 192/1000 [00:11<00:37, 21.80it/s]][24-10-14T00:31:40.950734Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 113.0 / 267  (42.3):  27%|██▋       | 266/1000 [00:15<00:45, 16.24it/s]2024-10-14T00:31:45.345487Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 120.0 / 296  (40.5):  30%|██▉       | 295/1000 [00:17<00:48, 14.59it/s] [24-10-14T00:31:47.124982Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 128.0 / 321  (39.9):  32%|███▏      | 321/1000 [00:19<00:39, 17.34it/s]2024-10-14T00:31:48.681461Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 143.0 / 347  (41.2):  35%|███▍      | 346/1000 [00:20<00:33, 19.51it/s]2024-10-14T00:31:49.962766Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 163.0 / 389  (41.9):  39%|███▉      | 388/1000 [00:23<00:33, 18.03it/s]2024-10-14T00:31:52.536848Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 172.0 / 417  (41.2):  42%|████▏     | 417/1000 [00:24<00:39, 14.93it/s]2024-10-14T00:31:54.840348Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 189.0 / 454  (41.6):  45%|████▌     | 453/1000 [00:26<00:13, 39.77it/s]2024-10-14T00:31:55.623884Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 189.0 / 459  (41.2):  46%|████▌     | 458/1000 [00:26<00:14, 37.57it/s]2024-10-14T00:31:55.936239Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 226.0 / 556  (40.6):  56%|█████▌    | 555/1000 [00:31<00:21, 21.04it/s]2024-10-14T00:32:01.365175Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 251.0 / 616  (40.7):  62%|██████▏   | 615/1000 [00:35<00:20, 18.62it/s]2024-10-14T00:32:05.097263Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 260.0 / 642  (40.5):  64%|██████▍   | 641/1000 [00:37<00:18, 19.18it/s]2024-10-14T00:32:06.503998Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 261.0 / 647  (40.3):  65%|██████▍   | 647/1000 [00:37<00:16, 20.83it/s]2024-10-14T00:32:06.831443Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 265.0 / 661  (40.1):  66%|██████▌   | 660/1000 [00:38<00:23, 14.31it/s]2024-10-14T00:32:07.840669Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 281.0 / 706  (39.8):  70%|███████   | 705/1000 [00:41<00:18, 16.18it/s]evaluate.py00:32:10.547187Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 287.0 / 722  (39.8):  72%|███████▏  | 721/1000 [00:41<00:17, 16.10it/s]2024-10-14T00:32:11.452398Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 309.0 / 782  (39.5):  78%|███████▊  | 781/1000 [00:45<00:14, 15.32it/s]2024-10-14T00:32:15.304364Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 326.0 / 815  (40.0):  81%|████████▏ | 814/1000 [00:47<00:11, 16.52it/s]2024-10-14T00:32:16.992089Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 330.0 / 822  (40.1):  82%|████████▏ | 821/1000 [00:47<00:07, 23.09it/s]2024-10-14T00:32:17.167717Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 334.0 / 830  (40.2):  83%|████████▎ | 830/1000 [00:48<00:07, 23.00it/s]2024-10-14T00:32:17.826132Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 343.0 / 858  (40.0):  86%|████████▌ | 857/1000 [00:50<00:10, 13.14it/s]dspy.evaluate.evaluate3161Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 355.0 / 894  (39.7):  89%|████████▉ | 893/1000 [00:52<00:08, 12.54it/s]2024-10-14T00:32:21.575357Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 376.0 / 957  (39.3):  96%|█████████▌| 956/1000 [00:55<00:02, 18.19it/s]2024-10-14T00:32:24.985062Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 391.0 / 992  (39.4):  99%|█████████▉| 992/1000 [00:55<00:00, 64.46it/s]2024-10-14T00:32:25.383175Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 393.0 / 999  (39.3): 100%|█████████▉| 998/1000 [00:56<00:00, 64.46it/s]2024-10-14T00:32:25.463070Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 393.0 / 1000  (39.3): 100%|██████████| 1000/1000 [00:56<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for meta-llama/Llama-3.2-1B-Instruct:epochs-2-total-trained-steps-96: 39.3, None, None\n",
      "Evaluating openai/meta-llama/Llama-3.2-1B-Instruct:epochs-0-total-trained-steps-32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0):   0%|          | 0/1000 [00:00<?, ?it/s]2024-10-14T00:32:29.378114Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 2  (50.0):   0%|          | 2/1000 [00:03<30:06,  1.81s/it]  2024-10-14T00:32:29.404290Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 5  (40.0):   0%|          | 5/1000 [00:03<10:06,  1.64it/s]2024-10-14T00:32:29.544841Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 6  (33.3):   0%|          | 5/1000 [00:03<10:06,  1.64it/s]2024-10-14T00:32:29.756067Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 13  (38.5):   1%|          | 12/1000 [00:04<03:24,  4.83it/s]evaluate.py00:32:30.084703Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 5.0 / 27  (18.5):   3%|▎         | 26/1000 [00:04<01:27, 11.16it/s]2024-10-14T00:32:30.777419Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 35  (14.3):   3%|▎         | 34/1000 [00:05<01:03, 15.27it/s]2024-10-14T00:32:31.701266Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 39  (15.4):   4%|▍         | 38/1000 [00:06<01:32, 10.43it/s]][24-10-14T00:32:31.750861Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 44  (15.9):   4%|▍         | 44/1000 [00:06<01:15, 12.71it/s]198eno0-14T00:32:32.129977Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =\n",
      "Average Metric: 12.0 / 57  (21.1):   6%|▌         | 57/1000 [00:07<01:21, 11.52it/s]2024-10-14T00:32:33.284337Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 60  (21.7):   6%|▌         | 59/1000 [00:07<01:27, 10.70it/s]2024-10-14T00:32:33.516746Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 61  (21.3):   6%|▌         | 60/1000 [00:07<01:27, 10.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 74  (25.7):   7%|▋         | 74/1000 [00:08<01:04, 14.31it/s]2024-10-14T00:32:34.509076Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 75  (25.3):   7%|▋         | 74/1000 [00:08<01:04, 14.31it/s]2024-10-14T00:32:34.520465Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 84  (23.8):   8%|▊         | 84/1000 [00:09<01:10, 13.06it/s]]024-10-14T00:32:35.273378Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 92  (22.8):   9%|▉         | 92/1000 [00:10<01:09, 13.15it/s]][24-10-14T00:32:35.867171Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 107  (23.4):  11%|█         | 106/1000 [00:10<00:57, 15.45it/s] 024-10-14T00:32:36.628356Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 25.0 / 108  (23.1):  11%|█         | 107/1000 [00:10<00:57, 15.45it/s]2024-10-14T00:32:36.636181Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 119  (21.8):  12%|█▏        | 118/1000 [00:11<01:10, 12.48it/s]=024-10-14T00:32:37.616325Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 28.0 / 123  (22.8):  12%|█▏        | 122/1000 [00:12<01:06, 13.27it/s]1984-10-14T00:32:37.844434Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 29.0 / 125  (23.2):  12%|█▏        | 124/1000 [00:12<01:05, 13.27it/s]2024-10-14T00:32:37.974406Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 29.0 / 128  (22.7):  13%|█▎        | 128/1000 [00:12<01:01, 14.19it/s]1984-10-14T00:32:38.211347Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 29.0 / 130  (22.3):  13%|█▎        | 129/1000 [00:12<01:01, 14.19it/s]2024-10-14T00:32:38.251945Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 143  (21.7):  14%|█▍        | 142/1000 [00:13<01:12, 11.83it/s]2024-10-14T00:32:39.473372Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 164  (20.1):  16%|█▋        | 163/1000 [00:15<01:17, 10.84it/s]2024-10-14T00:32:40.879908Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 168  (19.6):  17%|█▋        | 167/1000 [00:15<01:07, 12.31it/s]2024-10-14T00:32:41.153719Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 172  (19.2):  17%|█▋        | 172/1000 [00:15<01:03, 13.02it/s]dspy.evaluate.evaluate0133Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 174  (19.0):  17%|█▋        | 174/1000 [00:15<01:02, 13.22it/s]2024-10-14T00:32:41.670740Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 181  (18.2):  18%|█▊        | 181/1000 [00:16<00:48, 17.03it/s] 024-10-14T00:32:42.020722Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 212  (17.0):  21%|██        | 211/1000 [00:18<01:01, 12.77it/s]2024-10-14T00:32:44.072359Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 37.0 / 215  (17.2):  22%|██▏       | 215/1000 [00:18<00:31, 24.79it/s]2024-10-14T00:32:44.116766Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 223  (17.0):  22%|██▏       | 223/1000 [00:19<00:47, 16.31it/s]2024-10-14T00:32:45.018296Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 224  (17.0):  22%|██▏       | 223/1000 [00:19<00:47, 16.31it/s]2024-10-14T00:32:45.063426Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 43.0 / 256  (16.8):  26%|██▌       | 255/1000 [00:21<00:54, 13.64it/s]2024-10-14T00:32:47.084752Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 45.0 / 264  (17.0):  26%|██▋       | 263/1000 [00:21<00:50, 14.58it/s]2024-10-14T00:32:47.798280Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 45.0 / 273  (16.5):  27%|██▋       | 272/1000 [00:22<00:56, 12.97it/s] 024-10-14T00:32:48.231346Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 45.0 / 278  (16.2):  28%|██▊       | 278/1000 [00:22<00:56, 12.88it/s]2024-10-14T00:32:48.790468Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 282  (16.3):  28%|██▊       | 281/1000 [00:23<01:04, 11.08it/s]2024-10-14T00:32:49.071459Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 283  (16.3):  28%|██▊       | 282/1000 [00:23<01:04, 11.08it/s]2024-10-14T00:32:49.089174Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 286  (16.1):  28%|██▊       | 285/1000 [00:23<01:02, 11.39it/s]2024-10-14T00:32:49.479609Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 298  (15.8):  30%|██▉       | 298/1000 [00:24<00:47, 14.63it/s]2024-10-14T00:32:50.447680Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 317  (15.8):  32%|███▏      | 317/1000 [00:26<00:56, 12.05it/s]2024-10-14T00:32:51.949363Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 318  (15.7):  32%|███▏      | 317/1000 [00:26<00:56, 12.05it/s]2024-10-14T00:32:52.210523Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 51.0 / 321  (15.9):  32%|███▏      | 320/1000 [00:26<01:03, 10.75it/s]2024-10-14T00:32:52.236192Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 51.0 / 326  (15.6):  32%|███▎      | 325/1000 [00:26<00:55, 12.16it/s]2024-10-14T00:32:52.626066Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 346  (16.2):  34%|███▍      | 345/1000 [00:28<01:04, 10.22it/s]2024-10-14T00:32:54.300272Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 354  (16.1):  35%|███▌      | 353/1000 [00:29<01:07,  9.57it/s]2024-10-14T00:32:55.053744Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 58.0 / 364  (15.9):  36%|███▋      | 363/1000 [00:30<00:56, 11.35it/s]2024-10-14T00:32:55.862572Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 58.0 / 365  (15.9):  36%|███▋      | 364/1000 [00:30<00:56, 11.35it/s]2024-10-14T00:32:55.976191Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 381  (15.7):  38%|███▊      | 381/1000 [00:31<00:37, 16.38it/s]2024-10-14T00:32:57.317436Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 61.0 / 393  (15.5):  39%|███▉      | 393/1000 [00:33<01:16,  7.90it/s]2024-10-14T00:32:58.915323Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 395  (15.7):  39%|███▉      | 394/1000 [00:33<01:16,  7.90it/s]filename   ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 63.0 / 403  (15.6):  40%|████      | 403/1000 [00:34<01:02,  9.48it/s]2024-10-14T00:32:59.799653Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 63.0 / 411  (15.3):  41%|████      | 410/1000 [00:34<00:48, 12.25it/s]2024-10-14T00:33:00.553658Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 418  (15.3):  42%|████▏     | 417/1000 [00:35<01:04,  9.11it/s]2024-10-14T00:33:01.345295Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 67.0 / 438  (15.3):  44%|████▎     | 437/1000 [00:37<00:42, 13.13it/s]2024-10-14T00:33:03.240053Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 69.0 / 443  (15.6):  44%|████▍     | 443/1000 [00:37<00:52, 10.54it/s]2024-10-14T00:33:03.800742Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 69.0 / 446  (15.5):  44%|████▍     | 445/1000 [00:38<00:58,  9.52it/s]filename14T00:33:03.847724Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 70.0 / 457  (15.3):  46%|████▌     | 457/1000 [00:39<00:46, 11.77it/s]2024-10-14T00:33:04.869277Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 464  (15.3):  46%|████▋     | 463/1000 [00:39<00:55,  9.67it/s]2024-10-14T00:33:05.546956Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 472  (15.0):  47%|████▋     | 471/1000 [00:40<00:52, 10.04it/s]2024-10-14T00:33:06.241692Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 477  (14.9):  48%|████▊     | 476/1000 [00:40<00:52, 10.02it/s]2024-10-14T00:33:06.679456Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 478  (14.9):  48%|████▊     | 477/1000 [00:40<00:52, 10.02it/s]2024-10-14T00:33:06.771908Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 481  (14.8):  48%|████▊     | 481/1000 [00:41<00:55,  9.33it/s]2024-10-14T00:33:07.207535Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 484  (14.7):  48%|████▊     | 483/1000 [00:41<00:59,  8.65it/s]2024-10-14T00:33:07.464716Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 73.0 / 509  (14.3):  51%|█████     | 508/1000 [00:43<00:46, 10.67it/s]2024-10-14T00:33:09.969455Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 73.0 / 510  (14.3):  51%|█████     | 510/1000 [00:44<00:48, 10.17it/s]2024-10-14T00:33:09.991666Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 516  (14.5):  52%|█████▏    | 516/1000 [00:44<01:01,  7.86it/s]2024-10-14T00:33:10.774185Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 77.0 / 539  (14.3):  54%|█████▍    | 538/1000 [00:47<00:55,  8.31it/s]2024-10-14T00:33:13.011957Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 78.0 / 545  (14.3):  54%|█████▍    | 544/1000 [00:47<00:44, 10.29it/s]2024-10-14T00:33:13.579962Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 551  (14.3):  55%|█████▌    | 551/1000 [00:48<00:34, 13.20it/s] [24-10-14T00:33:13.962987Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 552  (14.3):  55%|█████▌    | 551/1000 [00:48<00:34, 13.20it/s]2024-10-14T00:33:13.985003Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 557  (14.4):  56%|█████▌    | 556/1000 [00:48<00:44,  9.92it/s]1984-10-14T00:33:14.438664Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 81.0 / 562  (14.4):  56%|█████▌    | 561/1000 [00:49<00:42, 10.22it/s]2024-10-14T00:33:15.225401Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 569  (14.2):  57%|█████▋    | 569/1000 [00:50<00:43,  9.80it/s]2024-10-14T00:33:15.866434Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 570  (14.2):  57%|█████▋    | 569/1000 [00:50<00:43,  9.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 571  (14.2):  57%|█████▋    | 570/1000 [00:50<00:43,  9.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 579  (14.0):  58%|█████▊    | 578/1000 [00:50<00:31, 13.23it/s]2024-10-14T00:33:16.456059Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 82.0 / 584  (14.0):  58%|█████▊    | 584/1000 [00:51<00:33, 12.36it/s]2024-10-14T00:33:16.932950Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 83.0 / 588  (14.1):  59%|█████▉    | 588/1000 [00:51<00:50,  8.09it/s]2024-10-14T00:33:17.632458Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 85.0 / 606  (14.0):  60%|██████    | 605/1000 [00:52<00:16, 24.63it/s]2024-10-14T00:33:17.877276Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 88.0 / 617  (14.3):  62%|██████▏   | 616/1000 [00:53<00:29, 13.16it/s] ilename14T00:33:18.977389Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.pylineno=198\n",
      "Average Metric: 89.0 / 624  (14.3):  62%|██████▏   | 624/1000 [00:53<00:32, 11.63it/s]2024-10-14T00:33:19.754484Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 90.0 / 629  (14.3):  63%|██████▎   | 628/1000 [00:54<00:35, 10.57it/s] 024-10-14T00:33:20.034772Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 95.0 / 654  (14.5):  65%|██████▌   | 654/1000 [00:56<00:32, 10.69it/s]2024-10-14T00:33:22.383588Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 96.0 / 668  (14.4):  67%|██████▋   | 667/1000 [00:58<00:33,  9.90it/s]2024-10-14T00:33:23.992768Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 101.0 / 680  (14.9):  68%|██████▊   | 680/1000 [00:59<00:31, 10.26it/s]2024-10-14T00:33:25.034514Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 101.0 / 689  (14.7):  69%|██████▉   | 688/1000 [00:59<00:25, 12.15it/s]2024-10-14T00:33:25.689807Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 102.0 / 699  (14.6):  70%|██████▉   | 699/1000 [01:00<00:21, 13.90it/s]2024-10-14T00:33:26.644876Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 104.0 / 704  (14.8):  70%|███████   | 703/1000 [01:01<00:31,  9.33it/s]2024-10-14T00:33:27.072656Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 104.0 / 708  (14.7):  71%|███████   | 708/1000 [01:01<00:29,  9.74it/s]2024-10-14T00:33:27.540429Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 104.0 / 709  (14.7):  71%|███████   | 708/1000 [01:01<00:29,  9.74it/s]2024-10-14T00:33:27.656640Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 104.0 / 719  (14.5):  72%|███████▏  | 718/1000 [01:02<00:30,  9.19it/s]2024-10-14T00:33:28.236292Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 104.0 / 720  (14.4):  72%|███████▏  | 719/1000 [01:02<00:30,  9.19it/s]2024-10-14T00:33:28.339888Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 105.0 / 724  (14.5):  72%|███████▏  | 723/1000 [01:02<00:20, 13.21it/s]lineno0-14T00:33:28.623126Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 107.0 / 744  (14.4):  74%|███████▍  | 743/1000 [01:04<00:24, 10.42it/s]dspy.evaluate.evaluate8524Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 108.0 / 747  (14.5):  75%|███████▍  | 747/1000 [01:05<00:22, 11.08it/s]2024-10-14T00:33:30.865933Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 108.0 / 753  (14.3):  75%|███████▌  | 753/1000 [01:05<00:29,  8.51it/s]1984-10-14T00:33:31.627379Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 109.0 / 758  (14.4):  76%|███████▌  | 757/1000 [01:05<00:28,  8.51it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 109.0 / 762  (14.3):  76%|███████▌  | 761/1000 [01:06<00:14, 16.03it/s]dspy.evaluate.evaluate2880Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 109.0 / 764  (14.3):  76%|███████▋  | 763/1000 [01:06<00:14, 16.03it/s]dspy.evaluate.evaluatexample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 112.0 / 771  (14.5):  77%|███████▋  | 771/1000 [01:06<00:15, 14.98it/s] [24-10-14T00:33:32.408144Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 112.0 / 772  (14.5):  77%|███████▋  | 771/1000 [01:06<00:15, 14.98it/s]2024-10-14T00:33:32.636658Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 112.0 / 776  (14.4):  78%|███████▊  | 776/1000 [01:07<00:15, 14.28it/s]2024-10-14T00:33:32.812404Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 115.0 / 786  (14.6):  78%|███████▊  | 785/1000 [01:07<00:19, 10.97it/s]2024-10-14T00:33:33.508330Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 116.0 / 791  (14.7):  79%|███████▉  | 790/1000 [01:08<00:11, 18.70it/s]2024-10-14T00:33:33.884542Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 116.0 / 792  (14.6):  79%|███████▉  | 792/1000 [01:08<00:13, 15.56it/s]2024-10-14T00:33:34.119157Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 117.0 / 806  (14.5):  81%|████████  | 806/1000 [01:09<00:17, 11.38it/s]2024-10-14T00:33:35.209518Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 121.0 / 816  (14.8):  82%|████████▏ | 816/1000 [01:10<00:19,  9.55it/s]2024-10-14T00:33:36.160616Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 122.0 / 822  (14.8):  82%|████████▏ | 821/1000 [01:10<00:17,  9.96it/s]2024-10-14T00:33:36.487688Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 122.0 / 825  (14.8):  82%|████████▏ | 824/1000 [01:11<00:12, 14.60it/s]2024-10-14T00:33:36.836814Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 126.0 / 839  (15.0):  84%|████████▍ | 839/1000 [01:12<00:17,  9.07it/s]2024-10-14T00:33:38.159953Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 126.0 / 844  (14.9):  84%|████████▍ | 843/1000 [01:12<00:15, 10.40it/s]2024-10-14T00:33:38.457432Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 128.0 / 854  (15.0):  85%|████████▌ | 854/1000 [01:13<00:13, 11.19it/s]2024-10-14T00:33:39.290118Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 129.0 / 858  (15.0):  86%|████████▌ | 857/1000 [01:13<00:13, 10.94it/s]2024-10-14T00:33:39.711505Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 129.0 / 873  (14.8):  87%|████████▋ | 872/1000 [01:15<00:09, 12.95it/s]2024-10-14T00:33:41.031020Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 129.0 / 882  (14.6):  88%|████████▊ | 881/1000 [01:16<00:12,  9.44it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 131.0 / 902  (14.5):  90%|█████████ | 901/1000 [01:18<00:10,  9.32it/s]2024-10-14T00:33:43.924327Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 134.0 / 911  (14.7):  91%|█████████ | 910/1000 [01:18<00:07, 11.97it/s]2024-10-14T00:33:44.492198Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 138.0 / 936  (14.7):  94%|█████████▎| 936/1000 [01:20<00:03, 17.67it/s]2024-10-14T00:33:46.255258Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 140.0 / 945  (14.8):  94%|█████████▍| 944/1000 [01:21<00:03, 18.54it/s]2024-10-14T00:33:46.830858Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 141.0 / 947  (14.9):  95%|█████████▍| 946/1000 [01:21<00:03, 16.36it/s]2024-10-14T00:33:47.097605Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 145.0 / 960  (15.1):  96%|█████████▌| 959/1000 [01:21<00:02, 19.18it/s]=024-10-14T00:33:47.681493Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 145.0 / 965  (15.0):  96%|█████████▋| 964/1000 [01:21<00:01, 19.18it/s]2024-10-14T00:33:47.737765Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 148.0 / 996  (14.9): 100%|█████████▉| 995/1000 [01:26<00:01,  3.67it/s]2024-10-14T00:33:52.722241Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 148.0 / 998  (14.8): 100%|█████████▉| 998/1000 [01:27<00:00,  3.42it/s]2024-10-14T00:33:53.298284Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 148.0 / 1000  (14.8): 100%|██████████| 1000/1000 [01:28<00:00, 11.32it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:33:55.196434Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<04:06,  1.21it/s]2024-10-14T00:33:55.221594Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/300 [00:00<04:06,  1.21it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 2/300 [00:00<04:05,  1.21it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   2%|▏         | 7/300 [00:01<00:42,  6.90it/s]2024-10-14T00:33:55.602679Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 9  (11.1):   3%|▎         | 8/300 [00:01<00:42,  6.90it/s]2024-10-14T00:33:55.646670Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 22  (36.4):   7%|▋         | 21/300 [00:01<00:15, 18.29it/s]2024-10-14T00:33:56.402347Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 33  (30.3):  11%|█         | 33/300 [00:02<00:13, 19.51it/s]2024-10-14T00:33:56.923478Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 37  (29.7):  12%|█▏        | 36/300 [00:02<00:15, 17.19it/s]2024-10-14T00:33:57.185612Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 39  (28.2):  13%|█▎        | 39/300 [00:03<00:16, 15.59it/s]2024-10-14T00:33:57.547627Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 44  (27.3):  14%|█▍        | 43/300 [00:03<00:17, 14.48it/s] 024-10-14T00:33:57.719613Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 54  (24.1):  18%|█▊        | 54/300 [00:04<00:19, 12.47it/s]2024-10-14T00:33:58.628476Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 66  (22.7):  22%|██▏       | 65/300 [00:04<00:16, 14.06it/s]2024-10-14T00:33:59.324886Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 67  (22.4):  22%|██▏       | 66/300 [00:04<00:16, 14.06it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 68  (22.1):  22%|██▏       | 67/300 [00:04<00:16, 14.06it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 73  (23.3):  24%|██▍       | 72/300 [00:05<00:16, 13.72it/s]2024-10-14T00:33:59.857294Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 85  (22.4):  28%|██▊       | 84/300 [00:06<00:15, 13.62it/s]] 24-10-14T00:34:00.898011Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 89  (21.3):  29%|██▉       | 88/300 [00:06<00:21, 10.09it/s]2024-10-14T00:34:01.201022Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 104  (19.2):  34%|███▍      | 103/300 [00:07<00:18, 10.65it/s]2024-10-14T00:34:02.275647Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 107  (18.7):  35%|███▌      | 106/300 [00:08<00:12, 15.23it/s]2024-10-14T00:34:02.692596Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 112  (18.8):  37%|███▋      | 111/300 [00:08<00:17, 11.05it/s]]024-10-14T00:34:03.026609Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 121  (18.2):  40%|████      | 120/300 [00:09<00:16, 10.63it/s]2024-10-14T00:34:03.735777Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 122  (18.0):  40%|████      | 121/300 [00:09<00:16, 10.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 125  (17.6):  41%|████▏     | 124/300 [00:09<00:13, 12.86it/s]2024-10-14T00:34:04.243408Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 135  (16.3):  45%|████▍     | 134/300 [00:10<00:16,  9.85it/s]2024-10-14T00:34:05.011802Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 139  (16.5):  46%|████▌     | 138/300 [00:11<00:14, 11.25it/s]2024-10-14T00:34:05.537256Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 149  (16.1):  49%|████▉     | 148/300 [00:12<00:14, 10.76it/s]2024-10-14T00:34:06.489307Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 158  (15.8):  52%|█████▏    | 157/300 [00:12<00:15,  9.00it/s]2024-10-14T00:34:07.348851Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 164  (15.9):  54%|█████▍    | 163/300 [00:13<00:15,  8.63it/s]lineno0-14T00:34:07.935773Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py =198\n",
      "Average Metric: 26.0 / 172  (15.1):  57%|█████▋    | 171/300 [00:13<00:11, 11.36it/s]2024-10-14T00:34:08.391085Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 174  (14.9):  58%|█████▊    | 173/300 [00:14<00:08, 15.49it/s]]024-10-14T00:34:08.612291Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 175  (14.9):  58%|█████▊    | 175/300 [00:14<00:09, 13.44it/s]2024-10-14T00:34:08.665119Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 181  (15.5):  60%|██████    | 180/300 [00:14<00:08, 13.77it/s]2024-10-14T00:34:09.015431Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 182  (15.4):  60%|██████    | 181/300 [00:14<00:08, 13.77it/s]2024-10-14T00:34:09.263482Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 184  (15.2):  61%|██████    | 183/300 [00:14<00:09, 12.59it/s]2024-10-14T00:34:09.319230Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 193  (14.5):  64%|██████▍   | 192/300 [00:15<00:08, 13.27it/s]dspy.evaluate.evaluate2781Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 29.0 / 202  (14.4):  67%|██████▋   | 201/300 [00:16<00:07, 14.05it/s]1984-10-14T00:34:10.642989Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 30.0 / 209  (14.4):  70%|██████▉   | 209/300 [00:16<00:07, 12.52it/s]2024-10-14T00:34:11.217139Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 219  (14.2):  73%|███████▎  | 219/300 [00:17<00:05, 13.86it/s]2024-10-14T00:34:12.185627Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 231  (14.3):  77%|███████▋  | 231/300 [00:18<00:03, 18.28it/s]2024-10-14T00:34:12.688961Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 236  (14.4):  78%|███████▊  | 235/300 [00:18<00:04, 14.63it/s]2024-10-14T00:34:13.051568Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 239  (14.6):  79%|███████▉  | 238/300 [00:18<00:03, 16.99it/s]2024-10-14T00:34:13.175775Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 37.0 / 251  (14.7):  84%|████████▎ | 251/300 [00:19<00:03, 15.87it/s]2024-10-14T00:34:14.138722Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 271  (14.0):  90%|█████████ | 270/300 [00:20<00:00, 35.49it/s]2024-10-14T00:34:14.484388Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 39.0 / 279  (14.0):  93%|█████████▎| 279/300 [00:20<00:00, 35.40it/s]2024-10-14T00:34:14.754629Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 299  (14.0): 100%|█████████▉| 299/300 [00:26<00:00,  3.32it/s]dspy.evaluate.evaluate0219Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 300  (14.0): 100%|██████████| 300/300 [00:26<00:00, 11.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 14.0 for seed -3\n",
      "Scores so far: [14.0]\n",
      "Best score so far: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14T00:34:20.656421Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-14T00:34:20.659601Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-14T00:34:20.660622Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1 / 7  (14.3):   2%|▏         | 6/300 [00:00<00:00, 697.64it/s]198uate.pyin dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filename= lineno=\n",
      "Average Metric: 3 / 18  (16.7):   6%|▌         | 17/300 [00:00<00:00, 655.84it/s]198y.evaluate.evaluate73Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. []filenameevaluate.pylineno=\n",
      "Average Metric: 3.0 / 26  (11.5):   8%|▊         | 25/300 [00:00<00:00, 561.09it/s]198eno.py00:34:20.673015Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] = =\n",
      "Average Metric: 3.0 / 35  (8.6):  11%|█▏        | 34/300 [00:00<00:00, 567.29it/s] 2024-10-14T00:34:20.675018Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 3.0 / 43  (7.0):  14%|█▍        | 42/300 [00:00<00:00, 577.24it/s]198enameluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] =evaluate.py lineno=\n",
      "Average Metric: 5.0 / 51  (9.8):  17%|█▋        | 50/300 [00:00<00:00, 571.37it/s] spy.evaluate.evaluate4073Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. []filenameevaluate.pylineno=198\n",
      "Average Metric: 7.0 / 58  (12.1):  19%|█▉        | 58/300 [00:00<00:00, 573.60it/s]evaluate.py0:34:20.690735Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate = lineno=198\n",
      "Average Metric: 8.0 / 68  (11.8):  22%|██▏       | 67/300 [00:00<00:00, 573.60it/s]198enome14T00:34:20.702802Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate =evaluate.py =\n",
      "Average Metric: 9.0 / 77  (11.7):  25%|██▌       | 76/300 [00:00<00:00, 573.60it/s] spy.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. []filename=evaluate.pylineno=198\n",
      "Average Metric: 10.0 / 85  (11.8):  28%|██▊       | 84/300 [00:00<00:00, 573.60it/s]inenome14T00:34:20.707121Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py =198\n",
      "Average Metric: 10.0 / 93  (10.8):  31%|███       | 92/300 [00:00<00:00, 573.60it/s] ilename14T00:34:20.709472Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]=evaluate.pylineno=198\n",
      "Average Metric: 14.0 / 102  (13.7):  34%|███▎      | 101/300 [00:00<00:00, 573.60it/s]24-10-14T00:34:20.712246Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 112  (14.3):  37%|███▋      | 111/300 [00:00<00:00, 573.60it/s]198luate.py00:34:20.717855Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] = lineno=\n",
      "Average Metric: 16.0 / 119  (13.4):  39%|███▉      | 118/300 [00:00<00:00, 560.92it/s]= 24-10-14T00:34:20.720439Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 17.0 / 129  (13.2):  43%|████▎     | 128/300 [00:00<00:00, 560.92it/s]198enote.py00:34:20.725748Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename= =\n",
      "Average Metric: 20.0 / 140  (14.3):  46%|████▋     | 139/300 [00:00<00:00, 560.92it/s]=spy.evaluate.evaluate6286Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filenameevaluate.py lineno=198\n",
      "Average Metric: 21.0 / 148  (14.2):  49%|████▉     | 147/300 [00:00<00:00, 560.92it/s]dspy.evaluate.evaluate7957Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 159  (13.2):  53%|█████▎    | 158/300 [00:00<00:00, 560.92it/s]=spy.evaluate.evaluate0951Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filenameevaluate.py lineno=198\n",
      "Average Metric: 25.0 / 168  (14.9):  56%|█████▌    | 167/300 [00:00<00:00, 560.92it/s]198y.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. []filename=evaluate.py lineno=\n",
      "Average Metric: 27.0 / 178  (15.2):  59%|█████▉    | 177/300 [00:00<00:00, 560.92it/s]= 24-10-14T00:34:20.743667Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno198\n",
      "Average Metric: 29.0 / 186  (15.6):  62%|██████▏   | 185/300 [00:00<00:00, 585.61it/s]lineno0-14T00:34:20.744736Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename=evaluate.py =198\n",
      "Average Metric: 31.0 / 196  (15.8):  65%|██████▌   | 195/300 [00:00<00:00, 585.61it/s]]024-10-14T00:34:20.745235Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 206  (15.5):  68%|██████▊   | 205/300 [00:00<00:00, 585.61it/s]2024-10-14T00:34:20.746641Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 215  (16.3):  71%|███████▏  | 214/300 [00:00<00:00, 585.61it/s]=spy.evaluate.evaluate5989Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filenameevaluate.py lineno=198\n",
      "Average Metric: 36.0 / 226  (15.9):  75%|███████▌  | 225/300 [00:00<00:00, 585.61it/s]=spy.evaluate.evaluate7114Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno198\n",
      "Average Metric: 38.0 / 235  (16.2):  78%|███████▊  | 234/300 [00:00<00:00, 585.61it/s]] 24-10-14T00:34:20.758934Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 242  (16.5):  80%|████████  | 241/300 [00:00<00:00, 600.81it/s]linenote.py00:34:20.761808Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate = =198\n",
      "Average Metric: 41.0 / 253  (16.2):  84%|████████▍ | 252/300 [00:00<00:00, 600.81it/s]198enofor example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py=\n",
      "Average Metric: 42.0 / 261  (16.1):  87%|████████▋ | 260/300 [00:00<00:00, 600.81it/s]filename 4T00:34:20.766894Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 275  (15.3):  91%|█████████▏| 274/300 [00:00<00:00, 600.81it/s]  ror    4T00:34:20.768303ZError for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 282  (14.9):  94%|█████████▎| 281/300 [00:00<00:00, 600.81it/s]1984-10-14T00:34:20.769343Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=\n",
      "Average Metric: 42.0 / 288  (14.6):  96%|█████████▌| 287/300 [00:00<00:00, 600.81it/s]][24-10-14T00:34:20.770623Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 289  (14.5):  96%|█████████▌| 288/300 [00:00<00:00, 600.81it/s]2024-10-14T00:34:20.773567Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 290  (14.5):  96%|█████████▋| 289/300 [00:00<00:00, 600.81it/s]2024-10-14T00:34:20.779510Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 291  (14.4):  97%|█████████▋| 290/300 [00:00<00:00, 600.81it/s]2024-10-14T00:34:20.784132Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 292  (14.4):  97%|█████████▋| 291/300 [00:00<00:00, 600.81it/s]2024-10-14T00:34:20.785758Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 293  (14.3):  97%|█████████▋| 292/300 [00:00<00:00, 600.81it/s]2024-10-14T00:34:20.793001Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 294  (14.3):  98%|█████████▊| 293/300 [00:00<00:00, 600.81it/s]2024-10-14T00:34:20.795119Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 295  (14.2):  98%|█████████▊| 294/300 [00:00<00:00, 600.81it/s]2024-10-14T00:34:20.799146Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 296  (14.2):  98%|█████████▊| 295/300 [00:00<00:00, 600.81it/s]2024-10-14T00:34:20.803889Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 297  (14.1):  99%|█████████▊| 296/300 [00:00<00:00, 600.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 298  (14.1):  99%|█████████▉| 297/300 [00:00<00:00, 600.81it/s]2024-10-14T00:34:20.816476Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 299  (14.0):  99%|█████████▉| 298/300 [00:00<00:00, 600.81it/s]2024-10-14T00:34:20.819957Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 300  (14.0): 100%|██████████| 300/300 [00:00<00:00, 494.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.0, 14.0]\n",
      "Best score so far: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2758 [00:01<46:44,  1.02s/it]2024-10-14T00:34:22.835194Z [error    ] Failed to run or to evaluate example Example({'text': 'Why do i have an extra fee on my statement?', 'label': 'extra_charge_on_statement', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 3/2758 [00:06<2:07:36,  2.78s/it]2024-10-14T00:34:28.593959Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was I charged extra when paying with card?', 'label': 'extra_charge_on_statement', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 9/2758 [00:09<28:09,  1.63it/s]  2024-10-14T00:34:30.731148Z [error    ] Failed to run or to evaluate example Example({'text': 'Why am I being a charged for using my card?', 'label': 'card_payment_fee_charged', 'answer': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 12/2758 [00:09<17:57,  2.55it/s]2024-10-14T00:34:31.548356Z [error    ] Failed to run or to evaluate example Example({'text': 'tell me why I was charged more with my card?', 'label': 'extra_charge_on_statement', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 16/2758 [00:11<34:12,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:34:34.755214Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:01<05:22,  1.08s/it]error    34.765689Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/300 [00:01<05:22,  1.08s/it]2024-10-14T00:34:34.769746Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 2/300 [00:01<05:21,  1.08s/it]2024-10-14T00:34:35.104924Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 60  (28.3):  20%|██        | 60/300 [00:04<00:13, 17.40it/s]1984-10-14T00:34:38.343483Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.pylineno=\n",
      "Average Metric: 20.0 / 68  (29.4):  22%|██▏       | 67/300 [00:05<00:10, 21.89it/s]]024-10-14T00:34:38.764706Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 71  (29.6):  23%|██▎       | 70/300 [00:05<00:13, 17.57it/s]2024-10-14T00:34:38.769064Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 84  (31.0):  28%|██▊       | 83/300 [00:06<00:17, 12.16it/s]2024-10-14T00:34:39.812565Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 29.0 / 89  (32.6):  29%|██▉       | 88/300 [00:06<00:13, 15.19it/s] 024-10-14T00:34:39.820204Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 96  (32.3):  32%|███▏      | 95/300 [00:06<00:12, 16.65it/s]2024-10-14T00:34:40.367008Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 97  (32.0):  32%|███▏      | 97/300 [00:06<00:10, 20.23it/s]2024-10-14T00:34:40.374042Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 103  (31.1):  34%|███▍      | 103/300 [00:07<00:11, 17.75it/s]2024-10-14T00:34:40.835065Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 109  (31.2):  36%|███▌      | 108/300 [00:07<00:12, 15.79it/s]2024-10-14T00:34:41.144944Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 113  (30.1):  37%|███▋      | 112/300 [00:07<00:09, 19.85it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 115  (29.6):  38%|███▊      | 114/300 [00:07<00:11, 16.34it/s]2024-10-14T00:34:41.529347Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 136  (29.4):  45%|████▌     | 135/300 [00:09<00:09, 16.81it/s]2024-10-14T00:34:42.981287Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 43.0 / 144  (29.9):  48%|████▊     | 143/300 [00:09<00:13, 11.77it/s]2024-10-14T00:34:43.457252Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 153  (30.1):  51%|█████     | 153/300 [00:10<00:11, 13.03it/s]]024-10-14T00:34:44.105856Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 177  (29.4):  59%|█████▉    | 177/300 [00:11<00:09, 12.99it/s]2024-10-14T00:34:45.683294Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 188  (28.2):  62%|██████▏   | 187/300 [00:12<00:08, 12.57it/s]=ilenameluate.evaluate4835Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] =evaluate.pylineno198\n",
      "Average Metric: 53.0 / 190  (27.9):  63%|██████▎   | 189/300 [00:12<00:08, 12.57it/s]2024-10-14T00:34:46.466215Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 194  (27.8):  64%|██████▍   | 193/300 [00:12<00:06, 17.56it/s]2024-10-14T00:34:46.542573Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 55.0 / 196  (28.1):  65%|██████▌   | 196/300 [00:13<00:06, 16.50it/s]2024-10-14T00:34:46.826194Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 206  (27.7):  68%|██████▊   | 205/300 [00:13<00:05, 17.16it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 72.0 / 238  (30.3):  79%|███████▉  | 237/300 [00:14<00:01, 32.29it/s]2024-10-14T00:34:48.468328Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 245  (30.2):  81%|████████▏ | 244/300 [00:15<00:02, 20.24it/s]2024-10-14T00:34:48.924963Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 246  (30.1):  82%|████████▏ | 245/300 [00:15<00:02, 20.24it/s]2024-10-14T00:34:48.932414Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 247  (30.0):  82%|████████▏ | 247/300 [00:15<00:02, 23.73it/s]2024-10-14T00:34:48.954699Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 76.0 / 253  (30.0):  84%|████████▍ | 252/300 [00:15<00:03, 15.10it/s]2024-10-14T00:34:49.622839Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 76.0 / 256  (29.7):  85%|████████▌ | 255/300 [00:15<00:02, 18.02it/s]2024-10-14T00:34:49.717339Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 91.0 / 300  (30.3): 100%|██████████| 300/300 [00:16<00:00, 17.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 30.33 for seed -1\n",
      "Scores so far: [14.0, 14.0, 30.33]\n",
      "Best score so far: 30.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/2758 [00:02<15:49,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:34:54.027854Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<04:12,  1.19it/s]14T00:34:54.035165Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 54  (29.6):  18%|█▊        | 53/300 [00:03<00:12, 19.40it/s]2024-10-14T00:34:56.505023Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 102  (30.4):  34%|███▎      | 101/300 [00:05<00:10, 19.67it/s]2024-10-14T00:34:58.895547Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 110  (29.1):  37%|███▋      | 110/300 [00:06<00:11, 16.34it/s]dspy.evaluate.evaluate5830Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 114  (28.1):  38%|███▊      | 113/300 [00:06<00:11, 16.34it/s]filename14T00:34:59.530200Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 41.0 / 150  (27.3):  50%|████▉     | 149/300 [00:08<00:08, 18.69it/s]2024-10-14T00:35:01.418422Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 51.0 / 190  (26.8):  63%|██████▎   | 189/300 [00:10<00:04, 25.91it/s]2024-10-14T00:35:03.728744Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 55.0 / 208  (26.4):  69%|██████▉   | 207/300 [00:10<00:02, 32.62it/s]2024-10-14T00:35:04.106059Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 231  (26.0):  77%|███████▋  | 230/300 [00:12<00:03, 23.02it/s]lineno0-14T00:35:05.493072Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 60.0 / 233  (25.8):  77%|███████▋  | 232/300 [00:12<00:03, 17.44it/s]2024-10-14T00:35:05.566514Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 300  (27.0): 100%|██████████| 300/300 [00:13<00:00, 21.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.0, 14.0, 30.33, 27.0]\n",
      "Best score so far: 30.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2758 [00:00<15:37,  2.94it/s]2024-10-14T00:35:07.881169Z [error    ] Failed to run or to evaluate example Example({'text': \"After making a transfer from a UK account it's not showing up. How long do these transfers normally take for you? I want to be certain everything is all right.\", 'label': 'transfer_not_received_by_recipient', 'answer': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 8/2758 [00:02<15:38,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:35:10.864544Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<03:44,  1.33it/s]2024-10-14T00:35:10.907358Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 300  (18.0): 100%|██████████| 300/300 [00:13<00:00, 22.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.0, 14.0, 30.33, 27.0, 18.0]\n",
      "Best score so far: 30.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2758 [00:00<16:08,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 56 / 300  (18.7): 100%|██████████| 300/300 [00:13<00:00, 22.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.0, 14.0, 30.33, 27.0, 18.0, 18.67]\n",
      "Best score so far: 30.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2758 [00:11<1:07:10,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:35:50.830062Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<04:08,  1.20it/s]2024-10-14T00:35:51.091042Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 50  (34.0):  16%|█▋        | 49/300 [00:03<00:11, 22.13it/s]2024-10-14T00:35:53.525563Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 52  (34.6):  17%|█▋        | 51/300 [00:03<00:13, 18.70it/s]2024-10-14T00:35:53.818691Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 100  (31.0):  33%|███▎      | 99/300 [00:07<00:12, 15.76it/s]2024-10-14T00:35:57.055990Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 105  (30.5):  35%|███▍      | 104/300 [00:07<00:13, 14.05it/s]2024-10-14T00:35:57.661896Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 218  (28.4):  72%|███████▏  | 217/300 [00:16<00:07, 10.44it/s]=valuate.py00:36:06.356059Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno198\n",
      "Average Metric: 87.0 / 300  (29.0): 100%|██████████| 300/300 [00:20<00:00, 14.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.0, 14.0, 30.33, 27.0, 18.0, 18.67, 29.0]\n",
      "Best score so far: 30.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2758 [00:00<12:07,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 5  (0.0):   2%|▏         | 5/300 [00:00<00:22, 13.28it/s]2024-10-14T00:36:12.741414Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   2%|▏         | 5/300 [00:00<00:22, 13.28it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 45.0 / 300  (15.0): 100%|██████████| 300/300 [00:15<00:00, 19.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.0, 14.0, 30.33, 27.0, 18.0, 18.67, 29.0, 15.0]\n",
      "Best score so far: 30.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2758 [00:00<?, ?it/s]2024-10-14T00:36:28.482912Z [error    ] Failed to run or to evaluate example Example({'text': 'When will a refund post to my account?', 'label': 'refund_not_showing_up', 'answer': 'refund_not_showing_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 6/2758 [00:02<15:01,  3.05it/s]2024-10-14T00:36:30.831169Z [error    ] Failed to run or to evaluate example Example({'text': \"Why didn't I receive the correct exchange rate for an item that I purchased?\", 'label': 'card_payment_wrong_exchange_rate', 'answer': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 8/2758 [00:03<18:46,  2.44it/s]2024-10-14T00:36:31.359544Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was I charged extra when transferring?', 'label': 'transfer_fee_charged', 'answer': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 9/2758 [00:03<16:08,  2.84it/s]2024-10-14T00:36:31.692167Z [error    ] Failed to run or to evaluate example Example({'text': 'How long does it take to show a deposit I made to my balance?', 'label': 'balance_not_updated_after_cheque_or_cash_deposit', 'answer': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 14/2758 [00:05<16:25,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 15 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:36:34.292946Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<04:54,  1.02it/s]14T00:36:34.318353Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/300 [00:01<04:54,  1.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 2/300 [00:01<04:53,  1.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 3/300 [00:01<04:52,  1.02it/s]2024-10-14T00:36:34.365142Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   1%|▏         | 4/300 [00:01<04:51,  1.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   2%|▏         | 6/300 [00:01<00:42,  6.91it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   2%|▏         | 6/300 [00:01<00:42,  6.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   2%|▏         | 7/300 [00:01<00:42,  6.91it/s]2024-10-14T00:36:34.804298Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 51  (33.3):  17%|█▋        | 50/300 [00:03<00:12, 20.76it/s]dspy.evaluate.evaluate2677Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 57  (31.6):  19%|█▊        | 56/300 [00:03<00:13, 18.68it/s]2024-10-14T00:36:36.909884Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 60  (30.0):  20%|█▉        | 59/300 [00:03<00:12, 18.68it/s]2024-10-14T00:36:37.016049Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 61  (29.5):  20%|██        | 61/300 [00:03<00:10, 23.38it/s]2024-10-14T00:36:37.041508Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 62  (29.0):  20%|██        | 61/300 [00:03<00:10, 23.38it/s]2024-10-14T00:36:37.067120Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 63  (28.6):  21%|██        | 62/300 [00:03<00:10, 23.38it/s]2024-10-14T00:36:37.315193Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 66  (27.3):  22%|██▏       | 65/300 [00:04<00:13, 17.99it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 67  (26.9):  22%|██▏       | 66/300 [00:04<00:13, 17.99it/s]2024-10-14T00:36:37.642692Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 87  (28.7):  29%|██▊       | 86/300 [00:05<00:11, 19.38it/s] [24-10-14T00:36:38.531287Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 32.0 / 110  (29.1):  36%|███▋      | 109/300 [00:05<00:05, 35.21it/s]2024-10-14T00:36:39.289544Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 115  (28.7):  38%|███▊      | 114/300 [00:06<00:07, 23.85it/s]2024-10-14T00:36:39.601878Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 118  (28.0):  39%|███▉      | 117/300 [00:06<00:09, 19.09it/s]2024-10-14T00:36:39.726144Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 120  (28.3):  40%|████      | 120/300 [00:06<00:07, 23.38it/s] 024-10-14T00:36:39.733918Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 122  (28.7):  40%|████      | 121/300 [00:06<00:07, 23.38it/s]2024-10-14T00:36:39.792493Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 123  (28.5):  41%|████      | 122/300 [00:06<00:07, 23.38it/s]2024-10-14T00:36:39.836737Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 125  (28.0):  42%|████▏     | 125/300 [00:07<00:11, 14.61it/s]2024-10-14T00:36:40.417194Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 127  (27.6):  42%|████▏     | 126/300 [00:07<00:11, 14.61it/s]2024-10-14T00:36:40.464165Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 37.0 / 131  (28.2):  43%|████▎     | 130/300 [00:07<00:11, 14.38it/s]2024-10-14T00:36:40.942138Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 134  (28.4):  45%|████▍     | 134/300 [00:07<00:15, 10.80it/s]2024-10-14T00:36:41.342397Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 136  (27.9):  45%|████▌     | 135/300 [00:08<00:15, 10.80it/s]2024-10-14T00:36:41.369344Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 39.0 / 150  (26.0):  50%|████▉     | 149/300 [00:08<00:11, 12.59it/s]2024-10-14T00:36:42.318855Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 154  (26.0):  51%|█████▏    | 154/300 [00:09<00:08, 16.87it/s]2024-10-14T00:36:42.410952Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 172  (25.6):  57%|█████▋    | 171/300 [00:09<00:07, 16.75it/s]=024-10-14T00:36:43.283554Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 46.0 / 181  (25.4):  60%|██████    | 181/300 [00:10<00:05, 20.26it/s]2024-10-14T00:36:43.723124Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 184  (25.5):  61%|██████▏   | 184/300 [00:10<00:07, 14.63it/s]2024-10-14T00:36:44.052590Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 48.0 / 189  (25.4):  63%|██████▎   | 189/300 [00:10<00:05, 19.36it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 48.0 / 190  (25.3):  63%|██████▎   | 189/300 [00:10<00:05, 19.36it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 48.0 / 192  (25.0):  64%|██████▎   | 191/300 [00:10<00:05, 19.36it/s]2024-10-14T00:36:44.231175Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 201  (24.9):  67%|██████▋   | 201/300 [00:11<00:05, 16.73it/s]=ilename14T00:36:44.885879Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 205  (24.4):  68%|██████▊   | 204/300 [00:11<00:05, 16.73it/s]2024-10-14T00:36:44.894730Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 206  (24.3):  69%|██████▊   | 206/300 [00:11<00:04, 21.65it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 58.0 / 233  (24.9):  77%|███████▋  | 232/300 [00:13<00:03, 17.09it/s]2024-10-14T00:36:46.521048Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 239  (25.1):  79%|███████▉  | 238/300 [00:13<00:03, 16.02it/s] 024-10-14T00:36:46.877376Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 61.0 / 242  (25.2):  80%|████████  | 241/300 [00:13<00:03, 16.02it/s]2024-10-14T00:36:46.976175Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 247  (25.1):  82%|████████▏ | 246/300 [00:13<00:03, 16.59it/s]2024-10-14T00:36:47.377197Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 253  (25.3):  84%|████████▍ | 252/300 [00:14<00:02, 16.58it/s]] 24-10-14T00:36:47.647153Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 288  (26.0):  96%|█████████▌| 287/300 [00:14<00:00, 48.65it/s]=024-10-14T00:36:48.196191Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 80.0 / 300  (26.7): 100%|██████████| 300/300 [00:14<00:00, 20.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.0, 14.0, 30.33, 27.0, 18.0, 18.67, 29.0, 15.0, 26.67]\n",
      "Best score so far: 30.33\n",
      "9 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]2024-10-14T00:36:49.716395Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/1000 [00:00<15:40,  1.06it/s]2024-10-14T00:36:49.906376Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 2/1000 [00:01<08:19,  2.00it/s]2024-10-14T00:36:50.128837Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   0%|          | 3/1000 [00:01<06:13,  2.67it/s]] 24-10-14T00:36:50.134391Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 12  (25.0):   1%|          | 11/1000 [00:01<01:47,  9.21it/s]filename14T00:36:50.760821Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 29  (27.6):   3%|▎         | 29/1000 [00:02<00:54, 17.85it/s]2024-10-14T00:36:51.583215Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 31  (25.8):   3%|▎         | 30/1000 [00:02<00:54, 17.85it/s]2024-10-14T00:36:51.590434Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 34  (26.5):   3%|▎         | 34/1000 [00:02<00:42, 22.51it/s]2024-10-14T00:36:51.641453Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 36  (25.0):   4%|▎         | 35/1000 [00:02<00:42, 22.51it/s]2024-10-14T00:36:51.979463Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 135  (34.1):  13%|█▎        | 134/1000 [00:09<01:00, 14.20it/s]2024-10-14T00:36:58.190254Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 49.0 / 144  (34.0):  14%|█▍        | 143/1000 [00:10<01:13, 11.61it/s]2024-10-14T00:36:58.810426Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 148  (33.8):  15%|█▍        | 147/1000 [00:10<00:58, 14.48it/s]2024-10-14T00:36:59.148141Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 151  (33.1):  15%|█▌        | 151/1000 [00:10<00:47, 17.89it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 53.0 / 156  (34.0):  16%|█▌        | 156/1000 [00:10<00:49, 17.15it/s]2024-10-14T00:36:59.564752Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 167  (33.5):  17%|█▋        | 166/1000 [00:11<00:50, 16.54it/s]2024-10-14T00:36:59.999700Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 170  (32.9):  17%|█▋        | 170/1000 [00:11<00:46, 17.73it/s]2024-10-14T00:37:00.299360Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 61.0 / 187  (32.6):  19%|█▊        | 187/1000 [00:12<00:52, 15.45it/s]2024-10-14T00:37:01.475050Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 66.0 / 199  (33.2):  20%|█▉        | 198/1000 [00:13<00:46, 17.29it/s]2024-10-14T00:37:02.252330Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 67.0 / 206  (32.5):  20%|██        | 205/1000 [00:13<01:01, 13.03it/s]=[24-10-14T00:37:02.538846Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filename=evaluate.py lineno198\n",
      "Average Metric: 68.0 / 209  (32.5):  21%|██        | 208/1000 [00:13<00:47, 16.77it/s]2024-10-14T00:37:02.669947Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 69.0 / 213  (32.4):  21%|██        | 212/1000 [00:14<00:35, 22.46it/s] 024-10-14T00:37:02.962231Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 228  (32.9):  23%|██▎       | 227/1000 [00:15<00:56, 13.64it/s] [24-10-14T00:37:03.809659Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 84.0 / 257  (32.7):  26%|██▌       | 256/1000 [00:16<00:47, 15.55it/s]lineno0-14T00:37:05.636012Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 86.0 / 262  (32.8):  26%|██▌       | 262/1000 [00:17<00:44, 16.44it/s]2024-10-14T00:37:06.033579Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 90.0 / 276  (32.6):  28%|██▊       | 275/1000 [00:18<00:53, 13.50it/s]2024-10-14T00:37:06.832857Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 90.0 / 280  (32.1):  28%|██▊       | 280/1000 [00:18<00:45, 15.99it/s]2024-10-14T00:37:07.389806Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 92.0 / 294  (31.3):  29%|██▉       | 293/1000 [00:19<01:14,  9.50it/s]2024-10-14T00:37:08.435031Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 94.0 / 311  (30.2):  31%|███       | 310/1000 [00:20<00:58, 11.78it/s]2024-10-14T00:37:09.736915Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 98.0 / 325  (30.2):  32%|███▏      | 324/1000 [00:21<00:37, 18.01it/s]2024-10-14T00:37:10.360745Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 109.0 / 356  (30.6):  36%|███▌      | 356/1000 [00:23<00:41, 15.40it/s]2024-10-14T00:37:12.460538Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 119.0 / 384  (31.0):  38%|███▊      | 383/1000 [00:25<00:35, 17.57it/s]=024-10-14T00:37:13.925019Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 121.0 / 388  (31.2):  39%|███▊      | 387/1000 [00:25<00:29, 20.58it/s]2024-10-14T00:37:14.342578Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 121.0 / 389  (31.1):  39%|███▉      | 389/1000 [00:25<00:36, 16.75it/s]2024-10-14T00:37:14.347853Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 121.0 / 390  (31.0):  39%|███▉      | 389/1000 [00:25<00:36, 16.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 123.0 / 409  (30.1):  41%|████      | 408/1000 [00:26<00:34, 17.31it/s]2024-10-14T00:37:15.427030Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 126.0 / 419  (30.1):  42%|████▏     | 418/1000 [00:27<00:39, 14.89it/s]2024-10-14T00:37:16.071807Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 128.0 / 425  (30.1):  42%|████▏     | 424/1000 [00:27<00:35, 16.15it/s]2024-10-14T00:37:16.655384Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 141.0 / 472  (29.9):  47%|████▋     | 472/1000 [00:30<00:31, 16.65it/s]=024-10-14T00:37:19.437068Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 144.0 / 477  (30.2):  48%|████▊     | 476/1000 [00:30<00:36, 14.46it/s]2024-10-14T00:37:19.806150Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 144.0 / 478  (30.1):  48%|████▊     | 477/1000 [00:31<00:36, 14.46it/s]2024-10-14T00:37:19.810163Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 147.0 / 485  (30.3):  48%|████▊     | 484/1000 [00:31<00:34, 15.06it/s]2024-10-14T00:37:20.172547Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 147.0 / 487  (30.2):  49%|████▊     | 487/1000 [00:31<00:24, 20.53it/s]2024-10-14T00:37:20.219874Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 147.0 / 489  (30.1):  49%|████▉     | 488/1000 [00:31<00:24, 20.53it/s]2024-10-14T00:37:20.539237Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 147.0 / 494  (29.8):  49%|████▉     | 493/1000 [00:32<00:34, 14.50it/s]2024-10-14T00:37:20.861636Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 147.0 / 498  (29.5):  50%|████▉     | 497/1000 [00:32<00:27, 18.27it/s]]024-10-14T00:37:20.872994Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 154.0 / 527  (29.2):  53%|█████▎    | 526/1000 [00:34<00:29, 16.19it/s]2024-10-14T00:37:23.195011Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 158.0 / 549  (28.8):  55%|█████▍    | 548/1000 [00:35<00:37, 12.11it/s]2024-10-14T00:37:24.498696Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 161.0 / 557  (28.9):  56%|█████▌    | 556/1000 [00:36<00:28, 15.46it/s]2024-10-14T00:37:25.140682Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 164.0 / 568  (28.9):  57%|█████▋    | 567/1000 [00:36<00:27, 15.64it/s]filename14T00:37:25.599072Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 171.0 / 583  (29.3):  58%|█████▊    | 582/1000 [00:37<00:29, 14.22it/s]2024-10-14T00:37:26.590630Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 172.0 / 586  (29.4):  58%|█████▊    | 585/1000 [00:37<00:21, 19.30it/s]2024-10-14T00:37:26.707373Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 180.0 / 605  (29.8):  60%|██████    | 604/1000 [00:39<00:24, 16.06it/s]2024-10-14T00:37:28.081348Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 186.0 / 617  (30.1):  62%|██████▏   | 617/1000 [00:40<00:28, 13.66it/s]2024-10-14T00:37:28.949622Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 188.0 / 622  (30.2):  62%|██████▏   | 622/1000 [00:40<00:20, 18.69it/s]2024-10-14T00:37:29.092190Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 196.0 / 646  (30.3):  65%|██████▍   | 646/1000 [00:41<00:27, 12.81it/s]2024-10-14T00:37:30.793909Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 196.0 / 652  (30.1):  65%|██████▌   | 652/1000 [00:42<00:26, 12.92it/s]2024-10-14T00:37:31.209260Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 196.0 / 654  (30.0):  65%|██████▌   | 653/1000 [00:42<00:26, 12.92it/s]2024-10-14T00:37:31.237744Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 207.0 / 680  (30.4):  68%|██████▊   | 679/1000 [00:44<00:20, 15.50it/s]lineno0-14T00:37:32.815679Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 211.0 / 702  (30.1):  70%|███████   | 701/1000 [00:45<00:15, 19.93it/s]2024-10-14T00:37:34.115259Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 211.0 / 703  (30.0):  70%|███████   | 702/1000 [00:45<00:14, 19.93it/s]2024-10-14T00:37:34.161018Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 211.0 / 705  (29.9):  70%|███████   | 705/1000 [00:45<00:18, 16.14it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 211.0 / 706  (29.9):  70%|███████   | 705/1000 [00:45<00:18, 16.14it/s]2024-10-14T00:37:34.177805Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 211.0 / 707  (29.8):  71%|███████   | 706/1000 [00:45<00:18, 16.14it/s]2024-10-14T00:37:34.215752Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 219.0 / 740  (29.6):  74%|███████▍  | 739/1000 [00:47<00:16, 15.65it/s]2024-10-14T00:37:36.455620Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 223.0 / 755  (29.5):  76%|███████▌  | 755/1000 [00:48<00:11, 21.06it/s]2024-10-14T00:37:37.537410Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 224.0 / 761  (29.4):  76%|███████▌  | 761/1000 [00:49<00:22, 10.85it/s]2024-10-14T00:37:38.205403Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 225.0 / 766  (29.4):  76%|███████▋  | 765/1000 [00:49<00:18, 12.84it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 230.0 / 792  (29.0):  79%|███████▉  | 791/1000 [00:50<00:10, 19.63it/s]dspy.evaluate.evaluate6121Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 230.0 / 793  (29.0):  79%|███████▉  | 792/1000 [00:50<00:10, 19.63it/s]2024-10-14T00:37:39.335892Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 231.0 / 800  (28.9):  80%|███████▉  | 799/1000 [00:51<00:11, 18.02it/s]2024-10-14T00:37:40.050992Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 232.0 / 804  (28.9):  80%|████████  | 803/1000 [00:51<00:15, 12.44it/s]2024-10-14T00:37:40.336236Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 243.0 / 831  (29.2):  83%|████████▎ | 830/1000 [00:53<00:08, 19.22it/s]2024-10-14T00:37:41.849182Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 244.0 / 838  (29.1):  84%|████████▎ | 837/1000 [00:53<00:09, 17.28it/s]=024-10-14T00:37:42.161557Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 247.0 / 846  (29.2):  85%|████████▍ | 846/1000 [00:53<00:08, 19.05it/s]2024-10-14T00:37:42.910251Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 248.0 / 857  (28.9):  86%|████████▌ | 856/1000 [00:54<00:10, 13.40it/s]2024-10-14T00:37:43.589913Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 250.0 / 861  (29.0):  86%|████████▌ | 860/1000 [00:54<00:10, 13.40it/s] [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 251.0 / 879  (28.6):  88%|████████▊ | 878/1000 [00:56<00:05, 20.51it/s]filename14T00:37:44.815431Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 253.0 / 882  (28.7):  88%|████████▊ | 881/1000 [00:56<00:07, 16.98it/s]2024-10-14T00:37:44.929623Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 256.0 / 897  (28.5):  90%|████████▉ | 896/1000 [00:56<00:04, 21.22it/s] [24-10-14T00:37:45.621704Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 260.0 / 906  (28.7):  90%|█████████ | 905/1000 [00:57<00:05, 15.87it/s]2024-10-14T00:37:46.307863Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 266.0 / 927  (28.7):  93%|█████████▎| 926/1000 [00:58<00:04, 17.29it/s]2024-10-14T00:37:47.633878Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 270.0 / 941  (28.7):  94%|█████████▍| 940/1000 [00:59<00:03, 15.85it/s]2024-10-14T00:37:48.453804Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 274.0 / 953  (28.8):  95%|█████████▌| 952/1000 [01:00<00:03, 13.23it/s]=024-10-14T00:37:49.310116Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 285.0 / 987  (28.9):  99%|█████████▊| 986/1000 [01:01<00:00, 42.41it/s]2024-10-14T00:37:49.862122Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 287.0 / 999  (28.7): 100%|█████████▉| 999/1000 [01:01<00:00, 46.74it/s]2024-10-14T00:37:52.762208Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 287.0 / 1000  (28.7): 100%|██████████| 1000/1000 [01:03<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for meta-llama/Llama-3.2-1B-Instruct:epochs-0-total-trained-steps-32: 28.7, None, None\n",
      "Evaluating openai/meta-llama/Llama-3.2-1B-Instruct:epochs-3-total-trained-steps-128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 181 / 1000  (18.1): 100%|██████████| 1000/1000 [01:35<00:00, 10.45it/s]\n",
      "Average Metric: 56 / 300  (18.7): 100%|██████████| 300/300 [00:28<00:00, 10.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 18.67 for seed -3\n",
      "Scores so far: [18.67]\n",
      "Best score so far: 18.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 56 / 300  (18.7): 100%|██████████| 300/300 [00:00<00:00, 1168.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [18.67, 18.67]\n",
      "Best score so far: 18.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/2758 [00:05<28:02,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:40:03.958608Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<02:27,  2.03it/s]2024-10-14T00:40:04.944170Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 54  (57.4):  18%|█▊        | 54/300 [00:04<00:17, 13.83it/s]=[24-10-14T00:40:08.269381Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 43.0 / 82  (52.4):  27%|██▋       | 81/300 [00:06<00:16, 13.09it/s]=024-10-14T00:40:10.317208Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 51.0 / 106  (48.1):  35%|███▌      | 106/300 [00:08<00:12, 15.23it/s]2024-10-14T00:40:12.233486Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 76.0 / 161  (47.2):  54%|█████▎    | 161/300 [00:12<00:06, 19.89it/s]2024-10-14T00:40:15.960071Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 95.0 / 200  (47.5):  66%|██████▋   | 199/300 [00:15<00:07, 14.37it/s]2024-10-14T00:40:18.582676Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 95.0 / 201  (47.3):  67%|██████▋   | 201/300 [00:15<00:05, 18.09it/s]2024-10-14T00:40:18.791351Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 120.0 / 244  (49.2):  81%|████████  | 243/300 [00:17<00:03, 15.66it/s]2024-10-14T00:40:21.410125Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 155.0 / 300  (51.7): 100%|██████████| 300/300 [00:19<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 51.67 for seed -1\n",
      "Scores so far: [18.67, 18.67, 51.67]\n",
      "Best score so far: 51.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/2758 [00:03<28:15,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:40:27.028378Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<03:59,  1.25it/s]2024-10-14T00:40:27.330182Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 34  (50.0):  11%|█▏        | 34/300 [00:02<00:08, 31.84it/s]2024-10-14T00:40:28.517117Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 52  (50.0):  17%|█▋        | 51/300 [00:03<00:17, 14.09it/s]2024-10-14T00:40:30.152117Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 161  (40.4):  53%|█████▎    | 160/300 [00:11<00:11, 11.88it/s]2024-10-14T00:40:37.604892Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 97.0 / 236  (41.1):  78%|███████▊  | 235/300 [00:16<00:03, 20.81it/s]dspy.evaluate.evaluate7301Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 100.0 / 241  (41.5):  80%|████████  | 240/300 [00:16<00:03, 17.33it/s]2024-10-14T00:40:42.904550Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 131.0 / 300  (43.7): 100%|██████████| 300/300 [00:18<00:00, 16.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [18.67, 18.67, 51.67, 43.67]\n",
      "Best score so far: 51.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2758 [00:04<26:10,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 69 / 300  (23.0): 100%|██████████| 300/300 [00:15<00:00, 19.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [18.67, 18.67, 51.67, 43.67, 23.0]\n",
      "Best score so far: 51.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2758 [00:01<25:50,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 65 / 300  (21.7): 100%|██████████| 300/300 [00:23<00:00, 12.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [18.67, 18.67, 51.67, 43.67, 23.0, 21.67]\n",
      "Best score so far: 51.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2758 [00:06<34:55,  1.31it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 93 / 300  (31.0): 100%|██████████| 300/300 [00:17<00:00, 17.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [18.67, 18.67, 51.67, 43.67, 23.0, 21.67, 31.0]\n",
      "Best score so far: 51.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2758 [00:01<23:50,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 29 / 300  (9.7): 100%|██████████| 300/300 [00:24<00:00, 12.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [18.67, 18.67, 51.67, 43.67, 23.0, 21.67, 31.0, 9.67]\n",
      "Best score so far: 51.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2758 [00:06<29:33,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:42:27.463763Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<04:56,  1.01it/s]2024-10-14T00:42:27.647578Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 51  (39.2):  17%|█▋        | 51/300 [00:03<00:17, 14.47it/s]2024-10-14T00:42:30.123432Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 39.0 / 103  (37.9):  34%|███▍      | 102/300 [00:06<00:15, 12.52it/s]2024-10-14T00:42:33.484584Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 152  (34.9):  50%|█████     | 151/300 [00:09<00:13, 11.32it/s]]024-10-14T00:42:36.078587Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 72.0 / 193  (37.3):  64%|██████▍   | 192/300 [00:11<00:04, 26.18it/s]2024-10-14T00:42:38.004552Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 98.0 / 245  (40.0):  81%|████████▏ | 244/300 [00:14<00:02, 24.54it/s]2024-10-14T00:42:41.311997Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 123.0 / 300  (41.0): 100%|██████████| 300/300 [00:16<00:00, 18.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [18.67, 18.67, 51.67, 43.67, 23.0, 21.67, 31.0, 9.67, 41.0]\n",
      "Best score so far: 51.67\n",
      "9 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]2024-10-14T00:42:44.165502Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 48  (45.8):   5%|▍         | 47/1000 [00:03<00:36, 26.02it/s]2024-10-14T00:42:47.113725Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 73.0 / 153  (47.7):  15%|█▌        | 152/1000 [00:11<01:02, 13.61it/s]2024-10-14T00:42:54.634207Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 155  (47.7):  15%|█▌        | 154/1000 [00:11<01:13, 11.52it/s]2024-10-14T00:42:54.681887Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 178  (44.9):  18%|█▊        | 177/1000 [00:13<01:01, 13.46it/s]2024-10-14T00:42:56.366475Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 130.0 / 289  (45.0):  29%|██▉       | 288/1000 [00:20<00:47, 15.09it/s]2024-10-14T00:43:04.101627Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 141.0 / 317  (44.5):  32%|███▏      | 316/1000 [00:23<01:06, 10.31it/s]198luate.pyxample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=\n",
      "Average Metric: 149.0 / 331  (45.0):  33%|███▎      | 330/1000 [00:24<00:47, 13.97it/s]filename14T00:43:07.087040Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 174.0 / 382  (45.5):  38%|███▊      | 381/1000 [00:27<00:47, 12.98it/s]2024-10-14T00:43:10.838890Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 185.0 / 405  (45.7):  40%|████      | 404/1000 [00:28<00:27, 21.91it/s]2024-10-14T00:43:11.712822Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 194.0 / 419  (46.3):  42%|████▏     | 418/1000 [00:29<00:48, 12.02it/s]2024-10-14T00:43:12.741966Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 197.0 / 430  (45.8):  43%|████▎     | 429/1000 [00:30<00:41, 13.60it/s]2024-10-14T00:43:13.813080Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 220.0 / 475  (46.3):  48%|████▊     | 475/1000 [00:33<00:44, 11.68it/s]2024-10-14T00:43:16.966243Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 250.0 / 532  (47.0):  53%|█████▎    | 532/1000 [00:37<00:40, 11.63it/s]=024-10-14T00:43:20.971968Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filenameevaluate.py lineno=198\n",
      "Average Metric: 263.0 / 557  (47.2):  56%|█████▌    | 556/1000 [00:39<00:28, 15.51it/s]2024-10-14T00:43:22.620871Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 266.0 / 565  (47.1):  56%|█████▋    | 564/1000 [00:40<00:33, 13.07it/s]2024-10-14T00:43:23.339496Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 302.0 / 630  (47.9):  63%|██████▎   | 629/1000 [00:44<00:32, 11.56it/s]2024-10-14T00:43:27.805486Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 310.0 / 645  (48.1):  64%|██████▍   | 644/1000 [00:45<00:18, 19.77it/s]2024-10-14T00:43:28.378666Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 326.0 / 677  (48.2):  68%|██████▊   | 677/1000 [00:47<00:23, 13.97it/s]2024-10-14T00:43:31.027139Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 343.0 / 711  (48.2):  71%|███████   | 711/1000 [00:50<00:20, 14.37it/s]2024-10-14T00:43:33.533654Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 345.0 / 721  (47.9):  72%|███████▏  | 720/1000 [00:50<00:13, 21.24it/s]2024-10-14T00:43:33.762249Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 363.0 / 775  (46.8):  77%|███████▋  | 774/1000 [00:54<00:17, 12.80it/s]1984-10-14T00:43:37.905387Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 379.0 / 805  (47.1):  80%|████████  | 804/1000 [00:56<00:10, 18.98it/s]2024-10-14T00:43:39.276090Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 384.0 / 818  (46.9):  82%|████████▏ | 818/1000 [00:57<00:15, 11.41it/s]2024-10-14T00:43:40.571328Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 403.0 / 857  (47.0):  86%|████████▌ | 856/1000 [00:59<00:08, 17.38it/s]2024-10-14T00:43:43.022606Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 426.0 / 903  (47.2):  90%|█████████ | 902/1000 [01:02<00:06, 14.73it/s]2024-10-14T00:43:46.074577Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 435.0 / 925  (47.0):  92%|█████████▏| 924/1000 [01:04<00:06, 11.98it/s]]024-10-14T00:43:47.862325Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 455.0 / 964  (47.2):  96%|█████████▋| 963/1000 [01:07<00:01, 19.81it/s]2024-10-14T00:43:50.235590Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 473.0 / 1000  (47.3): 100%|██████████| 1000/1000 [01:08<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for meta-llama/Llama-3.2-1B-Instruct:epochs-3-total-trained-steps-128: 47.3, None, None\n",
      "Evaluating openai/meta-llama/Llama-3.2-1B-Instruct:epochs-1-total-trained-steps-64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]2024-10-14T00:43:56.248843Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 84  (23.8):   8%|▊         | 84/1000 [00:12<01:33,  9.82it/s]2024-10-14T00:44:04.669823Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 100  (20.0):  10%|▉         | 99/1000 [00:13<01:39,  9.05it/s]2024-10-14T00:44:06.187343Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 132  (20.5):  13%|█▎        | 131/1000 [00:17<01:18, 11.09it/s]2024-10-14T00:44:09.471205Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 137  (20.4):  14%|█▎        | 136/1000 [00:17<01:30,  9.50it/s]2024-10-14T00:44:10.352742Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 30.0 / 160  (18.8):  16%|█▌        | 159/1000 [00:20<01:32,  9.04it/s]2024-10-14T00:44:12.742973Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 43.0 / 243  (17.7):  24%|██▍       | 243/1000 [00:30<01:36,  7.85it/s]2024-10-14T00:44:22.590754Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 48.0 / 281  (17.1):  28%|██▊       | 281/1000 [00:34<01:13,  9.76it/s]2024-10-14T00:44:26.597711Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 343  (16.6):  34%|███▍      | 342/1000 [00:41<00:57, 11.40it/s]2024-10-14T00:44:33.763684Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 61.0 / 375  (16.3):  37%|███▋      | 374/1000 [00:45<01:23,  7.52it/s] 024-10-14T00:44:37.395396Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 63.0 / 421  (15.0):  42%|████▏     | 420/1000 [00:50<01:28,  6.54it/s] [24-10-14T00:44:42.947639Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 67.0 / 439  (15.3):  44%|████▍     | 438/1000 [00:52<01:14,  7.50it/s]2024-10-14T00:44:44.724469Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 78.0 / 499  (15.6):  50%|████▉     | 499/1000 [00:58<00:43, 11.57it/s]2024-10-14T00:44:51.128988Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 505  (15.6):  50%|█████     | 505/1000 [00:59<00:55,  8.93it/s]2024-10-14T00:44:52.146288Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 514  (15.4):  51%|█████▏    | 513/1000 [01:00<00:52,  9.28it/s]2024-10-14T00:44:52.903514Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 520  (15.6):  52%|█████▏    | 520/1000 [01:01<00:57,  8.39it/s]2024-10-14T00:44:53.744471Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 84.0 / 536  (15.7):  54%|█████▎    | 535/1000 [01:03<00:47,  9.84it/s]2024-10-14T00:44:55.857408Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 84.0 / 544  (15.4):  54%|█████▍    | 543/1000 [01:04<00:59,  7.73it/s]2024-10-14T00:44:56.978474Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 84.0 / 546  (15.4):  55%|█████▍    | 546/1000 [01:04<01:06,  6.78it/s]2024-10-14T00:44:57.341262Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 84.0 / 549  (15.3):  55%|█████▍    | 549/1000 [01:05<00:52,  8.59it/s]2024-10-14T00:44:57.726387Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 568  (15.1):  57%|█████▋    | 567/1000 [01:07<00:43,  9.99it/s]2024-10-14T00:44:59.836656Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 87.0 / 571  (15.2):  57%|█████▋    | 571/1000 [01:07<00:48,  8.93it/s] 024-10-14T00:45:00.097975Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 88.0 / 575  (15.3):  57%|█████▊    | 575/1000 [01:08<00:56,  7.58it/s]2024-10-14T00:45:00.858401Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 89.0 / 594  (15.0):  59%|█████▉    | 594/1000 [01:11<00:51,  7.91it/s]evaluate.py00:45:03.275972Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 96.0 / 617  (15.6):  62%|██████▏   | 617/1000 [01:13<00:41,  9.21it/s]2024-10-14T00:45:05.850847Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 98.0 / 643  (15.2):  64%|██████▍   | 643/1000 [01:16<00:48,  7.39it/s]2024-10-14T00:45:09.158232Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 99.0 / 646  (15.3):  65%|██████▍   | 646/1000 [01:17<00:41,  8.53it/s]2024-10-14T00:45:09.539601Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 102.0 / 657  (15.5):  66%|██████▌   | 656/1000 [01:18<00:34, 10.08it/s]2024-10-14T00:45:10.614196Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 103.0 / 663  (15.5):  66%|██████▌   | 662/1000 [01:18<00:38,  8.82it/s]2024-10-14T00:45:11.264818Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 111.0 / 726  (15.3):  73%|███████▎  | 726/1000 [01:26<00:33,  8.08it/s]2024-10-14T00:45:18.926925Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 114.0 / 759  (15.0):  76%|███████▌  | 758/1000 [01:30<00:39,  6.14it/s]2024-10-14T00:45:23.474377Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 118.0 / 773  (15.3):  77%|███████▋  | 772/1000 [01:32<00:18, 12.17it/s]2024-10-14T00:45:24.921331Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 119.0 / 777  (15.3):  78%|███████▊  | 776/1000 [01:33<00:30,  7.40it/s]2024-10-14T00:45:25.481333Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 120.0 / 782  (15.3):  78%|███████▊  | 781/1000 [01:33<00:23,  9.21it/s]2024-10-14T00:45:26.122874Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 121.0 / 793  (15.3):  79%|███████▉  | 792/1000 [01:35<00:28,  7.34it/s]2024-10-14T00:45:27.494582Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 123.0 / 815  (15.1):  82%|████████▏ | 815/1000 [01:37<00:20,  8.82it/s]2024-10-14T00:45:30.015636Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 123.0 / 816  (15.1):  82%|████████▏ | 816/1000 [01:37<00:25,  7.34it/s]2024-10-14T00:45:30.057084Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 127.0 / 832  (15.3):  83%|████████▎ | 832/1000 [01:39<00:18,  8.88it/s]2024-10-14T00:45:31.925234Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 128.0 / 853  (15.0):  85%|████████▌ | 852/1000 [01:41<00:14, 10.06it/s]2024-10-14T00:45:34.112972Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 132.0 / 905  (14.6):  90%|█████████ | 905/1000 [01:47<00:08, 10.93it/s]2024-10-14T00:45:39.842157Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 135.0 / 916  (14.7):  92%|█████████▏| 916/1000 [01:48<00:10,  7.82it/s]2024-10-14T00:45:41.016680Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 138.0 / 926  (14.9):  93%|█████████▎| 926/1000 [01:49<00:09,  8.08it/s] [24-10-14T00:45:42.110360Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 144.0 / 977  (14.7):  98%|█████████▊| 976/1000 [01:54<00:01, 17.98it/s]2024-10-14T00:45:46.612233Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 144.0 / 979  (14.7):  98%|█████████▊| 979/1000 [01:54<00:01, 16.27it/s]2024-10-14T00:45:46.693985Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 145.0 / 997  (14.5): 100%|█████████▉| 997/1000 [01:58<00:01,  2.97it/s]2024-10-14T00:45:51.217725Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 145.0 / 998  (14.5): 100%|█████████▉| 998/1000 [01:58<00:00,  3.41it/s]2024-10-14T00:45:51.949619Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 145.0 / 1000  (14.5): 100%|██████████| 1000/1000 [01:59<00:00,  8.34it/s]\n",
      "Average Metric: 12 / 54  (22.2):  18%|█▊        | 54/300 [00:05<00:25,  9.69it/s]2024-10-14T00:45:57.515237Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 75  (18.7):  25%|██▍       | 74/300 [00:06<00:16, 13.82it/s]2024-10-14T00:45:59.456678Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 165  (17.0):  55%|█████▍    | 164/300 [00:16<00:17,  7.77it/s]2024-10-14T00:46:09.210278Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 29.0 / 176  (16.5):  58%|█████▊    | 175/300 [00:17<00:13,  9.60it/s]2024-10-14T00:46:10.234850Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 29.0 / 201  (14.4):  67%|██████▋   | 200/300 [00:20<00:13,  7.69it/s]2024-10-14T00:46:12.921696Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 222  (14.4):  74%|███████▍  | 222/300 [00:23<00:09,  8.58it/s]2024-10-14T00:46:15.617877Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 228  (14.5):  76%|███████▌  | 227/300 [00:23<00:08,  8.18it/s]2024-10-14T00:46:16.329183Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 37.0 / 258  (14.3):  86%|████████▌ | 258/300 [00:26<00:02, 16.02it/s]2024-10-14T00:46:19.101254Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 37.0 / 259  (14.3):  86%|████████▌ | 258/300 [00:26<00:02, 16.02it/s]2024-10-14T00:46:19.295279Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 280  (15.0):  93%|█████████▎| 280/300 [00:29<00:03,  5.50it/s]2024-10-14T00:46:21.693677Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 281  (14.9):  93%|█████████▎| 280/300 [00:29<00:03,  5.50it/s]2024-10-14T00:46:21.699892Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 290  (14.5):  97%|█████████▋| 290/300 [00:32<00:03,  2.75it/s]2024-10-14T00:46:24.729401Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 293  (14.3):  97%|█████████▋| 292/300 [00:32<00:01,  4.24it/s]2024-10-14T00:46:25.134641Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 297  (14.1):  99%|█████████▉| 297/300 [00:33<00:00,  3.54it/s]2024-10-14T00:46:26.664240Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 300  (14.0): 100%|██████████| 300/300 [00:34<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 14.0 for seed -3\n",
      "Scores so far: [14.0]\n",
      "Best score so far: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14T00:46:27.183301Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2 / 7  (28.6):   2%|▏         | 6/300 [00:00<00:00, 601.25it/s]=ilename example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.pylineno198\n",
      "Average Metric: 4 / 16  (25.0):   5%|▌         | 15/300 [00:00<00:00, 617.69it/s]198y.evaluate.evaluate60Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. []filename=evaluate.py lineno=\n",
      "Average Metric: 6 / 24  (25.0):   8%|▊         | 23/300 [00:00<00:00, 657.38it/s]][24-10-14T00:46:27.226967Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 9 / 31  (29.0):  10%|█         | 30/300 [00:00<00:00, 587.71it/s]198luate.py00:46:27.254630Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] = lineno=\n",
      "Average Metric: 10 / 39  (25.6):  13%|█▎        | 38/300 [00:00<00:00, 590.36it/s]198y.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filenameevaluate.py lineno=\n",
      "Average Metric: 11 / 49  (22.4):  16%|█▌        | 48/300 [00:00<00:00, 594.96it/s]filename14T00:46:27.262342Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 13 / 58  (22.4):  19%|█▉        | 57/300 [00:00<00:00, 604.08it/s]=ilename14T00:46:27.266096Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate evaluate.py lineno=198\n",
      "Average Metric: 15 / 66  (22.7):  22%|██▏       | 65/300 [00:00<00:00, 600.45it/s]198or for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filenameevaluate.py lineno=\n",
      "Average Metric: 16 / 74  (21.6):  24%|██▍       | 73/300 [00:00<00:00, 600.45it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18 / 83  (21.7):  27%|██▋       | 82/300 [00:00<00:00, 600.45it/s]=[24-10-14T00:46:27.290908Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 18 / 91  (19.8):  30%|███       | 90/300 [00:00<00:00, 600.45it/s]1984-10-14T00:46:27.293658Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filenameevaluate.pylineno=\n",
      "Average Metric: 19 / 100  (19.0):  33%|███▎      | 99/300 [00:00<00:00, 600.45it/s]inenofor example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 21 / 109  (19.3):  36%|███▌      | 108/300 [00:00<00:00, 600.45it/s]198enote.pyxample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= =\n",
      "Average Metric: 42.0 / 300  (14.0): 100%|██████████| 300/300 [00:00<00:00, 862.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.0, 14.0]\n",
      "Best score so far: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2758 [00:00<34:11,  1.34it/s]2024-10-14T00:46:29.031741Z [error    ] Failed to run or to evaluate example Example({'text': 'Why do i have an extra fee on my statement?', 'label': 'extra_charge_on_statement', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 9/2758 [00:04<22:34,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:46:33.371269Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<04:25,  1.12it/s]2024-10-14T00:46:33.841067Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 51  (29.4):  17%|█▋        | 51/300 [00:03<00:12, 19.55it/s]2024-10-14T00:46:36.135700Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 52  (28.8):  17%|█▋        | 51/300 [00:03<00:12, 19.55it/s]2024-10-14T00:46:36.179598Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 54  (27.8):  18%|█▊        | 54/300 [00:03<00:19, 12.71it/s]2024-10-14T00:46:36.418047Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 98  (33.7):  32%|███▏      | 97/300 [00:06<00:09, 21.90it/s]2024-10-14T00:46:38.545615Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 99  (33.3):  33%|███▎      | 99/300 [00:06<00:07, 27.17it/s]2024-10-14T00:46:38.571761Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 104  (31.7):  34%|███▍      | 103/300 [00:06<00:09, 20.58it/s]2024-10-14T00:46:38.996589Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 123  (29.3):  41%|████      | 122/300 [00:07<00:09, 18.39it/s]lineno0-14T00:46:40.257284Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 37.0 / 139  (26.6):  46%|████▌     | 138/300 [00:08<00:07, 23.11it/s]2024-10-14T00:46:41.103232Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 166  (25.3):  55%|█████▌    | 165/300 [00:10<00:13,  9.90it/s]2024-10-14T00:46:42.901128Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 195  (27.2):  65%|██████▌   | 195/300 [00:11<00:05, 18.92it/s]2024-10-14T00:46:44.341380Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 202  (26.7):  67%|██████▋   | 201/300 [00:12<00:04, 23.35it/s]2024-10-14T00:46:44.724193Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 232  (26.7):  77%|███████▋  | 231/300 [00:13<00:03, 19.12it/s]2024-10-14T00:46:46.510250Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 82.0 / 300  (27.3): 100%|██████████| 300/300 [00:18<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 27.33 for seed -1\n",
      "Scores so far: [14.0, 14.0, 27.33]\n",
      "Best score so far: 27.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2758 [00:03<25:40,  1.79it/s]2024-10-14T00:46:54.944681Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was I not allowed to do a transfer to a beneficiary?', 'label': 'beneficiary_not_allowed', 'answer': 'beneficiary_not_allowed'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 9/2758 [00:05<25:32,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 3  (0.0):   1%|          | 2/300 [00:00<01:10,  4.22it/s]2024-10-14T00:46:58.086290Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 300  (26.3): 100%|██████████| 300/300 [00:15<00:00, 19.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.0, 14.0, 27.33, 26.33]\n",
      "Best score so far: 27.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/2758 [00:10<58:08,  1.27s/it]  2024-10-14T00:47:23.330261Z [error    ] Failed to run or to evaluate example Example({'text': 'How long does it take to get a refund on something I bought?', 'label': 'request_refund', 'answer': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 20/2758 [00:30<1:09:24,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 21 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 79 / 300  (26.3): 100%|██████████| 300/300 [00:20<00:00, 14.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.0, 14.0, 27.33, 26.33, 26.33]\n",
      "Best score so far: 27.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/2758 [00:01<24:59,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 69 / 300  (23.0): 100%|██████████| 300/300 [00:18<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.0, 14.0, 27.33, 26.33, 26.33, 23.0]\n",
      "Best score so far: 27.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/2758 [00:05<33:30,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:48:31.369275Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 300  (23.7): 100%|██████████| 300/300 [00:26<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.0, 14.0, 27.33, 26.33, 26.33, 23.0, 23.67]\n",
      "Best score so far: 27.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2758 [00:00<21:47,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 36 / 300  (12.0): 100%|██████████| 300/300 [00:19<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [14.0, 14.0, 27.33, 26.33, 26.33, 23.0, 23.67, 12.0]\n",
      "Best score so far: 27.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/2758 [00:09<30:36,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 15 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:49:28.380656Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:01<05:25,  1.09s/it]2024-10-14T00:49:28.549590Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 51  (39.2):  17%|█▋        | 50/300 [00:03<00:08, 28.46it/s]2024-10-14T00:49:30.750541Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 133  (35.3):  44%|████▍     | 132/300 [00:07<00:04, 38.49it/s]2024-10-14T00:49:34.627074Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 134  (35.1):  45%|████▍     | 134/300 [00:07<00:07, 22.05it/s] [24-10-14T00:49:34.633063Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 183  (32.2):  61%|██████    | 182/300 [00:09<00:05, 22.04it/s]lineno0-14T00:49:36.867657Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 60.0 / 186  (32.3):  62%|██████▏   | 185/300 [00:10<00:04, 23.30it/s]2024-10-14T00:49:37.350680Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 77.0 / 235  (32.8):  78%|███████▊  | 234/300 [00:12<00:03, 20.52it/s]2024-10-14T00:49:39.926183Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 109.0 / 300  (36.3): 100%|██████████| 300/300 [00:14<00:00, 20.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 36.33 for seed 5\n",
      "Scores so far: [14.0, 14.0, 27.33, 26.33, 26.33, 23.0, 23.67, 12.0, 36.33]\n",
      "Best score so far: 36.33\n",
      "9 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]2024-10-14T00:49:43.406393Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 5  (20.0):   0%|          | 5/1000 [00:01<04:01,  4.12it/s]2024-10-14T00:49:43.856610Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 61.0 / 160  (38.1):  16%|█▌        | 159/1000 [00:10<01:13, 11.37it/s]2024-10-14T00:49:52.186069Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 201  (35.3):  20%|██        | 200/1000 [00:11<00:46, 17.16it/s]2024-10-14T00:49:54.050843Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 91.0 / 258  (35.3):  26%|██▌       | 257/1000 [00:15<00:49, 15.05it/s]2024-10-14T00:49:57.517129Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 98.0 / 302  (32.5):  30%|███       | 301/1000 [00:17<00:50, 13.97it/s]2024-10-14T00:49:59.607323Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 107.0 / 320  (33.4):  32%|███▏      | 320/1000 [00:18<00:34, 19.71it/s]dspy.evaluate.evaluate3534Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 126.0 / 369  (34.1):  37%|███▋      | 369/1000 [00:21<00:29, 21.35it/s] [24-10-14T00:50:03.246529Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 133.0 / 388  (34.3):  39%|███▊      | 387/1000 [00:21<00:31, 19.72it/s]2024-10-14T00:50:03.985537Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 146.0 / 431  (33.9):  43%|████▎     | 430/1000 [00:24<00:29, 19.39it/s]=024-10-14T00:50:06.395534Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 189.0 / 541  (34.9):  54%|█████▍    | 540/1000 [00:30<00:28, 16.27it/s]2024-10-14T00:50:12.761635Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 193.0 / 552  (35.0):  55%|█████▌    | 551/1000 [00:31<00:28, 15.88it/s]2024-10-14T00:50:13.304914Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 224.0 / 632  (35.4):  63%|██████▎   | 631/1000 [00:36<00:22, 16.58it/s]2024-10-14T00:50:18.232462Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 235.0 / 662  (35.5):  66%|██████▌   | 661/1000 [00:37<00:21, 16.03it/s]198luate.py00:50:20.035802Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=\n",
      "Average Metric: 248.0 / 705  (35.2):  70%|███████   | 704/1000 [00:40<00:13, 21.87it/s]evaluate.py00:50:22.519392Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 256.0 / 738  (34.7):  74%|███████▎  | 737/1000 [00:42<00:12, 21.20it/s]2024-10-14T00:50:24.424334Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 273.0 / 786  (34.7):  78%|███████▊  | 785/1000 [00:44<00:13, 15.97it/s]evaluate.py00:50:26.719801Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 290.0 / 830  (34.9):  83%|████████▎ | 830/1000 [00:47<00:09, 18.02it/s]=024-10-14T00:50:29.187137Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filenameevaluate.py lineno=198\n",
      "Average Metric: 296.0 / 846  (35.0):  84%|████████▍ | 845/1000 [00:48<00:10, 15.29it/s]2024-10-14T00:50:30.315293Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 297.0 / 857  (34.7):  86%|████████▌ | 856/1000 [00:48<00:06, 20.88it/s]2024-10-14T00:50:30.832438Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 297.0 / 867  (34.3):  87%|████████▋ | 866/1000 [00:49<00:06, 20.56it/s]2024-10-14T00:50:31.229190Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 299.0 / 873  (34.2):  87%|████████▋ | 872/1000 [00:49<00:06, 19.33it/s]2024-10-14T00:50:31.590590Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 305.0 / 890  (34.3):  89%|████████▉ | 889/1000 [00:50<00:06, 16.03it/s]2024-10-14T00:50:32.779103Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 331.0 / 951  (34.8):  95%|█████████▌| 951/1000 [00:53<00:01, 27.99it/s]2024-10-14T00:50:35.777790Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 341.0 / 980  (34.8):  98%|█████████▊| 979/1000 [00:54<00:00, 50.47it/s]lineno0-14T00:50:36.129214Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 349.0 / 1000  (34.9): 100%|██████████| 1000/1000 [00:54<00:00, 18.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for meta-llama/Llama-3.2-1B-Instruct:epochs-1-total-trained-steps-64: 34.9, None, None\n",
      "Evaluating openai/meta-llama/Llama-3.2-1B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]2024-10-14T00:50:37.207697Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/1000 [00:00<07:57,  2.09it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/1000 [00:00<07:57,  2.09it/s]2024-10-14T00:50:37.260363Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   0%|          | 2/1000 [00:00<07:57,  2.09it/s]2024-10-14T00:50:37.387604Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   0%|          | 4/1000 [00:00<02:19,  7.14it/s]2024-10-14T00:50:37.419194Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   0%|          | 4/1000 [00:00<02:19,  7.14it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   0%|          | 5/1000 [00:00<02:19,  7.14it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   1%|          | 7/1000 [00:00<01:31, 10.90it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   1%|          | 7/1000 [00:00<01:31, 10.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 9  (0.0):   1%|          | 8/1000 [00:00<01:30, 10.90it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 10  (0.0):   1%|          | 9/1000 [00:00<01:30, 10.90it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 12  (0.0):   1%|          | 11/1000 [00:00<00:58, 17.04it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 13  (0.0):   1%|          | 12/1000 [00:00<00:57, 17.04it/s]2024-10-14T00:50:37.531771Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 15  (0.0):   1%|▏         | 14/1000 [00:01<00:57, 17.04it/s] 024-10-14T00:50:37.534751Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 0.0 / 16  (0.0):   2%|▏         | 16/1000 [00:01<00:40, 24.59it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 17  (0.0):   2%|▏         | 16/1000 [00:01<00:40, 24.59it/s]2024-10-14T00:50:37.568529Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 18  (0.0):   2%|▏         | 17/1000 [00:01<00:39, 24.59it/s]2024-10-14T00:50:37.570962Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 19  (0.0):   2%|▏         | 18/1000 [00:01<00:39, 24.59it/s]2024-10-14T00:50:37.576909Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 20  (0.0):   2%|▏         | 19/1000 [00:01<00:39, 24.59it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 21  (0.0):   2%|▏         | 20/1000 [00:01<00:39, 24.59it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 22  (0.0):   2%|▏         | 22/1000 [00:01<00:30, 32.10it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 23  (0.0):   2%|▏         | 22/1000 [00:01<00:30, 32.10it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 24  (0.0):   2%|▏         | 23/1000 [00:01<00:30, 32.10it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 25  (0.0):   2%|▏         | 24/1000 [00:01<00:30, 32.10it/s]2024-10-14T00:50:37.653967Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 26  (0.0):   2%|▎         | 25/1000 [00:01<00:30, 32.10it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 27  (0.0):   3%|▎         | 26/1000 [00:01<00:30, 32.10it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 28  (0.0):   3%|▎         | 28/1000 [00:01<00:25, 38.11it/s]2024-10-14T00:50:37.703893Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 29  (0.0):   3%|▎         | 28/1000 [00:01<00:25, 38.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 30  (0.0):   3%|▎         | 29/1000 [00:01<00:25, 38.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 31  (0.0):   3%|▎         | 30/1000 [00:01<00:25, 38.11it/s]2024-10-14T00:50:37.742062Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 32  (0.0):   3%|▎         | 31/1000 [00:01<00:25, 38.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 33  (0.0):   3%|▎         | 32/1000 [00:01<00:25, 38.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 34  (0.0):   3%|▎         | 34/1000 [00:01<00:22, 43.46it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 35  (0.0):   3%|▎         | 34/1000 [00:01<00:22, 43.46it/s]2024-10-14T00:50:37.837263Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 36  (0.0):   4%|▎         | 35/1000 [00:01<00:22, 43.46it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 37  (0.0):   4%|▎         | 36/1000 [00:01<00:22, 43.46it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 38  (0.0):   4%|▎         | 37/1000 [00:01<00:22, 43.46it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 40  (0.0):   4%|▍         | 40/1000 [00:01<00:24, 38.82it/s]2024-10-14T00:50:38.295111Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 41  (0.0):   4%|▍         | 40/1000 [00:01<00:24, 38.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 42  (0.0):   4%|▍         | 41/1000 [00:01<00:24, 38.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 43  (0.0):   4%|▍         | 42/1000 [00:01<00:24, 38.82it/s]2024-10-14T00:50:38.460184Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 46  (0.0):   4%|▍         | 45/1000 [00:01<00:29, 32.68it/s]2024-10-14T00:50:38.468833Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 48  (0.0):   5%|▍         | 47/1000 [00:01<00:29, 32.68it/s]] ror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 49  (0.0):   5%|▍         | 48/1000 [00:01<00:29, 32.68it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 50  (0.0):   5%|▍         | 49/1000 [00:01<00:29, 32.68it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 51  (0.0):   5%|▌         | 51/1000 [00:01<00:24, 37.99it/s]2024-10-14T00:50:38.700584Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 52  (0.0):   5%|▌         | 51/1000 [00:01<00:24, 37.99it/s]2024-10-14T00:50:38.746624Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 53  (0.0):   5%|▌         | 52/1000 [00:02<00:24, 37.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 54  (0.0):   5%|▌         | 53/1000 [00:02<00:24, 37.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 56  (0.0):   6%|▌         | 56/1000 [00:02<00:33, 28.30it/s]linenote.py00:50:38.792806Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= =198\n",
      "Average Metric: 0.0 / 57  (0.0):   6%|▌         | 56/1000 [00:02<00:33, 28.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 58  (0.0):   6%|▌         | 57/1000 [00:02<00:33, 28.30it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 59  (0.0):   6%|▌         | 58/1000 [00:02<00:33, 28.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 60  (0.0):   6%|▌         | 59/1000 [00:02<00:33, 28.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 61  (0.0):   6%|▌         | 61/1000 [00:02<00:29, 31.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 62  (0.0):   6%|▌         | 61/1000 [00:02<00:29, 31.39it/s]2024-10-14T00:50:38.863504Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 63  (0.0):   6%|▌         | 62/1000 [00:02<00:29, 31.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 64  (0.0):   6%|▋         | 63/1000 [00:02<00:29, 31.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 65  (0.0):   6%|▋         | 64/1000 [00:02<00:29, 31.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 66  (0.0):   6%|▋         | 65/1000 [00:02<00:29, 31.39it/s]2024-10-14T00:50:38.926690Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 67  (0.0):   7%|▋         | 67/1000 [00:02<00:25, 36.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 68  (0.0):   7%|▋         | 67/1000 [00:02<00:25, 36.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 69  (0.0):   7%|▋         | 68/1000 [00:02<00:25, 36.78it/s]2024-10-14T00:50:38.969677Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 70  (0.0):   7%|▋         | 69/1000 [00:02<00:25, 36.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 71  (0.0):   7%|▋         | 70/1000 [00:02<00:25, 36.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 72  (0.0):   7%|▋         | 72/1000 [00:02<00:31, 29.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 73  (0.0):   7%|▋         | 72/1000 [00:02<00:31, 29.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 74  (0.0):   7%|▋         | 73/1000 [00:02<00:31, 29.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 75  (0.0):   7%|▋         | 74/1000 [00:02<00:31, 29.60it/s]2024-10-14T00:50:39.698306Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 76  (0.0):   8%|▊         | 76/1000 [00:02<00:43, 21.48it/s]2024-10-14T00:50:39.721803Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 79  (0.0):   8%|▊         | 78/1000 [00:03<00:42, 21.48it/s]error    4T00:50:39.733243Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 80  (0.0):   8%|▊         | 79/1000 [00:03<00:42, 21.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 81  (0.0):   8%|▊         | 80/1000 [00:03<00:42, 21.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 85  (3.5):   8%|▊         | 84/1000 [00:03<00:33, 27.44it/s]2024-10-14T00:50:39.955592Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 86  (3.5):   9%|▊         | 86/1000 [00:03<00:35, 25.76it/s]2024-10-14T00:50:39.965986Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 88  (3.4):   9%|▊         | 87/1000 [00:03<00:35, 25.76it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 89  (3.4):   9%|▉         | 88/1000 [00:03<00:35, 25.76it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 90  (3.3):   9%|▉         | 89/1000 [00:03<00:35, 25.76it/s]2024-10-14T00:50:40.013214Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 91  (3.3):   9%|▉         | 90/1000 [00:03<00:35, 25.76it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 92  (3.3):   9%|▉         | 92/1000 [00:03<00:28, 31.31it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 93  (3.2):   9%|▉         | 92/1000 [00:03<00:28, 31.31it/s]2024-10-14T00:50:40.035022Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 94  (3.2):   9%|▉         | 93/1000 [00:03<00:28, 31.31it/s]2024-10-14T00:50:40.051976Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 95  (3.2):   9%|▉         | 94/1000 [00:03<00:28, 31.31it/s]2024-10-14T00:50:40.088920Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 96  (3.1):  10%|▉         | 95/1000 [00:03<00:28, 31.31it/s]2024-10-14T00:50:40.287491Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 98  (4.1):  10%|▉         | 97/1000 [00:03<00:30, 29.91it/s]2024-10-14T00:50:40.328623Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 99  (4.0):  10%|▉         | 98/1000 [00:03<00:30, 29.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 100  (4.0):  10%|▉         | 99/1000 [00:03<00:30, 29.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 101  (4.0):  10%|█         | 101/1000 [00:03<00:28, 31.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 102  (3.9):  10%|█         | 101/1000 [00:03<00:28, 31.34it/s]2024-10-14T00:50:40.398983Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 103  (3.9):  10%|█         | 102/1000 [00:03<00:28, 31.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 104  (3.8):  10%|█         | 103/1000 [00:03<00:28, 31.34it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 105  (3.8):  10%|█         | 104/1000 [00:03<00:28, 31.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 106  (3.8):  11%|█         | 106/1000 [00:03<00:25, 35.26it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 107  (3.7):  11%|█         | 106/1000 [00:03<00:25, 35.26it/s]2024-10-14T00:50:40.525682Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 108  (3.7):  11%|█         | 107/1000 [00:03<00:25, 35.26it/s]2024-10-14T00:50:40.660495Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 109  (3.7):  11%|█         | 108/1000 [00:03<00:25, 35.26it/s]2024-10-14T00:50:40.669904Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 110  (3.6):  11%|█         | 110/1000 [00:03<00:30, 28.81it/s]2024-10-14T00:50:40.681897Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 111  (3.6):  11%|█         | 110/1000 [00:03<00:30, 28.81it/s]2024-10-14T00:50:40.686725Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 112  (3.6):  11%|█         | 111/1000 [00:04<00:30, 28.81it/s]2024-10-14T00:50:40.690551Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 113  (3.5):  11%|█         | 112/1000 [00:04<00:30, 28.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 114  (3.5):  11%|█▏        | 113/1000 [00:04<00:30, 28.81it/s]2024-10-14T00:50:40.711346Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 115  (3.5):  11%|█▏        | 114/1000 [00:04<00:30, 28.81it/s]2024-10-14T00:50:40.718993Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 116  (3.4):  12%|█▏        | 116/1000 [00:04<00:25, 34.83it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 117  (3.4):  12%|█▏        | 116/1000 [00:04<00:25, 34.83it/s]2024-10-14T00:50:41.036848Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 118  (3.4):  12%|█▏        | 117/1000 [00:04<00:25, 34.83it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 119  (3.4):  12%|█▏        | 118/1000 [00:04<00:25, 34.83it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 120  (3.3):  12%|█▏        | 119/1000 [00:04<00:25, 34.83it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 121  (3.3):  12%|█▏        | 121/1000 [00:04<00:32, 26.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 124  (3.2):  12%|█▏        | 123/1000 [00:04<00:32, 26.66it/s]=rror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 4.0 / 125  (3.2):  12%|█▏        | 124/1000 [00:04<00:32, 26.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 126  (3.2):  12%|█▎        | 125/1000 [00:04<00:32, 26.66it/s]2024-10-14T00:50:41.117861Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 127  (3.1):  13%|█▎        | 127/1000 [00:04<00:27, 32.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 128  (3.1):  13%|█▎        | 127/1000 [00:04<00:27, 32.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 130  (3.1):  13%|█▎        | 129/1000 [00:04<00:26, 32.29it/s]2024-10-14T00:50:41.383078Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 131  (3.1):  13%|█▎        | 131/1000 [00:04<00:29, 29.31it/s]2024-10-14T00:50:41.409787Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 132  (3.0):  13%|█▎        | 131/1000 [00:04<00:29, 29.31it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 133  (3.0):  13%|█▎        | 132/1000 [00:04<00:29, 29.31it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 134  (3.0):  13%|█▎        | 133/1000 [00:04<00:29, 29.31it/s]2024-10-14T00:50:41.455014Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 135  (3.0):  14%|█▎        | 135/1000 [00:04<00:27, 31.02it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 136  (2.9):  14%|█▎        | 135/1000 [00:04<00:27, 31.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 137  (2.9):  14%|█▎        | 136/1000 [00:04<00:27, 31.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 138  (2.9):  14%|█▎        | 137/1000 [00:04<00:27, 31.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 139  (2.9):  14%|█▍        | 138/1000 [00:04<00:27, 31.02it/s]2024-10-14T00:50:41.508207Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 140  (2.9):  14%|█▍        | 139/1000 [00:04<00:27, 31.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 142  (3.5):  14%|█▍        | 141/1000 [00:05<00:23, 37.28it/s]=024-10-14T00:50:41.869210Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 5.0 / 145  (3.4):  14%|█▍        | 144/1000 [00:05<00:22, 37.28it/s]=[error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 5.0 / 147  (3.4):  15%|█▍        | 146/1000 [00:05<00:36, 23.54it/s]dspy.evaluate.evaluatexample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 150  (3.3):  15%|█▍        | 149/1000 [00:05<00:36, 23.54it/s]][error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 152  (3.3):  15%|█▌        | 151/1000 [00:05<00:36, 23.54it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 153  (3.3):  15%|█▌        | 152/1000 [00:05<00:28, 29.48it/s]2024-10-14T00:50:42.026766Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 154  (3.2):  15%|█▌        | 153/1000 [00:05<00:28, 29.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 157  (3.8):  16%|█▌        | 156/1000 [00:05<00:28, 29.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 158  (3.8):  16%|█▌        | 158/1000 [00:05<00:24, 34.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 159  (3.8):  16%|█▌        | 158/1000 [00:05<00:24, 34.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 160  (3.8):  16%|█▌        | 159/1000 [00:05<00:24, 34.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 161  (3.7):  16%|█▌        | 160/1000 [00:05<00:24, 34.80it/s]2024-10-14T00:50:42.107474Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 163  (4.3):  16%|█▌        | 162/1000 [00:05<00:24, 34.80it/s]2024-10-14T00:50:42.136540Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 164  (4.3):  16%|█▋        | 164/1000 [00:05<00:21, 39.07it/s]2024-10-14T00:50:42.142760Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 165  (4.2):  16%|█▋        | 164/1000 [00:05<00:21, 39.07it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 166  (4.2):  16%|█▋        | 165/1000 [00:05<00:21, 39.07it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 167  (4.2):  17%|█▋        | 166/1000 [00:05<00:21, 39.07it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 168  (4.2):  17%|█▋        | 167/1000 [00:05<00:21, 39.07it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 169  (4.1):  17%|█▋        | 168/1000 [00:05<00:21, 39.07it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 170  (4.1):  17%|█▋        | 170/1000 [00:05<00:19, 42.82it/s]2024-10-14T00:50:42.234493Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 171  (4.1):  17%|█▋        | 170/1000 [00:05<00:19, 42.82it/s]2024-10-14T00:50:42.235011Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 172  (4.1):  17%|█▋        | 171/1000 [00:05<00:19, 42.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 173  (4.0):  17%|█▋        | 172/1000 [00:05<00:19, 42.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 174  (4.0):  17%|█▋        | 173/1000 [00:05<00:19, 42.82it/s]2024-10-14T00:50:42.295466Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 175  (4.0):  17%|█▋        | 174/1000 [00:05<00:19, 42.82it/s]2024-10-14T00:50:42.325221Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 176  (4.0):  18%|█▊        | 176/1000 [00:05<00:17, 46.91it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 177  (4.0):  18%|█▊        | 176/1000 [00:05<00:17, 46.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 178  (3.9):  18%|█▊        | 177/1000 [00:05<00:17, 46.91it/s]2024-10-14T00:50:42.752202Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 179  (3.9):  18%|█▊        | 178/1000 [00:06<00:17, 46.91it/s]2024-10-14T00:50:42.774448Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 181  (3.9):  18%|█▊        | 180/1000 [00:06<00:17, 46.91it/s]2024-10-14T00:50:42.890160Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 182  (3.8):  18%|█▊        | 182/1000 [00:06<00:26, 30.38it/s]2024-10-14T00:50:42.924546Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 183  (3.8):  18%|█▊        | 182/1000 [00:06<00:26, 30.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 184  (3.8):  18%|█▊        | 183/1000 [00:06<00:26, 30.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 185  (3.8):  18%|█▊        | 184/1000 [00:06<00:26, 30.38it/s]2024-10-14T00:50:42.940959Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 186  (3.8):  18%|█▊        | 185/1000 [00:06<00:26, 30.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 187  (3.7):  19%|█▊        | 187/1000 [00:06<00:25, 31.51it/s]2024-10-14T00:50:42.989020Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 188  (3.7):  19%|█▊        | 187/1000 [00:06<00:25, 31.51it/s]2024-10-14T00:50:42.992485Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 189  (3.7):  19%|█▉        | 188/1000 [00:06<00:25, 31.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 190  (3.7):  19%|█▉        | 189/1000 [00:06<00:25, 31.51it/s]2024-10-14T00:50:43.003971Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 191  (3.7):  19%|█▉        | 190/1000 [00:06<00:25, 31.51it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 192  (3.6):  19%|█▉        | 191/1000 [00:06<00:25, 31.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 193  (3.6):  19%|█▉        | 193/1000 [00:06<00:21, 37.03it/s]2024-10-14T00:50:43.235347Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 194  (3.6):  19%|█▉        | 193/1000 [00:06<00:21, 37.03it/s]2024-10-14T00:50:43.261020Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 196  (3.6):  20%|█▉        | 195/1000 [00:06<00:21, 37.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 197  (3.6):  20%|█▉        | 196/1000 [00:06<00:21, 37.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 199  (3.5):  20%|█▉        | 198/1000 [00:06<00:24, 32.29it/s]linenor    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 7.0 / 200  (3.5):  20%|█▉        | 199/1000 [00:06<00:24, 32.29it/s]2024-10-14T00:50:43.297971Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 201  (3.5):  20%|██        | 200/1000 [00:06<00:24, 32.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 202  (3.5):  20%|██        | 201/1000 [00:06<00:24, 32.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 203  (3.4):  20%|██        | 202/1000 [00:06<00:24, 32.29it/s]2024-10-14T00:50:43.348022Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 204  (3.4):  20%|██        | 204/1000 [00:06<00:21, 36.62it/s]2024-10-14T00:50:43.399475Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 205  (3.4):  20%|██        | 204/1000 [00:06<00:21, 36.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 206  (3.4):  20%|██        | 205/1000 [00:06<00:21, 36.62it/s]2024-10-14T00:50:43.423432Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 207  (3.4):  21%|██        | 206/1000 [00:06<00:21, 36.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 208  (3.4):  21%|██        | 207/1000 [00:06<00:21, 36.62it/s]2024-10-14T00:50:43.644443Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 209  (3.3):  21%|██        | 209/1000 [00:06<00:23, 33.33it/s]2024-10-14T00:50:43.679623Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 211  (3.3):  21%|██        | 210/1000 [00:06<00:23, 33.33it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 213  (3.8):  21%|██        | 212/1000 [00:06<00:23, 33.33it/s]2024-10-14T00:50:43.758544Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 214  (3.7):  21%|██▏       | 214/1000 [00:07<00:22, 35.57it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 216  (3.7):  22%|██▏       | 215/1000 [00:07<00:22, 35.57it/s] 024-10-14T00:50:43.897764Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 8.0 / 217  (3.7):  22%|██▏       | 216/1000 [00:07<00:22, 35.57it/s]2024-10-14T00:50:43.906436Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 219  (3.7):  22%|██▏       | 218/1000 [00:07<00:26, 29.13it/s]2024-10-14T00:50:43.930679Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 221  (4.1):  22%|██▏       | 220/1000 [00:07<00:26, 29.13it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 222  (4.1):  22%|██▏       | 221/1000 [00:07<00:26, 29.13it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 223  (4.0):  22%|██▏       | 222/1000 [00:07<00:26, 29.13it/s]2024-10-14T00:50:43.961863Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 224  (4.0):  22%|██▏       | 223/1000 [00:07<00:26, 29.13it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 225  (4.0):  22%|██▎       | 225/1000 [00:07<00:21, 36.54it/s]2024-10-14T00:50:43.996764Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 226  (4.0):  22%|██▎       | 225/1000 [00:07<00:21, 36.54it/s]2024-10-14T00:50:44.003042Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 227  (4.0):  23%|██▎       | 226/1000 [00:07<00:21, 36.54it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 228  (3.9):  23%|██▎       | 227/1000 [00:07<00:21, 36.54it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 229  (3.9):  23%|██▎       | 228/1000 [00:07<00:21, 36.54it/s]2024-10-14T00:50:44.273718Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 230  (3.9):  23%|██▎       | 230/1000 [00:07<00:23, 32.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 231  (3.9):  23%|██▎       | 230/1000 [00:07<00:23, 32.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 232  (3.9):  23%|██▎       | 231/1000 [00:07<00:23, 32.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 233  (3.9):  23%|██▎       | 232/1000 [00:07<00:23, 32.70it/s]2024-10-14T00:50:44.329141Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 234  (3.8):  23%|██▎       | 233/1000 [00:07<00:23, 32.70it/s]2024-10-14T00:50:44.350873Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 235  (3.8):  24%|██▎       | 235/1000 [00:07<00:21, 35.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 238  (3.8):  24%|██▎       | 237/1000 [00:07<00:21, 35.63it/s]2024-10-14T00:50:44.526533Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 239  (3.8):  24%|██▍       | 239/1000 [00:07<00:24, 31.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 240  (3.8):  24%|██▍       | 239/1000 [00:07<00:24, 31.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 241  (3.7):  24%|██▍       | 240/1000 [00:07<00:24, 31.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 242  (3.7):  24%|██▍       | 241/1000 [00:07<00:23, 31.66it/s]2024-10-14T00:50:44.578075Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 243  (3.7):  24%|██▍       | 242/1000 [00:07<00:23, 31.66it/s]2024-10-14T00:50:44.582453Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 244  (3.7):  24%|██▍       | 243/1000 [00:07<00:23, 31.66it/s]2024-10-14T00:50:44.591498Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 245  (3.7):  24%|██▍       | 245/1000 [00:07<00:20, 36.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 247  (3.6):  25%|██▍       | 246/1000 [00:08<00:20, 36.43it/s]2024-10-14T00:50:44.812099Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 250  (3.6):  25%|██▍       | 249/1000 [00:08<00:22, 32.91it/s]2024-10-14T00:50:44.819067Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 251  (3.6):  25%|██▌       | 250/1000 [00:08<00:22, 32.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 252  (3.6):  25%|██▌       | 251/1000 [00:08<00:22, 32.91it/s]2024-10-14T00:50:44.891507Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 253  (3.6):  25%|██▌       | 253/1000 [00:08<00:21, 34.48it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 254  (3.5):  25%|██▌       | 253/1000 [00:08<00:21, 34.48it/s]2024-10-14T00:50:44.905449Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 255  (3.5):  25%|██▌       | 254/1000 [00:08<00:21, 34.48it/s]2024-10-14T00:50:44.911710Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 256  (3.5):  26%|██▌       | 255/1000 [00:08<00:21, 34.48it/s]2024-10-14T00:50:44.914492Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 257  (3.5):  26%|██▌       | 256/1000 [00:08<00:21, 34.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 258  (3.5):  26%|██▌       | 257/1000 [00:08<00:21, 34.48it/s]2024-10-14T00:50:44.942670Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 260  (3.5):  26%|██▌       | 259/1000 [00:08<00:18, 40.35it/s]2024-10-14T00:50:45.164342Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 261  (3.4):  26%|██▌       | 260/1000 [00:08<00:18, 40.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 262  (3.4):  26%|██▌       | 261/1000 [00:08<00:18, 40.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 263  (3.4):  26%|██▌       | 262/1000 [00:08<00:18, 40.35it/s]2024-10-14T00:50:45.200829Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 264  (3.4):  26%|██▋       | 264/1000 [00:08<00:21, 34.73it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 265  (3.4):  26%|██▋       | 264/1000 [00:08<00:21, 34.73it/s]2024-10-14T00:50:45.380254Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 266  (3.4):  26%|██▋       | 265/1000 [00:08<00:21, 34.73it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 269  (3.3):  27%|██▋       | 268/1000 [00:08<00:25, 28.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 270  (3.3):  27%|██▋       | 269/1000 [00:08<00:25, 28.39it/s]2024-10-14T00:50:45.422995Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 271  (3.3):  27%|██▋       | 270/1000 [00:08<00:25, 28.39it/s]2024-10-14T00:50:45.429747Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 272  (3.3):  27%|██▋       | 271/1000 [00:08<00:25, 28.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 273  (3.3):  27%|██▋       | 272/1000 [00:08<00:25, 28.39it/s]2024-10-14T00:50:45.489827Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 274  (3.3):  27%|██▋       | 274/1000 [00:08<00:21, 34.19it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 275  (3.3):  27%|██▋       | 274/1000 [00:08<00:21, 34.19it/s]2024-10-14T00:50:45.502478Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 276  (3.3):  28%|██▊       | 275/1000 [00:08<00:21, 34.19it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 277  (3.2):  28%|██▊       | 276/1000 [00:08<00:21, 34.19it/s]2024-10-14T00:50:45.713762Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 279  (3.2):  28%|██▊       | 278/1000 [00:09<00:23, 30.49it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 280  (3.2):  28%|██▊       | 279/1000 [00:09<00:23, 30.49it/s]2024-10-14T00:50:45.770916Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 281  (3.2):  28%|██▊       | 280/1000 [00:09<00:23, 30.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 282  (3.2):  28%|██▊       | 281/1000 [00:09<00:23, 30.49it/s]2024-10-14T00:50:45.829708Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 284  (3.2):  28%|██▊       | 283/1000 [00:09<00:20, 34.52it/s]2024-10-14T00:50:45.956379Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 286  (3.1):  28%|██▊       | 285/1000 [00:09<00:20, 34.52it/s]=[error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 9.0 / 289  (3.1):  29%|██▉       | 288/1000 [00:09<00:25, 28.35it/s]2024-10-14T00:50:46.001002Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 290  (3.1):  29%|██▉       | 289/1000 [00:09<00:25, 28.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 291  (3.1):  29%|██▉       | 290/1000 [00:09<00:25, 28.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 293  (3.1):  29%|██▉       | 293/1000 [00:09<00:20, 34.08it/s]filename14T00:50:46.024020Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 294  (3.1):  29%|██▉       | 293/1000 [00:09<00:20, 34.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 295  (3.1):  29%|██▉       | 294/1000 [00:09<00:20, 34.08it/s]2024-10-14T00:50:46.111897Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 296  (3.0):  30%|██▉       | 295/1000 [00:09<00:20, 34.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 297  (3.0):  30%|██▉       | 296/1000 [00:09<00:20, 34.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 298  (3.0):  30%|██▉       | 297/1000 [00:09<00:20, 34.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 299  (3.0):  30%|██▉       | 298/1000 [00:09<00:20, 34.08it/s]2024-10-14T00:50:46.146347Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 300  (3.0):  30%|███       | 300/1000 [00:09<00:17, 40.96it/s]2024-10-14T00:50:46.379585Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 301  (3.0):  30%|███       | 300/1000 [00:09<00:17, 40.96it/s]2024-10-14T00:50:46.386670Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 303  (3.0):  30%|███       | 302/1000 [00:09<00:17, 40.96it/s]2024-10-14T00:50:46.394466Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 304  (3.0):  30%|███       | 303/1000 [00:09<00:17, 40.96it/s]2024-10-14T00:50:46.450006Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 306  (2.9):  30%|███       | 305/1000 [00:09<00:20, 34.09it/s]][error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 307  (2.9):  31%|███       | 306/1000 [00:09<00:20, 34.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 308  (2.9):  31%|███       | 307/1000 [00:09<00:20, 34.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 309  (2.9):  31%|███       | 308/1000 [00:09<00:20, 34.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 310  (2.9):  31%|███       | 309/1000 [00:09<00:20, 34.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 311  (2.9):  31%|███       | 311/1000 [00:09<00:17, 39.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 313  (2.9):  31%|███       | 312/1000 [00:10<00:17, 39.29it/s]2024-10-14T00:50:46.739484Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 316  (2.8):  32%|███▏      | 316/1000 [00:10<00:20, 33.25it/s]2024-10-14T00:50:46.744421Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 317  (2.8):  32%|███▏      | 316/1000 [00:10<00:20, 33.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 318  (2.8):  32%|███▏      | 317/1000 [00:10<00:20, 33.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 319  (2.8):  32%|███▏      | 318/1000 [00:10<00:20, 33.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 320  (2.8):  32%|███▏      | 319/1000 [00:10<00:20, 33.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 321  (2.8):  32%|███▏      | 320/1000 [00:10<00:20, 33.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 322  (2.8):  32%|███▏      | 322/1000 [00:10<00:18, 37.45it/s]2024-10-14T00:50:47.025220Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 323  (2.8):  32%|███▏      | 322/1000 [00:10<00:18, 37.45it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 324  (2.8):  32%|███▏      | 323/1000 [00:10<00:18, 37.45it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 325  (2.8):  32%|███▏      | 324/1000 [00:10<00:18, 37.45it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 327  (2.8):  33%|███▎      | 327/1000 [00:10<00:21, 31.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 328  (2.7):  33%|███▎      | 327/1000 [00:10<00:21, 31.47it/s]2024-10-14T00:50:47.085757Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 329  (2.7):  33%|███▎      | 328/1000 [00:10<00:21, 31.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 330  (2.7):  33%|███▎      | 329/1000 [00:10<00:21, 31.47it/s]2024-10-14T00:50:47.118976Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 331  (2.7):  33%|███▎      | 330/1000 [00:10<00:21, 31.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 332  (2.7):  33%|███▎      | 331/1000 [00:10<00:21, 31.47it/s]2024-10-14T00:50:47.127955Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 333  (2.7):  33%|███▎      | 333/1000 [00:10<00:18, 36.43it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 334  (2.7):  33%|███▎      | 333/1000 [00:10<00:18, 36.43it/s]2024-10-14T00:50:47.175404Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 335  (2.7):  33%|███▎      | 334/1000 [00:10<00:18, 36.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 336  (2.7):  34%|███▎      | 335/1000 [00:10<00:18, 36.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 337  (2.7):  34%|███▎      | 336/1000 [00:10<00:18, 36.43it/s]2024-10-14T00:50:47.646565Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 339  (2.9):  34%|███▍      | 338/1000 [00:11<00:30, 21.53it/s][error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 341  (2.9):  34%|███▍      | 340/1000 [00:11<00:30, 21.53it/s]2024-10-14T00:50:47.688173Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 343  (3.2):  34%|███▍      | 342/1000 [00:11<00:30, 21.53it/s]2024-10-14T00:50:47.699987Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 344  (3.2):  34%|███▍      | 344/1000 [00:11<00:24, 26.26it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 346  (3.2):  34%|███▍      | 345/1000 [00:11<00:24, 26.26it/s]error    4T00:50:47.765330Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 347  (3.2):  35%|███▍      | 346/1000 [00:11<00:24, 26.26it/s]2024-10-14T00:50:47.769070Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 350  (3.1):  35%|███▍      | 349/1000 [00:11<00:21, 29.80it/s]lineno0-14T00:50:47.775745Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 11.0 / 351  (3.1):  35%|███▌      | 350/1000 [00:11<00:21, 29.80it/s]2024-10-14T00:50:47.809864Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 352  (3.1):  35%|███▌      | 351/1000 [00:11<00:21, 29.80it/s]2024-10-14T00:50:47.813854Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 353  (3.1):  35%|███▌      | 352/1000 [00:11<00:21, 29.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 354  (3.1):  35%|███▌      | 353/1000 [00:11<00:21, 29.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 355  (3.1):  35%|███▌      | 354/1000 [00:11<00:21, 29.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 356  (3.1):  36%|███▌      | 356/1000 [00:11<00:17, 36.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 358  (3.1):  36%|███▌      | 357/1000 [00:11<00:17, 36.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 359  (3.1):  36%|███▌      | 358/1000 [00:11<00:17, 36.48it/s]2024-10-14T00:50:47.876289Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 360  (3.1):  36%|███▌      | 359/1000 [00:11<00:17, 36.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 361  (3.0):  36%|███▌      | 360/1000 [00:11<00:17, 36.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 362  (3.0):  36%|███▌      | 362/1000 [00:11<00:15, 41.09it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 363  (3.0):  36%|███▌      | 362/1000 [00:11<00:15, 41.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 364  (3.0):  36%|███▋      | 363/1000 [00:11<00:15, 41.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 365  (3.0):  36%|███▋      | 364/1000 [00:11<00:15, 41.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 366  (3.0):  36%|███▋      | 365/1000 [00:11<00:15, 41.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 367  (3.0):  37%|███▋      | 366/1000 [00:11<00:15, 41.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 368  (3.0):  37%|███▋      | 368/1000 [00:11<00:14, 44.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 369  (3.0):  37%|███▋      | 368/1000 [00:11<00:14, 44.18it/s]2024-10-14T00:50:48.019879Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 370  (3.0):  37%|███▋      | 369/1000 [00:11<00:14, 44.18it/s]2024-10-14T00:50:48.096416Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 371  (3.0):  37%|███▋      | 370/1000 [00:11<00:14, 44.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 372  (3.0):  37%|███▋      | 371/1000 [00:11<00:14, 44.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 373  (2.9):  37%|███▋      | 372/1000 [00:11<00:14, 44.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 375  (2.9):  37%|███▋      | 374/1000 [00:11<00:13, 47.31it/s]2024-10-14T00:50:48.556026Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 376  (2.9):  38%|███▊      | 375/1000 [00:11<00:13, 47.31it/s]2024-10-14T00:50:48.585998Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 377  (2.9):  38%|███▊      | 376/1000 [00:11<00:13, 47.31it/s]2024-10-14T00:50:48.592521Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 378  (2.9):  38%|███▊      | 377/1000 [00:11<00:13, 47.31it/s]2024-10-14T00:50:48.596653Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 379  (2.9):  38%|███▊      | 378/1000 [00:11<00:13, 47.31it/s]2024-10-14T00:50:48.800646Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 380  (2.9):  38%|███▊      | 380/1000 [00:12<00:22, 28.12it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 381  (2.9):  38%|███▊      | 380/1000 [00:12<00:22, 28.12it/s]2024-10-14T00:50:48.830256Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 383  (2.9):  38%|███▊      | 382/1000 [00:12<00:21, 28.12it/s]2024-10-14T00:50:48.835827Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 384  (2.9):  38%|███▊      | 383/1000 [00:12<00:21, 28.12it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 385  (2.9):  38%|███▊      | 385/1000 [00:12<00:20, 29.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 387  (2.8):  39%|███▊      | 386/1000 [00:12<00:20, 29.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 388  (2.8):  39%|███▊      | 387/1000 [00:12<00:20, 29.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 389  (2.8):  39%|███▉      | 388/1000 [00:12<00:20, 29.81it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 390  (2.8):  39%|███▉      | 389/1000 [00:12<00:20, 29.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 391  (2.8):  39%|███▉      | 391/1000 [00:12<00:17, 34.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 392  (2.8):  39%|███▉      | 391/1000 [00:12<00:17, 34.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 393  (2.8):  39%|███▉      | 392/1000 [00:12<00:17, 34.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 394  (2.8):  39%|███▉      | 393/1000 [00:12<00:17, 34.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 395  (2.8):  39%|███▉      | 394/1000 [00:12<00:17, 34.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 396  (2.8):  40%|███▉      | 395/1000 [00:12<00:17, 34.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 397  (2.8):  40%|███▉      | 396/1000 [00:12<00:17, 34.99it/s]2024-10-14T00:50:49.249658Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 398  (2.8):  40%|███▉      | 398/1000 [00:12<00:17, 35.30it/s]2024-10-14T00:50:49.274438Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 399  (2.8):  40%|███▉      | 398/1000 [00:12<00:17, 35.30it/s]2024-10-14T00:50:49.278128Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 400  (2.8):  40%|███▉      | 399/1000 [00:12<00:17, 35.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 401  (2.7):  40%|████      | 400/1000 [00:12<00:16, 35.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 402  (2.7):  40%|████      | 401/1000 [00:12<00:16, 35.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 403  (2.7):  40%|████      | 403/1000 [00:12<00:16, 36.65it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 404  (2.7):  40%|████      | 403/1000 [00:12<00:16, 36.65it/s]2024-10-14T00:50:49.337283Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 405  (2.7):  40%|████      | 404/1000 [00:12<00:16, 36.65it/s]2024-10-14T00:50:49.344672Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 407  (2.9):  41%|████      | 406/1000 [00:12<00:16, 36.65it/s]2024-10-14T00:50:49.550826Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 408  (2.9):  41%|████      | 408/1000 [00:12<00:17, 33.00it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 409  (2.9):  41%|████      | 408/1000 [00:12<00:17, 33.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 410  (2.9):  41%|████      | 409/1000 [00:12<00:17, 33.00it/s]2024-10-14T00:50:49.590432Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 411  (2.9):  41%|████      | 410/1000 [00:12<00:17, 33.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 412  (2.9):  41%|████      | 411/1000 [00:12<00:17, 33.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 413  (2.9):  41%|████▏     | 413/1000 [00:12<00:16, 36.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 414  (2.9):  41%|████▏     | 413/1000 [00:12<00:16, 36.11it/s]2024-10-14T00:50:49.793297Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 416  (2.9):  42%|████▏     | 415/1000 [00:13<00:16, 36.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 419  (2.9):  42%|████▏     | 418/1000 [00:13<00:17, 33.80it/s]2024-10-14T00:50:49.864585Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 421  (2.9):  42%|████▏     | 420/1000 [00:13<00:17, 33.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 422  (2.8):  42%|████▏     | 421/1000 [00:13<00:17, 33.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 423  (2.8):  42%|████▏     | 422/1000 [00:13<00:17, 33.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 424  (2.8):  42%|████▏     | 424/1000 [00:13<00:15, 38.23it/s]2024-10-14T00:50:50.068673Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 425  (2.8):  42%|████▏     | 424/1000 [00:13<00:15, 38.23it/s]2024-10-14T00:50:50.091425Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 427  (2.8):  43%|████▎     | 426/1000 [00:13<00:15, 38.23it/s]2024-10-14T00:50:50.116447Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 428  (2.8):  43%|████▎     | 427/1000 [00:13<00:14, 38.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 429  (2.8):  43%|████▎     | 429/1000 [00:13<00:17, 33.58it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 430  (2.8):  43%|████▎     | 429/1000 [00:13<00:17, 33.58it/s]2024-10-14T00:50:50.276895Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 431  (2.8):  43%|████▎     | 430/1000 [00:13<00:16, 33.58it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 432  (2.8):  43%|████▎     | 431/1000 [00:13<00:16, 33.58it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 433  (2.8):  43%|████▎     | 433/1000 [00:13<00:19, 28.58it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 434  (2.8):  43%|████▎     | 433/1000 [00:13<00:19, 28.58it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 435  (2.8):  43%|████▎     | 434/1000 [00:13<00:19, 28.58it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 436  (2.8):  44%|████▎     | 435/1000 [00:13<00:19, 28.58it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 437  (2.7):  44%|████▎     | 436/1000 [00:13<00:19, 28.58it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 438  (2.7):  44%|████▎     | 437/1000 [00:13<00:19, 28.58it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 439  (2.7):  44%|████▍     | 439/1000 [00:13<00:16, 33.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 440  (2.7):  44%|████▍     | 439/1000 [00:13<00:16, 33.81it/s]2024-10-14T00:50:50.381157Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 441  (2.7):  44%|████▍     | 440/1000 [00:13<00:16, 33.81it/s]2024-10-14T00:50:50.398438Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 442  (2.7):  44%|████▍     | 441/1000 [00:13<00:16, 33.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 443  (2.7):  44%|████▍     | 442/1000 [00:13<00:16, 33.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 444  (2.7):  44%|████▍     | 443/1000 [00:13<00:16, 33.81it/s]2024-10-14T00:50:50.593197Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 445  (2.7):  44%|████▍     | 445/1000 [00:13<00:14, 37.12it/s]2024-10-14T00:50:50.629380Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 446  (2.7):  44%|████▍     | 445/1000 [00:13<00:14, 37.12it/s]2024-10-14T00:50:50.637956Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 447  (2.7):  45%|████▍     | 446/1000 [00:13<00:14, 37.12it/s]2024-10-14T00:50:50.640344Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 448  (2.7):  45%|████▍     | 447/1000 [00:13<00:14, 37.12it/s]2024-10-14T00:50:50.664137Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 450  (2.7):  45%|████▌     | 450/1000 [00:14<00:16, 33.22it/s]2024-10-14T00:50:50.810494Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 453  (2.6):  45%|████▌     | 452/1000 [00:14<00:16, 33.22it/s]2024-10-14T00:50:50.849116Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 454  (2.6):  45%|████▌     | 453/1000 [00:14<00:16, 33.22it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 455  (2.6):  46%|████▌     | 455/1000 [00:14<00:14, 36.62it/s]2024-10-14T00:50:50.875101Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 456  (2.6):  46%|████▌     | 455/1000 [00:14<00:14, 36.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 457  (2.6):  46%|████▌     | 456/1000 [00:14<00:14, 36.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 458  (2.6):  46%|████▌     | 457/1000 [00:14<00:14, 36.62it/s]2024-10-14T00:50:51.071961Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 459  (2.6):  46%|████▌     | 458/1000 [00:14<00:14, 36.62it/s]2024-10-14T00:50:51.095138Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 460  (2.6):  46%|████▌     | 460/1000 [00:14<00:16, 32.17it/s]2024-10-14T00:50:51.099722Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 462  (2.6):  46%|████▌     | 461/1000 [00:14<00:16, 32.17it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 463  (2.6):  46%|████▌     | 462/1000 [00:14<00:16, 32.17it/s]2024-10-14T00:50:51.138985Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 464  (2.6):  46%|████▋     | 463/1000 [00:14<00:16, 32.17it/s]2024-10-14T00:50:51.142448Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 465  (2.6):  46%|████▋     | 465/1000 [00:14<00:15, 35.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 466  (2.6):  46%|████▋     | 465/1000 [00:14<00:15, 35.40it/s]2024-10-14T00:50:51.241394Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 467  (2.6):  47%|████▋     | 466/1000 [00:14<00:15, 35.40it/s]2024-10-14T00:50:51.348849Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 469  (2.6):  47%|████▋     | 469/1000 [00:14<00:16, 31.40it/s]2024-10-14T00:50:51.353088Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 471  (2.5):  47%|████▋     | 470/1000 [00:14<00:16, 31.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 472  (2.5):  47%|████▋     | 471/1000 [00:14<00:16, 31.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 473  (2.5):  47%|████▋     | 472/1000 [00:14<00:16, 31.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 474  (2.5):  47%|████▋     | 474/1000 [00:14<00:15, 34.83it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 475  (2.5):  47%|████▋     | 474/1000 [00:14<00:15, 34.83it/s]2024-10-14T00:50:51.465302Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 476  (2.5):  48%|████▊     | 475/1000 [00:14<00:15, 34.83it/s]2024-10-14T00:50:51.634458Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 477  (2.5):  48%|████▊     | 476/1000 [00:14<00:15, 34.83it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 478  (2.5):  48%|████▊     | 478/1000 [00:14<00:17, 29.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 480  (2.7):  48%|████▊     | 479/1000 [00:14<00:17, 29.62it/s]2024-10-14T00:50:51.653514Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 482  (2.7):  48%|████▊     | 481/1000 [00:15<00:17, 29.62it/s]2024-10-14T00:50:51.656710Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 483  (2.7):  48%|████▊     | 483/1000 [00:15<00:15, 33.21it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 484  (2.7):  48%|████▊     | 483/1000 [00:15<00:15, 33.21it/s]2024-10-14T00:50:51.683740Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 485  (2.7):  48%|████▊     | 484/1000 [00:15<00:15, 33.21it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 486  (2.7):  48%|████▊     | 485/1000 [00:15<00:15, 33.21it/s]2024-10-14T00:50:51.706425Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 487  (2.7):  49%|████▊     | 486/1000 [00:15<00:15, 33.21it/s]2024-10-14T00:50:51.712182Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 488  (2.7):  49%|████▊     | 487/1000 [00:15<00:15, 33.21it/s]2024-10-14T00:50:51.757093Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 489  (2.7):  49%|████▉     | 489/1000 [00:15<00:13, 38.51it/s] [24-10-14T00:50:51.764472Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 490  (2.7):  49%|████▉     | 489/1000 [00:15<00:13, 38.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 491  (2.6):  49%|████▉     | 490/1000 [00:15<00:13, 38.51it/s]2024-10-14T00:50:52.023425Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 492  (2.6):  49%|████▉     | 491/1000 [00:15<00:13, 38.51it/s]2024-10-14T00:50:52.064600Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 493  (2.6):  49%|████▉     | 492/1000 [00:15<00:13, 38.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 494  (2.6):  49%|████▉     | 494/1000 [00:15<00:15, 33.41it/s]2024-10-14T00:50:52.077906Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 495  (2.6):  49%|████▉     | 494/1000 [00:15<00:15, 33.41it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 496  (2.6):  50%|████▉     | 495/1000 [00:15<00:15, 33.41it/s]2024-10-14T00:50:52.164924Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 497  (2.6):  50%|████▉     | 496/1000 [00:15<00:15, 33.41it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 498  (2.6):  50%|████▉     | 497/1000 [00:15<00:15, 33.41it/s]2024-10-14T00:50:52.281697Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 500  (2.6):  50%|████▉     | 499/1000 [00:15<00:16, 30.51it/s]2024-10-14T00:50:52.312779Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 501  (2.6):  50%|█████     | 500/1000 [00:15<00:16, 30.51it/s]2024-10-14T00:50:52.326707Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 502  (2.6):  50%|█████     | 501/1000 [00:15<00:16, 30.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 503  (2.6):  50%|█████     | 502/1000 [00:15<00:16, 30.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 505  (2.6):  50%|█████     | 505/1000 [00:15<00:16, 30.32it/s]2024-10-14T00:50:52.534427Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 507  (2.6):  51%|█████     | 506/1000 [00:15<00:16, 30.32it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 508  (2.6):  51%|█████     | 507/1000 [00:15<00:16, 30.32it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 510  (2.5):  51%|█████     | 509/1000 [00:15<00:16, 29.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 511  (2.5):  51%|█████     | 510/1000 [00:15<00:16, 29.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 512  (2.5):  51%|█████     | 511/1000 [00:15<00:16, 29.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 513  (2.5):  51%|█████     | 512/1000 [00:15<00:16, 29.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 514  (2.5):  51%|█████▏    | 513/1000 [00:15<00:16, 29.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 515  (2.5):  52%|█████▏    | 515/1000 [00:15<00:13, 35.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 516  (2.5):  52%|█████▏    | 515/1000 [00:16<00:13, 35.69it/s]2024-10-14T00:50:52.682042Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 517  (2.5):  52%|█████▏    | 516/1000 [00:16<00:13, 35.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 518  (2.5):  52%|█████▏    | 517/1000 [00:16<00:13, 35.69it/s]2024-10-14T00:50:52.917409Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 519  (2.5):  52%|█████▏    | 519/1000 [00:16<00:15, 30.68it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 520  (2.5):  52%|█████▏    | 519/1000 [00:16<00:15, 30.68it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 521  (2.5):  52%|█████▏    | 520/1000 [00:16<00:15, 30.68it/s]2024-10-14T00:50:52.976984Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 522  (2.5):  52%|█████▏    | 521/1000 [00:16<00:15, 30.68it/s]2024-10-14T00:50:53.022595Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 523  (2.5):  52%|█████▏    | 523/1000 [00:16<00:14, 32.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 524  (2.5):  52%|█████▏    | 523/1000 [00:16<00:14, 32.24it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 525  (2.5):  52%|█████▏    | 524/1000 [00:16<00:14, 32.24it/s]2024-10-14T00:50:53.126911Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 526  (2.5):  52%|█████▎    | 525/1000 [00:16<00:14, 32.24it/s]2024-10-14T00:50:53.136843Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 527  (2.5):  53%|█████▎    | 527/1000 [00:16<00:14, 32.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 532  (2.6):  53%|█████▎    | 531/1000 [00:16<00:14, 32.05it/s]2024-10-14T00:50:53.225248Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 533  (2.6):  53%|█████▎    | 532/1000 [00:16<00:14, 32.05it/s]2024-10-14T00:50:53.576638Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 534  (2.6):  53%|█████▎    | 534/1000 [00:16<00:20, 22.26it/s]2024-10-14T00:50:53.580600Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 536  (2.6):  54%|█████▎    | 535/1000 [00:16<00:20, 22.26it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 538  (2.6):  54%|█████▎    | 537/1000 [00:16<00:19, 23.25it/s]] ror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 541  (2.6):  54%|█████▍    | 540/1000 [00:17<00:19, 23.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 544  (2.8):  54%|█████▍    | 543/1000 [00:17<00:15, 29.74it/s]] 24-10-14T00:50:53.631287Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 545  (2.8):  54%|█████▍    | 544/1000 [00:17<00:15, 29.74it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 546  (2.7):  55%|█████▍    | 545/1000 [00:17<00:15, 29.74it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 550  (2.9):  55%|█████▍    | 549/1000 [00:17<00:36, 12.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 552  (2.9):  55%|█████▌    | 551/1000 [00:18<00:36, 12.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 554  (2.9):  55%|█████▌    | 554/1000 [00:18<00:24, 18.03it/s]][error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 555  (2.9):  55%|█████▌    | 554/1000 [00:18<00:24, 18.03it/s]2024-10-14T00:50:53.714167Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 557  (2.9):  56%|█████▌    | 556/1000 [00:18<00:24, 18.03it/s]198or    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 16.0 / 559  (2.9):  56%|█████▌    | 558/1000 [00:18<00:24, 18.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 560  (2.9):  56%|█████▌    | 560/1000 [00:18<00:18, 23.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 561  (2.9):  56%|█████▌    | 560/1000 [00:18<00:18, 23.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 562  (2.8):  56%|█████▌    | 561/1000 [00:18<00:18, 23.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 563  (2.8):  56%|█████▌    | 562/1000 [00:18<00:18, 23.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 564  (2.8):  56%|█████▋    | 563/1000 [00:18<00:18, 23.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 565  (2.8):  56%|█████▋    | 565/1000 [00:18<00:15, 27.19it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 566  (2.8):  56%|█████▋    | 565/1000 [00:18<00:15, 27.19it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 567  (2.8):  57%|█████▋    | 566/1000 [00:18<00:15, 27.19it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 568  (2.8):  57%|█████▋    | 567/1000 [00:18<00:15, 27.19it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 569  (2.8):  57%|█████▋    | 568/1000 [00:18<00:15, 27.19it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 570  (2.8):  57%|█████▋    | 569/1000 [00:18<00:15, 27.19it/s]2024-10-14T00:50:54.749567Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 571  (2.8):  57%|█████▋    | 571/1000 [00:18<00:13, 32.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 572  (2.8):  57%|█████▋    | 571/1000 [00:18<00:13, 32.05it/s]2024-10-14T00:50:54.769962Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 573  (2.8):  57%|█████▋    | 572/1000 [00:18<00:13, 32.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 574  (2.8):  57%|█████▋    | 573/1000 [00:18<00:13, 32.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 575  (2.8):  57%|█████▋    | 574/1000 [00:18<00:13, 32.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 576  (2.8):  57%|█████▊    | 575/1000 [00:18<00:13, 32.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 577  (2.8):  58%|█████▊    | 577/1000 [00:18<00:11, 36.80it/s]2024-10-14T00:50:54.861618Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 578  (2.8):  58%|█████▊    | 577/1000 [00:18<00:11, 36.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 579  (2.8):  58%|█████▊    | 578/1000 [00:18<00:11, 36.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 580  (2.8):  58%|█████▊    | 579/1000 [00:18<00:11, 36.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 581  (2.8):  58%|█████▊    | 580/1000 [00:18<00:11, 36.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 582  (2.7):  58%|█████▊    | 581/1000 [00:18<00:11, 36.80it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 583  (2.7):  58%|█████▊    | 583/1000 [00:18<00:10, 41.65it/s]2024-10-14T00:50:55.505451Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 584  (2.7):  58%|█████▊    | 583/1000 [00:18<00:10, 41.65it/s]2024-10-14T00:50:55.532339Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 585  (2.7):  58%|█████▊    | 584/1000 [00:18<00:09, 41.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 586  (2.7):  58%|█████▊    | 585/1000 [00:18<00:09, 41.65it/s]2024-10-14T00:50:55.557356Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 587  (2.7):  59%|█████▊    | 586/1000 [00:18<00:09, 41.65it/s]2024-10-14T00:50:55.570782Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 588  (2.7):  59%|█████▊    | 587/1000 [00:18<00:09, 41.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 589  (2.7):  59%|█████▉    | 589/1000 [00:18<00:12, 32.16it/s]2024-10-14T00:50:55.751816Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 590  (2.7):  59%|█████▉    | 589/1000 [00:19<00:12, 32.16it/s]2024-10-14T00:50:55.785605Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 591  (2.7):  59%|█████▉    | 590/1000 [00:19<00:12, 32.16it/s]2024-10-14T00:50:55.789264Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 592  (2.7):  59%|█████▉    | 591/1000 [00:19<00:12, 32.16it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 593  (2.7):  59%|█████▉    | 592/1000 [00:19<00:12, 32.16it/s]2024-10-14T00:50:55.802930Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 594  (2.7):  59%|█████▉    | 594/1000 [00:19<00:15, 26.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 595  (2.7):  59%|█████▉    | 594/1000 [00:19<00:15, 26.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 596  (2.7):  60%|█████▉    | 595/1000 [00:19<00:15, 26.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 597  (2.7):  60%|█████▉    | 596/1000 [00:19<00:15, 26.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 598  (2.7):  60%|█████▉    | 597/1000 [00:19<00:15, 26.39it/s]2024-10-14T00:50:55.850242Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 599  (2.7):  60%|█████▉    | 598/1000 [00:19<00:15, 26.39it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 600  (2.7):  60%|██████    | 600/1000 [00:19<00:12, 31.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 601  (2.7):  60%|██████    | 600/1000 [00:19<00:12, 31.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 602  (2.7):  60%|██████    | 601/1000 [00:19<00:12, 31.81it/s]2024-10-14T00:50:55.898895Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 603  (2.7):  60%|██████    | 602/1000 [00:19<00:12, 31.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 604  (2.6):  60%|██████    | 603/1000 [00:19<00:12, 31.81it/s]2024-10-14T00:50:55.938737Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 605  (2.6):  60%|██████    | 604/1000 [00:19<00:12, 31.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 606  (2.6):  61%|██████    | 606/1000 [00:19<00:10, 36.98it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 610  (2.6):  61%|██████    | 609/1000 [00:19<00:10, 36.98it/s]2024-10-14T00:50:56.253757Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 611  (2.6):  61%|██████    | 611/1000 [00:19<00:11, 33.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 612  (2.6):  61%|██████    | 611/1000 [00:19<00:11, 33.65it/s]2024-10-14T00:50:56.281600Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 613  (2.6):  61%|██████    | 612/1000 [00:19<00:11, 33.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 614  (2.6):  61%|██████▏   | 613/1000 [00:19<00:11, 33.65it/s]2024-10-14T00:50:56.314969Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 615  (2.6):  61%|██████▏   | 614/1000 [00:19<00:11, 33.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 616  (2.6):  62%|██████▏   | 615/1000 [00:19<00:11, 33.65it/s]2024-10-14T00:50:56.496879Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 617  (2.6):  62%|██████▏   | 617/1000 [00:19<00:12, 31.91it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 619  (2.6):  62%|██████▏   | 618/1000 [00:19<00:11, 31.91it/s]2024-10-14T00:50:56.508101Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 620  (2.6):  62%|██████▏   | 619/1000 [00:19<00:11, 31.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 621  (2.6):  62%|██████▏   | 620/1000 [00:19<00:11, 31.91it/s]2024-10-14T00:50:56.555563Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 622  (2.6):  62%|██████▏   | 621/1000 [00:19<00:11, 31.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 624  (2.6):  62%|██████▏   | 623/1000 [00:19<00:10, 36.06it/s]2024-10-14T00:50:56.743521Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 625  (2.6):  62%|██████▏   | 624/1000 [00:20<00:10, 36.06it/s]2024-10-14T00:50:56.766497Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 627  (2.6):  63%|██████▎   | 626/1000 [00:20<00:10, 36.06it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 628  (2.5):  63%|██████▎   | 628/1000 [00:20<00:11, 32.60it/s]2024-10-14T00:50:56.819076Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 629  (2.5):  63%|██████▎   | 628/1000 [00:20<00:11, 32.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 630  (2.5):  63%|██████▎   | 629/1000 [00:20<00:11, 32.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 631  (2.5):  63%|██████▎   | 630/1000 [00:20<00:11, 32.60it/s]2024-10-14T00:50:56.984946Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 632  (2.5):  63%|██████▎   | 632/1000 [00:20<00:12, 29.28it/s]error    4T00:50:56.995858Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 633  (2.5):  63%|██████▎   | 632/1000 [00:20<00:12, 29.28it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 634  (2.5):  63%|██████▎   | 633/1000 [00:20<00:12, 29.28it/s]2024-10-14T00:50:57.025526Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 635  (2.5):  63%|██████▎   | 634/1000 [00:20<00:12, 29.28it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 636  (2.5):  64%|██████▎   | 636/1000 [00:20<00:11, 30.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 637  (2.5):  64%|██████▎   | 636/1000 [00:20<00:11, 30.47it/s]2024-10-14T00:50:57.067662Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 638  (2.5):  64%|██████▎   | 637/1000 [00:20<00:11, 30.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 639  (2.5):  64%|██████▍   | 638/1000 [00:20<00:11, 30.47it/s]2024-10-14T00:50:57.077089Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 640  (2.5):  64%|██████▍   | 639/1000 [00:20<00:11, 30.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 641  (2.5):  64%|██████▍   | 640/1000 [00:20<00:11, 30.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 642  (2.5):  64%|██████▍   | 642/1000 [00:20<00:09, 36.59it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 643  (2.5):  64%|██████▍   | 642/1000 [00:20<00:09, 36.59it/s]2024-10-14T00:50:57.133296Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 644  (2.5):  64%|██████▍   | 643/1000 [00:20<00:09, 36.59it/s]2024-10-14T00:50:57.352450Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 645  (2.5):  64%|██████▍   | 644/1000 [00:20<00:09, 36.59it/s]2024-10-14T00:50:57.392585Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 647  (2.5):  65%|██████▍   | 647/1000 [00:20<00:10, 32.54it/s]2024-10-14T00:50:57.442109Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 648  (2.5):  65%|██████▍   | 647/1000 [00:20<00:10, 32.54it/s]2024-10-14T00:50:57.832848Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 649  (2.5):  65%|██████▍   | 648/1000 [00:21<00:10, 32.54it/s]2024-10-14T00:50:57.859468Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 651  (2.5):  65%|██████▌   | 651/1000 [00:21<00:18, 18.82it/s] [24-10-14T00:50:57.864027Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 652  (2.5):  65%|██████▌   | 651/1000 [00:21<00:18, 18.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 653  (2.5):  65%|██████▌   | 652/1000 [00:21<00:18, 18.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 654  (2.4):  65%|██████▌   | 653/1000 [00:21<00:18, 18.82it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 655  (2.4):  65%|██████▌   | 654/1000 [00:21<00:18, 18.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 656  (2.4):  66%|██████▌   | 656/1000 [00:21<00:14, 23.05it/s]2024-10-14T00:50:57.935469Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 657  (2.4):  66%|██████▌   | 656/1000 [00:21<00:14, 23.05it/s]2024-10-14T00:50:57.953807Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 658  (2.4):  66%|██████▌   | 657/1000 [00:21<00:14, 23.05it/s]2024-10-14T00:50:57.960937Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 659  (2.4):  66%|██████▌   | 658/1000 [00:21<00:14, 23.05it/s]2024-10-14T00:50:57.966878Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 660  (2.4):  66%|██████▌   | 659/1000 [00:21<00:14, 23.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 661  (2.4):  66%|██████▌   | 660/1000 [00:21<00:14, 23.05it/s]2024-10-14T00:50:58.222358Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 662  (2.4):  66%|██████▌   | 662/1000 [00:21<00:14, 24.14it/s]2024-10-14T00:50:58.249094Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 664  (2.4):  66%|██████▋   | 663/1000 [00:21<00:13, 24.14it/s]2024-10-14T00:50:58.252596Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 667  (2.4):  67%|██████▋   | 666/1000 [00:21<00:13, 24.14it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 668  (2.4):  67%|██████▋   | 667/1000 [00:21<00:11, 27.82it/s]2024-10-14T00:50:58.295148Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 669  (2.4):  67%|██████▋   | 668/1000 [00:21<00:11, 27.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 670  (2.4):  67%|██████▋   | 669/1000 [00:21<00:11, 27.82it/s]2024-10-14T00:50:58.327866Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 671  (2.4):  67%|██████▋   | 670/1000 [00:21<00:11, 27.82it/s]2024-10-14T00:50:58.519303Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 672  (2.4):  67%|██████▋   | 672/1000 [00:21<00:12, 26.95it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 673  (2.4):  67%|██████▋   | 672/1000 [00:21<00:12, 26.95it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 674  (2.4):  67%|██████▋   | 673/1000 [00:21<00:12, 26.95it/s]2024-10-14T00:50:58.549723Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 675  (2.4):  67%|██████▋   | 674/1000 [00:21<00:12, 26.95it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 676  (2.4):  68%|██████▊   | 676/1000 [00:21<00:11, 29.33it/s]] 24-10-14T00:50:58.626151Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 677  (2.4):  68%|██████▊   | 676/1000 [00:21<00:11, 29.33it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 678  (2.4):  68%|██████▊   | 677/1000 [00:21<00:11, 29.33it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 679  (2.4):  68%|██████▊   | 678/1000 [00:21<00:10, 29.33it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 680  (2.4):  68%|██████▊   | 679/1000 [00:21<00:10, 29.33it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 681  (2.3):  68%|██████▊   | 680/1000 [00:21<00:10, 29.33it/s]2024-10-14T00:50:58.678050Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 683  (2.3):  68%|██████▊   | 682/1000 [00:22<00:09, 34.40it/s]2024-10-14T00:50:58.891509Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 684  (2.3):  68%|██████▊   | 683/1000 [00:22<00:09, 34.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 685  (2.3):  68%|██████▊   | 684/1000 [00:22<00:09, 34.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 686  (2.3):  69%|██████▊   | 686/1000 [00:22<00:10, 29.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 687  (2.3):  69%|██████▊   | 686/1000 [00:22<00:10, 29.02it/s]2024-10-14T00:50:58.943205Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 688  (2.3):  69%|██████▊   | 687/1000 [00:22<00:10, 29.02it/s]2024-10-14T00:50:59.004793Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 689  (2.3):  69%|██████▉   | 688/1000 [00:22<00:10, 29.02it/s]2024-10-14T00:50:59.011302Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 690  (2.3):  69%|██████▉   | 689/1000 [00:22<00:10, 29.02it/s]2024-10-14T00:50:59.142740Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 693  (2.3):  69%|██████▉   | 692/1000 [00:22<00:10, 28.24it/s] 024-10-14T00:50:59.166570Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 694  (2.3):  69%|██████▉   | 693/1000 [00:22<00:10, 28.24it/s]2024-10-14T00:50:59.226117Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 695  (2.3):  69%|██████▉   | 694/1000 [00:22<00:10, 28.24it/s]2024-10-14T00:50:59.344752Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 696  (2.3):  70%|██████▉   | 696/1000 [00:22<00:11, 26.79it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 697  (2.3):  70%|██████▉   | 696/1000 [00:22<00:11, 26.79it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 698  (2.3):  70%|██████▉   | 697/1000 [00:22<00:11, 26.79it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 699  (2.3):  70%|██████▉   | 698/1000 [00:22<00:11, 26.79it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 700  (2.3):  70%|███████   | 700/1000 [00:22<00:10, 28.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 701  (2.3):  70%|███████   | 700/1000 [00:22<00:10, 28.48it/s]2024-10-14T00:50:59.423778Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 702  (2.3):  70%|███████   | 701/1000 [00:22<00:10, 28.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 703  (2.3):  70%|███████   | 702/1000 [00:22<00:10, 28.48it/s]2024-10-14T00:50:59.445208Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 704  (2.3):  70%|███████   | 703/1000 [00:22<00:10, 28.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 705  (2.3):  70%|███████   | 704/1000 [00:22<00:10, 28.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 706  (2.3):  71%|███████   | 706/1000 [00:22<00:08, 34.45it/s]2024-10-14T00:50:59.470248Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 710  (2.4):  71%|███████   | 709/1000 [00:23<00:08, 34.45it/s]2024-10-14T00:50:59.711944Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 711  (2.4):  71%|███████   | 710/1000 [00:23<00:09, 30.80it/s]2024-10-14T00:50:59.771405Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 712  (2.4):  71%|███████   | 711/1000 [00:23<00:09, 30.80it/s]2024-10-14T00:50:59.781883Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 714  (2.4):  71%|███████▏  | 713/1000 [00:23<00:09, 30.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 715  (2.4):  71%|███████▏  | 714/1000 [00:23<00:09, 30.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 716  (2.4):  72%|███████▏  | 716/1000 [00:23<00:07, 36.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 718  (2.4):  72%|███████▏  | 717/1000 [00:23<00:07, 36.80it/s]2024-10-14T00:51:00.018125Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 719  (2.4):  72%|███████▏  | 718/1000 [00:23<00:07, 36.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 720  (2.4):  72%|███████▏  | 719/1000 [00:23<00:07, 36.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 721  (2.4):  72%|███████▏  | 721/1000 [00:23<00:08, 31.72it/s]2024-10-14T00:51:00.111198Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 723  (2.4):  72%|███████▏  | 722/1000 [00:23<00:08, 31.72it/s]2024-10-14T00:51:00.223207Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 724  (2.3):  72%|███████▏  | 723/1000 [00:23<00:08, 31.72it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 725  (2.3):  72%|███████▎  | 725/1000 [00:23<00:10, 27.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 726  (2.3):  72%|███████▎  | 725/1000 [00:23<00:10, 27.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 727  (2.3):  73%|███████▎  | 726/1000 [00:23<00:10, 27.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 728  (2.3):  73%|███████▎  | 727/1000 [00:23<00:10, 27.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 729  (2.3):  73%|███████▎  | 728/1000 [00:23<00:10, 27.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 730  (2.3):  73%|███████▎  | 730/1000 [00:23<00:08, 31.56it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 731  (2.3):  73%|███████▎  | 730/1000 [00:23<00:08, 31.56it/s]2024-10-14T00:51:00.299913Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 732  (2.3):  73%|███████▎  | 731/1000 [00:23<00:08, 31.56it/s]2024-10-14T00:51:00.303650Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 733  (2.3):  73%|███████▎  | 732/1000 [00:23<00:08, 31.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 734  (2.3):  73%|███████▎  | 733/1000 [00:23<00:08, 31.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 735  (2.3):  73%|███████▎  | 734/1000 [00:23<00:08, 31.56it/s]2024-10-14T00:51:00.558794Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 736  (2.3):  74%|███████▎  | 736/1000 [00:23<00:08, 31.58it/s]2024-10-14T00:51:00.582449Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 737  (2.3):  74%|███████▎  | 736/1000 [00:23<00:08, 31.58it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 738  (2.3):  74%|███████▎  | 737/1000 [00:23<00:08, 31.58it/s]2024-10-14T00:51:00.617719Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 739  (2.3):  74%|███████▍  | 738/1000 [00:23<00:08, 31.58it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 740  (2.3):  74%|███████▍  | 739/1000 [00:23<00:08, 31.58it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 742  (2.3):  74%|███████▍  | 741/1000 [00:24<00:07, 34.47it/s]2024-10-14T00:51:01.056906Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 744  (2.3):  74%|███████▍  | 743/1000 [00:24<00:07, 34.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 747  (2.3):  75%|███████▍  | 746/1000 [00:24<00:12, 20.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 750  (2.3):  75%|███████▍  | 749/1000 [00:24<00:12, 20.47it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 751  (2.3):  75%|███████▌  | 750/1000 [00:24<00:12, 20.47it/s]2024-10-14T00:51:01.076457Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 752  (2.3):  75%|███████▌  | 752/1000 [00:24<00:09, 27.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 753  (2.3):  75%|███████▌  | 752/1000 [00:24<00:09, 27.29it/s]2024-10-14T00:51:01.093679Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 754  (2.3):  75%|███████▌  | 753/1000 [00:24<00:09, 27.29it/s]2024-10-14T00:51:01.112131Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 755  (2.3):  75%|███████▌  | 754/1000 [00:24<00:09, 27.29it/s]2024-10-14T00:51:01.132866Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 756  (2.2):  76%|███████▌  | 755/1000 [00:24<00:08, 27.29it/s]2024-10-14T00:51:01.152676Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 757  (2.2):  76%|███████▌  | 757/1000 [00:24<00:07, 31.06it/s]] 24-10-14T00:51:01.170476Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 758  (2.2):  76%|███████▌  | 757/1000 [00:24<00:07, 31.06it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 759  (2.2):  76%|███████▌  | 758/1000 [00:24<00:07, 31.06it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 760  (2.2):  76%|███████▌  | 759/1000 [00:24<00:07, 31.06it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 761  (2.2):  76%|███████▌  | 760/1000 [00:24<00:07, 31.06it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 762  (2.2):  76%|███████▌  | 761/1000 [00:24<00:07, 31.06it/s]2024-10-14T00:51:01.276555Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 763  (2.2):  76%|███████▋  | 763/1000 [00:24<00:06, 36.49it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 764  (2.2):  76%|███████▋  | 763/1000 [00:24<00:06, 36.49it/s]2024-10-14T00:51:01.474577Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 766  (2.2):  76%|███████▋  | 765/1000 [00:24<00:06, 36.49it/s]2024-10-14T00:51:01.604284Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 767  (2.2):  77%|███████▋  | 766/1000 [00:24<00:06, 36.49it/s]2024-10-14T00:51:01.641164Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 768  (2.2):  77%|███████▋  | 768/1000 [00:24<00:07, 32.15it/s]2024-10-14T00:51:01.729630Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 770  (2.2):  77%|███████▋  | 769/1000 [00:25<00:07, 32.15it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 771  (2.2):  77%|███████▋  | 770/1000 [00:25<00:07, 32.15it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 773  (2.2):  77%|███████▋  | 772/1000 [00:25<00:07, 30.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 774  (2.2):  77%|███████▋  | 773/1000 [00:25<00:07, 30.77it/s]2024-10-14T00:51:01.919010Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 775  (2.2):  77%|███████▋  | 774/1000 [00:25<00:07, 30.77it/s]2024-10-14T00:51:01.962994Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 776  (2.2):  78%|███████▊  | 776/1000 [00:25<00:07, 28.05it/s]2024-10-14T00:51:01.987721Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 777  (2.2):  78%|███████▊  | 776/1000 [00:25<00:07, 28.05it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 778  (2.2):  78%|███████▊  | 777/1000 [00:25<00:07, 28.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 779  (2.2):  78%|███████▊  | 778/1000 [00:25<00:07, 28.05it/s]2024-10-14T00:51:02.031000Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 780  (2.2):  78%|███████▊  | 780/1000 [00:25<00:07, 30.05it/s]2024-10-14T00:51:02.045731Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 781  (2.2):  78%|███████▊  | 780/1000 [00:25<00:07, 30.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 782  (2.2):  78%|███████▊  | 781/1000 [00:25<00:07, 30.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 783  (2.2):  78%|███████▊  | 782/1000 [00:25<00:07, 30.05it/s]2024-10-14T00:51:02.260352Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 784  (2.2):  78%|███████▊  | 784/1000 [00:25<00:08, 26.68it/s]error    4T00:51:02.283950Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 786  (2.2):  78%|███████▊  | 785/1000 [00:25<00:08, 26.68it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 787  (2.2):  79%|███████▊  | 786/1000 [00:25<00:08, 26.68it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 788  (2.2):  79%|███████▉  | 788/1000 [00:25<00:07, 28.85it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 789  (2.2):  79%|███████▉  | 788/1000 [00:25<00:07, 28.85it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 790  (2.2):  79%|███████▉  | 789/1000 [00:25<00:07, 28.85it/s]2024-10-14T00:51:02.377423Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 791  (2.1):  79%|███████▉  | 790/1000 [00:25<00:07, 28.85it/s]2024-10-14T00:51:02.382993Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 792  (2.1):  79%|███████▉  | 791/1000 [00:25<00:07, 28.85it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 793  (2.1):  79%|███████▉  | 792/1000 [00:25<00:07, 28.85it/s]2024-10-14T00:51:02.587666Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 794  (2.1):  79%|███████▉  | 794/1000 [00:25<00:07, 28.63it/s]2024-10-14T00:51:02.610694Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 796  (2.3):  80%|███████▉  | 795/1000 [00:25<00:07, 28.63it/s]2024-10-14T00:51:02.645242Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 797  (2.3):  80%|███████▉  | 796/1000 [00:25<00:07, 28.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 798  (2.3):  80%|███████▉  | 797/1000 [00:25<00:07, 28.63it/s]2024-10-14T00:51:02.781807Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 799  (2.3):  80%|███████▉  | 799/1000 [00:26<00:07, 27.49it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 800  (2.2):  80%|███████▉  | 799/1000 [00:26<00:07, 27.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 801  (2.2):  80%|████████  | 800/1000 [00:26<00:07, 27.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 802  (2.2):  80%|████████  | 801/1000 [00:26<00:07, 27.49it/s]2024-10-14T00:51:02.829941Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 803  (2.2):  80%|████████  | 802/1000 [00:26<00:07, 27.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 804  (2.2):  80%|████████  | 804/1000 [00:26<00:06, 31.46it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 805  (2.2):  80%|████████  | 804/1000 [00:26<00:06, 31.46it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 807  (2.4):  81%|████████  | 806/1000 [00:26<00:06, 31.46it/s]2024-10-14T00:51:03.049794Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 810  (2.3):  81%|████████  | 809/1000 [00:26<00:06, 28.23it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 811  (2.3):  81%|████████  | 810/1000 [00:26<00:06, 28.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 812  (2.3):  81%|████████  | 811/1000 [00:26<00:06, 28.23it/s]2024-10-14T00:51:03.239919Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 814  (2.3):  81%|████████▏ | 813/1000 [00:26<00:06, 28.85it/s]]024-10-14T00:51:03.264156Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 815  (2.3):  81%|████████▏ | 814/1000 [00:26<00:06, 28.85it/s]2024-10-14T00:51:03.298680Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 816  (2.3):  82%|████████▏ | 815/1000 [00:26<00:06, 28.85it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 818  (2.3):  82%|████████▏ | 817/1000 [00:26<00:06, 28.85it/s]2024-10-14T00:51:03.444731Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 819  (2.3):  82%|████████▏ | 819/1000 [00:26<00:06, 28.84it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 820  (2.3):  82%|████████▏ | 819/1000 [00:26<00:06, 28.84it/s]2024-10-14T00:51:03.480508Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 821  (2.3):  82%|████████▏ | 820/1000 [00:26<00:06, 28.84it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 823  (2.3):  82%|████████▏ | 822/1000 [00:26<00:06, 28.84it/s]][error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 824  (2.3):  82%|████████▏ | 824/1000 [00:26<00:05, 32.53it/s]2024-10-14T00:51:03.507066Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 825  (2.3):  82%|████████▏ | 824/1000 [00:26<00:05, 32.53it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 826  (2.3):  82%|████████▎ | 825/1000 [00:26<00:05, 32.53it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 829  (2.3):  83%|████████▎ | 828/1000 [00:26<00:05, 30.48it/s]2024-10-14T00:51:03.747157Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 831  (2.4):  83%|████████▎ | 830/1000 [00:27<00:05, 30.48it/s]2024-10-14T00:51:03.755470Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 832  (2.4):  83%|████████▎ | 831/1000 [00:27<00:05, 30.48it/s]2024-10-14T00:51:03.783384Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 833  (2.4):  83%|████████▎ | 832/1000 [00:27<00:05, 30.48it/s]2024-10-14T00:51:03.808398Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 835  (2.4):  83%|████████▎ | 834/1000 [00:27<00:04, 36.24it/s]2024-10-14T00:51:03.933218Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 836  (2.4):  84%|████████▎ | 835/1000 [00:27<00:04, 36.24it/s]2024-10-14T00:51:03.957008Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 837  (2.4):  84%|████████▎ | 836/1000 [00:27<00:04, 36.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 839  (2.4):  84%|████████▍ | 838/1000 [00:27<00:04, 32.91it/s]2024-10-14T00:51:04.005613Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 840  (2.4):  84%|████████▍ | 839/1000 [00:27<00:04, 32.91it/s]2024-10-14T00:51:04.025460Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 843  (2.5):  84%|████████▍ | 842/1000 [00:27<00:05, 30.60it/s]error    4T00:51:04.139693Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 845  (2.5):  84%|████████▍ | 844/1000 [00:27<00:05, 30.60it/s]2024-10-14T00:51:04.481683Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 846  (2.5):  85%|████████▍ | 846/1000 [00:27<00:07, 20.31it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 847  (2.5):  85%|████████▍ | 846/1000 [00:27<00:07, 20.31it/s]2024-10-14T00:51:04.513056Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 848  (2.5):  85%|████████▍ | 847/1000 [00:27<00:07, 20.31it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 849  (2.5):  85%|████████▍ | 848/1000 [00:27<00:07, 20.31it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 850  (2.5):  85%|████████▍ | 849/1000 [00:27<00:07, 20.31it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 851  (2.5):  85%|████████▌ | 851/1000 [00:27<00:06, 24.73it/s]2024-10-14T00:51:04.554466Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 852  (2.5):  85%|████████▌ | 851/1000 [00:27<00:06, 24.73it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 853  (2.5):  85%|████████▌ | 852/1000 [00:27<00:05, 24.73it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 855  (2.5):  86%|████████▌ | 855/1000 [00:28<00:05, 25.16it/s]2024-10-14T00:51:04.790267Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 856  (2.5):  86%|████████▌ | 855/1000 [00:28<00:05, 25.16it/s]2024-10-14T00:51:04.809541Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 858  (2.4):  86%|████████▌ | 858/1000 [00:28<00:05, 23.89it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 859  (2.4):  86%|████████▌ | 858/1000 [00:28<00:05, 23.89it/s]2024-10-14T00:51:04.959595Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 860  (2.4):  86%|████████▌ | 859/1000 [00:28<00:05, 23.89it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 861  (2.4):  86%|████████▌ | 860/1000 [00:28<00:05, 23.89it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 862  (2.4):  86%|████████▌ | 862/1000 [00:28<00:05, 26.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 863  (2.4):  86%|████████▌ | 862/1000 [00:28<00:05, 26.81it/s]2024-10-14T00:51:05.017738Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 864  (2.4):  86%|████████▋ | 863/1000 [00:28<00:05, 26.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 865  (2.4):  86%|████████▋ | 864/1000 [00:28<00:05, 26.81it/s]2024-10-14T00:51:05.109248Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 866  (2.4):  86%|████████▋ | 865/1000 [00:28<00:05, 26.81it/s]2024-10-14T00:51:05.247344Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 867  (2.4):  87%|████████▋ | 867/1000 [00:28<00:05, 24.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 869  (2.4):  87%|████████▋ | 868/1000 [00:28<00:05, 24.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 870  (2.4):  87%|████████▋ | 869/1000 [00:28<00:05, 24.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 871  (2.4):  87%|████████▋ | 871/1000 [00:28<00:04, 27.31it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 872  (2.4):  87%|████████▋ | 871/1000 [00:28<00:04, 27.31it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 873  (2.4):  87%|████████▋ | 872/1000 [00:28<00:04, 27.31it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 874  (2.4):  87%|████████▋ | 873/1000 [00:28<00:04, 27.31it/s]2024-10-14T00:51:05.359091Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 875  (2.4):  87%|████████▋ | 874/1000 [00:28<00:04, 27.31it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 876  (2.4):  88%|████████▊ | 876/1000 [00:28<00:03, 32.05it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 877  (2.4):  88%|████████▊ | 876/1000 [00:28<00:03, 32.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 878  (2.4):  88%|████████▊ | 877/1000 [00:28<00:03, 32.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 879  (2.4):  88%|████████▊ | 878/1000 [00:28<00:03, 32.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 882  (2.5):  88%|████████▊ | 881/1000 [00:28<00:03, 30.65it/s]2024-10-14T00:51:05.661684Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 883  (2.5):  88%|████████▊ | 882/1000 [00:28<00:03, 30.65it/s]2024-10-14T00:51:05.726485Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 884  (2.5):  88%|████████▊ | 883/1000 [00:28<00:03, 30.65it/s]2024-10-14T00:51:05.826989Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 885  (2.5):  88%|████████▊ | 885/1000 [00:29<00:04, 27.71it/s]2024-10-14T00:51:05.850200Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 886  (2.5):  88%|████████▊ | 885/1000 [00:29<00:04, 27.71it/s]2024-10-14T00:51:05.865087Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 887  (2.5):  89%|████████▊ | 886/1000 [00:29<00:04, 27.71it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 888  (2.5):  89%|████████▊ | 887/1000 [00:29<00:04, 27.71it/s]2024-10-14T00:51:05.891116Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 889  (2.5):  89%|████████▉ | 889/1000 [00:29<00:03, 29.52it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 890  (2.5):  89%|████████▉ | 889/1000 [00:29<00:03, 29.52it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 891  (2.5):  89%|████████▉ | 890/1000 [00:29<00:03, 29.52it/s]2024-10-14T00:51:05.904570Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 892  (2.5):  89%|████████▉ | 891/1000 [00:29<00:03, 29.52it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 893  (2.5):  89%|████████▉ | 892/1000 [00:29<00:03, 29.52it/s]2024-10-14T00:51:06.129037Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 894  (2.5):  89%|████████▉ | 894/1000 [00:29<00:03, 27.94it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 896  (2.5):  90%|████████▉ | 895/1000 [00:29<00:03, 27.94it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 897  (2.5):  90%|████████▉ | 896/1000 [00:29<00:03, 27.94it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 898  (2.4):  90%|████████▉ | 897/1000 [00:29<00:03, 27.94it/s]2024-10-14T00:51:06.214086Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 899  (2.4):  90%|████████▉ | 899/1000 [00:29<00:03, 32.36it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 900  (2.4):  90%|████████▉ | 899/1000 [00:29<00:03, 32.36it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 902  (2.5):  90%|█████████ | 901/1000 [00:29<00:03, 32.36it/s]2024-10-14T00:51:06.391996Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 903  (2.5):  90%|█████████ | 903/1000 [00:29<00:03, 29.87it/s]] 24-10-14T00:51:06.399871Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 904  (2.5):  90%|█████████ | 903/1000 [00:29<00:03, 29.87it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 905  (2.5):  90%|█████████ | 904/1000 [00:29<00:03, 29.87it/s]2024-10-14T00:51:06.441609Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 906  (2.5):  90%|█████████ | 905/1000 [00:29<00:03, 29.87it/s]2024-10-14T00:51:06.580418Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 907  (2.5):  91%|█████████ | 907/1000 [00:29<00:03, 26.98it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 909  (2.5):  91%|█████████ | 908/1000 [00:29<00:03, 26.98it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 911  (2.5):  91%|█████████ | 910/1000 [00:29<00:03, 26.98it/s]2024-10-14T00:51:06.629982Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 913  (2.5):  91%|█████████ | 912/1000 [00:29<00:02, 31.64it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 914  (2.5):  91%|█████████▏| 913/1000 [00:29<00:02, 31.64it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 915  (2.5):  91%|█████████▏| 914/1000 [00:30<00:02, 31.64it/s]2024-10-14T00:51:06.694347Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 916  (2.5):  92%|█████████▏| 915/1000 [00:30<00:02, 31.64it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 917  (2.5):  92%|█████████▏| 916/1000 [00:30<00:02, 31.64it/s]2024-10-14T00:51:06.881561Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 919  (2.5):  92%|█████████▏| 918/1000 [00:30<00:02, 31.30it/s]2024-10-14T00:51:06.922598Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 920  (2.5):  92%|█████████▏| 919/1000 [00:30<00:02, 31.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 921  (2.5):  92%|█████████▏| 920/1000 [00:30<00:02, 31.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 922  (2.5):  92%|█████████▏| 921/1000 [00:30<00:02, 31.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 923  (2.5):  92%|█████████▏| 923/1000 [00:30<00:02, 34.45it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 924  (2.5):  92%|█████████▏| 923/1000 [00:30<00:02, 34.45it/s]2024-10-14T00:51:07.117539Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 926  (2.6):  92%|█████████▎| 925/1000 [00:30<00:02, 34.45it/s]2024-10-14T00:51:07.168752Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 927  (2.6):  93%|█████████▎| 927/1000 [00:30<00:02, 30.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 928  (2.6):  93%|█████████▎| 927/1000 [00:30<00:02, 30.49it/s]2024-10-14T00:51:07.217371Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 929  (2.6):  93%|█████████▎| 928/1000 [00:30<00:02, 30.49it/s]2024-10-14T00:51:07.223883Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 931  (2.6):  93%|█████████▎| 931/1000 [00:30<00:02, 29.04it/s]2024-10-14T00:51:07.350153Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 932  (2.6):  93%|█████████▎| 931/1000 [00:30<00:02, 29.04it/s]2024-10-14T00:51:07.377419Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 933  (2.6):  93%|█████████▎| 932/1000 [00:30<00:02, 29.04it/s]2024-10-14T00:51:07.408810Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 935  (2.6):  93%|█████████▎| 934/1000 [00:30<00:02, 29.04it/s]2024-10-14T00:51:07.517959Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 936  (2.6):  94%|█████████▎| 935/1000 [00:30<00:02, 25.49it/s]2024-10-14T00:51:07.539583Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 937  (2.6):  94%|█████████▎| 936/1000 [00:30<00:02, 25.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 938  (2.6):  94%|█████████▎| 937/1000 [00:30<00:02, 25.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 939  (2.6):  94%|█████████▍| 938/1000 [00:30<00:02, 25.49it/s]2024-10-14T00:51:07.591453Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 940  (2.6):  94%|█████████▍| 940/1000 [00:30<00:01, 30.17it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 941  (2.6):  94%|█████████▍| 940/1000 [00:30<00:01, 30.17it/s]2024-10-14T00:51:07.624432Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 942  (2.5):  94%|█████████▍| 941/1000 [00:30<00:01, 30.17it/s]2024-10-14T00:51:07.638661Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 945  (2.5):  94%|█████████▍| 944/1000 [00:31<00:02, 20.47it/s]2024-10-14T00:51:08.065395Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 947  (2.5):  95%|█████████▍| 947/1000 [00:31<00:02, 21.69it/s]=[error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 25.0 / 950  (2.6):  95%|█████████▍| 949/1000 [00:31<00:02, 21.69it/s]]024-10-14T00:51:08.079044Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 951  (2.6):  95%|█████████▌| 950/1000 [00:31<00:02, 21.69it/s]2024-10-14T00:51:08.087250Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 952  (2.6):  95%|█████████▌| 951/1000 [00:31<00:02, 21.69it/s]2024-10-14T00:51:08.092865Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 953  (2.6):  95%|█████████▌| 952/1000 [00:31<00:02, 21.69it/s]2024-10-14T00:51:08.102161Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 954  (2.6):  95%|█████████▌| 954/1000 [00:31<00:01, 30.86it/s]error    4T00:51:08.106912Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 955  (2.6):  95%|█████████▌| 954/1000 [00:31<00:01, 30.86it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 957  (2.6):  96%|█████████▌| 956/1000 [00:31<00:01, 30.86it/s] [24-10-14T00:51:08.160860Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 958  (2.6):  96%|█████████▌| 957/1000 [00:31<00:01, 30.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 959  (2.6):  96%|█████████▌| 958/1000 [00:31<00:01, 30.86it/s]2024-10-14T00:51:08.184844Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 960  (2.6):  96%|█████████▌| 959/1000 [00:31<00:01, 30.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 961  (2.6):  96%|█████████▌| 960/1000 [00:31<00:01, 30.86it/s]2024-10-14T00:51:08.198657Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 962  (2.6):  96%|█████████▌| 962/1000 [00:31<00:00, 41.07it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 963  (2.6):  96%|█████████▌| 962/1000 [00:31<00:00, 41.07it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 964  (2.6):  96%|█████████▋| 963/1000 [00:31<00:00, 41.07it/s]2024-10-14T00:51:08.232257Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 966  (2.6):  96%|█████████▋| 965/1000 [00:31<00:00, 41.07it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 967  (2.6):  97%|█████████▋| 966/1000 [00:31<00:00, 41.07it/s]2024-10-14T00:51:08.245033Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 968  (2.6):  97%|█████████▋| 967/1000 [00:31<00:00, 41.07it/s]2024-10-14T00:51:08.250849Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 969  (2.6):  97%|█████████▋| 968/1000 [00:31<00:00, 41.07it/s]2024-10-14T00:51:08.267221Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 970  (2.6):  97%|█████████▋| 970/1000 [00:31<00:00, 48.69it/s]2024-10-14T00:51:08.293123Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 971  (2.6):  97%|█████████▋| 970/1000 [00:31<00:00, 48.69it/s]2024-10-14T00:51:08.312811Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 972  (2.6):  97%|█████████▋| 971/1000 [00:31<00:00, 48.69it/s]2024-10-14T00:51:08.321437Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 973  (2.6):  97%|█████████▋| 972/1000 [00:31<00:00, 48.69it/s]2024-10-14T00:51:08.385599Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 974  (2.6):  97%|█████████▋| 973/1000 [00:31<00:00, 48.69it/s]2024-10-14T00:51:08.411440Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 976  (2.6):  98%|█████████▊| 975/1000 [00:31<00:00, 48.69it/s]2024-10-14T00:51:08.416169Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 977  (2.6):  98%|█████████▊| 976/1000 [00:31<00:00, 48.69it/s]2024-10-14T00:51:08.425902Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 979  (2.6):  98%|█████████▊| 978/1000 [00:31<00:00, 48.69it/s]2024-10-14T00:51:08.436985Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 980  (2.6):  98%|█████████▊| 980/1000 [00:31<00:00, 61.16it/s]2024-10-14T00:51:08.473873Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 986  (2.5):  98%|█████████▊| 985/1000 [00:32<00:00, 61.16it/s]2024-10-14T00:51:10.339973Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 998  (2.7): 100%|█████████▉| 997/1000 [00:36<00:00,  6.09it/s]2024-10-14T00:51:13.623299Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 1000  (2.7): 100%|██████████| 1000/1000 [00:37<00:00, 26.81it/s]\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:51:14.760054Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<02:09,  2.30it/s]2024-10-14T00:51:14.785522Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/300 [00:00<02:09,  2.30it/s]2024-10-14T00:51:14.919522Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 3/300 [00:00<00:51,  5.80it/s]2024-10-14T00:51:14.941645Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 3/300 [00:00<00:51,  5.80it/s]2024-10-14T00:51:14.967384Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   1%|▏         | 4/300 [00:00<00:51,  5.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   2%|▏         | 5/300 [00:00<00:50,  5.80it/s]2024-10-14T00:51:14.997563Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   2%|▏         | 7/300 [00:00<00:23, 12.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   2%|▏         | 7/300 [00:00<00:23, 12.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 9  (0.0):   3%|▎         | 8/300 [00:00<00:23, 12.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 10  (0.0):   3%|▎         | 9/300 [00:00<00:23, 12.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 11  (0.0):   4%|▎         | 11/300 [00:00<00:15, 18.39it/s]error    4T00:51:15.098445Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 12  (0.0):   4%|▎         | 11/300 [00:00<00:15, 18.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 13  (0.0):   4%|▍         | 12/300 [00:00<00:15, 18.39it/s]2024-10-14T00:51:15.110647Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 14  (0.0):   4%|▍         | 13/300 [00:00<00:15, 18.39it/s]2024-10-14T00:51:15.124247Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 15  (0.0):   5%|▍         | 14/300 [00:00<00:15, 18.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 16  (0.0):   5%|▌         | 16/300 [00:00<00:11, 25.61it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 17  (0.0):   5%|▌         | 16/300 [00:00<00:11, 25.61it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 18  (0.0):   6%|▌         | 17/300 [00:00<00:11, 25.61it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 19  (0.0):   6%|▌         | 18/300 [00:01<00:11, 25.61it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 20  (0.0):   6%|▋         | 19/300 [00:01<00:10, 25.61it/s]2024-10-14T00:51:15.184547Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 21  (0.0):   7%|▋         | 20/300 [00:01<00:10, 25.61it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 22  (0.0):   7%|▋         | 22/300 [00:01<00:08, 33.68it/s]2024-10-14T00:51:15.209991Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 23  (0.0):   7%|▋         | 22/300 [00:01<00:08, 33.68it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 24  (0.0):   8%|▊         | 23/300 [00:01<00:08, 33.68it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 25  (0.0):   8%|▊         | 24/300 [00:01<00:08, 33.68it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 26  (0.0):   8%|▊         | 25/300 [00:01<00:08, 33.68it/s]2024-10-14T00:51:15.255817Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 27  (0.0):   9%|▊         | 26/300 [00:01<00:08, 33.68it/s]2024-10-14T00:51:15.261650Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 28  (0.0):   9%|▉         | 28/300 [00:01<00:06, 40.19it/s]error    4T00:51:15.279488Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 29  (0.0):   9%|▉         | 28/300 [00:01<00:06, 40.19it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 30  (0.0):  10%|▉         | 29/300 [00:01<00:06, 40.19it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 31  (0.0):  10%|█         | 30/300 [00:01<00:06, 40.19it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 32  (0.0):  10%|█         | 31/300 [00:01<00:06, 40.19it/s]2024-10-14T00:51:15.679272Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 33  (0.0):  11%|█         | 33/300 [00:01<00:07, 35.76it/s]2024-10-14T00:51:15.707399Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 34  (0.0):  11%|█         | 33/300 [00:01<00:07, 35.76it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 35  (0.0):  11%|█▏        | 34/300 [00:01<00:07, 35.76it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 36  (0.0):  12%|█▏        | 35/300 [00:01<00:07, 35.76it/s]2024-10-14T00:51:15.777381Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 37  (0.0):  12%|█▏        | 36/300 [00:01<00:07, 35.76it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 38  (0.0):  13%|█▎        | 38/300 [00:01<00:07, 35.50it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 39  (0.0):  13%|█▎        | 38/300 [00:01<00:07, 35.50it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 40  (0.0):  13%|█▎        | 39/300 [00:01<00:07, 35.50it/s]2024-10-14T00:51:15.820832Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 41  (0.0):  13%|█▎        | 40/300 [00:01<00:07, 35.50it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 42  (0.0):  14%|█▎        | 41/300 [00:01<00:07, 35.50it/s]2024-10-14T00:51:15.845668Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 43  (0.0):  14%|█▍        | 42/300 [00:01<00:07, 35.50it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 44  (0.0):  15%|█▍        | 44/300 [00:01<00:06, 40.61it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 48  (2.1):  16%|█▌        | 47/300 [00:01<00:06, 40.61it/s]2024-10-14T00:51:16.069980Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 49  (2.0):  16%|█▋        | 49/300 [00:01<00:06, 36.55it/s]2024-10-14T00:51:16.117190Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 50  (2.0):  16%|█▋        | 49/300 [00:01<00:06, 36.55it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 52  (3.8):  17%|█▋        | 51/300 [00:01<00:06, 36.55it/s]2024-10-14T00:51:16.259974Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 54  (3.7):  18%|█▊        | 53/300 [00:01<00:07, 32.01it/s]filename   ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 55  (3.6):  18%|█▊        | 54/300 [00:01<00:07, 32.01it/s]2024-10-14T00:51:16.274832Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 56  (3.6):  18%|█▊        | 55/300 [00:02<00:07, 32.01it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 57  (3.5):  19%|█▊        | 56/300 [00:02<00:07, 32.01it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 58  (3.4):  19%|█▉        | 58/300 [00:02<00:06, 34.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 59  (3.4):  19%|█▉        | 58/300 [00:02<00:06, 34.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 60  (3.3):  20%|█▉        | 59/300 [00:02<00:06, 34.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 61  (3.3):  20%|██        | 60/300 [00:02<00:06, 34.90it/s]2024-10-14T00:51:16.384870Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 62  (3.2):  20%|██        | 61/300 [00:02<00:06, 34.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 63  (3.2):  21%|██        | 62/300 [00:02<00:06, 34.90it/s]2024-10-14T00:51:16.745477Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 64  (3.1):  21%|██▏       | 64/300 [00:02<00:09, 25.28it/s]2024-10-14T00:51:16.767764Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 65  (3.1):  21%|██▏       | 64/300 [00:02<00:09, 25.28it/s]2024-10-14T00:51:16.807050Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 68  (2.9):  23%|██▎       | 68/300 [00:02<00:09, 24.65it/s]2024-10-14T00:51:16.825007Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 70  (2.9):  23%|██▎       | 69/300 [00:02<00:09, 24.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 71  (2.8):  23%|██▎       | 70/300 [00:02<00:09, 24.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 73  (2.7):  24%|██▍       | 72/300 [00:02<00:09, 24.65it/s]2024-10-14T00:51:16.912492Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 77  (2.6):  25%|██▌       | 76/300 [00:02<00:08, 27.90it/s]  24-10-14T00:51:16.917629Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 2.0 / 78  (2.6):  26%|██▌       | 77/300 [00:02<00:07, 27.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 81  (2.5):  27%|██▋       | 80/300 [00:02<00:06, 35.33it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 85  (4.7):  28%|██▊       | 84/300 [00:02<00:06, 35.33it/s]2024-10-14T00:51:16.977075Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 86  (4.7):  28%|██▊       | 85/300 [00:02<00:06, 35.33it/s]2024-10-14T00:51:16.982232Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 87  (4.6):  29%|██▊       | 86/300 [00:02<00:06, 35.33it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 88  (4.5):  29%|██▉       | 88/300 [00:02<00:04, 42.91it/s] [24-10-14T00:51:16.997583Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 90  (4.4):  30%|██▉       | 89/300 [00:02<00:04, 42.91it/s]2024-10-14T00:51:17.002672Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 91  (4.4):  30%|███       | 90/300 [00:03<00:04, 42.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 92  (4.3):  30%|███       | 91/300 [00:03<00:04, 42.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 93  (4.3):  31%|███       | 92/300 [00:03<00:04, 42.91it/s]2024-10-14T00:51:17.030693Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 94  (4.3):  31%|███▏      | 94/300 [00:03<00:04, 46.40it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 95  (4.2):  31%|███▏      | 94/300 [00:03<00:04, 46.40it/s]2024-10-14T00:51:17.047961Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 96  (4.2):  32%|███▏      | 95/300 [00:03<00:04, 46.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 97  (4.1):  32%|███▏      | 96/300 [00:03<00:04, 46.40it/s]2024-10-14T00:51:17.138068Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 98  (4.1):  32%|███▏      | 97/300 [00:03<00:04, 46.40it/s]2024-10-14T00:51:17.143391Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 99  (4.0):  33%|███▎      | 98/300 [00:03<00:04, 46.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 100  (4.0):  33%|███▎      | 100/300 [00:03<00:04, 48.92it/s][error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 101  (4.0):  33%|███▎      | 100/300 [00:03<00:04, 48.92it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 102  (3.9):  34%|███▎      | 101/300 [00:03<00:04, 48.92it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 103  (3.9):  34%|███▍      | 102/300 [00:03<00:04, 48.92it/s]2024-10-14T00:51:17.281458Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 104  (3.8):  34%|███▍      | 103/300 [00:03<00:04, 48.92it/s]2024-10-14T00:51:17.334046Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 105  (3.8):  35%|███▍      | 104/300 [00:03<00:04, 48.92it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 106  (3.8):  35%|███▌      | 106/300 [00:03<00:03, 51.17it/s]2024-10-14T00:51:17.733224Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 107  (3.7):  35%|███▌      | 106/300 [00:03<00:03, 51.17it/s]2024-10-14T00:51:18.091788Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 108  (3.7):  36%|███▌      | 107/300 [00:03<00:03, 51.17it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 109  (3.7):  36%|███▌      | 108/300 [00:03<00:03, 51.17it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 110  (3.6):  36%|███▋      | 109/300 [00:03<00:03, 51.17it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 111  (3.6):  37%|███▋      | 110/300 [00:03<00:03, 51.17it/s]2024-10-14T00:51:18.150769Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 112  (3.6):  37%|███▋      | 112/300 [00:03<00:08, 23.05it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 113  (3.5):  37%|███▋      | 112/300 [00:03<00:08, 23.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 114  (3.5):  38%|███▊      | 113/300 [00:03<00:08, 23.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 115  (3.5):  38%|███▊      | 114/300 [00:03<00:08, 23.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 116  (3.4):  38%|███▊      | 115/300 [00:03<00:08, 23.05it/s]2024-10-14T00:51:18.407020Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 117  (3.4):  39%|███▉      | 117/300 [00:04<00:07, 23.18it/s]2024-10-14T00:51:18.431866Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 118  (3.4):  39%|███▉      | 117/300 [00:04<00:07, 23.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 119  (3.4):  39%|███▉      | 118/300 [00:04<00:07, 23.18it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 120  (3.3):  40%|███▉      | 119/300 [00:04<00:07, 23.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 121  (3.3):  40%|████      | 121/300 [00:04<00:07, 23.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 122  (3.3):  40%|████      | 121/300 [00:04<00:07, 23.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 123  (3.3):  41%|████      | 122/300 [00:04<00:07, 23.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 124  (3.2):  41%|████      | 123/300 [00:04<00:07, 23.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 125  (3.2):  41%|████▏     | 124/300 [00:04<00:07, 23.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 126  (3.2):  42%|████▏     | 126/300 [00:04<00:06, 27.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 127  (3.1):  42%|████▏     | 126/300 [00:04<00:06, 27.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 128  (3.1):  42%|████▏     | 127/300 [00:04<00:06, 27.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 129  (3.1):  43%|████▎     | 128/300 [00:04<00:06, 27.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 130  (3.1):  43%|████▎     | 129/300 [00:04<00:06, 27.40it/s]2024-10-14T00:51:18.582975Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 131  (3.1):  43%|████▎     | 130/300 [00:04<00:06, 27.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 132  (3.0):  44%|████▍     | 132/300 [00:04<00:05, 33.27it/s]2024-10-14T00:51:18.610421Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 133  (3.0):  44%|████▍     | 132/300 [00:04<00:05, 33.27it/s]2024-10-14T00:51:18.613739Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 134  (3.0):  44%|████▍     | 133/300 [00:04<00:05, 33.27it/s]2024-10-14T00:51:18.619625Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 135  (3.0):  45%|████▍     | 134/300 [00:04<00:04, 33.27it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 136  (2.9):  45%|████▌     | 135/300 [00:04<00:04, 33.27it/s]2024-10-14T00:51:18.638663Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 137  (2.9):  45%|████▌     | 136/300 [00:04<00:04, 33.27it/s]2024-10-14T00:51:18.656889Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 138  (2.9):  46%|████▌     | 138/300 [00:04<00:04, 38.26it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 139  (2.9):  46%|████▌     | 138/300 [00:04<00:04, 38.26it/s]2024-10-14T00:51:19.004966Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 140  (2.9):  46%|████▋     | 139/300 [00:04<00:04, 38.26it/s]2024-10-14T00:51:19.027014Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 142  (3.5):  47%|████▋     | 141/300 [00:04<00:04, 38.26it/s]2024-10-14T00:51:19.096101Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 144  (3.5):  48%|████▊     | 143/300 [00:04<00:04, 32.88it/s]2024-10-14T00:51:19.182108Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 145  (3.4):  48%|████▊     | 144/300 [00:04<00:04, 32.88it/s]2024-10-14T00:51:19.189696Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 146  (3.4):  48%|████▊     | 145/300 [00:04<00:04, 32.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 147  (3.4):  49%|████▉     | 147/300 [00:04<00:04, 31.34it/s]error    4T00:51:19.214518Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 148  (3.4):  49%|████▉     | 147/300 [00:04<00:04, 31.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 149  (3.4):  49%|████▉     | 148/300 [00:04<00:04, 31.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 150  (3.3):  50%|████▉     | 149/300 [00:04<00:04, 31.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 152  (3.3):  51%|█████     | 152/300 [00:05<00:04, 30.54it/s]2024-10-14T00:51:19.436004Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 153  (3.3):  51%|█████     | 152/300 [00:05<00:04, 30.54it/s]2024-10-14T00:51:19.460328Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 154  (3.2):  51%|█████     | 153/300 [00:05<00:04, 30.54it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 155  (3.2):  51%|█████▏    | 154/300 [00:05<00:04, 30.54it/s]2024-10-14T00:51:19.511102Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 156  (3.2):  52%|█████▏    | 156/300 [00:05<00:04, 32.40it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 157  (3.2):  52%|█████▏    | 156/300 [00:05<00:04, 32.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 158  (3.2):  52%|█████▏    | 157/300 [00:05<00:04, 32.40it/s]2024-10-14T00:51:19.686988Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 159  (3.1):  53%|█████▎    | 158/300 [00:05<00:04, 32.40it/s]2024-10-14T00:51:19.694822Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 161  (3.1):  53%|█████▎    | 160/300 [00:05<00:05, 26.29it/s]error    4T00:51:19.720768Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 162  (3.1):  54%|█████▎    | 161/300 [00:05<00:05, 26.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 163  (3.1):  54%|█████▍    | 162/300 [00:05<00:05, 26.29it/s]2024-10-14T00:51:19.741974Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 164  (3.0):  54%|█████▍    | 163/300 [00:05<00:05, 26.29it/s]2024-10-14T00:51:19.777718Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 165  (3.0):  55%|█████▌    | 165/300 [00:05<00:04, 30.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 166  (3.0):  55%|█████▌    | 165/300 [00:05<00:04, 30.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 167  (3.0):  55%|█████▌    | 166/300 [00:05<00:04, 30.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 168  (3.0):  56%|█████▌    | 167/300 [00:05<00:04, 30.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 169  (3.0):  56%|█████▌    | 168/300 [00:05<00:04, 30.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 170  (2.9):  56%|█████▋    | 169/300 [00:05<00:04, 30.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 171  (2.9):  57%|█████▋    | 171/300 [00:05<00:03, 36.45it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 172  (2.9):  57%|█████▋    | 171/300 [00:05<00:03, 36.45it/s]2024-10-14T00:51:19.835392Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 173  (2.9):  57%|█████▋    | 172/300 [00:05<00:03, 36.45it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 174  (2.9):  58%|█████▊    | 173/300 [00:05<00:03, 36.45it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 175  (2.9):  58%|█████▊    | 174/300 [00:05<00:03, 36.45it/s]2024-10-14T00:51:19.885679Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 177  (3.4):  59%|█████▉    | 177/300 [00:05<00:03, 34.20it/s]2024-10-14T00:51:20.183605Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 178  (3.4):  59%|█████▉    | 177/300 [00:05<00:03, 34.20it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 180  (3.3):  60%|█████▉    | 179/300 [00:05<00:03, 34.20it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 181  (3.3):  60%|██████    | 181/300 [00:05<00:03, 34.81it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 182  (3.3):  60%|██████    | 181/300 [00:05<00:03, 34.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 183  (3.3):  61%|██████    | 182/300 [00:05<00:03, 34.81it/s]2024-10-14T00:51:20.252496Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 184  (3.3):  61%|██████    | 183/300 [00:05<00:03, 34.81it/s]2024-10-14T00:51:20.276863Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 185  (3.2):  61%|██████▏   | 184/300 [00:06<00:03, 34.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 186  (3.2):  62%|██████▏   | 186/300 [00:06<00:03, 37.93it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 187  (3.2):  62%|██████▏   | 186/300 [00:06<00:03, 37.93it/s]2024-10-14T00:51:20.313519Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 188  (3.2):  62%|██████▏   | 187/300 [00:06<00:02, 37.93it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 189  (3.2):  63%|██████▎   | 188/300 [00:06<00:02, 37.93it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 191  (3.1):  64%|██████▎   | 191/300 [00:06<00:03, 33.44it/s]2024-10-14T00:51:20.586159Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 192  (3.1):  64%|██████▎   | 191/300 [00:06<00:03, 33.44it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 193  (3.1):  64%|██████▍   | 192/300 [00:06<00:03, 33.44it/s]2024-10-14T00:51:20.602603Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 195  (3.1):  65%|██████▍   | 194/300 [00:06<00:03, 33.44it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 196  (3.1):  65%|██████▌   | 196/300 [00:06<00:02, 36.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 197  (3.0):  65%|██████▌   | 196/300 [00:06<00:02, 36.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 198  (3.0):  66%|██████▌   | 197/300 [00:06<00:02, 36.49it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 199  (3.0):  66%|██████▌   | 198/300 [00:06<00:02, 36.49it/s]2024-10-14T00:51:20.837052Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 205  (2.9):  68%|██████▊   | 205/300 [00:06<00:02, 35.69it/s]2024-10-14T00:51:20.969067Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 206  (2.9):  68%|██████▊   | 205/300 [00:06<00:02, 35.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 207  (2.9):  69%|██████▊   | 206/300 [00:06<00:02, 35.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 208  (2.9):  69%|██████▉   | 207/300 [00:06<00:02, 35.69it/s]2024-10-14T00:51:20.981850Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 209  (2.9):  69%|██████▉   | 208/300 [00:06<00:02, 35.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 210  (2.9):  70%|███████   | 210/300 [00:06<00:02, 38.62it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 211  (2.8):  70%|███████   | 210/300 [00:06<00:02, 38.62it/s]2024-10-14T00:51:21.179113Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 212  (2.8):  70%|███████   | 211/300 [00:06<00:02, 38.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 213  (2.8):  71%|███████   | 212/300 [00:06<00:02, 38.62it/s]2024-10-14T00:51:21.196156Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 214  (2.8):  71%|███████   | 213/300 [00:06<00:02, 38.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 215  (2.8):  72%|███████▏  | 215/300 [00:06<00:02, 32.90it/s]2024-10-14T00:51:21.237014Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 216  (2.8):  72%|███████▏  | 215/300 [00:06<00:02, 32.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 217  (2.8):  72%|███████▏  | 216/300 [00:06<00:02, 32.90it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 218  (2.8):  72%|███████▏  | 217/300 [00:06<00:02, 32.90it/s]2024-10-14T00:51:21.301175Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 219  (2.7):  73%|███████▎  | 218/300 [00:07<00:02, 32.90it/s]2024-10-14T00:51:21.305618Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 220  (2.7):  73%|███████▎  | 219/300 [00:07<00:02, 32.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 222  (2.7):  74%|███████▎  | 221/300 [00:07<00:02, 37.74it/s]2024-10-14T00:51:21.495900Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 223  (2.7):  74%|███████▍  | 222/300 [00:07<00:02, 37.74it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 224  (2.7):  74%|███████▍  | 223/300 [00:07<00:02, 37.74it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 225  (2.7):  75%|███████▍  | 224/300 [00:07<00:02, 37.74it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 226  (2.7):  75%|███████▌  | 226/300 [00:07<00:02, 30.99it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 227  (2.6):  75%|███████▌  | 226/300 [00:07<00:02, 30.99it/s]2024-10-14T00:51:21.551604Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 228  (2.6):  76%|███████▌  | 227/300 [00:07<00:02, 30.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 229  (2.6):  76%|███████▌  | 228/300 [00:07<00:02, 30.99it/s]2024-10-14T00:51:21.582755Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 230  (2.6):  76%|███████▋  | 229/300 [00:07<00:02, 30.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 231  (2.6):  77%|███████▋  | 230/300 [00:07<00:02, 30.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 232  (2.6):  77%|███████▋  | 232/300 [00:07<00:01, 36.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 233  (2.6):  77%|███████▋  | 232/300 [00:07<00:01, 36.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 234  (2.6):  78%|███████▊  | 233/300 [00:07<00:01, 36.38it/s]2024-10-14T00:51:21.872224Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 235  (2.6):  78%|███████▊  | 234/300 [00:07<00:01, 36.38it/s]2024-10-14T00:51:21.896509Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 237  (2.5):  79%|███████▉  | 237/300 [00:07<00:02, 30.29it/s]=valuate.py] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno198\n",
      "Average Metric: 8.0 / 241  (3.3):  80%|████████  | 240/300 [00:07<00:01, 30.29it/s] rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 242  (3.3):  80%|████████  | 241/300 [00:07<00:01, 30.29it/s]2024-10-14T00:51:21.916047Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 243  (3.3):  81%|████████  | 242/300 [00:07<00:01, 30.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 244  (3.3):  81%|████████▏ | 244/300 [00:07<00:01, 37.37it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 245  (3.3):  81%|████████▏ | 244/300 [00:07<00:01, 37.37it/s]2024-10-14T00:51:22.022274Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 246  (3.3):  82%|████████▏ | 245/300 [00:07<00:01, 37.37it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 247  (3.2):  82%|████████▏ | 246/300 [00:07<00:01, 37.37it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 248  (3.2):  82%|████████▏ | 247/300 [00:07<00:01, 37.37it/s]2024-10-14T00:51:22.239517Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 250  (3.2):  83%|████████▎ | 249/300 [00:07<00:01, 33.61it/s]2024-10-14T00:51:22.244428Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 252  (3.2):  84%|████████▎ | 251/300 [00:07<00:01, 33.61it/s]2024-10-14T00:51:22.288657Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 253  (3.2):  84%|████████▍ | 252/300 [00:07<00:01, 33.61it/s]2024-10-14T00:51:22.293010Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 254  (3.1):  84%|████████▍ | 253/300 [00:07<00:01, 33.61it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 255  (3.1):  85%|████████▍ | 254/300 [00:07<00:01, 33.61it/s]2024-10-14T00:51:22.306764Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 256  (3.1):  85%|████████▌ | 255/300 [00:08<00:01, 33.61it/s]2024-10-14T00:51:22.331155Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 257  (3.1):  86%|████████▌ | 257/300 [00:08<00:01, 42.45it/s]2024-10-14T00:51:22.342382Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 259  (3.1):  86%|████████▌ | 258/300 [00:08<00:00, 42.45it/s]2024-10-14T00:51:22.348584Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 260  (3.1):  86%|████████▋ | 259/300 [00:08<00:00, 42.45it/s]2024-10-14T00:51:22.402868Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 262  (3.4):  87%|████████▋ | 261/300 [00:08<00:00, 42.45it/s]2024-10-14T00:51:22.408535Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 263  (3.4):  87%|████████▋ | 262/300 [00:08<00:00, 42.45it/s]2024-10-14T00:51:22.418213Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 264  (3.4):  88%|████████▊ | 263/300 [00:08<00:00, 42.45it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 266  (3.4):  88%|████████▊ | 265/300 [00:08<00:00, 49.45it/s]2024-10-14T00:51:22.433026Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 267  (3.4):  89%|████████▊ | 266/300 [00:08<00:00, 49.45it/s]2024-10-14T00:51:22.446662Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 268  (3.4):  89%|████████▉ | 267/300 [00:08<00:00, 49.45it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 271  (3.3):  90%|█████████ | 270/300 [00:08<00:00, 49.45it/s]] 24-10-14T00:51:22.478962Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 273  (3.3):  91%|█████████ | 272/300 [00:08<00:00, 49.45it/s]2024-10-14T00:51:22.501955Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 274  (3.3):  91%|█████████▏| 274/300 [00:08<00:00, 55.12it/s] [24-10-14T00:51:22.508132Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 275  (3.3):  91%|█████████▏| 274/300 [00:08<00:00, 55.12it/s]2024-10-14T00:51:22.558303Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 276  (3.3):  92%|█████████▏| 275/300 [00:08<00:00, 55.12it/s]2024-10-14T00:51:22.578441Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 278  (3.2):  92%|█████████▏| 277/300 [00:08<00:00, 55.12it/s] [24-10-14T00:51:22.582591Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 280  (3.2):  93%|█████████▎| 279/300 [00:08<00:00, 55.12it/s]2024-10-14T00:51:22.597620Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 281  (3.2):  93%|█████████▎| 280/300 [00:08<00:00, 55.12it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 285  (3.2):  95%|█████████▍| 284/300 [00:08<00:00, 58.91it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 287  (3.1):  95%|█████████▌| 286/300 [00:08<00:00, 58.91it/s]error    4T00:51:22.617891Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 288  (3.1):  96%|█████████▌| 287/300 [00:08<00:00, 58.91it/s]2024-10-14T00:51:22.622366Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 290  (3.1):  96%|█████████▋| 289/300 [00:08<00:00, 58.91it/s]2024-10-14T00:51:22.631769Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 291  (3.1):  97%|█████████▋| 290/300 [00:08<00:00, 58.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 292  (3.1):  97%|█████████▋| 291/300 [00:08<00:00, 58.91it/s]2024-10-14T00:51:22.663681Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 293  (3.1):  97%|█████████▋| 292/300 [00:08<00:00, 58.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 294  (3.1):  98%|█████████▊| 293/300 [00:08<00:00, 58.91it/s]2024-10-14T00:51:22.741916Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 300  (3.3): 100%|██████████| 300/300 [00:13<00:00, 22.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 3.33 for seed -3\n",
      "Scores so far: [3.33]\n",
      "Best score so far: 3.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14T00:51:27.805464Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-14T00:51:27.806959Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-14T00:51:27.808297Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 6  (50.0):   2%|▏         | 5/300 [00:00<00:00, 488.39it/s]198.evaluate.evaluatel'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename=evaluate.py lineno=\n",
      "Average Metric: 3.0 / 12  (25.0):   4%|▎         | 11/300 [00:00<00:00, 550.09it/s]filename example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate =evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 13  (23.1):   4%|▍         | 12/300 [00:00<00:00, 399.31it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 14  (21.4):   4%|▍         | 13/300 [00:00<00:00, 318.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 15  (20.0):   5%|▍         | 14/300 [00:00<00:01, 275.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 18  (16.7):   6%|▌         | 17/300 [00:00<00:01, 263.52it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 19  (15.8):   6%|▌         | 18/300 [00:00<00:01, 247.74it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 20  (15.0):   6%|▋         | 19/300 [00:00<00:01, 227.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 22  (13.6):   7%|▋         | 21/300 [00:00<00:01, 219.55it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 23  (13.0):   8%|▊         | 23/300 [00:00<00:01, 214.30it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 25  (16.0):   8%|▊         | 24/300 [00:00<00:01, 214.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 26  (15.4):   8%|▊         | 25/300 [00:00<00:01, 214.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 28  (14.3):   9%|▉         | 27/300 [00:00<00:01, 214.30it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 29  (13.8):   9%|▉         | 28/300 [00:00<00:01, 214.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 30  (13.3):  10%|▉         | 29/300 [00:00<00:01, 214.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 31  (12.9):  10%|█         | 30/300 [00:00<00:01, 214.30it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 33  (12.1):  11%|█         | 32/300 [00:00<00:01, 214.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 34  (11.8):  11%|█         | 33/300 [00:00<00:01, 214.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 36  (11.1):  12%|█▏        | 35/300 [00:00<00:01, 214.30it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 37  (10.8):  12%|█▏        | 36/300 [00:00<00:01, 214.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 38  (10.5):  12%|█▏        | 37/300 [00:00<00:01, 214.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 40  (10.0):  13%|█▎        | 39/300 [00:00<00:01, 214.30it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 41  (9.8):  13%|█▎        | 40/300 [00:00<00:01, 214.30it/s]  [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 42  (9.5):  14%|█▎        | 41/300 [00:00<00:01, 214.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 43  (9.3):  14%|█▍        | 42/300 [00:00<00:01, 214.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 44  (9.1):  14%|█▍        | 43/300 [00:00<00:01, 214.30it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 46  (8.7):  15%|█▌        | 45/300 [00:00<00:01, 154.38it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 47  (8.5):  15%|█▌        | 46/300 [00:00<00:01, 154.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 48  (8.3):  16%|█▌        | 47/300 [00:00<00:01, 154.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 49  (8.2):  16%|█▌        | 48/300 [00:00<00:01, 154.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 52  (7.7):  17%|█▋        | 51/300 [00:00<00:01, 154.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 53  (7.5):  17%|█▋        | 52/300 [00:00<00:01, 154.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 54  (7.4):  18%|█▊        | 53/300 [00:00<00:01, 154.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 55  (7.3):  18%|█▊        | 54/300 [00:00<00:01, 154.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 57  (7.0):  19%|█▊        | 56/300 [00:00<00:01, 154.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 58  (6.9):  19%|█▉        | 57/300 [00:00<00:01, 154.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 59  (6.8):  19%|█▉        | 58/300 [00:00<00:01, 154.38it/s]2024-10-14T00:51:27.862841Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 60  (6.7):  20%|█▉        | 59/300 [00:00<00:01, 154.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 61  (6.6):  20%|██        | 60/300 [00:00<00:01, 154.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 62  (6.5):  21%|██        | 62/300 [00:00<00:01, 140.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 63  (6.3):  21%|██        | 62/300 [00:00<00:01, 140.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 64  (6.2):  21%|██        | 63/300 [00:00<00:01, 140.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 65  (6.2):  21%|██▏       | 64/300 [00:00<00:01, 140.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 66  (6.1):  22%|██▏       | 65/300 [00:00<00:01, 140.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 68  (5.9):  22%|██▏       | 67/300 [00:00<00:01, 140.49it/s]error    4T00:51:27.873693Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 69  (5.8):  23%|██▎       | 68/300 [00:00<00:01, 140.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 70  (5.7):  23%|██▎       | 69/300 [00:00<00:01, 140.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 74  (6.8):  24%|██▍       | 73/300 [00:00<00:01, 140.49it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 75  (6.7):  25%|██▍       | 74/300 [00:00<00:01, 140.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 76  (6.6):  25%|██▌       | 75/300 [00:00<00:01, 140.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 77  (6.5):  26%|██▌       | 77/300 [00:00<00:01, 129.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 78  (6.4):  26%|██▌       | 77/300 [00:00<00:01, 129.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 79  (6.3):  26%|██▌       | 78/300 [00:00<00:01, 129.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 80  (6.2):  26%|██▋       | 79/300 [00:00<00:01, 129.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 81  (6.2):  27%|██▋       | 80/300 [00:00<00:01, 129.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 82  (6.1):  27%|██▋       | 81/300 [00:00<00:01, 129.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 83  (6.0):  27%|██▋       | 82/300 [00:00<00:01, 129.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 84  (6.0):  28%|██▊       | 83/300 [00:00<00:01, 129.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 85  (5.9):  28%|██▊       | 84/300 [00:00<00:01, 129.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 86  (5.8):  28%|██▊       | 85/300 [00:00<00:01, 129.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 87  (5.7):  29%|██▊       | 86/300 [00:00<00:01, 129.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 88  (5.7):  29%|██▉       | 87/300 [00:00<00:01, 129.49it/s]2024-10-14T00:51:28.021400Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 89  (5.6):  29%|██▉       | 88/300 [00:00<00:01, 129.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 90  (5.6):  30%|██▉       | 89/300 [00:00<00:01, 129.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 91  (5.5):  30%|███       | 91/300 [00:00<00:01, 119.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 92  (5.4):  30%|███       | 91/300 [00:00<00:01, 119.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 93  (5.4):  31%|███       | 92/300 [00:00<00:01, 119.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 94  (5.3):  31%|███       | 93/300 [00:00<00:01, 119.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 96  (5.2):  32%|███▏      | 95/300 [00:00<00:01, 119.00it/s]error    4T00:51:28.091982Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 97  (5.2):  32%|███▏      | 96/300 [00:00<00:01, 119.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 98  (5.1):  32%|███▏      | 97/300 [00:00<00:01, 119.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 99  (5.1):  33%|███▎      | 98/300 [00:00<00:01, 119.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 100  (5.0):  33%|███▎      | 99/300 [00:00<00:01, 119.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 102  (5.9):  34%|███▎      | 101/300 [00:00<00:01, 119.00it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 103  (5.8):  34%|███▍      | 102/300 [00:00<00:01, 119.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 104  (5.8):  35%|███▍      | 104/300 [00:00<00:01, 118.77it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 105  (5.7):  35%|███▍      | 104/300 [00:00<00:01, 118.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 108  (5.6):  36%|███▌      | 107/300 [00:00<00:01, 118.77it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 109  (5.5):  36%|███▌      | 108/300 [00:00<00:01, 118.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 110  (5.5):  36%|███▋      | 109/300 [00:00<00:01, 118.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 111  (5.4):  37%|███▋      | 110/300 [00:00<00:01, 118.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 112  (5.4):  37%|███▋      | 111/300 [00:00<00:01, 118.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 114  (5.3):  38%|███▊      | 113/300 [00:00<00:01, 118.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 115  (5.2):  38%|███▊      | 114/300 [00:00<00:01, 118.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 116  (5.2):  38%|███▊      | 115/300 [00:00<00:01, 118.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 117  (5.1):  39%|███▉      | 117/300 [00:00<00:01, 120.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 118  (5.1):  39%|███▉      | 117/300 [00:00<00:01, 120.78it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 119  (5.0):  39%|███▉      | 118/300 [00:00<00:01, 120.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 120  (5.0):  40%|███▉      | 119/300 [00:00<00:01, 120.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 121  (5.0):  40%|████      | 120/300 [00:00<00:01, 120.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 122  (4.9):  40%|████      | 121/300 [00:00<00:01, 120.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 123  (4.9):  41%|████      | 122/300 [00:00<00:01, 120.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 124  (4.8):  41%|████      | 123/300 [00:00<00:01, 120.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 125  (4.8):  41%|████▏     | 124/300 [00:00<00:01, 120.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 126  (4.8):  42%|████▏     | 125/300 [00:00<00:01, 120.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 128  (4.7):  42%|████▏     | 127/300 [00:01<00:01, 120.78it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 129  (4.7):  43%|████▎     | 128/300 [00:01<00:01, 120.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 130  (4.6):  43%|████▎     | 130/300 [00:01<00:01, 114.78it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 131  (4.6):  43%|████▎     | 130/300 [00:01<00:01, 114.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 132  (4.5):  44%|████▎     | 131/300 [00:01<00:01, 114.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 133  (4.5):  44%|████▍     | 132/300 [00:01<00:01, 114.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 135  (4.4):  45%|████▍     | 134/300 [00:01<00:01, 114.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 136  (4.4):  45%|████▌     | 135/300 [00:01<00:01, 114.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 137  (4.4):  45%|████▌     | 136/300 [00:01<00:01, 114.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 138  (4.3):  46%|████▌     | 137/300 [00:01<00:01, 114.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 139  (4.3):  46%|████▌     | 138/300 [00:01<00:01, 114.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 140  (4.3):  46%|████▋     | 139/300 [00:01<00:01, 114.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 142  (4.2):  47%|████▋     | 142/300 [00:01<00:01, 113.23it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 143  (4.2):  47%|████▋     | 142/300 [00:01<00:01, 113.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 144  (4.2):  48%|████▊     | 143/300 [00:01<00:01, 113.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 145  (4.1):  48%|████▊     | 144/300 [00:01<00:01, 113.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 147  (4.1):  49%|████▊     | 146/300 [00:01<00:01, 113.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 148  (4.1):  49%|████▉     | 147/300 [00:01<00:01, 113.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 149  (4.0):  49%|████▉     | 148/300 [00:01<00:01, 113.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 150  (4.0):  50%|████▉     | 149/300 [00:01<00:01, 113.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 151  (4.0):  50%|█████     | 150/300 [00:01<00:01, 113.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 152  (3.9):  50%|█████     | 151/300 [00:01<00:01, 113.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 154  (3.9):  51%|█████▏    | 154/300 [00:01<00:01, 112.43it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 155  (3.9):  51%|█████▏    | 154/300 [00:01<00:01, 112.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 158  (3.8):  52%|█████▏    | 157/300 [00:01<00:01, 112.43it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 159  (3.8):  53%|█████▎    | 158/300 [00:01<00:01, 112.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 160  (3.8):  53%|█████▎    | 159/300 [00:01<00:01, 112.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 161  (3.7):  53%|█████▎    | 160/300 [00:01<00:01, 112.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 162  (3.7):  54%|█████▎    | 161/300 [00:01<00:01, 112.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 163  (3.7):  54%|█████▍    | 162/300 [00:01<00:01, 112.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 164  (3.7):  54%|█████▍    | 163/300 [00:01<00:01, 112.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 165  (3.6):  55%|█████▍    | 164/300 [00:01<00:01, 112.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 166  (3.6):  55%|█████▌    | 166/300 [00:01<00:01, 113.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 167  (3.6):  55%|█████▌    | 166/300 [00:01<00:01, 113.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 169  (3.6):  56%|█████▌    | 168/300 [00:01<00:01, 113.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 170  (3.5):  56%|█████▋    | 169/300 [00:01<00:01, 113.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 171  (3.5):  57%|█████▋    | 170/300 [00:01<00:01, 113.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 172  (3.5):  57%|█████▋    | 171/300 [00:01<00:01, 113.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 173  (3.5):  57%|█████▋    | 172/300 [00:01<00:01, 113.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 174  (3.4):  58%|█████▊    | 173/300 [00:01<00:01, 113.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 175  (3.4):  58%|█████▊    | 174/300 [00:01<00:01, 113.29it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 177  (3.4):  59%|█████▊    | 176/300 [00:01<00:01, 113.29it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 178  (3.4):  59%|█████▉    | 178/300 [00:01<00:01, 112.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 179  (3.4):  59%|█████▉    | 178/300 [00:01<00:01, 112.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 180  (3.3):  60%|█████▉    | 179/300 [00:01<00:01, 112.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 181  (3.3):  60%|██████    | 180/300 [00:01<00:01, 112.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 184  (3.8):  61%|██████    | 183/300 [00:01<00:01, 112.90it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 185  (3.8):  61%|██████▏   | 184/300 [00:01<00:01, 112.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 186  (3.8):  62%|██████▏   | 185/300 [00:01<00:01, 112.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 187  (3.7):  62%|██████▏   | 186/300 [00:01<00:01, 112.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 188  (3.7):  62%|██████▏   | 187/300 [00:01<00:01, 112.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 190  (4.2):  63%|██████▎   | 189/300 [00:01<00:00, 112.90it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 191  (4.2):  64%|██████▎   | 191/300 [00:01<00:00, 116.86it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 192  (4.2):  64%|██████▎   | 191/300 [00:01<00:00, 116.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 193  (4.1):  64%|██████▍   | 192/300 [00:01<00:00, 116.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 195  (4.1):  65%|██████▍   | 194/300 [00:01<00:00, 116.86it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 196  (4.1):  65%|██████▌   | 195/300 [00:01<00:00, 116.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 197  (4.1):  65%|██████▌   | 196/300 [00:01<00:00, 116.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 198  (4.0):  66%|██████▌   | 197/300 [00:01<00:00, 116.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 199  (4.0):  66%|██████▌   | 198/300 [00:01<00:00, 116.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 200  (4.0):  66%|██████▋   | 199/300 [00:01<00:00, 116.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 201  (4.0):  67%|██████▋   | 200/300 [00:01<00:00, 116.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 202  (4.0):  67%|██████▋   | 201/300 [00:01<00:00, 116.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 204  (3.9):  68%|██████▊   | 203/300 [00:01<00:00, 114.23it/s]dspy.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 205  (3.9):  68%|██████▊   | 204/300 [00:01<00:00, 114.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 207  (3.9):  69%|██████▊   | 206/300 [00:01<00:00, 114.23it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 208  (3.8):  69%|██████▉   | 207/300 [00:01<00:00, 114.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 209  (3.8):  69%|██████▉   | 208/300 [00:01<00:00, 114.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 210  (3.8):  70%|██████▉   | 209/300 [00:01<00:00, 114.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 211  (3.8):  70%|███████   | 210/300 [00:01<00:00, 114.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 212  (3.8):  70%|███████   | 211/300 [00:01<00:00, 114.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 214  (4.2):  71%|███████   | 213/300 [00:01<00:00, 114.23it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 217  (4.1):  72%|███████▏  | 216/300 [00:01<00:00, 114.23it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 218  (4.1):  73%|███████▎  | 218/300 [00:01<00:00, 123.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 219  (4.1):  73%|███████▎  | 218/300 [00:01<00:00, 123.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 221  (4.1):  73%|███████▎  | 220/300 [00:01<00:00, 123.03it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 222  (4.1):  74%|███████▎  | 221/300 [00:01<00:00, 123.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 223  (4.0):  74%|███████▍  | 222/300 [00:01<00:00, 123.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 224  (4.0):  74%|███████▍  | 223/300 [00:01<00:00, 123.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 225  (4.0):  75%|███████▍  | 224/300 [00:01<00:00, 123.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 226  (4.0):  75%|███████▌  | 225/300 [00:01<00:00, 123.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 228  (3.9):  76%|███████▌  | 227/300 [00:01<00:00, 123.03it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 229  (3.9):  76%|███████▌  | 228/300 [00:01<00:00, 123.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 232  (3.9):  77%|███████▋  | 231/300 [00:01<00:00, 124.09it/s] [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 233  (3.9):  77%|███████▋  | 232/300 [00:01<00:00, 124.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 235  (3.8):  78%|███████▊  | 234/300 [00:01<00:00, 124.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 236  (3.8):  78%|███████▊  | 235/300 [00:01<00:00, 124.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 237  (3.8):  79%|███████▊  | 236/300 [00:01<00:00, 124.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 238  (3.8):  79%|███████▉  | 237/300 [00:01<00:00, 124.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 239  (3.8):  79%|███████▉  | 238/300 [00:01<00:00, 124.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 241  (3.7):  80%|████████  | 240/300 [00:01<00:00, 124.09it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 243  (3.7):  81%|████████  | 242/300 [00:01<00:00, 124.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 245  (3.7):  81%|████████▏ | 244/300 [00:01<00:00, 124.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 246  (3.7):  82%|████████▏ | 246/300 [00:01<00:00, 129.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 247  (3.6):  82%|████████▏ | 246/300 [00:01<00:00, 129.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 248  (3.6):  82%|████████▏ | 247/300 [00:02<00:00, 129.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 250  (4.0):  83%|████████▎ | 249/300 [00:02<00:00, 129.11it/s]] rror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 251  (4.0):  83%|████████▎ | 250/300 [00:02<00:00, 129.11it/s]2024-10-14T00:51:29.407325Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 252  (4.0):  84%|████████▎ | 251/300 [00:02<00:00, 129.11it/s]2024-10-14T00:51:29.416854Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 253  (4.0):  84%|████████▍ | 252/300 [00:02<00:00, 129.11it/s]2024-10-14T00:51:29.426547Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 254  (3.9):  84%|████████▍ | 253/300 [00:02<00:00, 129.11it/s]2024-10-14T00:51:29.436270Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 255  (3.9):  85%|████████▍ | 254/300 [00:02<00:00, 129.11it/s]2024-10-14T00:51:29.446832Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 256  (3.9):  85%|████████▌ | 255/300 [00:02<00:00, 129.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 257  (3.9):  85%|████████▌ | 256/300 [00:02<00:00, 129.11it/s]2024-10-14T00:51:29.467655Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 258  (3.9):  86%|████████▌ | 257/300 [00:02<00:00, 129.11it/s]2024-10-14T00:51:29.478016Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 259  (3.9):  86%|████████▋ | 259/300 [00:02<00:00, 123.92it/s]2024-10-14T00:51:29.488201Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 260  (3.8):  86%|████████▋ | 259/300 [00:02<00:00, 123.92it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 261  (3.8):  87%|████████▋ | 260/300 [00:02<00:00, 123.92it/s]2024-10-14T00:51:29.507544Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 262  (3.8):  87%|████████▋ | 261/300 [00:02<00:00, 123.92it/s]2024-10-14T00:51:29.517215Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 263  (3.8):  87%|████████▋ | 262/300 [00:02<00:00, 123.92it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 264  (3.8):  88%|████████▊ | 263/300 [00:02<00:00, 123.92it/s]2024-10-14T00:51:29.536546Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 265  (3.8):  88%|████████▊ | 264/300 [00:02<00:00, 123.92it/s]2024-10-14T00:51:29.546436Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 266  (3.8):  88%|████████▊ | 265/300 [00:02<00:00, 123.92it/s]2024-10-14T00:51:29.556361Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 267  (3.7):  89%|████████▊ | 266/300 [00:02<00:00, 123.92it/s]2024-10-14T00:51:29.567802Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 268  (3.7):  89%|████████▉ | 267/300 [00:02<00:00, 123.92it/s]2024-10-14T00:51:29.577982Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 269  (3.7):  89%|████████▉ | 268/300 [00:02<00:00, 123.92it/s]2024-10-14T00:51:29.588114Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 270  (3.7):  90%|████████▉ | 269/300 [00:02<00:00, 123.92it/s]2024-10-14T00:51:29.599136Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 271  (3.7):  90%|█████████ | 270/300 [00:02<00:00, 123.92it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 272  (3.7):  91%|█████████ | 272/300 [00:02<00:00, 116.71it/s]2024-10-14T00:51:29.618939Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 273  (3.7):  91%|█████████ | 272/300 [00:02<00:00, 116.71it/s]2024-10-14T00:51:29.628794Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 274  (3.6):  91%|█████████ | 273/300 [00:02<00:00, 116.71it/s]2024-10-14T00:51:29.638413Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 275  (3.6):  91%|█████████▏| 274/300 [00:02<00:00, 116.71it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 276  (3.6):  92%|█████████▏| 275/300 [00:02<00:00, 116.71it/s]2024-10-14T00:51:29.661274Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 277  (3.6):  92%|█████████▏| 276/300 [00:02<00:00, 116.71it/s]2024-10-14T00:51:29.670549Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 278  (3.6):  92%|█████████▏| 277/300 [00:02<00:00, 116.71it/s]2024-10-14T00:51:29.681751Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 279  (3.6):  93%|█████████▎| 278/300 [00:02<00:00, 116.71it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 280  (3.6):  93%|█████████▎| 279/300 [00:02<00:00, 116.71it/s]2024-10-14T00:51:29.701699Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 281  (3.6):  93%|█████████▎| 280/300 [00:02<00:00, 116.71it/s]2024-10-14T00:51:29.711428Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 282  (3.5):  94%|█████████▎| 281/300 [00:02<00:00, 116.71it/s]2024-10-14T00:51:29.720732Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 283  (3.5):  94%|█████████▍| 282/300 [00:02<00:00, 116.71it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 284  (3.5):  95%|█████████▍| 284/300 [00:02<00:00, 112.84it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 285  (3.5):  95%|█████████▍| 284/300 [00:02<00:00, 112.84it/s]2024-10-14T00:51:29.752423Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 286  (3.5):  95%|█████████▌| 285/300 [00:02<00:00, 112.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 287  (3.5):  95%|█████████▌| 286/300 [00:02<00:00, 112.84it/s]2024-10-14T00:51:29.774417Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 288  (3.5):  96%|█████████▌| 287/300 [00:02<00:00, 112.84it/s]2024-10-14T00:51:29.784165Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 289  (3.5):  96%|█████████▌| 288/300 [00:02<00:00, 112.84it/s]2024-10-14T00:51:29.798342Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 290  (3.4):  96%|█████████▋| 289/300 [00:02<00:00, 112.84it/s]2024-10-14T00:51:29.808153Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 291  (3.4):  97%|█████████▋| 290/300 [00:02<00:00, 112.84it/s]2024-10-14T00:51:29.817666Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 292  (3.4):  97%|█████████▋| 291/300 [00:02<00:00, 112.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 293  (3.4):  97%|█████████▋| 292/300 [00:02<00:00, 112.84it/s]2024-10-14T00:51:29.837806Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 294  (3.4):  98%|█████████▊| 293/300 [00:02<00:00, 112.84it/s]2024-10-14T00:51:29.848788Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 295  (3.4):  98%|█████████▊| 294/300 [00:02<00:00, 112.84it/s]2024-10-14T00:51:29.859732Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 296  (3.4):  99%|█████████▊| 296/300 [00:02<00:00, 109.26it/s]] 24-10-14T00:51:29.869900Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 297  (3.4):  99%|█████████▊| 296/300 [00:02<00:00, 109.26it/s]2024-10-14T00:51:29.879779Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 298  (3.4):  99%|█████████▉| 297/300 [00:02<00:00, 109.26it/s]2024-10-14T00:51:29.890594Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 299  (3.3):  99%|█████████▉| 298/300 [00:02<00:00, 109.26it/s]2024-10-14T00:51:29.901372Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 300  (3.3): 100%|██████████| 300/300 [00:02<00:00, 119.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [3.33, 3.33]\n",
      "Best score so far: 3.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2758 [00:00<?, ?it/s]2024-10-14T00:51:30.647020Z [error    ] Failed to run or to evaluate example Example({'text': \"I attempted to top up my account but it's been frozen in a pending state for well over an hour now! Is this normal? I'm a new customer and this is my first time doing this. I assumed it would be done quicker than this.\", 'label': 'pending_top_up', 'answer': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 1/2758 [00:00<11:36,  3.96it/s]2024-10-14T00:51:30.807778Z [error    ] Failed to run or to evaluate example Example({'text': 'Why do i have an extra fee on my statement?', 'label': 'extra_charge_on_statement', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 2/2758 [00:00<09:06,  5.04it/s]2024-10-14T00:51:30.969767Z [error    ] Failed to run or to evaluate example Example({'text': 'There is more than one charge on my account for a transaction.', 'label': 'transaction_charged_twice', 'answer': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 3/2758 [00:00<08:20,  5.51it/s]2024-10-14T00:51:31.129145Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was I charged extra when paying with card?', 'label': 'extra_charge_on_statement', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 4/2758 [00:00<07:55,  5.79it/s]2024-10-14T00:51:31.405849Z [error    ] Failed to run or to evaluate example Example({'text': 'Where do I go for a refund?', 'label': 'request_refund', 'answer': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['label']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 5/2758 [00:01<09:39,  4.75it/s]2024-10-14T00:51:31.596395Z [error    ] Failed to run or to evaluate example Example({'text': 'Why have you declined my card payment?', 'label': 'declined_card_payment', 'answer': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 7/2758 [00:01<09:08,  5.02it/s]2024-10-14T00:51:31.950123Z [error    ] Failed to run or to evaluate example Example({'text': \"I'm waiting on a top-up, its still pending\", 'label': 'pending_top_up', 'answer': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 8/2758 [00:01<08:36,  5.33it/s]2024-10-14T00:51:32.110338Z [error    ] Failed to run or to evaluate example Example({'text': \"I have a transaction and would like to know if I it's cancelable?\", 'label': 'cancel_transfer', 'answer': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 9/2758 [00:01<08:12,  5.58it/s]2024-10-14T00:51:32.288729Z [error    ] Failed to run or to evaluate example Example({'text': 'Why am I being a charged for using my card?', 'label': 'card_payment_fee_charged', 'answer': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 10/2758 [00:01<08:11,  5.59it/s]2024-10-14T00:51:32.503543Z [error    ] Failed to run or to evaluate example Example({'text': 'I paid with a card and there is an extra charge. Why?', 'label': 'extra_charge_on_statement', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 11/2758 [00:02<08:41,  5.27it/s]2024-10-14T00:51:32.621256Z [error    ] Failed to run or to evaluate example Example({'text': 'my payment was rejected', 'label': 'declined_card_payment', 'answer': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 12/2758 [00:02<07:41,  5.95it/s]2024-10-14T00:51:32.852783Z [error    ] Failed to run or to evaluate example Example({'text': 'tell me why I was charged more with my card?', 'label': 'extra_charge_on_statement', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 13/2758 [00:02<08:35,  5.33it/s]2024-10-14T00:51:33.018471Z [error    ] Failed to run or to evaluate example Example({'text': 'I transferred some money but it is not here yet', 'label': 'transfer_not_received_by_recipient', 'answer': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 14/2758 [00:02<08:16,  5.53it/s]2024-10-14T00:51:33.122562Z [error    ] Failed to run or to evaluate example Example({'text': 'I think when I withdrew money when out of country the exchange rate was wrong.', 'label': 'wrong_exchange_rate_for_cash_withdrawal', 'answer': 'wrong_exchange_rate_for_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 15/2758 [00:02<07:11,  6.35it/s]2024-10-14T00:51:33.230547Z [error    ] Failed to run or to evaluate example Example({'text': \"I tried updating my balance by cheque yesterday but it doesn't seem to be working. Shouldn't that be faster? Please check my account something has gone wrong there.\", 'label': 'balance_not_updated_after_cheque_or_cash_deposit', 'answer': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 17/2758 [00:02<06:26,  7.09it/s]2024-10-14T00:51:33.529000Z [error    ] Failed to run or to evaluate example Example({'text': 'I paid with my card and was charged extra', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 18/2758 [00:03<06:42,  6.81it/s]2024-10-14T00:51:33.631560Z [error    ] Failed to run or to evaluate example Example({'text': \"I am reluctant to use ATMs international because I don't get an accurate exchange rate\", 'label': 'wrong_exchange_rate_for_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 19/2758 [00:03<06:07,  7.46it/s]2024-10-14T00:51:33.871841Z [error    ] Failed to run or to evaluate example Example({'text': 'I\\'m pretty frustrated about a pound charge that keeps  showing up in my account statement. It\\'s listed in the app as \"pending\", it never changes, and now I\\'m thinking someone\\'s hacked my account!', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 20/2758 [00:03<07:32,  6.04it/s]2024-10-14T00:51:34.041598Z [error    ] Failed to run or to evaluate example Example({'text': 'What is the reason for the fee charge on my transfer?', 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 21/2758 [00:03<07:36,  5.99it/s]2024-10-14T00:51:34.220570Z [error    ] Failed to run or to evaluate example Example({'text': 'Why has my card been charged an extra pound?', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 22/2758 [00:03<07:46,  5.87it/s]2024-10-14T00:51:34.378130Z [error    ] Failed to run or to evaluate example Example({'text': 'I was overcharged an additional pound.', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 23/2758 [00:03<07:36,  5.99it/s]2024-10-14T00:51:34.900666Z [error    ] Failed to run or to evaluate example Example({'text': 'How can I tell if there will be a fee added to my payment or not?', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['label', 'reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 24/2758 [00:04<12:27,  3.66it/s]2024-10-14T00:51:35.067541Z [error    ] Failed to run or to evaluate example Example({'text': 'How long does my top up pending last?', 'label': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 25/2758 [00:04<10:59,  4.14it/s]2024-10-14T00:51:35.228105Z [error    ] Failed to run or to evaluate example Example({'text': 'I tried to withdraw cash, but got declined!', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 26/2758 [00:04<09:53,  4.60it/s]2024-10-14T00:51:35.388204Z [error    ] Failed to run or to evaluate example Example({'text': 'I got less cash than what I specified at the ATM.', 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 28/2758 [00:05<10:14,  4.44it/s]2024-10-14T00:51:35.877622Z [error    ] Failed to run or to evaluate example Example({'text': \"Why isn't my deposit in my account?\", 'label': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 29/2758 [00:05<09:58,  4.56it/s]2024-10-14T00:51:36.042540Z [error    ] Failed to run or to evaluate example Example({'text': 'I want to get some cash from the ATM using my card but I dont want to be charged any fees. Ive taken some money out before with no fees, but recently Ive been getting charged. Why?', 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 30/2758 [00:05<09:13,  4.93it/s]2024-10-14T00:51:36.234729Z [error    ] Failed to run or to evaluate example Example({'text': \"i've waited 2 days for a transfer to reach a retailers account, am i going to have to wait longer.\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 31/2758 [00:05<09:05,  5.00it/s]2024-10-14T00:51:36.396022Z [error    ] Failed to run or to evaluate example Example({'text': 'It looks like my card payment was sent back.', 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 33/2758 [00:06<11:34,  3.92it/s]2024-10-14T00:51:37.044578Z [error    ] Failed to run or to evaluate example Example({'text': 'Hello I made a bank account transfer from the UK. The transfer was a couple hours ago, nothing has shown up yet.  Can you check to see if everything okay. Please.', 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 34/2758 [00:06<11:20,  4.00it/s]2024-10-14T00:51:37.252155Z [error    ] Failed to run or to evaluate example Example({'text': 'How can my new card be activated?', 'label': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 35/2758 [00:06<10:45,  4.22it/s]2024-10-14T00:51:37.434277Z [error    ] Failed to run or to evaluate example Example({'text': 'I received a fee I should not have.', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 36/2758 [00:07<10:00,  4.53it/s]2024-10-14T00:51:37.645305Z [error    ] Failed to run or to evaluate example Example({'text': \"I think I was charged extra on my payment on last Saturday.  Maybe the exchange rate was wrong?  I'd like a refund.\", 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 37/2758 [00:07<09:52,  4.60it/s]2024-10-14T00:51:37.873111Z [error    ] Failed to run or to evaluate example Example({'text': 'My card is showing multiple charges for the same items on my recent statement. I was wondering what actions of needed to take to fix this issue', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 38/2758 [00:07<10:01,  4.52it/s]2024-10-14T00:51:38.079123Z [error    ] Failed to run or to evaluate example Example({'text': 'why was my payment reverted on the app', 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 39/2758 [00:07<09:48,  4.62it/s]2024-10-14T00:51:38.272411Z [error    ] Failed to run or to evaluate example Example({'text': 'Why am I charged whenever I withdraw cash?', 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 40/2758 [00:07<09:29,  4.77it/s]2024-10-14T00:51:38.452597Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was I charged twice?', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 41/2758 [00:08<09:04,  4.99it/s]2024-10-14T00:51:38.614295Z [error    ] Failed to run or to evaluate example Example({'text': \"The cash I wanted wasn't there.\", 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 42/2758 [00:08<08:33,  5.29it/s]2024-10-14T00:51:38.775887Z [error    ] Failed to run or to evaluate example Example({'text': \"There is a strange payment on my card and I don't know what to do.\", 'label': 'card_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 43/2758 [00:08<08:10,  5.53it/s]2024-10-14T00:51:38.956436Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was my card payment reversed?', 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 45/2758 [00:08<08:30,  5.31it/s]2024-10-14T00:51:39.321587Z [error    ] Failed to run or to evaluate example Example({'text': 'I did not make a cash withdrawal that is on my statement', 'label': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 47/2758 [00:09<08:21,  5.41it/s]2024-10-14T00:51:39.679468Z [error    ] Failed to run or to evaluate example Example({'text': \"I made a check and cash deposit that wasn't credited to my account.\", 'label': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 49/2758 [00:09<08:30,  5.31it/s]2024-10-14T00:51:40.097461Z [error    ] Failed to run or to evaluate example Example({'text': 'What am I going to need in order to activate my card?', 'label': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 50/2758 [00:09<08:43,  5.17it/s]2024-10-14T00:51:40.267444Z [error    ] Failed to run or to evaluate example Example({'text': 'Can you look into why my most recent top-up is showing as pending? I thought it was supposed to be instantaneous.', 'label': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 53/2758 [00:10<10:47,  4.18it/s]2024-10-14T00:51:41.032548Z [error    ] Failed to run or to evaluate example Example({'text': 'Hi, I made a transfer yesterday that I need to reverse.  I need to put the money in a different account.', 'label': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 54/2758 [00:10<10:24,  4.33it/s]2024-10-14T00:51:41.238726Z [error    ] Failed to run or to evaluate example Example({'text': 'My rate of exchange was wrong.', 'label': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 56/2758 [00:11<10:45,  4.19it/s]2024-10-14T00:51:41.726594Z [error    ] Failed to run or to evaluate example Example({'text': 'When will I recieve my new card?', 'label': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 57/2758 [00:11<10:24,  4.32it/s]2024-10-14T00:51:41.836263Z [error    ] Failed to run or to evaluate example Example({'text': 'I would like to be assisted with the activation of my card.', 'label': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 60/2758 [00:11<10:02,  4.48it/s]2024-10-14T00:51:42.519390Z [error    ] Failed to run or to evaluate example Example({'text': \"I set up a payment to a new payee and sent some money but the person I'm sending it to has not received it.  Can you check where the money is?\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 61/2758 [00:12<09:18,  4.83it/s]2024-10-14T00:51:42.725160Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was my withdrawal requested cancelled by the ATM?', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 62/2758 [00:12<09:17,  4.83it/s]2024-10-14T00:51:42.886713Z [error    ] Failed to run or to evaluate example Example({'text': \"There's a direct debit payment that I don't recognize.\", 'label': 'direct_debit_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 63/2758 [00:12<08:41,  5.17it/s]2024-10-14T00:51:43.038392Z [error    ] Failed to run or to evaluate example Example({'text': 'I got cash abroad and need to check the exchange rate', 'label': 'wrong_exchange_rate_for_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 64/2758 [00:12<08:06,  5.54it/s]2024-10-14T00:51:43.221415Z [error    ] Failed to run or to evaluate example Example({'text': 'What is the reason for my beneficiary to be disallowed?', 'label': 'beneficiary_not_allowed'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 65/2758 [00:12<08:08,  5.52it/s]2024-10-14T00:51:43.379773Z [error    ] Failed to run or to evaluate example Example({'text': \"A couple weeks ago there was a debit taken from my account from a transaction I don't recall. Is it possible to trace this transaction to make sure I'm not being scammed?\", 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 66/2758 [00:12<07:49,  5.73it/s]2024-10-14T00:51:43.600593Z [error    ] Failed to run or to evaluate example Example({'text': 'Why is there a fee on my money transfer?', 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 67/2758 [00:13<08:27,  5.30it/s]2024-10-14T00:51:43.819622Z [error    ] Failed to run or to evaluate example Example({'text': 'My refund has not arrived, and I am unsure why. Who do I contact?', 'label': 'refund_not_showing_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 68/2758 [00:13<08:51,  5.07it/s]2024-10-14T00:51:44.026168Z [error    ] Failed to run or to evaluate example Example({'text': 'I have enough money in my account, so why is my card being declined?', 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 69/2758 [00:13<08:59,  4.99it/s]2024-10-14T00:51:44.367475Z [error    ] Failed to run or to evaluate example Example({'text': 'What do I need to do to get my new card which I have requested 2 weeks ago?', 'label': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 70/2758 [00:13<10:51,  4.12it/s]2024-10-14T00:51:44.547543Z [error    ] Failed to run or to evaluate example Example({'text': 'Can you please refund my item?', 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 71/2758 [00:14<10:01,  4.47it/s]2024-10-14T00:51:44.707675Z [error    ] Failed to run or to evaluate example Example({'text': 'It appears my top-up is still pending.', 'label': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 72/2758 [00:14<09:10,  4.88it/s]2024-10-14T00:51:44.868711Z [error    ] Failed to run or to evaluate example Example({'text': 'i didnt do this charge', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 74/2758 [00:14<09:04,  4.93it/s]2024-10-14T00:51:45.256672Z [error    ] Failed to run or to evaluate example Example({'text': 'I just had a look at my statement. Why have I been changed for using the ATM?', 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 75/2758 [00:14<08:29,  5.27it/s]2024-10-14T00:51:45.374080Z [error    ] Failed to run or to evaluate example Example({'text': \"Why didn't my transfer to a beneficiary go through?\", 'label': 'beneficiary_not_allowed'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 76/2758 [00:14<07:29,  5.97it/s]2024-10-14T00:51:45.559061Z [error    ] Failed to run or to evaluate example Example({'text': 'When will my transfer process?', 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 77/2758 [00:15<07:43,  5.78it/s]2024-10-14T00:51:45.720678Z [error    ] Failed to run or to evaluate example Example({'text': \"I made a cash deposit and the balance wasn't updated.\", 'label': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 78/2758 [00:15<07:34,  5.90it/s]2024-10-14T00:51:45.824512Z [error    ] Failed to run or to evaluate example Example({'text': \"I just realised I made the wrong payment yesterday. Can you please change it to the right account? It's my rent payment and really really needs to be in the right account by tomorrow\", 'label': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 79/2758 [00:15<06:41,  6.67it/s]2024-10-14T00:51:46.059479Z [error    ] Failed to run or to evaluate example Example({'text': 'Can you check the exchange rate on a cash transaction I did overseas', 'label': 'wrong_exchange_rate_for_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 80/2758 [00:15<07:48,  5.71it/s]2024-10-14T00:51:46.240623Z [error    ] Failed to run or to evaluate example Example({'text': 'Do you give refunds?', 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 81/2758 [00:15<07:54,  5.64it/s]2024-10-14T00:51:46.400386Z [error    ] Failed to run or to evaluate example Example({'text': 'I would like to get help from someone in your customer service department with assisting me with activating my card.', 'label': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 82/2758 [00:16<07:40,  5.81it/s]2024-10-14T00:51:46.631891Z [error    ] Failed to run or to evaluate example Example({'text': 'Please help me with the amount that i have withdrawn from the ATM today, the ATM has given me wrong sum of amount, and i could see that the app is displaying the greater amount than taken out.', 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 84/2758 [00:16<09:27,  4.71it/s]2024-10-14T00:51:47.130272Z [error    ] Failed to run or to evaluate example Example({'text': \"I've got a weird problem: I purchased something a week or maybe it was two weeks ago, and the funds have come back into my account! Can you explain this?\", 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 85/2758 [00:16<09:45,  4.57it/s]2024-10-14T00:51:47.321596Z [error    ] Failed to run or to evaluate example Example({'text': 'It is urgency. Please freeze my card now. As someone in some odd remote town has withdrawn some money by using my card. As i did not withdraw any money.', 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 86/2758 [00:16<09:21,  4.76it/s]2024-10-14T00:51:47.527906Z [error    ] Failed to run or to evaluate example Example({'text': \"I tried to pull cash from an ATM but it wouldn't let me.\", 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 87/2758 [00:17<09:19,  4.78it/s]2024-10-14T00:51:47.772667Z [error    ] Failed to run or to evaluate example Example({'text': \"I ordered something, and now I have buyer's remorse. Since what I ordered hasn't come yet, can you just cancel the payment since I already know I want a refund for it?\", 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 88/2758 [00:17<09:47,  4.55it/s]2024-10-14T00:51:47.880690Z [error    ] Failed to run or to evaluate example Example({'text': 'Why am I still not able to see the money I deposited a week ago? This is urgent!!', 'label': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 89/2758 [00:17<08:16,  5.37it/s]2024-10-14T00:51:48.137790Z [error    ] Failed to run or to evaluate example Example({'text': 'Hi, I am unable to see transaction in my account which i made couples of hours ago from my UK account. Please help me in this.', 'label': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 90/2758 [00:17<09:13,  4.82it/s]2024-10-14T00:51:48.301161Z [error    ] Failed to run or to evaluate example Example({'text': \"It's not letting me transfer money to my beneficiery.\", 'label': 'beneficiary_not_allowed'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 91/2758 [00:17<08:38,  5.14it/s]2024-10-14T00:51:48.494909Z [error    ] Failed to run or to evaluate example Example({'text': 'Please double check my card - withdrawal was working fine so far, but this morning on the way to work it suddenly got declined!', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 92/2758 [00:18<08:37,  5.16it/s]2024-10-14T00:51:48.658707Z [error    ] Failed to run or to evaluate example Example({'text': 'I have a transaction showing up more than once.', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 93/2758 [00:18<08:12,  5.41it/s]2024-10-14T00:51:48.824394Z [error    ] Failed to run or to evaluate example Example({'text': 'I need to be made aware when I am being charged an extra amount for payments please. I looked over the app earlier and noticed an additional feel related to one of the payments. I was not warned about this before.', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 95/2758 [00:18<08:05,  5.49it/s]2024-10-14T00:51:49.172735Z [error    ] Failed to run or to evaluate example Example({'text': \"There was a transaction this morning that I'd like to reverse.\", 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▎         | 98/2758 [00:19<10:42,  4.14it/s]2024-10-14T00:51:49.913933Z [error    ] Failed to run or to evaluate example Example({'text': 'I tried to withdraw cash and got declined, why is that?', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▎         | 99/2758 [00:19<09:38,  4.60it/s]2024-10-14T00:51:50.100247Z [error    ] Failed to run or to evaluate example Example({'text': \"My card has been declined by two separate ATM, and I'm worried something is wrong with my account. Would you please see if my account is okay?\", 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▎         | 100/2758 [00:19<09:12,  4.81it/s]2024-10-14T00:51:50.308339Z [error    ] Failed to run or to evaluate example Example({'text': \"Help!  In the app there is a direct debit that I don't remember.\", 'label': 'direct_debit_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▎         | 101/2758 [00:19<09:12,  4.80it/s]2024-10-14T00:51:50.499527Z [error    ] Failed to run or to evaluate example Example({'text': \"I normally don't use ATMs, but I was in a rush today and had to withdraw some cash. The ATM gave me the wrong amount of money and now my app is not showing the same amount as it should. What do I do?\", 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▎         | 102/2758 [00:20<08:58,  4.93it/s]2024-10-14T00:51:50.709587Z [error    ] Failed to run or to evaluate example Example({'text': 'Why am I charged a fee for getting cash?', 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▎         | 103/2758 [00:20<09:04,  4.88it/s]2024-10-14T00:51:50.869417Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was I charged more than I should have been?', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 104/2758 [00:20<08:28,  5.22it/s]2024-10-14T00:51:51.037241Z [error    ] Failed to run or to evaluate example Example({'text': 'I needed $100 but all it gave me was $20.', 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 105/2758 [00:20<08:09,  5.42it/s]2024-10-14T00:51:51.249231Z [error    ] Failed to run or to evaluate example Example({'text': 'hey, I think someone stole my card numbers. There is a purchase showing up on my app from a store pretty far away from me.. I really need that money back to pay my rent.', 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 106/2758 [00:20<08:31,  5.19it/s]2024-10-14T00:51:51.409886Z [error    ] Failed to run or to evaluate example Example({'text': 'Is there a reason my top-up has not gone through?', 'label': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 107/2758 [00:21<08:07,  5.43it/s]2024-10-14T00:51:51.625419Z [error    ] Failed to run or to evaluate example Example({'text': 'I deposited cash into my account a week ago and it is still not available, please tell me why? I need the cash back now.', 'label': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 108/2758 [00:21<08:30,  5.19it/s]2024-10-14T00:51:51.778002Z [error    ] Failed to run or to evaluate example Example({'text': 'I need a refund. This is not what i wanted.', 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 109/2758 [00:21<07:57,  5.55it/s]2024-10-14T00:51:51.935032Z [error    ] Failed to run or to evaluate example Example({'text': 'Why did you give me so little currency?', 'label': 'wrong_exchange_rate_for_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 110/2758 [00:21<07:39,  5.77it/s]2024-10-14T00:51:52.052156Z [error    ] Failed to run or to evaluate example Example({'text': 'Where is the cash I deposited?', 'label': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 111/2758 [00:21<06:54,  6.39it/s]2024-10-14T00:51:52.265067Z [error    ] Failed to run or to evaluate example Example({'text': 'How long does it take for transfers to process?  I sent funds to a friend, and she says that she has not yet received anything.', 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 112/2758 [00:21<07:38,  5.77it/s]2024-10-14T00:51:52.504838Z [error    ] Failed to run or to evaluate example Example({'text': 'I am trying  to  transfer and  it has been  stopped why is  that', 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 114/2758 [00:22<08:41,  5.07it/s]2024-10-14T00:51:52.879134Z [error    ] Failed to run or to evaluate example Example({'text': 'I think my card payment was cancelled. What happened?', 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 115/2758 [00:22<08:18,  5.31it/s]2024-10-14T00:51:52.989151Z [error    ] Failed to run or to evaluate example Example({'text': 'I am concerned that I am being doubled charged for several items purchased in the past week.  Please review my statement and correct.', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 116/2758 [00:22<07:16,  6.06it/s]2024-10-14T00:51:53.166209Z [error    ] Failed to run or to evaluate example Example({'text': 'A payment is showing twice. Why is that?', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 117/2758 [00:22<07:24,  5.94it/s]2024-10-14T00:51:53.327194Z [error    ] Failed to run or to evaluate example Example({'text': 'I tired to get cash in the ATM but it was cancelled', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 118/2758 [00:22<07:19,  6.01it/s]2024-10-14T00:51:53.484650Z [error    ] Failed to run or to evaluate example Example({'text': \"I'm not sure why my card didn't work\", 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 120/2758 [00:27<1:08:07,  1.55s/it]2024-10-14T00:51:58.431840Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was a fee added to my bill when I used my card?', 'label': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 121/2758 [00:28<49:49,  1.13s/it]  2024-10-14T00:51:58.553380Z [error    ] Failed to run or to evaluate example Example({'text': 'I cannot see a refund in my account', 'label': 'refund_not_showing_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 122/2758 [00:28<36:28,  1.20it/s]2024-10-14T00:51:58.786012Z [error    ] Failed to run or to evaluate example Example({'text': \"Hello I changed my mind and really need a refund on something I bought recently. Can you please cancel the transaction and get me my money back. Please it's urgent.\", 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 123/2758 [00:28<28:35,  1.54it/s]2024-10-14T00:51:58.987381Z [error    ] Failed to run or to evaluate example Example({'text': 'I see a charge of 1L I do not recognize on my statement', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 124/2758 [00:28<22:39,  1.94it/s]2024-10-14T00:51:59.147948Z [error    ] Failed to run or to evaluate example Example({'text': 'My payment had a wrong exchange rate.', 'label': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▍         | 125/2758 [00:28<17:58,  2.44it/s]2024-10-14T00:51:59.497847Z [error    ] Failed to run or to evaluate example Example({'text': \"Can you please sort out your top up? I need this to go through asap because I really need the money. It's already been pending for an hour.\", 'label': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▍         | 126/2758 [00:29<17:12,  2.55it/s]2024-10-14T00:51:59.685001Z [error    ] Failed to run or to evaluate example Example({'text': \"I was just contacted by a seller that let me know they didn't get my money even though I'm very sure it was removed from my account. Now it's back in my account. Get this resolved quickly.\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▍         | 127/2758 [00:29<14:28,  3.03it/s]2024-10-14T00:51:59.884092Z [error    ] Failed to run or to evaluate example Example({'text': 'The exchange rate is bad. Are you sure this is the exchange rate?', 'label': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▍         | 128/2758 [00:29<12:45,  3.44it/s]2024-10-14T00:52:00.079375Z [error    ] Failed to run or to evaluate example Example({'text': 'Why do I have a charge for an ATM withdrawal? I thought these were free?', 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▍         | 129/2758 [00:29<11:28,  3.82it/s]2024-10-14T00:52:00.238153Z [error    ] Failed to run or to evaluate example Example({'text': 'What is this $1 charge on my account?', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▍         | 130/2758 [00:29<10:07,  4.33it/s]2024-10-14T00:52:00.400070Z [error    ] Failed to run or to evaluate example Example({'text': 'I made a mistake of transferring, can I cancel my previous transfer?', 'label': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▍         | 132/2758 [00:30<10:35,  4.13it/s]2024-10-14T00:52:01.071344Z [error    ] Failed to run or to evaluate example Example({'text': 'How long does it take to recieve my new card?', 'label': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▍         | 133/2758 [00:30<12:05,  3.62it/s]2024-10-14T00:52:01.321984Z [error    ] Failed to run or to evaluate example Example({'text': 'I deposited a check yesterday and Im not seeing it in my account. i need the money, is there something wrong with my account? check it out please', 'label': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▍         | 134/2758 [00:30<11:44,  3.72it/s]2024-10-14T00:52:01.485399Z [error    ] Failed to run or to evaluate example Example({'text': \"I didn't realize that there were any fees for withdrawing money from my account--this has never happened to me before.  What exactly are the fees?\", 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▍         | 135/2758 [00:31<10:20,  4.22it/s]2024-10-14T00:52:01.595257Z [error    ] Failed to run or to evaluate example Example({'text': \"Why can't I get cash from the ATM?\", 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▍         | 136/2758 [00:31<08:41,  5.03it/s]2024-10-14T00:52:01.757765Z [error    ] Failed to run or to evaluate example Example({'text': \"I haven't yet received money that I transferred\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▍         | 137/2758 [00:31<08:12,  5.32it/s]2024-10-14T00:52:01.945390Z [error    ] Failed to run or to evaluate example Example({'text': \"My wallet got stolen a couple hours ago and now I've seen there already is a withdrawal. Help this is absolutely urgent I don't want to loose more money\", 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▌         | 138/2758 [00:31<08:11,  5.33it/s]2024-10-14T00:52:02.134931Z [error    ] Failed to run or to evaluate example Example({'text': 'Why am I being declined?', 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▌         | 139/2758 [00:31<08:12,  5.31it/s]2024-10-14T00:52:02.322170Z [error    ] Failed to run or to evaluate example Example({'text': 'Why and I being charged this fee?', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▌         | 140/2758 [00:31<08:12,  5.32it/s]2024-10-14T00:52:02.483749Z [error    ] Failed to run or to evaluate example Example({'text': \"I was charge a fee that I wasn't told about\", 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▌         | 141/2758 [00:32<07:51,  5.55it/s]2024-10-14T00:52:02.647362Z [error    ] Failed to run or to evaluate example Example({'text': 'A random charge got added to my card', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▌         | 143/2758 [00:32<07:44,  5.63it/s]2024-10-14T00:52:02.992810Z [error    ] Failed to run or to evaluate example Example({'text': 'I did not get the right amount of cash from the ATM.', 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▌         | 144/2758 [00:32<07:35,  5.74it/s]2024-10-14T00:52:03.259632Z [error    ] Failed to run or to evaluate example Example({'text': \"Is there a place to check for fee for payments? I feel like I'm getting charged too much at times.\", 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['label']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▌         | 146/2758 [00:33<08:15,  5.27it/s]2024-10-14T00:52:03.585590Z [error    ] Failed to run or to evaluate example Example({'text': 'Would it be possible to activate my card?', 'label': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▌         | 148/2758 [00:33<10:08,  4.29it/s]2024-10-14T00:52:04.097085Z [error    ] Failed to run or to evaluate example Example({'text': \"Payment I didn't do.\", 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▌         | 149/2758 [00:33<09:07,  4.76it/s]2024-10-14T00:52:04.291769Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was i charged for making a withdrawal? After i went grocery shopping i withdrew some money from my account and now there is another charge.', 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▌         | 151/2758 [00:34<09:28,  4.58it/s]2024-10-14T00:52:04.829244Z [error    ] Failed to run or to evaluate example Example({'text': \"I got a notice from my app that I withdrew cash but I don't remember doing so. How do I fix this?\", 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 152/2758 [00:34<10:27,  4.15it/s]2024-10-14T00:52:04.993907Z [error    ] Failed to run or to evaluate example Example({'text': 'I transferred money from one account to another account and I charged a fee for it. Why is that?', 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 153/2758 [00:34<09:25,  4.60it/s]2024-10-14T00:52:05.274865Z [error    ] Failed to run or to evaluate example Example({'text': 'How long will it take for my money to be deposited?', 'label': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 154/2758 [00:34<10:13,  4.24it/s]2024-10-14T00:52:05.440389Z [error    ] Failed to run or to evaluate example Example({'text': \"How long do transfers to international banks take? I made one to france a couple of days ago, but it's still not there.\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 155/2758 [00:35<09:19,  4.65it/s]2024-10-14T00:52:05.630790Z [error    ] Failed to run or to evaluate example Example({'text': 'A transfer has been made in my account that I need to cancel.  This was a mistake on my part and I hope we can get this resolved quickly.', 'label': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 156/2758 [00:35<08:59,  4.82it/s]2024-10-14T00:52:05.857494Z [error    ] Failed to run or to evaluate example Example({'text': 'Several items I have charged this week are appearing twice.  Please review my statement and remove any duplicate charges.', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 157/2758 [00:35<09:14,  4.69it/s]2024-10-14T00:52:06.019627Z [error    ] Failed to run or to evaluate example Example({'text': 'A payment on my statement is wrong.', 'label': 'extra_charge_on_statement', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 158/2758 [00:35<08:34,  5.05it/s]2024-10-14T00:52:06.453175Z [error    ] Failed to run or to evaluate example Example({'text': 'My statement is showing an extra £1 charge and I am unsure why. Is there an explanation for this?', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 159/2758 [00:36<11:38,  3.72it/s]2024-10-14T00:52:06.563303Z [error    ] Failed to run or to evaluate example Example({'text': 'Why is this not letting me exchange crypto? I need help making this transaction go through.', 'label': 'beneficiary_not_allowed'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 160/2758 [00:36<09:33,  4.53it/s]2024-10-14T00:52:06.735002Z [error    ] Failed to run or to evaluate example Example({'text': 'Why do I get declined when I try to withdraw cash?', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 161/2758 [00:36<08:55,  4.85it/s]2024-10-14T00:52:06.895129Z [error    ] Failed to run or to evaluate example Example({'text': 'I checked my account today and saw that I was charged an extra pound that I did not spend.', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 162/2758 [00:36<08:19,  5.19it/s]2024-10-14T00:52:07.081221Z [error    ] Failed to run or to evaluate example Example({'text': 'How can I cancel a transaction to a wrong account?', 'label': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 163/2758 [00:36<08:13,  5.26it/s]2024-10-14T00:52:07.230625Z [error    ] Failed to run or to evaluate example Example({'text': 'I tried withdrawing but my cash is not showing up?', 'label': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 164/2758 [00:36<07:42,  5.61it/s]2024-10-14T00:52:07.431221Z [error    ] Failed to run or to evaluate example Example({'text': 'Why have I been charged for pulling cash out of my own account?', 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 165/2758 [00:37<07:59,  5.41it/s]2024-10-14T00:52:07.684287Z [error    ] Failed to run or to evaluate example Example({'text': 'where is my money from this morning', 'label': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 166/2758 [00:37<08:53,  4.86it/s]2024-10-14T00:52:07.872588Z [error    ] Failed to run or to evaluate example Example({'text': 'Please check my Card. As Withdrawal was working fine so far, but this morning suddenly got declined. Can you please check the problem?', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 167/2758 [00:37<08:37,  5.01it/s]2024-10-14T00:52:08.108098Z [error    ] Failed to run or to evaluate example Example({'text': 'My app is showing a payment that I know I did not do. Can you please cancel that transaction and credit my account please?', 'label': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 168/2758 [00:37<09:05,  4.75it/s]2024-10-14T00:52:08.266202Z [error    ] Failed to run or to evaluate example Example({'text': 'I made a purchase but never expected to see a fee charged for the transaction.', 'label': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 169/2758 [00:37<08:25,  5.12it/s]2024-10-14T00:52:08.444705Z [error    ] Failed to run or to evaluate example Example({'text': 'Why am I being charged for transferring money?', 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 170/2758 [00:38<08:12,  5.25it/s]2024-10-14T00:52:08.607283Z [error    ] Failed to run or to evaluate example Example({'text': 'Is it possible that my card payment was reverted?', 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 171/2758 [00:38<07:49,  5.51it/s]2024-10-14T00:52:08.797428Z [error    ] Failed to run or to evaluate example Example({'text': 'I  see an extra 1£ charge on my app. Why did It charge me extra?', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▋         | 173/2758 [00:38<10:25,  4.13it/s]2024-10-14T00:52:09.289987Z [error    ] Failed to run or to evaluate example Example({'text': \"Why can't I transfer money to a beneficiary\", 'label': 'beneficiary_not_allowed'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▋         | 174/2758 [00:38<08:47,  4.90it/s]2024-10-14T00:52:09.447667Z [error    ] Failed to run or to evaluate example Example({'text': 'Help, your app is showing a larger WD than I actually did earlier at an ATM.', 'label': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▋         | 175/2758 [00:39<08:11,  5.25it/s]2024-10-14T00:52:09.630266Z [error    ] Failed to run or to evaluate example Example({'text': 'Why is my cash request and the amount I received different?', 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▋         | 177/2758 [00:40<18:03,  2.38it/s]2024-10-14T00:52:10.700739Z [error    ] Failed to run or to evaluate example Example({'text': \"So I've been using my account frequently to manage payments for my vacation house in a different country, and now I'm getting hit with ridiculously high fees! What's with that? Ought not I be rewarded as a frequent user?\", 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▋         | 178/2758 [00:40<14:03,  3.06it/s]2024-10-14T00:52:10.928301Z [error    ] Failed to run or to evaluate example Example({'text': \"I transferred 7,000 to a receiver outside the EU and they received a lesser amount than what I sent, Unfortunately, now I must send an additional transfer to the receiver so that they can receive the full amount I initially sent.  I'm not sure why they received a lesser amount than what I initially sen, but can you please look into this and let me know what happened?\", 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▋         | 179/2758 [00:40<12:46,  3.37it/s]2024-10-14T00:52:11.139201Z [error    ] Failed to run or to evaluate example Example({'text': 'Why have I been charged a fee for cash withdrawal?', 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 180/2758 [00:40<11:39,  3.69it/s]2024-10-14T00:52:11.247479Z [error    ] Failed to run or to evaluate example Example({'text': \"Why can't I see my refund in my statement?\", 'label': 'refund_not_showing_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 182/2758 [00:41<09:21,  4.58it/s]2024-10-14T00:52:11.618613Z [error    ] Failed to run or to evaluate example Example({'text': \"Can I make a withdraw in my home currency at an ATM? I'm on vacation and am a bit worried because I don't have cash with me. Is it possible to withdraw here without any additional costs or fees?\", 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 183/2758 [00:41<08:38,  4.97it/s]2024-10-14T00:52:11.729252Z [error    ] Failed to run or to evaluate example Example({'text': \"I was trying to purchase some crypto and the app won't allow me to do it. What's the deal with this? I really wanted to complete the exchange.\", 'label': 'beneficiary_not_allowed'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 184/2758 [00:41<07:28,  5.75it/s]2024-10-14T00:52:11.909219Z [error    ] Failed to run or to evaluate example Example({'text': 'Why has transferring money resulted in a charge?', 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 185/2758 [00:41<07:33,  5.67it/s]2024-10-14T00:52:12.086631Z [error    ] Failed to run or to evaluate example Example({'text': 'I have a card payment that has been pending for some time and would like to know when it is going to go through.', 'label': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 186/2758 [00:41<07:33,  5.67it/s]2024-10-14T00:52:12.248259Z [error    ] Failed to run or to evaluate example Example({'text': 'I was charged multiple times for one transaction.', 'label': 'transaction_charged_twice', 'answer': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 188/2758 [00:42<08:56,  4.79it/s]2024-10-14T00:52:12.701421Z [error    ] Failed to run or to evaluate example Example({'text': 'Please help me with my card. As i have tried to use my card in two different ATMs but repeatedly it was declining by ATM.', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 190/2758 [00:42<08:51,  4.83it/s]2024-10-14T00:52:13.167485Z [error    ] Failed to run or to evaluate example Example({'text': \"Could you please tell me why my card payment didn't work?\", 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 191/2758 [00:42<09:06,  4.69it/s]2024-10-14T00:52:13.327641Z [error    ] Failed to run or to evaluate example Example({'text': 'When will my returned transaction show up on my account?', 'label': 'refund_not_showing_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 192/2758 [00:42<08:26,  5.07it/s]2024-10-14T00:52:13.504664Z [error    ] Failed to run or to evaluate example Example({'text': \"There are some charges that I don't recognize.  It happened days ago.  Can I get these charges back?  Should I cancel my card?\", 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 193/2758 [00:43<08:10,  5.23it/s]2024-10-14T00:52:13.654615Z [error    ] Failed to run or to evaluate example Example({'text': \"I've been waiting since Friday, where is my money?\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 194/2758 [00:43<07:37,  5.60it/s]2024-10-14T00:52:13.858977Z [error    ] Failed to run or to evaluate example Example({'text': 'I am having trouble withdrawing cash.', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 195/2758 [00:43<07:57,  5.37it/s]2024-10-14T00:52:14.076235Z [error    ] Failed to run or to evaluate example Example({'text': 'Is my card lost? I am still waiting for it to be delivered.', 'label': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 197/2758 [00:43<08:24,  5.08it/s]2024-10-14T00:52:19.079261Z [error    ] Failed to run or to evaluate example Example({'text': 'How long is a top up supposed to be pending, because an hour is too long! Can you fix this to go through?', 'label': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 199/2758 [00:49<55:14,  1.30s/it]  2024-10-14T00:52:19.963547Z [error    ] Failed to run or to evaluate example Example({'text': \"I need my account checked because it appears there is a problem. I attempted to update my balance yesterday using cheque but it doesn't seem to have worked.  Should this not be faster than this?\", 'label': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 200/2758 [00:49<41:51,  1.02it/s]2024-10-14T00:52:20.168816Z [error    ] Failed to run or to evaluate example Example({'text': \"The ATM didn't give me enough money! I asked for more than it gave. What do I do?\", 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 201/2758 [00:49<31:55,  1.34it/s]2024-10-14T00:52:20.401673Z [error    ] Failed to run or to evaluate example Example({'text': \"My new landlord is a lier and is trying to rip me off by saying I've not paid my rent when I have paid my rent.  What is going on?  They say the money hasn't got to them but I see it going out of my account.  Can you check that the money went to the right place?\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 202/2758 [00:50<25:19,  1.68it/s]2024-10-14T00:52:20.591589Z [error    ] Failed to run or to evaluate example Example({'text': 'I am still waiting for a transfer I did', 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 203/2758 [00:50<20:07,  2.12it/s]2024-10-14T00:52:20.760699Z [error    ] Failed to run or to evaluate example Example({'text': \"There is a withdrawal in my account I didn't make.\", 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 204/2758 [00:50<16:14,  2.62it/s]2024-10-14T00:52:20.921683Z [error    ] Failed to run or to evaluate example Example({'text': \"I looked on the app and it says I withdrew cash.  I didn't!\", 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 206/2758 [00:50<11:59,  3.55it/s]2024-10-14T00:52:21.308383Z [error    ] Failed to run or to evaluate example Example({'text': 'Why is my card payment still a pending transaction?', 'label': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  8%|▊         | 208/2758 [00:51<10:07,  4.20it/s]2024-10-14T00:52:21.766365Z [error    ] Failed to run or to evaluate example Example({'text': 'I was charged twice for a restaurant, can you take the second charge off?', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  8%|▊         | 209/2758 [00:51<10:17,  4.13it/s]2024-10-14T00:52:21.953440Z [error    ] Failed to run or to evaluate example Example({'text': \"after going over my transactions for the last couple of months I noticed a pretty large charge that I know I did not make. I know it's been a while but can I still dispute this charge?\", 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  8%|▊         | 210/2758 [00:51<09:34,  4.44it/s]2024-10-14T00:52:22.110662Z [error    ] Failed to run or to evaluate example Example({'text': 'I received the wrong amount of cash back', 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  8%|▊         | 211/2758 [00:51<08:42,  4.87it/s]2024-10-14T00:52:22.271965Z [error    ] Failed to run or to evaluate example Example({'text': \"I sent a payment but now it's not showing up.\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  8%|▊         | 212/2758 [00:51<08:09,  5.20it/s]2024-10-14T00:52:22.485290Z [error    ] Failed to run or to evaluate example Example({'text': \"My card payment's cancelled\", 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  8%|▊         | 213/2758 [00:52<08:24,  5.04it/s]2024-10-14T00:52:22.679266Z [error    ] Failed to run or to evaluate example Example({'text': 'do you offer refunds? i would like to return purchase.', 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  8%|▊         | 215/2758 [00:52<10:49,  3.92it/s]2024-10-14T00:52:23.282495Z [error    ] Failed to run or to evaluate example Example({'text': 'A wrong amount of cash we sent to me.', 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  8%|▊         | 216/2758 [00:52<10:16,  4.12it/s]2024-10-14T00:52:23.488914Z [error    ] Failed to run or to evaluate example Example({'text': \"Please help!  The app won't let me cancel a money transfer.  I accidently sent money to an account that wasn't mine.  I need this cancelled immediately.\", 'label': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  8%|▊         | 217/2758 [00:53<09:49,  4.31it/s]2024-10-14T00:52:23.649617Z [error    ] Failed to run or to evaluate example Example({'text': 'What is this fee showing up in my account for?', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  8%|▊         | 218/2758 [00:53<08:53,  4.76it/s]2024-10-14T00:52:23.829405Z [error    ] Failed to run or to evaluate example Example({'text': \"I've been using my account while abroad for a while but only recently I've been charged a fee. Why am I only being charged a fee now.\", 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  8%|▊         | 219/2758 [00:53<08:30,  4.97it/s]2024-10-14T00:52:24.038459Z [error    ] Failed to run or to evaluate example Example({'text': 'I have been waiting for my card payment to be moved from pending status for an unusually long time.  What is going on here and do you have an idea of when I can expect it to go through?', 'label': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  8%|▊         | 221/2758 [00:53<10:18,  4.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 222 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:52:24.837102Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<02:23,  2.09it/s]2024-10-14T00:52:25.347753Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|          | 2/300 [00:00<01:51,  2.68it/s]error    4T00:52:25.367845Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 2/300 [00:00<01:51,  2.68it/s]2024-10-14T00:52:25.388864Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 3/300 [00:00<01:50,  2.68it/s]2024-10-14T00:52:25.395393Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   1%|▏         | 4/300 [00:00<01:50,  2.68it/s]2024-10-14T00:52:25.423856Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 45  (20.0):  15%|█▍        | 44/300 [00:01<00:07, 33.17it/s] 024-10-14T00:52:26.569526Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 13.0 / 56  (23.2):  19%|█▊        | 56/300 [00:02<00:07, 32.38it/s] 024-10-14T00:52:26.955554Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno=198\n",
      "Average Metric: 15.0 / 68  (22.1):  22%|██▏       | 67/300 [00:02<00:07, 33.12it/s]2024-10-14T00:52:27.335126Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 92  (25.0):  31%|███       | 92/300 [00:03<00:05, 37.59it/s]dspy.evaluate.evaluate2084Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 104  (25.0):  34%|███▍      | 103/300 [00:03<00:05, 38.58it/s]2024-10-14T00:52:28.432109Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 109  (23.9):  36%|███▌      | 108/300 [00:04<00:08, 22.18it/s]2024-10-14T00:52:28.822378Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 29.0 / 123  (23.6):  41%|████      | 122/300 [00:04<00:05, 30.23it/s]2024-10-14T00:52:29.177556Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 154  (22.7):  51%|█████▏    | 154/300 [00:05<00:03, 38.46it/s]2024-10-14T00:52:29.909252Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 155  (22.6):  51%|█████▏    | 154/300 [00:05<00:03, 38.46it/s]2024-10-14T00:52:29.942479Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 157  (22.3):  52%|█████▏    | 156/300 [00:05<00:03, 38.46it/s]2024-10-14T00:52:29.953140Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 158  (22.2):  52%|█████▏    | 157/300 [00:05<00:03, 38.46it/s]2024-10-14T00:52:29.958409Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 43.0 / 184  (23.4):  61%|██████    | 183/300 [00:06<00:03, 34.95it/s]2024-10-14T00:52:30.872530Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 208  (25.0):  69%|██████▉   | 207/300 [00:06<00:02, 39.02it/s]2024-10-14T00:52:31.531344Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 210  (25.2):  70%|██████▉   | 209/300 [00:07<00:02, 39.02it/s]2024-10-14T00:52:31.673271Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 211  (25.1):  70%|███████   | 211/300 [00:07<00:02, 30.75it/s]error    4T00:52:31.683011Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 212  (25.0):  70%|███████   | 211/300 [00:07<00:02, 30.75it/s]2024-10-14T00:52:31.706952Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 217  (24.9):  72%|███████▏  | 216/300 [00:07<00:03, 27.27it/s] [24-10-14T00:52:31.925665Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 220  (24.5):  73%|███████▎  | 219/300 [00:07<00:02, 29.24it/s]filename14T00:52:31.971241Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 234  (24.4):  78%|███████▊  | 234/300 [00:07<00:02, 30.83it/s]2024-10-14T00:52:32.487579Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 240  (24.6):  80%|███████▉  | 239/300 [00:08<00:01, 31.94it/s]2024-10-14T00:52:32.562420Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 254  (25.2):  84%|████████▍ | 253/300 [00:08<00:01, 32.41it/s]2024-10-14T00:52:32.933921Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 76.0 / 300  (25.3): 100%|██████████| 300/300 [00:08<00:00, 34.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 25.33 for seed -1\n",
      "Scores so far: [3.33, 3.33, 25.33]\n",
      "Best score so far: 25.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2758 [00:00<11:47,  3.90it/s]2024-10-14T00:52:33.816834Z [error    ] Failed to run or to evaluate example Example({'text': 'Why is there an uknown charge showing on my account?', 'label': 'extra_charge_on_statement', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 2/2758 [00:00<09:32,  4.82it/s]2024-10-14T00:52:33.982957Z [error    ] Failed to run or to evaluate example Example({'text': 'The amount of exchange was not correct for the item i bought.', 'label': 'card_payment_wrong_exchange_rate', 'answer': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 3/2758 [00:00<08:38,  5.32it/s]2024-10-14T00:52:34.159265Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was my transfer stopped ?', 'label': 'transfer_not_received_by_recipient', 'answer': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 4/2758 [00:00<08:26,  5.43it/s]2024-10-14T00:52:34.322567Z [error    ] Failed to run or to evaluate example Example({'text': 'I deposited money in the form of a cheque, but my balance has not increased.', 'label': 'balance_not_updated_after_cheque_or_cash_deposit', 'answer': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 5/2758 [00:00<08:05,  5.67it/s]2024-10-14T00:52:34.480181Z [error    ] Failed to run or to evaluate example Example({'text': 'I just got my card and cannot get it to work.', 'label': 'activate_my_card', 'answer': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 6/2758 [00:01<07:47,  5.88it/s]2024-10-14T00:52:34.671305Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was I not allowed to do a transfer to a beneficiary?', 'label': 'beneficiary_not_allowed', 'answer': 'beneficiary_not_allowed'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 7/2758 [00:01<08:06,  5.66it/s]2024-10-14T00:52:34.681641Z [error    ] Failed to run or to evaluate example Example({'text': 'I was charged multiple times for one transaction.', 'label': 'transaction_charged_twice', 'answer': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:52:34.843606Z [error    ] Failed to run or to evaluate example Example({'text': 'The other bank confirmed a transfer I made, but this account is not reflecting it yet.', 'label': 'balance_not_updated_after_bank_transfer', 'answer': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 9/2758 [00:01<06:06,  7.50it/s]2024-10-14T00:52:35.009325Z [error    ] Failed to run or to evaluate example Example({'text': \"I made a top up yesterday but it's still pending.\", 'label': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 10/2758 [00:01<06:28,  7.07it/s]2024-10-14T00:52:35.227886Z [error    ] Failed to run or to evaluate example Example({'text': 'I have my card here with me and someone has just made a withdrawal for 500. Please help!', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 12/2758 [00:02<12:31,  3.65it/s]2024-10-14T00:52:35.977758Z [error    ] Failed to run or to evaluate example Example({'text': 'Why am I charged to get money from the ATM?', 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 13/2758 [00:02<11:23,  4.01it/s]2024-10-14T00:52:36.179723Z [error    ] Failed to run or to evaluate example Example({'text': 'Why have I received a rebate for my payment after a week?', 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 14/2758 [00:02<10:44,  4.26it/s]2024-10-14T00:52:38.408072Z [error    ] Failed to run or to evaluate example Example({'text': \"How do I see what fees I am supposed to be charged on my account? I've noticed fees on some transactions, but not on others. This is very confusing and I cannot find a pattern to what I am being charged?\", 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 15/2758 [00:05<37:19,  1.23it/s]2024-10-14T00:52:38.571771Z [error    ] Failed to run or to evaluate example Example({'text': 'I could not transfer to a beneficiary', 'label': 'beneficiary_not_allowed'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 18/2758 [00:05<20:40,  2.21it/s]2024-10-14T00:52:39.300008Z [error    ] Failed to run or to evaluate example Example({'text': 'I received a returned payment that I made.', 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 19/2758 [00:05<16:52,  2.71it/s]2024-10-14T00:52:39.462020Z [error    ] Failed to run or to evaluate example Example({'text': 'What is the refund process?', 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 21/2758 [00:06<13:48,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 22 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:52:40.657401Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<02:42,  1.85it/s] ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 3/300 [00:00<01:06,  4.47it/s]2024-10-14T00:52:40.900857Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 54  (42.6):  18%|█▊        | 53/300 [00:02<00:08, 29.69it/s]2024-10-14T00:52:42.508623Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 55  (41.8):  18%|█▊        | 54/300 [00:02<00:08, 29.69it/s]2024-10-14T00:52:42.694464Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 39.0 / 107  (36.4):  35%|███▌      | 106/300 [00:04<00:06, 29.20it/s]2024-10-14T00:52:44.471238Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 39.0 / 115  (33.9):  38%|███▊      | 114/300 [00:04<00:06, 29.41it/s]2024-10-14T00:52:44.765336Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 68.0 / 196  (34.7):  65%|██████▌   | 195/300 [00:06<00:02, 35.62it/s]error    4T00:52:47.019005Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 72.0 / 202  (35.6):  67%|██████▋   | 201/300 [00:07<00:02, 33.94it/s]]024-10-14T00:52:47.244349Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 72.0 / 204  (35.3):  68%|██████▊   | 203/300 [00:07<00:02, 33.94it/s]2024-10-14T00:52:47.326781Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 209  (35.4):  69%|██████▉   | 208/300 [00:07<00:02, 32.65it/s] 024-10-14T00:52:47.509347Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 94.0 / 256  (36.7):  85%|████████▌ | 255/300 [00:08<00:01, 38.23it/s]2024-10-14T00:52:48.794862Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 112.0 / 300  (37.3): 100%|██████████| 300/300 [00:09<00:00, 32.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 37.33 for seed 0\n",
      "Scores so far: [3.33, 3.33, 25.33, 37.33]\n",
      "Best score so far: 37.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2758 [00:00<?, ?it/s]2024-10-14T00:52:49.499805Z [error    ] Failed to run or to evaluate example Example({'text': 'Why am I charged a fee when using my debit or credit card?', 'label': 'card_payment_fee_charged', 'answer': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 1/2758 [00:00<08:24,  5.46it/s]2024-10-14T00:52:49.676111Z [error    ] Failed to run or to evaluate example Example({'text': \"After making a transfer from a UK account it's not showing up. How long do these transfers normally take for you? I want to be certain everything is all right.\", 'label': 'transfer_not_received_by_recipient', 'answer': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 3/2758 [00:00<08:20,  5.51it/s]2024-10-14T00:52:49.875654Z [error    ] Failed to run or to evaluate example Example({'text': 'A payment on my statement is wrong.', 'label': 'extra_charge_on_statement', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:52:50.045133Z [error    ] Failed to run or to evaluate example Example({'text': 'Why did using an ATM cause me to be charged an additional fee?', 'label': 'cash_withdrawal_charge', 'answer': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 5/2758 [00:00<06:01,  7.62it/s]2024-10-14T00:52:50.269940Z [error    ] Failed to run or to evaluate example Example({'text': 'Hi, I checked my transactions and saw that I was charged twice during a restaurant visit. I would like to get my money back.', 'label': 'transaction_charged_twice', 'answer': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 6/2758 [00:00<07:14,  6.34it/s]2024-10-14T00:52:50.438335Z [error    ] Failed to run or to evaluate example Example({'text': 'How long does it take to get a refund on something I bought?', 'label': 'request_refund', 'answer': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 7/2758 [00:01<07:20,  6.25it/s]2024-10-14T00:52:50.449569Z [error    ] Failed to run or to evaluate example Example({'text': \"I'm waiting on a top-up, its still pending\", 'label': 'pending_top_up', 'answer': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:52:50.718995Z [error    ] Failed to run or to evaluate example Example({'text': \"There is a top up that has been pending for an hour and I don't know why.  I was expecting it immediately and need it now!\", 'label': 'pending_top_up', 'answer': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 9/2758 [00:01<06:54,  6.63it/s]2024-10-14T00:52:50.882170Z [error    ] Failed to run or to evaluate example Example({'text': \"There was money taken out of my account, and I'm pretty sure I didn't do it.\", 'label': 'transaction_charged_twice', 'answer': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 10/2758 [00:01<07:02,  6.50it/s]2024-10-14T00:52:51.110959Z [error    ] Failed to run or to evaluate example Example({'text': 'Where is the card I ordered 2 weeks ago?', 'label': 'card_arrival', 'answer': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 11/2758 [00:01<07:56,  5.77it/s]2024-10-14T00:52:51.311214Z [error    ] Failed to run or to evaluate example Example({'text': \"I still haven't gotten my new card.  When will it get here?\", 'label': 'card_arrival', 'answer': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 13/2758 [00:02<09:38,  4.75it/s]2024-10-14T00:52:51.813691Z [error    ] Failed to run or to evaluate example Example({'text': \"Every ATM I visit is rejecting my card and I don't know why. There should be money on it. Can you check it to see if something is wrong or if I'm doing something wrong?\", 'label': 'declined_cash_withdrawal', 'answer': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 14/2758 [00:02<09:40,  4.73it/s]2024-10-14T00:52:51.976053Z [error    ] Failed to run or to evaluate example Example({'text': 'My card is showing a fee from when I used it, but I thought this card was supposed to be fee free?', 'label': 'card_payment_fee_charged', 'answer': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 15/2758 [00:02<09:01,  5.07it/s]2024-10-14T00:52:52.137507Z [error    ] Failed to run or to evaluate example Example({'text': \"The card payment didn't work\", 'label': 'declined_card_payment', 'answer': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 17/2758 [00:03<09:23,  4.87it/s]2024-10-14T00:52:52.561711Z [error    ] Failed to run or to evaluate example Example({'text': \"I requested a refund directly from the seller but I still don't have it. I just want you to send me my money back. I did what you said to do and I still don't have it.\", 'label': 'request_refund', 'answer': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 18/2758 [00:03<08:57,  5.10it/s]2024-10-14T00:52:52.726753Z [error    ] Failed to run or to evaluate example Example({'text': 'I see a fee that I think was charged because I paid by card.', 'label': 'card_payment_fee_charged', 'answer': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 19/2758 [00:03<08:32,  5.34it/s]2024-10-14T00:52:52.933470Z [error    ] Failed to run or to evaluate example Example({'text': \"Why isn't my balance updating?  I did a bank transfer and it isn't current.\", 'label': 'balance_not_updated_after_bank_transfer', 'answer': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 21/2758 [00:03<08:20,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 22 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:52:54.048176Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 46  (30.4):  15%|█▌        | 45/300 [00:01<00:06, 37.95it/s]2024-10-14T00:52:55.046017Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 51  (31.4):  17%|█▋        | 50/300 [00:01<00:06, 37.52it/s] 024-10-14T00:52:55.123586Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 20.0 / 73  (27.4):  24%|██▍       | 72/300 [00:02<00:06, 35.82it/s]2024-10-14T00:52:55.681069Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 126  (25.4):  42%|████▏     | 126/300 [00:03<00:03, 44.28it/s]2024-10-14T00:52:57.203060Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 136  (26.5):  45%|████▌     | 135/300 [00:03<00:03, 50.03it/s]=024-10-14T00:52:57.359610Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 41.0 / 153  (26.8):  51%|█████     | 152/300 [00:04<00:02, 57.14it/s]2024-10-14T00:52:57.736016Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 41.0 / 154  (26.6):  51%|█████▏    | 154/300 [00:04<00:03, 45.89it/s]error    4T00:52:57.742475Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 41.0 / 155  (26.5):  51%|█████▏    | 154/300 [00:04<00:03, 45.89it/s]2024-10-14T00:52:57.869699Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 226  (26.1):  75%|███████▌  | 225/300 [00:06<00:02, 33.86it/s]2024-10-14T00:52:59.637187Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 66.0 / 252  (26.2):  84%|████████▎ | 251/300 [00:06<00:01, 46.96it/s]2024-10-14T00:53:00.182526Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 83.0 / 300  (27.7): 100%|██████████| 300/300 [00:07<00:00, 41.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [3.33, 3.33, 25.33, 37.33, 27.67]\n",
      "Best score so far: 37.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2758 [00:00<?, ?it/s]2024-10-14T00:53:00.882898Z [error    ] Failed to run or to evaluate example Example({'text': \"I think something went wrong, I didn't get the right amount.\", 'label': 'wrong_amount_of_cash_received', 'answer': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 1/2758 [00:00<09:27,  4.86it/s]2024-10-14T00:53:01.042448Z [error    ] Failed to run or to evaluate example Example({'text': 'top up is still pending', 'label': 'pending_top_up', 'answer': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 3/2758 [00:00<08:24,  5.46it/s]2024-10-14T00:53:01.447713Z [error    ] Failed to run or to evaluate example Example({'text': \"Explain why my card payment wouldn't go through.\", 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 4/2758 [00:00<09:00,  5.10it/s]2024-10-14T00:53:01.606299Z [error    ] Failed to run or to evaluate example Example({'text': 'Why do I see extra charges for withdrawing my money?', 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 5/2758 [00:00<08:21,  5.49it/s]2024-10-14T00:53:01.797440Z [error    ] Failed to run or to evaluate example Example({'text': 'How come there is an extra fee on my statement?', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 6/2758 [00:01<08:31,  5.38it/s]2024-10-14T00:53:01.808839Z [error    ] Failed to run or to evaluate example Example({'text': \"I transferred 7,000 to a receiver outside the EU and they received a lesser amount than what I sent, Unfortunately, now I must send an additional transfer to the receiver so that they can receive the full amount I initially sent.  I'm not sure why they received a lesser amount than what I initially sen, but can you please look into this and let me know what happened?\", 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:53:01.818225Z [error    ] Failed to run or to evaluate example Example({'text': \"I've got a weird problem: I purchased something a week or maybe it was two weeks ago, and the funds have come back into my account! Can you explain this?\", 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:53:01.827325Z [error    ] Failed to run or to evaluate example Example({'text': 'I got cash abroad and need to check the exchange rate', 'label': 'wrong_exchange_rate_for_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:53:01.993013Z [error    ] Failed to run or to evaluate example Example({'text': 'Someone else charged my card!', 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 10/2758 [00:01<04:22, 10.49it/s]2024-10-14T00:53:02.252432Z [error    ] Failed to run or to evaluate example Example({'text': 'Why is my payment declined? It looked like everything worked ok and my account was fine.', 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 12/2758 [00:01<04:51,  9.41it/s]2024-10-14T00:53:02.430146Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was I charged twice for my item!', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 13/2758 [00:01<05:28,  8.36it/s]2024-10-14T00:53:02.639892Z [error    ] Failed to run or to evaluate example Example({'text': \"How long should it take for my top-up to finish? I've been waiting a while.\", 'label': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 14/2758 [00:01<06:20,  7.21it/s]2024-10-14T00:53:02.812970Z [error    ] Failed to run or to evaluate example Example({'text': \"I have a service fee that I've never seen before. It showed up after I bought something from an international seller online.\", 'label': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 15/2758 [00:02<06:41,  6.83it/s]2024-10-14T00:53:02.984617Z [error    ] Failed to run or to evaluate example Example({'text': \"I returned an item but don't see it on my account?\", 'label': 'refund_not_showing_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 16/2758 [00:02<06:58,  6.55it/s]2024-10-14T00:53:03.256127Z [error    ] Failed to run or to evaluate example Example({'text': 'how come when i asked for 100 it only gave me 20.00 in the app', 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 17/2758 [00:02<08:23,  5.44it/s]2024-10-14T00:53:03.443396Z [error    ] Failed to run or to evaluate example Example({'text': 'The ATM keeps declining my card! I tried two different ATMs already can you please check if everything is alright with my account??', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 19/2758 [00:02<08:32,  5.34it/s]2024-10-14T00:53:03.747610Z [error    ] Failed to run or to evaluate example Example({'text': \"I need some help figuring out what this strange payment is on my account. It's stays pending and won't go away.\", 'label': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 20/2758 [00:03<07:32,  6.06it/s]2024-10-14T00:53:03.910528Z [error    ] Failed to run or to evaluate example Example({'text': 'How long does a top-up take to go through?', 'label': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 21/2758 [00:03<07:30,  6.08it/s]2024-10-14T00:53:04.082597Z [error    ] Failed to run or to evaluate example Example({'text': 'What is the time for a transfer?', 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 22/2758 [00:03<07:36,  6.00it/s]2024-10-14T00:53:04.294227Z [error    ] Failed to run or to evaluate example Example({'text': 'My card payments have stopped.', 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 23/2758 [00:03<08:11,  5.56it/s]2024-10-14T00:53:04.452032Z [error    ] Failed to run or to evaluate example Example({'text': \"What happens when I money transaction doesn't show up on the receiving side?\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 25/2758 [00:04<10:33,  4.32it/s]2024-10-14T00:53:04.998913Z [error    ] Failed to run or to evaluate example Example({'text': 'Why did I get charged a fee for transferring money?', 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 26/2758 [00:04<09:49,  4.64it/s]2024-10-14T00:53:05.274804Z [error    ] Failed to run or to evaluate example Example({'text': \"How long do transfers take? I sent money to a friend who needs it urgently. It's been hours and has not gone through.\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 27/2758 [00:04<10:37,  4.28it/s]2024-10-14T00:53:05.437701Z [error    ] Failed to run or to evaluate example Example({'text': 'How long before transferred money shows up?', 'label': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 28/2758 [00:04<09:42,  4.69it/s]2024-10-14T00:53:05.677466Z [error    ] Failed to run or to evaluate example Example({'text': \"The day before yesterday, I performed a transfer within the country. It still has not completed. Can you check on that? The account number is definitely correct, as I've checked.\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 29/2758 [00:04<10:01,  4.54it/s]2024-10-14T00:53:05.852066Z [error    ] Failed to run or to evaluate example Example({'text': 'My statement indicates I made a payment to an unfamiliar merchant.', 'label': 'card_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 30/2758 [00:05<09:23,  4.84it/s]2024-10-14T00:53:06.033834Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was I charged this extra fee while doing a transfer?', 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 31/2758 [00:05<09:03,  5.02it/s]2024-10-14T00:53:06.192680Z [error    ] Failed to run or to evaluate example Example({'text': 'Why would my payment still show as pending?', 'label': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 33/2758 [00:05<08:30,  5.34it/s]2024-10-14T00:53:09.519345Z [error    ] Failed to run or to evaluate example Example({'text': 'when should I receive my refund', 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 35/2758 [00:08<37:26,  1.21it/s]2024-10-14T00:53:09.744395Z [error    ] Failed to run or to evaluate example Example({'text': 'To many charges on my card how do I go about fixing that?', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 36/2758 [00:09<30:40,  1.48it/s]2024-10-14T00:53:09.906378Z [error    ] Failed to run or to evaluate example Example({'text': 'There is a debit transaction on my statement that I did not make', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 37/2758 [00:09<24:36,  1.84it/s]2024-10-14T00:53:10.118509Z [error    ] Failed to run or to evaluate example Example({'text': \"I needed to make a payment on my account, but I typed in the incorrect number.  The app won't allow me to cancel this transaction.  I need it cancelled ASAP!!\", 'label': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 38/2758 [00:09<20:29,  2.21it/s]2024-10-14T00:53:10.340728Z [error    ] Failed to run or to evaluate example Example({'text': 'how long does it take to reflect in my balance a top up', 'label': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 39/2758 [00:09<17:33,  2.58it/s]2024-10-14T00:53:10.501708Z [error    ] Failed to run or to evaluate example Example({'text': 'The payment I made with my card is not showing up.', 'label': 'card_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 40/2758 [00:09<14:37,  3.10it/s]2024-10-14T00:53:10.675297Z [error    ] Failed to run or to evaluate example Example({'text': 'Can you explain the transfer fee that I was charged?', 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 41/2758 [00:09<12:39,  3.58it/s]2024-10-14T00:53:10.838899Z [error    ] Failed to run or to evaluate example Example({'text': 'On my last trip, I received the incorrect exchange rate.', 'label': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 42/2758 [00:10<11:07,  4.07it/s]2024-10-14T00:53:11.030013Z [error    ] Failed to run or to evaluate example Example({'text': 'I have an incorrect charge and would like a refund.', 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 43/2758 [00:10<10:24,  4.35it/s]2024-10-14T00:53:11.190725Z [error    ] Failed to run or to evaluate example Example({'text': 'I got money overseas and the exchange rate was wrong', 'label': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 44/2758 [00:10<09:28,  4.78it/s]2024-10-14T00:53:11.380517Z [error    ] Failed to run or to evaluate example Example({'text': \"I went to the store and tried to make a purchase.  The first time, it was declined, but the second one went through.  But my App shows me that I've already been charged once and the second charge is still pending.  Can you make sure that I'm not charged twice?\", 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 45/2758 [00:10<09:11,  4.92it/s]2024-10-14T00:53:11.571597Z [error    ] Failed to run or to evaluate example Example({'text': \"My payment has been declined!! What's going on, I thought everything was alright and working well?\", 'label': 'declined_card_payment', 'answer': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 47/2758 [00:11<10:00,  4.52it/s]2024-10-14T00:53:12.004723Z [error    ] Failed to run or to evaluate example Example({'text': \"My payment didn't work and the money is in back in my account.\", 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 48/2758 [00:11<09:11,  4.91it/s]2024-10-14T00:53:12.208184Z [error    ] Failed to run or to evaluate example Example({'text': 'How can I dispute a debit transaction?', 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 50/2758 [00:11<10:16,  4.40it/s]2024-10-14T00:53:12.657162Z [error    ] Failed to run or to evaluate example Example({'text': 'I have a charge I did not make.', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 51/2758 [00:11<09:25,  4.79it/s]2024-10-14T00:53:12.881164Z [error    ] Failed to run or to evaluate example Example({'text': 'There is a fraudulent payment!', 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 52/2758 [00:12<09:36,  4.69it/s]2024-10-14T00:53:13.078554Z [error    ] Failed to run or to evaluate example Example({'text': 'Can I get an item refunded?', 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 53/2758 [00:12<09:24,  4.79it/s]2024-10-14T00:53:13.255003Z [error    ] Failed to run or to evaluate example Example({'text': 'I see I was charged $1 for a transaction.', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 54/2758 [00:12<08:58,  5.02it/s]2024-10-14T00:53:13.266444Z [error    ] Failed to run or to evaluate example Example({'text': 'I transferred money from one account to another account and I charged a fee for it. Why is that?', 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:53:13.444441Z [error    ] Failed to run or to evaluate example Example({'text': 'Explain the extra fee on my card when paying.', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 56/2758 [00:12<06:47,  6.63it/s]2024-10-14T00:53:13.455511Z [error    ] Failed to run or to evaluate example Example({'text': 'I see a charge of 1L I do not recognize on my statement', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:53:13.617465Z [error    ] Failed to run or to evaluate example Example({'text': 'I was spending cash with my card and got a fee.', 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 58/2758 [00:12<05:37,  7.99it/s]2024-10-14T00:53:13.782964Z [error    ] Failed to run or to evaluate example Example({'text': 'what is going on with my cash withdrawal? the exchange rate is wrong', 'label': 'wrong_exchange_rate_for_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 59/2758 [00:13<06:02,  7.45it/s]2024-10-14T00:53:13.947095Z [error    ] Failed to run or to evaluate example Example({'text': 'I think I was charged twice, please help!', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 61/2758 [00:13<09:57,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 62 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:53:15.068431Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<02:52,  1.74it/s]2024-10-14T00:53:15.096975Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/300 [00:00<02:52,  1.74it/s]2024-10-14T00:53:15.119127Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 6  (50.0):   2%|▏         | 6/300 [00:00<00:26, 11.05it/s]lineno0-14T00:53:15.172253Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 23.0 / 61  (37.7):  20%|██        | 60/300 [00:02<00:05, 44.98it/s]2024-10-14T00:53:16.719999Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 62  (37.1):  20%|██        | 61/300 [00:02<00:05, 44.98it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 63  (36.5):  21%|██        | 62/300 [00:02<00:05, 44.98it/s]2024-10-14T00:53:16.729914Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 64  (35.9):  21%|██        | 63/300 [00:02<00:05, 44.98it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 86  (32.6):  28%|██▊       | 85/300 [00:02<00:05, 42.33it/s]2024-10-14T00:53:17.375239Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 115  (29.6):  38%|███▊      | 114/300 [00:03<00:04, 40.79it/s]2024-10-14T00:53:18.133879Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 123  (29.3):  41%|████      | 122/300 [00:03<00:05, 34.44it/s]dspy.evaluate.evaluate5398Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 125  (28.8):  41%|████▏     | 124/300 [00:03<00:05, 34.44it/s]error    4T00:53:18.329280Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 37.0 / 127  (29.1):  42%|████▏     | 127/300 [00:03<00:04, 38.93it/s]2024-10-14T00:53:18.420529Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 130  (29.2):  43%|████▎     | 129/300 [00:03<00:04, 38.93it/s]2024-10-14T00:53:18.497811Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 137  (29.2):  45%|████▌     | 136/300 [00:04<00:05, 29.17it/s]2024-10-14T00:53:18.811154Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 41.0 / 141  (29.1):  47%|████▋     | 140/300 [00:04<00:04, 32.55it/s]2024-10-14T00:53:18.993258Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 41.0 / 144  (28.5):  48%|████▊     | 143/300 [00:04<00:04, 32.55it/s]dspy.evaluate.evaluate example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 168  (26.2):  56%|█████▌    | 167/300 [00:05<00:04, 30.17it/s]=024-10-14T00:53:19.900731Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 56.0 / 202  (27.7):  67%|██████▋   | 201/300 [00:06<00:02, 43.56it/s] 024-10-14T00:53:20.703923Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 56.0 / 203  (27.6):  67%|██████▋   | 202/300 [00:06<00:02, 43.56it/s]2024-10-14T00:53:20.861905Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 211  (28.0):  70%|███████   | 210/300 [00:06<00:02, 36.28it/s] [24-10-14T00:53:20.986714Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 223  (27.8):  74%|███████▍  | 222/300 [00:06<00:02, 38.76it/s]2024-10-14T00:53:21.257749Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 69.0 / 244  (28.3):  81%|████████  | 243/300 [00:08<00:04, 13.43it/s]2024-10-14T00:53:22.742538Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 248  (28.6):  82%|████████▏ | 247/300 [00:08<00:02, 18.83it/s]=024-10-14T00:53:22.807685Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 79.0 / 275  (28.7):  91%|█████████▏| 274/300 [00:08<00:00, 33.36it/s]2024-10-14T00:53:22.986186Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 300  (28.7): 100%|██████████| 300/300 [00:08<00:00, 34.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [3.33, 3.33, 25.33, 37.33, 27.67, 28.67]\n",
      "Best score so far: 37.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2758 [00:00<?, ?it/s]2024-10-14T00:53:24.890197Z [error    ] Failed to run or to evaluate example Example({'text': 'How can I check on the status of my new card?', 'label': 'card_arrival', 'answer': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 1/2758 [00:01<1:12:22,  1.58s/it]2024-10-14T00:53:25.056505Z [error    ] Failed to run or to evaluate example Example({'text': \"Where are my funds? I topped off my car but it didn't seem to complete.\", 'label': 'pending_top_up', 'answer': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 2/2758 [00:01<34:16,  1.34it/s]  2024-10-14T00:53:25.238234Z [error    ] Failed to run or to evaluate example Example({'text': 'One of my charges was declined, but the second one went through.  But I notice on my App that one of them has gone through, and the other one is still pending.  Please ensure that only one charge is processed. Thanks', 'label': 'reverted_card_payment', 'answer': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 4/2758 [00:06<1:40:15,  2.18s/it]2024-10-14T00:53:30.197655Z [error    ] Failed to run or to evaluate example Example({'text': 'I bought something and received it, but the payment went back to my account. Is the seller okay?', 'label': 'reverted_card_payment', 'answer': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 5/2758 [00:06<1:06:58,  1.46s/it]2024-10-14T00:53:30.403753Z [error    ] Failed to run or to evaluate example Example({'text': \"I was charged extra or a hidden fee when I purchased something from you. What's the deal? I didn't authorize that charge.\", 'label': 'extra_charge_on_statement', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 7/2758 [00:07<36:45,  1.25it/s]  2024-10-14T00:53:30.935805Z [error    ] Failed to run or to evaluate example Example({'text': \"How long does it take for money to transfer as my balance hasn't been updated\", 'label': 'balance_not_updated_after_bank_transfer', 'answer': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 9/2758 [00:08<38:11,  1.20it/s]2024-10-14T00:53:32.416661Z [error    ] Failed to run or to evaluate example Example({'text': 'I thought transfers were free, why was I charged?', 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 10/2758 [00:09<28:40,  1.60it/s]2024-10-14T00:53:32.427715Z [error    ] Failed to run or to evaluate example Example({'text': 'tell me why I was charged more with my card?', 'label': 'extra_charge_on_statement', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:53:32.590305Z [error    ] Failed to run or to evaluate example Example({'text': 'The card payment I attempted to make failed.', 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 12/2758 [00:09<17:05,  2.68it/s]2024-10-14T00:53:32.755599Z [error    ] Failed to run or to evaluate example Example({'text': 'I think a fee was applied for paying with a card.', 'label': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 13/2758 [00:09<14:41,  3.11it/s]2024-10-14T00:53:32.985566Z [error    ] Failed to run or to evaluate example Example({'text': 'Machines make mistakes too! The ATM gave me the wrong amount of money. Too much!', 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 14/2758 [00:09<13:36,  3.36it/s]2024-10-14T00:53:33.200168Z [error    ] Failed to run or to evaluate example Example({'text': \"I needed cash from the ATM but I couldn't get it.\", 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 15/2758 [00:09<12:33,  3.64it/s]2024-10-14T00:53:33.404947Z [error    ] Failed to run or to evaluate example Example({'text': 'How long does a transfer from the UK account usually take? After completing the transfer it is not showing up. I need to know that everything I actually went okay.', 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 16/2758 [00:10<11:39,  3.92it/s]2024-10-14T00:53:33.416416Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was I charged this extra fee while doing a transfer?', 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:53:33.572966Z [error    ] Failed to run or to evaluate example Example({'text': 'I already got my item but just got my money back', 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 19/2758 [00:10<06:40,  6.84it/s]2024-10-14T00:53:33.734184Z [error    ] Failed to run or to evaluate example Example({'text': \"I'm using the app and I noticed a payment that I didn't make.\", 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 20/2758 [00:10<06:48,  6.70it/s]2024-10-14T00:53:33.919472Z [error    ] Failed to run or to evaluate example Example({'text': 'I am seeing in the App a payment that its not mine', 'label': 'card_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 22/2758 [00:13<40:32,  1.12it/s]2024-10-14T00:53:37.217050Z [error    ] Failed to run or to evaluate example Example({'text': 'I am seeing in the App a some cash withdrawal that does not belong to me', 'label': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 23/2758 [00:13<31:54,  1.43it/s]2024-10-14T00:53:37.396665Z [error    ] Failed to run or to evaluate example Example({'text': 'Unusual direct deposit', 'label': 'direct_debit_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 24/2758 [00:14<25:29,  1.79it/s]2024-10-14T00:53:37.562152Z [error    ] Failed to run or to evaluate example Example({'text': 'What is this strange payment in my account?', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 26/2758 [00:14<20:58,  2.17it/s]2024-10-14T00:53:38.212489Z [error    ] Failed to run or to evaluate example Example({'text': \"I see a payment on my statement for  a place I didn't make a purchase at.\", 'label': 'card_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 27/2758 [00:14<17:02,  2.67it/s]2024-10-14T00:53:38.369707Z [error    ] Failed to run or to evaluate example Example({'text': 'I could not get the cash I wanted', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 28/2758 [00:15<14:08,  3.22it/s]2024-10-14T00:53:38.481770Z [error    ] Failed to run or to evaluate example Example({'text': \"I thought I can make transfers for free, this is not fair. I bought something online from abroad and there was some weird additional fee that I've never seen before?\", 'label': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 29/2758 [00:15<11:28,  3.96it/s]2024-10-14T00:53:38.638575Z [error    ] Failed to run or to evaluate example Example({'text': 'I made a mistake and performed a transaction on the wrong account!', 'label': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 30/2758 [00:15<10:11,  4.46it/s]2024-10-14T00:53:38.791765Z [error    ] Failed to run or to evaluate example Example({'text': 'Is it possible to get a refund?', 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 31/2758 [00:15<09:14,  4.92it/s]2024-10-14T00:53:38.960692Z [error    ] Failed to run or to evaluate example Example({'text': \"My payment came back for something i'm trying to buy online? it's been doing it for two weeks.  do you know what the issue is?\", 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 33/2758 [00:15<09:02,  5.03it/s]2024-10-14T00:53:39.514929Z [error    ] Failed to run or to evaluate example Example({'text': 'I am having an issue with an in country transfer I did a few days ago. It has yet to appear in my account. I have checked to be sure that all account information is correct multiple times. What is taking the transfer so long?', 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 34/2758 [00:16<10:57,  4.15it/s]2024-10-14T00:53:39.724960Z [error    ] Failed to run or to evaluate example Example({'text': \"I'm really upset because I made a typo during a transfer and now I've sent money to the wrong account.  I can't fix this with the app.  Please help me immediately!\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 35/2758 [00:16<10:31,  4.31it/s]2024-10-14T00:53:39.872180Z [error    ] Failed to run or to evaluate example Example({'text': \"Help! I think someone has a copy of my card - I still have my card, but a five hundred pound cash withdrawal that I didn't authorize is shown on my account.\", 'label': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 36/2758 [00:16<09:22,  4.84it/s]2024-10-14T00:53:39.883932Z [error    ] Failed to run or to evaluate example Example({'text': 'Is my card lost? I am still waiting for it to be delivered.', 'label': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:53:40.062191Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was I charged twice for the same thing?', 'label': 'transaction_charged_twice', 'answer': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 38/2758 [00:16<07:01,  6.45it/s]2024-10-14T00:53:40.322583Z [error    ] Failed to run or to evaluate example Example({'text': 'What is the reason for my card payment to be reverted?', 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 40/2758 [00:17<12:09,  3.73it/s]2024-10-14T00:53:41.042269Z [error    ] Failed to run or to evaluate example Example({'text': \"I have been waiting for my top-up to complete and it still hasn't gone through.\", 'label': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 41/2758 [00:17<11:22,  3.98it/s]2024-10-14T00:53:41.265606Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was my cash withdrawal given the wrong exchange rate?', 'label': 'wrong_exchange_rate_for_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 42/2758 [00:17<11:01,  4.11it/s]2024-10-14T00:53:41.427471Z [error    ] Failed to run or to evaluate example Example({'text': \"My money hasn't been deposited yet. When will it be?\", 'label': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 43/2758 [00:18<09:57,  4.54it/s]2024-10-14T00:53:41.628404Z [error    ] Failed to run or to evaluate example Example({'text': 'I would like to cancel a transfer...is this possible?', 'label': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['label']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 44/2758 [00:18<09:43,  4.65it/s]2024-10-14T00:53:41.849692Z [error    ] Failed to run or to evaluate example Example({'text': \"I need to cancel my card.  There are a few charges from a couple days ago that I didn't make.  Can I get credit for these charges?\", 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 45/2758 [00:18<09:47,  4.62it/s]2024-10-14T00:53:41.960614Z [error    ] Failed to run or to evaluate example Example({'text': 'Hi, I am interested buying crypto currency but unable to purchase it through the application. I do want to do the exchange, Could you please let me know what is the problem?', 'label': 'beneficiary_not_allowed'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 46/2758 [00:18<08:22,  5.40it/s]2024-10-14T00:53:42.158901Z [error    ] Failed to run or to evaluate example Example({'text': 'I am still waiting on my card?', 'label': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 47/2758 [00:18<08:32,  5.29it/s]2024-10-14T00:53:42.405073Z [error    ] Failed to run or to evaluate example Example({'text': 'Why is my card payment cancelled?', 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 48/2758 [00:19<09:18,  4.86it/s]2024-10-14T00:53:42.567138Z [error    ] Failed to run or to evaluate example Example({'text': 'I received the wrong exchange rate for an item i bought.', 'label': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 51/2758 [00:19<12:26,  3.62it/s]2024-10-14T00:53:43.255404Z [error    ] Failed to run or to evaluate example Example({'text': 'Can you explain the transfer fee that I was charged?', 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:53:43.458155Z [error    ] Failed to run or to evaluate example Example({'text': 'Who do I call to cancel a transfer?', 'label': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 53/2758 [00:20<08:55,  5.05it/s]2024-10-14T00:53:43.647675Z [error    ] Failed to run or to evaluate example Example({'text': 'My card payment reverted back, I think.', 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 55/2758 [00:20<10:32,  4.27it/s]2024-10-14T00:53:44.153332Z [error    ] Failed to run or to evaluate example Example({'text': 'I have a payment in my statement that is off', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 56/2758 [00:20<09:40,  4.65it/s]2024-10-14T00:53:44.313026Z [error    ] Failed to run or to evaluate example Example({'text': 'When using my card I was charged a fee for doing so, why?', 'label': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 57/2758 [00:20<08:58,  5.01it/s]2024-10-14T00:53:44.474012Z [error    ] Failed to run or to evaluate example Example({'text': 'The exchange rate was different when I got cash', 'label': 'wrong_exchange_rate_for_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 59/2758 [00:21<09:36,  4.69it/s]2024-10-14T00:53:44.909237Z [error    ] Failed to run or to evaluate example Example({'text': \"I put cash in my account, but I don't see it.\", 'label': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 60/2758 [00:21<08:54,  5.05it/s]2024-10-14T00:53:45.070762Z [error    ] Failed to run or to evaluate example Example({'text': 'If the ATM only gave me 10 pounds instead of the 30 I requested, what do I do?', 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 61/2758 [00:21<08:24,  5.34it/s]2024-10-14T00:53:45.268427Z [error    ] Failed to run or to evaluate example Example({'text': 'wheres my money receipt', 'label': 'refund_not_showing_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 62/2758 [00:21<08:33,  5.25it/s]2024-10-14T00:53:45.434203Z [error    ] Failed to run or to evaluate example Example({'text': 'How can I investigate a missing refund?', 'label': 'refund_not_showing_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 63/2758 [00:22<08:13,  5.46it/s]2024-10-14T00:53:45.595362Z [error    ] Failed to run or to evaluate example Example({'text': \"I've already sent the money out and still have not received money in my account.\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 64/2758 [00:22<07:55,  5.67it/s]2024-10-14T00:53:45.704499Z [error    ] Failed to run or to evaluate example Example({'text': \"Why can't I see a transfer to my account?\", 'label': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 65/2758 [00:22<07:00,  6.40it/s]2024-10-14T00:53:45.887230Z [error    ] Failed to run or to evaluate example Example({'text': 'Why is my app showing me taking money that I did not take out?', 'label': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 66/2758 [00:22<07:22,  6.09it/s]2024-10-14T00:53:46.036917Z [error    ] Failed to run or to evaluate example Example({'text': 'I see cash in my app but I did not get it.', 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 68/2758 [00:22<07:35,  5.90it/s]2024-10-14T00:53:46.239876Z [error    ] Failed to run or to evaluate example Example({'text': 'why was my payment reverted on the app', 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:53:46.396955Z [error    ] Failed to run or to evaluate example Example({'text': 'I was charged twice.', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 71/2758 [00:23<07:59,  5.60it/s]2024-10-14T00:53:46.830221Z [error    ] Failed to run or to evaluate example Example({'text': \"Are you ripping people off with the exchange rate?  It can't be that atrocious between banks.\", 'label': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 72/2758 [00:23<07:09,  6.25it/s]2024-10-14T00:53:46.840822Z [error    ] Failed to run or to evaluate example Example({'text': \"I just realised I made the wrong payment yesterday. Can you please change it to the right account? It's my rent payment and really really needs to be in the right account by tomorrow\", 'label': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:53:47.009667Z [error    ] Failed to run or to evaluate example Example({'text': \"How long should a transfer normally take to process completely? I have a friend that needs it right away, but it's already been 2 hours and she hasn't received it.\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 75/2758 [00:24<07:41,  5.81it/s]2024-10-14T00:53:47.503162Z [error    ] Failed to run or to evaluate example Example({'text': \"Hi! A seller that I requested a refund from a long time ago has yet to send the money into my account, even though I keep checking it. Can the seller be contacted by you guys to see what's going on?\", 'label': 'refund_not_showing_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 76/2758 [00:24<07:49,  5.71it/s]2024-10-14T00:53:47.514088Z [error    ] Failed to run or to evaluate example Example({'text': 'I got less cash than what I specified at the ATM.', 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 78/2758 [00:24<14:01,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 79 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:53:48.649978Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<02:59,  1.67it/s]2024-10-14T00:53:48.678410Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/300 [00:00<02:59,  1.67it/s]2024-10-14T00:53:48.686111Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 2/300 [00:00<02:58,  1.67it/s]2024-10-14T00:53:48.703044Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 3/300 [00:00<02:58,  1.67it/s]2024-10-14T00:53:48.849872Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   2%|▏         | 5/300 [00:00<00:38,  7.60it/s]2024-10-14T00:53:48.876491Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   2%|▏         | 5/300 [00:00<00:38,  7.60it/s]2024-10-14T00:53:48.899458Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 13  (23.1):   4%|▍         | 12/300 [00:01<00:21, 13.11it/s]2024-10-14T00:53:49.118499Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 44  (22.7):  14%|█▍        | 43/300 [00:01<00:07, 34.39it/s]2024-10-14T00:53:49.814102Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 51  (21.6):  17%|█▋        | 50/300 [00:01<00:06, 36.29it/s]2024-10-14T00:53:50.029548Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 54  (20.4):  18%|█▊        | 53/300 [00:02<00:06, 36.29it/s]2024-10-14T00:53:50.131176Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 56  (19.6):  18%|█▊        | 55/300 [00:02<00:06, 35.81it/s]2024-10-14T00:53:50.203014Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 57  (19.3):  19%|█▊        | 56/300 [00:02<00:06, 35.81it/s]2024-10-14T00:53:50.233632Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 65  (18.5):  21%|██▏       | 64/300 [00:02<00:07, 32.07it/s]2024-10-14T00:53:50.452892Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 66  (18.2):  22%|██▏       | 65/300 [00:02<00:07, 32.07it/s]2024-10-14T00:53:50.472940Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 67  (17.9):  22%|██▏       | 66/300 [00:02<00:07, 32.07it/s]2024-10-14T00:53:50.491860Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 68  (17.6):  23%|██▎       | 68/300 [00:02<00:06, 35.76it/s]] 24-10-14T00:53:50.514792Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 78  (19.2):  26%|██▌       | 77/300 [00:02<00:06, 32.53it/s]lineno0-14T00:53:50.727545Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 15.0 / 86  (17.4):  28%|██▊       | 85/300 [00:02<00:06, 33.24it/s]=024-10-14T00:53:51.000843Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 15.0 / 90  (16.7):  30%|██▉       | 89/300 [00:03<00:06, 34.06it/s]error    4T00:53:51.099118Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 93  (16.1):  31%|███       | 92/300 [00:03<00:06, 34.06it/s] 024-10-14T00:53:51.120898Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 16.0 / 98  (16.3):  32%|███▏      | 97/300 [00:03<00:04, 44.42it/s]2024-10-14T00:53:51.208807Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 102  (15.7):  34%|███▍      | 102/300 [00:03<00:03, 49.66it/s]2024-10-14T00:53:51.316970Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 111  (16.2):  37%|███▋      | 110/300 [00:03<00:04, 40.24it/s]2024-10-14T00:53:51.593941Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 112  (16.1):  37%|███▋      | 111/300 [00:03<00:04, 40.24it/s]2024-10-14T00:53:51.598844Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 113  (15.9):  38%|███▊      | 113/300 [00:03<00:04, 41.63it/s]2024-10-14T00:53:51.606928Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 119  (16.0):  39%|███▉      | 118/300 [00:03<00:05, 33.61it/s]2024-10-14T00:53:51.931058Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 120  (15.8):  40%|███▉      | 119/300 [00:03<00:05, 33.61it/s]2024-10-14T00:53:51.936498Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 125  (15.2):  41%|████▏     | 124/300 [00:03<00:05, 33.41it/s]2024-10-14T00:53:52.026882Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 126  (15.1):  42%|████▏     | 125/300 [00:03<00:05, 33.41it/s]2024-10-14T00:53:52.143944Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 139  (15.8):  46%|████▌     | 138/300 [00:04<00:07, 21.09it/s] spy.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename=evaluate.pylineno=198\n",
      "Average Metric: 23.0 / 148  (15.5):  49%|████▉     | 147/300 [00:04<00:04, 35.53it/s] 024-10-14T00:53:52.893524Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 28.0 / 161  (17.4):  53%|█████▎    | 160/300 [00:05<00:03, 45.07it/s]2024-10-14T00:53:53.101488Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 165  (17.0):  55%|█████▍    | 164/300 [00:05<00:02, 50.41it/s]filenamer example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 30.0 / 175  (17.1):  58%|█████▊    | 174/300 [00:05<00:02, 57.37it/s] rror    4T00:53:53.287082Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 177  (17.5):  59%|█████▉    | 177/300 [00:05<00:02, 58.49it/s]2024-10-14T00:53:53.470665Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 178  (17.4):  59%|█████▉    | 177/300 [00:05<00:02, 58.49it/s]2024-10-14T00:53:53.514886Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 179  (17.3):  59%|█████▉    | 178/300 [00:05<00:02, 58.49it/s]2024-10-14T00:53:53.519214Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 180  (17.2):  60%|█████▉    | 179/300 [00:05<00:02, 58.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 181  (17.1):  60%|██████    | 180/300 [00:05<00:02, 58.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 184  (17.4):  61%|██████▏   | 184/300 [00:05<00:03, 33.60it/s]2024-10-14T00:53:53.756954Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 186  (17.2):  62%|██████▏   | 185/300 [00:05<00:03, 33.60it/s]2024-10-14T00:53:53.790808Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 197  (18.3):  65%|██████▌   | 196/300 [00:06<00:03, 30.08it/s]2024-10-14T00:53:54.153520Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 37.0 / 208  (17.8):  69%|██████▉   | 207/300 [00:06<00:02, 40.93it/s] 024-10-14T00:53:54.347941Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 41.0 / 225  (18.2):  75%|███████▌  | 225/300 [00:06<00:01, 37.51it/s]2024-10-14T00:53:54.848155Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 43.0 / 234  (18.4):  78%|███████▊  | 233/300 [00:06<00:01, 35.00it/s]2024-10-14T00:53:55.063843Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 237  (18.6):  79%|███████▊  | 236/300 [00:07<00:01, 32.66it/s]2024-10-14T00:53:55.231902Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 241  (19.1):  80%|████████  | 241/300 [00:07<00:01, 35.94it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 242  (19.0):  80%|████████  | 241/300 [00:07<00:01, 35.94it/s]2024-10-14T00:53:55.244487Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 244  (18.9):  81%|████████  | 243/300 [00:07<00:01, 35.94it/s]error    4T00:53:55.332240Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 300  (20.0): 100%|██████████| 300/300 [00:07<00:00, 37.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [3.33, 3.33, 25.33, 37.33, 27.67, 28.67, 20.0]\n",
      "Best score so far: 37.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2758 [00:00<15:22,  2.99it/s]2024-10-14T00:53:59.296324Z [error    ] Failed to run or to evaluate example Example({'text': 'Help me activate my card.', 'label': 'activate_my_card', 'answer': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 2/2758 [00:03<1:25:09,  1.85s/it]2024-10-14T00:53:59.474833Z [error    ] Failed to run or to evaluate example Example({'text': 'I have cash deposit to my account but it is experiencing a problem', 'label': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 4/2758 [00:03<33:59,  1.35it/s]  2024-10-14T00:53:59.849493Z [error    ] Failed to run or to evaluate example Example({'text': 'I transferred money but the balance did not update.', 'label': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 5/2758 [00:03<24:30,  1.87it/s]2024-10-14T00:54:00.071740Z [error    ] Failed to run or to evaluate example Example({'text': 'When will I get my new card?', 'label': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 6/2758 [00:04<19:37,  2.34it/s]2024-10-14T00:54:00.238442Z [error    ] Failed to run or to evaluate example Example({'text': \"I didn't receive the correct exchange rate when I got cash.\", 'label': 'wrong_exchange_rate_for_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 7/2758 [00:04<15:41,  2.92it/s]2024-10-14T00:54:00.429419Z [error    ] Failed to run or to evaluate example Example({'text': \"I've changed my mind on an item.  How do I get a refund?\", 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 8/2758 [00:04<13:29,  3.40it/s]2024-10-14T00:54:00.699602Z [error    ] Failed to run or to evaluate example Example({'text': \"Hey there's a fee for a transfer on my account.  Why?!\", 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 10/2758 [00:04<22:38,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:54:01.788666Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<02:24,  2.07it/s]2024-10-14T00:54:01.812677Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 93  (34.4):  31%|███       | 92/300 [00:02<00:06, 31.96it/s]lineno0-14T00:54:04.244906Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 41.0 / 123  (33.3):  41%|████      | 122/300 [00:03<00:04, 40.80it/s]2024-10-14T00:54:05.074172Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 41.0 / 131  (31.3):  43%|████▎     | 130/300 [00:03<00:04, 35.26it/s]2024-10-14T00:54:05.288921Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 41.0 / 132  (31.1):  44%|████▎     | 131/300 [00:03<00:04, 35.26it/s]2024-10-14T00:54:05.308274Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 135  (31.1):  45%|████▍     | 134/300 [00:04<00:04, 35.26it/s]2024-10-14T00:54:05.372157Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 219  (32.4):  73%|███████▎  | 218/300 [00:06<00:01, 48.31it/s] 024-10-14T00:54:07.517434Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 84.0 / 267  (31.5):  89%|████████▊ | 266/300 [00:07<00:00, 56.90it/s]2024-10-14T00:54:08.763401Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 98.0 / 300  (32.7): 100%|██████████| 300/300 [00:07<00:00, 38.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [3.33, 3.33, 25.33, 37.33, 27.67, 28.67, 20.0, 32.67]\n",
      "Best score so far: 37.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/2758 [00:00<11:08,  4.12it/s]2024-10-14T00:54:09.554357Z [error    ] Failed to run or to evaluate example Example({'text': 'I made a mistake and need to cancel a transfer.', 'label': 'cancel_transfer', 'answer': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 2/2758 [00:00<08:55,  5.15it/s]2024-10-14T00:54:09.666117Z [error    ] Failed to run or to evaluate example Example({'text': 'Why cant I transfer to my account?', 'label': 'transfer_not_received_by_recipient', 'answer': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 3/2758 [00:00<07:10,  6.41it/s]2024-10-14T00:54:09.857324Z [error    ] Failed to run or to evaluate example Example({'text': \"I just initiated a transfer but I'd like to cancel it.\", 'label': 'cancel_transfer', 'answer': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 4/2758 [00:00<07:49,  5.87it/s]2024-10-14T00:54:09.868363Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was I charged twice for the same thing?', 'label': 'transaction_charged_twice', 'answer': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:54:10.073257Z [error    ] Failed to run or to evaluate example Example({'text': 'Why are my withdrawals suddenly being declined?', 'label': 'declined_cash_withdrawal', 'answer': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 6/2758 [00:00<06:17,  7.28it/s]2024-10-14T00:54:10.245994Z [error    ] Failed to run or to evaluate example Example({'text': \"Why didn't I receive the correct exchange rate for an item that I purchased?\", 'label': 'card_payment_wrong_exchange_rate', 'answer': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 7/2758 [00:01<06:44,  6.81it/s]2024-10-14T00:54:10.256846Z [error    ] Failed to run or to evaluate example Example({'text': \"My payment has been declined!! What's going on, I thought everything was alright and working well?\", 'label': 'declined_card_payment', 'answer': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:54:10.419251Z [error    ] Failed to run or to evaluate example Example({'text': 'Why was I charged extra when transferring?', 'label': 'transfer_fee_charged', 'answer': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 9/2758 [00:01<05:30,  8.31it/s]2024-10-14T00:54:10.584148Z [error    ] Failed to run or to evaluate example Example({'text': 'How long does it take to show a deposit I made to my balance?', 'label': 'balance_not_updated_after_cheque_or_cash_deposit', 'answer': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 10/2758 [00:01<05:59,  7.63it/s]2024-10-14T00:54:10.805385Z [error    ] Failed to run or to evaluate example Example({'text': 'Why is a payment I made reverted back to my account?', 'label': 'reverted_card_payment', 'answer': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  0%|          | 13/2758 [00:02<11:07,  4.11it/s]2024-10-14T00:54:11.638282Z [error    ] Failed to run or to evaluate example Example({'text': 'I recently deposited a cheque and cannot find the cash from it.', 'label': 'balance_not_updated_after_cheque_or_cash_deposit', 'answer': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 14/2758 [00:02<10:06,  4.52it/s]2024-10-14T00:54:11.803549Z [error    ] Failed to run or to evaluate example Example({'text': 'I have an unusual payment in my statement', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 15/2758 [00:02<09:22,  4.88it/s]2024-10-14T00:54:11.919118Z [error    ] Failed to run or to evaluate example Example({'text': 'When can I expect my refund?', 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 16/2758 [00:02<08:10,  5.59it/s]2024-10-14T00:54:12.086281Z [error    ] Failed to run or to evaluate example Example({'text': 'I have been double charged for a couple of things this week, and would appreciate a refund for the duplicate charges.', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 17/2758 [00:02<08:00,  5.70it/s]2024-10-14T00:54:12.251469Z [error    ] Failed to run or to evaluate example Example({'text': 'I transferred some cash and it has not arrived yet.', 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 18/2758 [00:03<07:52,  5.80it/s]2024-10-14T00:54:12.434371Z [error    ] Failed to run or to evaluate example Example({'text': \"There's something wrong on my bill. A transfer fee should never have been added.\", 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 20/2758 [00:03<09:01,  5.06it/s]2024-10-14T00:54:12.694893Z [error    ] Failed to run or to evaluate example Example({'text': \"Is there a place to check for fee for payments? I feel like I'm getting charged too much at times.\", 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['label']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 23/2758 [00:08<45:37,  1.00s/it]2024-10-14T00:54:17.859641Z [error    ] Failed to run or to evaluate example Example({'text': 'Can you check the exchange rate on a cash transaction I did overseas', 'label': 'wrong_exchange_rate_for_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:54:18.056833Z [error    ] Failed to run or to evaluate example Example({'text': \"I've tried several times to make a payment and every time my card is declined? Could my card be locked? I don't know what to do.\", 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 25/2758 [00:08<28:41,  1.59it/s]2024-10-14T00:54:18.260786Z [error    ] Failed to run or to evaluate example Example({'text': \"During the last month I used this account to make payments for my place abroad. I noticed the fees have increased and I wonder why. Shouldn't frequent users have less fees as incentive to keep using instead of increasing them out of nowhere?\", 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 27/2758 [00:09<21:52,  2.08it/s]2024-10-14T00:54:18.742487Z [error    ] Failed to run or to evaluate example Example({'text': 'The exchange rate is incorrect for something I bought', 'label': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 28/2758 [00:09<18:04,  2.52it/s]2024-10-14T00:54:18.953660Z [error    ] Failed to run or to evaluate example Example({'text': 'I would like to track the card you sent to me.', 'label': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 29/2758 [00:09<15:47,  2.88it/s]2024-10-14T00:54:19.178652Z [error    ] Failed to run or to evaluate example Example({'text': \"Why couldn't I get cash from an ATM?\", 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 30/2758 [00:10<14:13,  3.20it/s]2024-10-14T00:54:19.337493Z [error    ] Failed to run or to evaluate example Example({'text': 'There is a strange charge on my debit statement', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 31/2758 [00:10<12:14,  3.71it/s]2024-10-14T00:54:19.546271Z [error    ] Failed to run or to evaluate example Example({'text': \"I attempted to deposit a cheque yesterday but the balance isn't showing today. Is it still pending?\", 'label': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 32/2758 [00:10<11:25,  3.98it/s]2024-10-14T00:54:19.744654Z [error    ] Failed to run or to evaluate example Example({'text': 'Why has my card payment not yet been applied to my account?', 'label': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|          | 33/2758 [00:10<10:42,  4.24it/s]2024-10-14T00:54:21.419456Z [error    ] Failed to run or to evaluate example Example({'text': 'I see an unauthorized withdraw.', 'label': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 35/2758 [00:12<24:10,  1.88it/s]2024-10-14T00:54:21.810724Z [error    ] Failed to run or to evaluate example Example({'text': 'Where did the  €1 fee in my statement come from', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 36/2758 [00:12<19:09,  2.37it/s]2024-10-14T00:54:21.821653Z [error    ] Failed to run or to evaluate example Example({'text': \"I have been waiting for my top-up to complete and it still hasn't gone through.\", 'label': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 38/2758 [00:13<17:48,  2.54it/s]2024-10-14T00:54:22.539797Z [error    ] Failed to run or to evaluate example Example({'text': 'hey, I think someone stole my card numbers. There is a purchase showing up on my app from a store pretty far away from me.. I really need that money back to pay my rent.', 'label': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:54:22.652025Z [error    ] Failed to run or to evaluate example Example({'text': 'Hi, I am unable to use my card in ATM. I had tried my card in two ATMs but both ATMs declined it. Could you please check my account?', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 41/2758 [00:13<13:11,  3.43it/s]2024-10-14T00:54:23.236571Z [error    ] Failed to run or to evaluate example Example({'text': \"I'm trying to make a payment to my new landlord. Even though the payment was sent a few days ago, it isn't clearing on their side. Can you verify that payment has been made?\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 43/2758 [00:14<11:40,  3.88it/s]2024-10-14T00:54:23.479515Z [error    ] Failed to run or to evaluate example Example({'text': \"Hey there's a fee for a transfer on my account.  Why?!\", 'label': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:54:23.586744Z [error    ] Failed to run or to evaluate example Example({'text': 'My top up keeps showing pending?  How long will things be like this?  Days, weeks, months?  I need the money quite urgently for an important coffee purchase, can you please let me know when top up will work?', 'label': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 45/2758 [00:14<07:52,  5.74it/s]2024-10-14T00:54:23.814602Z [error    ] Failed to run or to evaluate example Example({'text': 'What do I need to do for a refund?', 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 46/2758 [00:14<08:25,  5.36it/s]2024-10-14T00:54:23.975065Z [error    ] Failed to run or to evaluate example Example({'text': \"What is this cash withdrawal I don't recognize?\", 'label': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 47/2758 [00:14<08:08,  5.55it/s]2024-10-14T00:54:24.150541Z [error    ] Failed to run or to evaluate example Example({'text': 'Is there a problem with my account? When I tried to withdraw cash at an ATM I was denied.', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 48/2758 [00:14<08:04,  5.59it/s]2024-10-14T00:54:24.347394Z [error    ] Failed to run or to evaluate example Example({'text': 'I got the incorrect amount of money given to me from my account', 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 50/2758 [00:15<08:28,  5.33it/s]2024-10-14T00:54:24.653968Z [error    ] Failed to run or to evaluate example Example({'text': 'I was under the impression ATM cash withdrawals were free. Why was I suddenly charged for my most recent ATM transaction?', 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 51/2758 [00:15<07:26,  6.06it/s]2024-10-14T00:54:24.808360Z [error    ] Failed to run or to evaluate example Example({'text': 'The exchange rate for case abroad is applied wrong.', 'label': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 52/2758 [00:15<07:18,  6.17it/s]2024-10-14T00:54:24.917983Z [error    ] Failed to run or to evaluate example Example({'text': \"I made a transfer and the person I transferred the money to didn't receive the right amount? Why did this happen and how do I get the rest of the money to them?\", 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 53/2758 [00:15<06:36,  6.82it/s]2024-10-14T00:54:25.025640Z [error    ] Failed to run or to evaluate example Example({'text': \"Where can I find out the fee structure for my account? I have been charged fees for some transactions, but not for other ones. I can't find a pattern in these fees.\", 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 54/2758 [00:15<06:05,  7.41it/s]2024-10-14T00:54:25.230613Z [error    ] Failed to run or to evaluate example Example({'text': 'Could you please help me?  I made my rent payment and have double checked that I sent it to the right account.  The person receiving it says he has not received it but it shows complete on my side.', 'label': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 55/2758 [00:16<07:01,  6.41it/s]2024-10-14T00:54:25.337757Z [error    ] Failed to run or to evaluate example Example({'text': 'Why is my card being declined at the ATM? I have tried multiple ATMs and i keep running into the same problem. Could you verify that everything is okay with my account?', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 56/2758 [00:16<06:22,  7.06it/s]2024-10-14T00:54:25.348813Z [error    ] Failed to run or to evaluate example Example({'text': 'I was charged twice for a restaurant, can you take the second charge off?', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:54:25.488569Z [error    ] Failed to run or to evaluate example Example({'text': 'Give me a refund', 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 58/2758 [00:16<05:00,  8.99it/s]2024-10-14T00:54:25.645062Z [error    ] Failed to run or to evaluate example Example({'text': 'What do I do if my top-up has not gone through?', 'label': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 60/2758 [00:16<08:27,  5.32it/s]2024-10-14T00:54:26.178871Z [error    ] Failed to run or to evaluate example Example({'text': 'I made a purchase and was charged at the wrong foreign exchange rate.', 'label': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 61/2758 [00:17<08:06,  5.55it/s]2024-10-14T00:54:26.364364Z [error    ] Failed to run or to evaluate example Example({'text': 'I just had my card get declined at the ATM! I need to get money out but I am unable to.  Why has this happened?', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 62/2758 [00:17<08:10,  5.50it/s]2024-10-14T00:54:26.537774Z [error    ] Failed to run or to evaluate example Example({'text': 'Would you please check my Card. As Withdrawal was working fine so far, but this morning suddenly got declined. Can you please check the problem?', 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 63/2758 [00:17<08:03,  5.58it/s]2024-10-14T00:54:26.760476Z [error    ] Failed to run or to evaluate example Example({'text': \"Why wouldn't my withdrawal go through?\", 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 64/2758 [00:17<08:37,  5.21it/s]2024-10-14T00:54:26.936542Z [error    ] Failed to run or to evaluate example Example({'text': 'How can I verify if a cash withdrawal was made from my account? I still have my card with me but I did not authorize the withdrawal that just occurred.', 'label': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 65/2758 [00:17<08:24,  5.34it/s]2024-10-14T00:54:27.134618Z [error    ] Failed to run or to evaluate example Example({'text': \"I'm going to cancel a purchase.\", 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 66/2758 [00:17<08:32,  5.26it/s]2024-10-14T00:54:27.531687Z [error    ] Failed to run or to evaluate example Example({'text': \"Hey, I got charged extra for some reason when I purchased an app. Is this a hidden fee or something? I don't think it's very cool.\", 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 67/2758 [00:18<11:17,  3.97it/s]2024-10-14T00:54:27.696023Z [error    ] Failed to run or to evaluate example Example({'text': 'The ATM did not give me as much cash as I requested.', 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 68/2758 [00:18<10:07,  4.43it/s]2024-10-14T00:54:27.804981Z [error    ] Failed to run or to evaluate example Example({'text': \"I tried to get money out of the Notting Hill ATM earlier, but wasn't able to. Is my card working okay? It's the first time I tried using it.\", 'label': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 70/2758 [00:23<1:10:03,  1.56s/it]2024-10-14T00:54:32.755356Z [error    ] Failed to run or to evaluate example Example({'text': 'Who do I call to activate my new card?', 'label': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 71/2758 [00:23<51:17,  1.15s/it]  2024-10-14T00:54:32.961461Z [error    ] Failed to run or to evaluate example Example({'text': \"How do I dispute a direct debit that I didn't do?\", 'label': 'direct_debit_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 72/2758 [00:23<38:40,  1.16it/s]2024-10-14T00:54:33.149689Z [error    ] Failed to run or to evaluate example Example({'text': 'my payment was rejected, do you know why?', 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 73/2758 [00:23<29:36,  1.51it/s]2024-10-14T00:54:33.310442Z [error    ] Failed to run or to evaluate example Example({'text': 'I was charged a fee for withdrawing cash.', 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 75/2758 [00:24<18:51,  2.37it/s]2024-10-14T00:54:33.711574Z [error    ] Failed to run or to evaluate example Example({'text': \"help, I see money missing I didn't take out.\", 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 76/2758 [00:24<15:43,  2.84it/s]2024-10-14T00:54:33.869999Z [error    ] Failed to run or to evaluate example Example({'text': 'Is it possible to use an ATM when I am not in the country and make a withdraw with out extra fees?', 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 78/2758 [00:25<12:58,  3.44it/s]2024-10-14T00:54:34.355441Z [error    ] Failed to run or to evaluate example Example({'text': \"Is there an issue with my account?  I don't see a cheque deposit that I made yesterday.  Please assist.\", 'label': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 79/2758 [00:25<11:47,  3.79it/s]2024-10-14T00:54:34.648189Z [error    ] Failed to run or to evaluate example Example({'text': \"I'm still waiting for my card that was issued a week ago. What should I do?\", 'label': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 81/2758 [00:25<11:18,  3.95it/s]2024-10-14T00:54:34.867626Z [error    ] Failed to run or to evaluate example Example({'text': 'The card payment I attempted to make failed.', 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:54:35.042530Z [error    ] Failed to run or to evaluate example Example({'text': 'Hello, in these holidays i have been overcharged on the amount i have withdrawn on one of your ATMs. I did not had any clue about the horrible charges otherwise i would not have withdrawn.', 'label': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 83/2758 [00:25<07:59,  5.58it/s]2024-10-14T00:54:35.205282Z [error    ] Failed to run or to evaluate example Example({'text': 'I hate this ATM, it charged me an extra fee, Why did it charge?', 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 84/2758 [00:26<07:48,  5.71it/s]2024-10-14T00:54:35.364399Z [error    ] Failed to run or to evaluate example Example({'text': 'I paid with my card so so why was I charged a transaction fee?', 'label': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 87/2758 [00:31<1:06:36,  1.50s/it]2024-10-14T00:54:40.709935Z [error    ] Failed to run or to evaluate example Example({'text': 'How long do I have to wait for my bank transfer to appear in my account?', 'label': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 91/2758 [00:31<24:01,  1.85it/s]  2024-10-14T00:54:41.021967Z [error    ] Failed to run or to evaluate example Example({'text': \"Help!  The app has an ATM withdrawl that I didn't make.\", 'label': 'declined_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 92/2758 [00:31<20:20,  2.18it/s]2024-10-14T00:54:41.209020Z [error    ] Failed to run or to evaluate example Example({'text': 'I am waiting on the refund', 'label': 'refund_not_showing_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 93/2758 [00:32<17:34,  2.53it/s]2024-10-14T00:54:41.413484Z [error    ] Failed to run or to evaluate example Example({'text': \"The app is showing a cash withdrawal that I didn't make.\", 'label': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 94/2758 [00:32<15:29,  2.87it/s]2024-10-14T00:54:41.616774Z [error    ] Failed to run or to evaluate example Example({'text': \"Is my card actually working? It's the first time I tried using it\", 'label': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 95/2758 [00:32<13:48,  3.21it/s]2024-10-14T00:54:41.780170Z [error    ] Failed to run or to evaluate example Example({'text': \"I don't know where this debit transaction on my statement came from.\", 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 96/2758 [00:32<12:00,  3.69it/s]2024-10-14T00:54:41.888556Z [error    ] Failed to run or to evaluate example Example({'text': \"It's been some time ago that I placed an order and it just isn't coming. At this point just give me back my money because I'm not paying them.\", 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▎         | 97/2758 [00:32<09:59,  4.44it/s]2024-10-14T00:54:42.057457Z [error    ] Failed to run or to evaluate example Example({'text': 'Why would my payment for my card show as pending?', 'label': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▎         | 98/2758 [00:32<09:16,  4.78it/s]2024-10-14T00:54:42.218709Z [error    ] Failed to run or to evaluate example Example({'text': \"I deposited a check yesterday to up my account balance, but that deposit hasn't shown up yet.  It's been a day already!\", 'label': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▎         | 99/2758 [00:33<08:39,  5.12it/s]2024-10-14T00:54:42.228910Z [error    ] Failed to run or to evaluate example Example({'text': 'Can you please refund my item?', 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:54:42.238011Z [error    ] Failed to run or to evaluate example Example({'text': 'Why am I being declined?', 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:54:42.440925Z [error    ] Failed to run or to evaluate example Example({'text': \"I made a cash deposit a few days ago and it's still not reflected in my account. Do you know what might have happened?\", 'label': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▎         | 102/2758 [00:33<05:40,  7.80it/s]2024-10-14T00:54:42.602690Z [error    ] Failed to run or to evaluate example Example({'text': 'I have been charged for one thing two times.', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▎         | 103/2758 [00:33<05:58,  7.40it/s]2024-10-14T00:54:42.779944Z [error    ] Failed to run or to evaluate example Example({'text': \"I've been charged an extra £1 and I don't know what it's for\", 'label': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 104/2758 [00:33<06:24,  6.91it/s]2024-10-14T00:54:42.791046Z [error    ] Failed to run or to evaluate example Example({'text': 'I was charged twice.', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:54:42.898322Z [error    ] Failed to run or to evaluate example Example({'text': 'There is a payment with my card which i definitely did not make by me .Never seen that it before.', 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 106/2758 [00:33<04:54,  9.01it/s]2024-10-14T00:54:43.058954Z [error    ] Failed to run or to evaluate example Example({'text': \"The ATM shows a withdraw of the amount of money I requested but I didn't revieve that amount in cash.\", 'label': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-14T00:54:43.236741Z [error    ] Failed to run or to evaluate example Example({'text': 'In reviewing my statement, I show I have two charges for the same purchase at the same time, which I have not made in duplicate? How do I get this solved?', 'label': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 108/2758 [00:34<05:50,  7.57it/s]2024-10-14T00:54:43.414984Z [error    ] Failed to run or to evaluate example Example({'text': 'I was using a foreign currecy to make a payment and the applied the wrong rate.', 'label': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 110/2758 [00:34<08:23,  5.26it/s]2024-10-14T00:54:43.989153Z [error    ] Failed to run or to evaluate example Example({'text': \"Hey, I ordered a thing but changed my mind and want a refund on it. Since I haven't received the thing, would you just go ahead and cancel the payment for me?\", 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 111/2758 [00:34<08:41,  5.07it/s]2024-10-14T00:54:44.098376Z [error    ] Failed to run or to evaluate example Example({'text': 'Hello, I believe there has been a mistake made on the exchange rate for my card. Could you please check the official interbank exchange rate for me?', 'label': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 113/2758 [00:35<08:04,  5.46it/s]2024-10-14T00:54:44.465501Z [error    ] Failed to run or to evaluate example Example({'text': \"Some cash withdrawal that I didn't make showed up in the app.\", 'label': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 114/2758 [00:35<07:47,  5.66it/s]2024-10-14T00:54:44.627184Z [error    ] Failed to run or to evaluate example Example({'text': 'I want to be sure that everything is okay here. I just made a transfer from a UK account and it is still not showing up. How long does this typically take?', 'label': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 115/2758 [00:35<07:36,  5.79it/s]2024-10-14T00:54:44.825514Z [error    ] Failed to run or to evaluate example Example({'text': \"I was under the impression that transfers were going to be free and here I was charged for something I bought overseas!  I don't think this fee is right\", 'label': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 116/2758 [00:35<07:55,  5.56it/s]2024-10-14T00:54:44.935518Z [error    ] Failed to run or to evaluate example Example({'text': 'I am not able to purchase anything online! I have been using my card on multiple sites over a period of two weeks and none of the payments have gone through. Why is this happening?', 'label': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 118/2758 [00:36<09:01,  4.87it/s]2024-10-14T00:54:45.360414Z [error    ] Failed to run or to evaluate example Example({'text': \"Give me back my money, I'm not paying the sellers. It has been a long time ago that I made an order and it just isn't coming.\", 'label': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 119/2758 [00:36<07:47,  5.65it/s]2024-10-14T00:54:45.567250Z [error    ] Failed to run or to evaluate example Example({'text': \"I really was trying to complete this exhange. I was trying to purchase some crypto but the app won't allow me to do it. Can you tell me what's going on here?\", 'label': 'beneficiary_not_allowed'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 120/2758 [00:36<08:10,  5.38it/s]2024-10-14T00:54:45.789133Z [error    ] Failed to run or to evaluate example Example({'text': \"Why can't a beneficiary receive a money transfer from me?\", 'label': 'beneficiary_not_allowed'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7afe8aba9160> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 122/2758 [00:36<13:11,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 123 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-14T00:54:46.796258Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<03:00,  1.66it/s]2024-10-14T00:54:46.824811Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 50  (40.0):  16%|█▋        | 49/300 [00:02<00:08, 28.75it/s]2024-10-14T00:54:48.380367Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 98  (32.7):  32%|███▏      | 97/300 [00:03<00:05, 39.76it/s]2024-10-14T00:54:49.835114Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 45.0 / 150  (30.0):  50%|█████     | 150/300 [00:05<00:03, 39.34it/s]2024-10-14T00:54:51.473658Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 45.0 / 151  (29.8):  50%|█████     | 150/300 [00:05<00:03, 39.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 45.0 / 153  (29.4):  51%|█████     | 152/300 [00:05<00:03, 39.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 201  (30.8):  67%|██████▋   | 200/300 [00:06<00:02, 45.90it/s]2024-10-14T00:54:52.934275Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 240  (33.3):  80%|███████▉  | 239/300 [00:07<00:01, 31.82it/s] 024-10-14T00:54:54.071281Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 81.0 / 247  (32.8):  82%|████████▏ | 246/300 [00:08<00:01, 37.88it/s]2024-10-14T00:54:54.363221Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 100.0 / 300  (33.3): 100%|██████████| 300/300 [00:08<00:00, 34.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [3.33, 3.33, 25.33, 37.33, 27.67, 28.67, 20.0, 32.67, 33.33]\n",
      "Best score so far: 37.33\n",
      "9 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]2024-10-14T00:54:55.941105Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/1000 [00:00<08:44,  1.90it/s]2024-10-14T00:54:56.068286Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 2/1000 [00:00<04:53,  3.40it/s]2024-10-14T00:54:56.097036Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   0%|          | 2/1000 [00:00<04:53,  3.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 45  (33.3):   4%|▍         | 44/1000 [00:01<00:21, 44.99it/s]2024-10-14T00:54:57.262957Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 52  (28.8):   5%|▌         | 51/1000 [00:02<00:20, 46.39it/s]2024-10-14T00:54:57.546032Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 55  (27.3):   5%|▌         | 54/1000 [00:02<00:23, 39.77it/s]2024-10-14T00:54:57.719918Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 49.0 / 140  (35.0):  14%|█▍        | 139/1000 [00:05<00:25, 33.13it/s]evaluate.py00:55:00.394637Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 57.0 / 155  (36.8):  15%|█▌        | 154/1000 [00:05<00:27, 31.22it/s] 024-10-14T00:55:00.857605Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 60.0 / 166  (36.1):  16%|█▋        | 165/1000 [00:05<00:23, 36.26it/s]filename14T00:55:01.169239Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 167  (35.9):  17%|█▋        | 166/1000 [00:05<00:23, 36.26it/s]2024-10-14T00:55:01.310466Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 179  (35.8):  18%|█▊        | 178/1000 [00:06<00:21, 38.43it/s]=024-10-14T00:55:01.592403Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 64.0 / 182  (35.2):  18%|█▊        | 181/1000 [00:06<00:25, 31.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 185  (35.1):  18%|█▊        | 184/1000 [00:06<00:25, 31.90it/s]2024-10-14T00:55:01.708182Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 84.0 / 247  (34.0):  25%|██▍       | 246/1000 [00:08<00:21, 35.68it/s]2024-10-14T00:55:03.950380Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 253  (34.0):  25%|██▌       | 252/1000 [00:08<00:26, 27.85it/s]2024-10-14T00:55:04.155195Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 99.0 / 291  (34.0):  29%|██▉       | 290/1000 [00:09<00:19, 37.13it/s]2024-10-14T00:55:05.105158Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 99.0 / 292  (33.9):  29%|██▉       | 291/1000 [00:09<00:19, 37.13it/s]2024-10-14T00:55:05.255967Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 131.0 / 378  (34.7):  38%|███▊      | 377/1000 [00:12<00:20, 30.45it/s]evaluate.pyte.evaluate3865Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename= lineno=198\n",
      "Average Metric: 150.0 / 438  (34.2):  44%|████▎     | 437/1000 [00:14<00:11, 49.01it/s]2024-10-14T00:55:09.469834Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 164.0 / 476  (34.5):  48%|████▊     | 475/1000 [00:15<00:12, 41.68it/s]2024-10-14T00:55:10.542925Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 166.0 / 481  (34.5):  48%|████▊     | 480/1000 [00:15<00:13, 38.16it/s]2024-10-14T00:55:10.820066Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 178.0 / 504  (35.3):  50%|█████     | 503/1000 [00:16<00:15, 31.20it/s]2024-10-14T00:55:11.477016Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 185.0 / 532  (34.8):  53%|█████▎    | 531/1000 [00:16<00:14, 33.40it/s]2024-10-14T00:55:12.239501Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 194.0 / 556  (34.9):  56%|█████▌    | 555/1000 [00:17<00:12, 34.81it/s]2024-10-14T00:55:13.005784Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 219.0 / 607  (36.1):  61%|██████    | 606/1000 [00:19<00:15, 25.74it/s]198or for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 229.0 / 638  (35.9):  64%|██████▍   | 638/1000 [00:19<00:08, 44.96it/s]2024-10-14T00:55:15.404736Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 230.0 / 645  (35.7):  64%|██████▍   | 644/1000 [00:20<00:08, 40.74it/s]2024-10-14T00:55:15.678690Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 231.0 / 647  (35.7):  65%|██████▍   | 646/1000 [00:20<00:08, 40.74it/s]2024-10-14T00:55:15.821128Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 232.0 / 652  (35.6):  65%|██████▌   | 651/1000 [00:20<00:11, 29.42it/s]filename14T00:55:15.993685Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 247.0 / 695  (35.5):  69%|██████▉   | 694/1000 [00:21<00:09, 33.51it/s]2024-10-14T00:55:17.266592Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 258.0 / 720  (35.8):  72%|███████▏  | 720/1000 [00:22<00:08, 31.97it/s]2024-10-14T00:55:18.026033Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 273.0 / 789  (34.6):  79%|███████▉  | 789/1000 [00:24<00:07, 26.55it/s]=024-10-14T00:55:20.215393Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno198\n",
      "Average Metric: 276.0 / 796  (34.7):  80%|███████▉  | 795/1000 [00:24<00:06, 32.22it/s]lineno0-14T00:55:20.365104Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 288.0 / 824  (35.0):  82%|████████▏ | 823/1000 [00:25<00:04, 37.92it/s]2024-10-14T00:55:21.284557Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 288.0 / 826  (34.9):  83%|████████▎ | 826/1000 [00:25<00:06, 25.87it/s]2024-10-14T00:55:21.410665Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 288.0 / 827  (34.8):  83%|████████▎ | 826/1000 [00:25<00:06, 25.87it/s]2024-10-14T00:55:21.555263Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 303.0 / 867  (34.9):  87%|████████▋ | 867/1000 [00:27<00:02, 45.39it/s]2024-10-14T00:55:22.590477Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 305.0 / 870  (35.1):  87%|████████▋ | 869/1000 [00:27<00:02, 45.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 322.0 / 929  (34.7):  93%|█████████▎| 928/1000 [00:29<00:02, 33.12it/s] 024-10-14T00:55:25.047573Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 333.0 / 949  (35.1):  95%|█████████▍| 948/1000 [00:30<00:01, 43.93it/s]2024-10-14T00:55:25.476399Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 341.0 / 974  (35.0):  97%|█████████▋| 973/1000 [00:30<00:00, 43.46it/s]lineno0-14T00:55:26.023911Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 353.0 / 997  (35.4): 100%|█████████▉| 996/1000 [00:30<00:00, 45.39it/s]2024-10-14T00:55:26.182573Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 353.0 / 1000  (35.3): 100%|██████████| 1000/1000 [00:30<00:00, 32.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for base: 35.3, None, None\n"
     ]
    }
   ],
   "source": [
    "COMPILE_PROGRAM = False\n",
    "\n",
    "ft_results = {}\n",
    "for folder, llama in all_llamas.items():\n",
    "    print(\"Evaluating\", llama.model)\n",
    "    ft_results[folder] = {}\n",
    "    with dspy.context(lm=llama):\n",
    "        evaluate_devset = Evaluate(devset=devset_synthetic, metric=metric, num_threads=NUM_THREADS, display_progress=True, max_errors=10000)\n",
    "        \n",
    "        vanilla_program = IntentClassificationModule()\n",
    "        devset_result = evaluate_devset(vanilla_program)\n",
    "        ft_results[folder][\"vanilla\"] = {\"devset\": devset_result}\n",
    "\n",
    "        if COMPILE_PROGRAM:\n",
    "            bfrs_finetuned_program = bfrs_optimizer.compile(vanilla_program, trainset=ft_optimizer_trainset, valset=ft_optimizer_devset)\n",
    "            bfrs_finetuned_program.save(f\"simpleintent_1b_32_ft_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}_{folder.split('/')[-1]}.json\")\n",
    "        else:\n",
    "            bfrs_finetuned_program = IntentClassificationModule()\n",
    "            bfrs_finetuned_program.load(f\"simpleintent_1b_32_ft_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}_{folder.split('/')[-1]}.json\")\n",
    "        \n",
    "        llama_8b_bfrs_finetuned_eval = evaluate_devset(bfrs_finetuned_program)\n",
    "        ft_results[folder][\"bfrs\"] = {\"devset\": llama_8b_bfrs_finetuned_eval, \"true_labels\": None, \"testset\": None}\n",
    "        print(f\"result for {folder}: {llama_8b_bfrs_finetuned_eval}, None, None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/Llama-3.2-1B-Instruct:epochs-4-total-trained-steps-160': {'vanilla': {'devset': 17.9},\n",
       "  'bfrs': {'devset': 47.5, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-5-total-trained-steps-192': {'vanilla': {'devset': 19.0},\n",
       "  'bfrs': {'devset': 50.2, 'true_labels': None, 'testset': 50.3}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-2-total-trained-steps-96': {'vanilla': {'devset': 15.2},\n",
       "  'bfrs': {'devset': 39.3, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-0-total-trained-steps-32': {'vanilla': {'devset': 14.8},\n",
       "  'bfrs': {'devset': 28.7, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-3-total-trained-steps-128': {'vanilla': {'devset': 18.1},\n",
       "  'bfrs': {'devset': 47.3, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-1-total-trained-steps-64': {'vanilla': {'devset': 14.5},\n",
       "  'bfrs': {'devset': 34.9, 'true_labels': None, 'testset': None}},\n",
       " 'base': {'vanilla': {'devset': 2.7},\n",
       "  'bfrs': {'devset': 35.3, 'true_labels': None, 'testset': 35.1}}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if False:\n",
    "    import json\n",
    "    with open(\"ft_results.json\", \"w\") as f:\n",
    "        json.dump(ft_results, f)\n",
    "else:\n",
    "    ft_results = json.load(open(\"ft_results.json\"))\n",
    "ft_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best non-base model: meta-llama/Llama-3.2-1B-Instruct:epochs-5-total-trained-steps-192\n",
      "Evaluating base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]2024-10-14T01:36:52.609895Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/1000 [00:00<09:14,  1.80it/s]14T01:36:52.621999Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/1000 [00:00<09:14,  1.80it/s]2024-10-14T01:36:52.964831Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   0%|          | 3/1000 [00:00<04:39,  3.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   0%|          | 3/1000 [00:00<04:39,  3.56it/s]2024-10-14T01:36:53.008228Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   0%|          | 4/1000 [00:00<04:39,  3.56it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   0%|          | 5/1000 [00:01<04:39,  3.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   1%|          | 7/1000 [00:01<01:50,  9.01it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   1%|          | 7/1000 [00:01<01:50,  9.01it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 9  (0.0):   1%|          | 8/1000 [00:01<01:50,  9.01it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 10  (0.0):   1%|          | 9/1000 [00:01<01:49,  9.01it/s]2024-10-14T01:36:53.090222Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 11  (0.0):   1%|          | 10/1000 [00:01<01:49,  9.01it/s]2024-10-14T01:36:53.095006Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 12  (0.0):   1%|          | 12/1000 [00:01<01:02, 15.91it/s]2024-10-14T01:36:53.107261Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 13  (0.0):   1%|          | 12/1000 [00:01<01:02, 15.91it/s]2024-10-14T01:36:53.113430Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 14  (0.0):   1%|▏         | 13/1000 [00:01<01:02, 15.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 15  (0.0):   1%|▏         | 14/1000 [00:01<01:01, 15.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 16  (0.0):   2%|▏         | 15/1000 [00:01<01:01, 15.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 17  (0.0):   2%|▏         | 16/1000 [00:01<01:01, 15.91it/s]2024-10-14T01:36:53.167699Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 18  (0.0):   2%|▏         | 18/1000 [00:01<00:41, 23.83it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 19  (0.0):   2%|▏         | 18/1000 [00:01<00:41, 23.83it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 20  (0.0):   2%|▏         | 19/1000 [00:01<00:41, 23.83it/s]2024-10-14T01:36:53.235346Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 21  (0.0):   2%|▏         | 20/1000 [00:01<00:41, 23.83it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 22  (0.0):   2%|▏         | 21/1000 [00:01<00:41, 23.83it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 23  (0.0):   2%|▏         | 22/1000 [00:01<00:41, 23.83it/s]2024-10-14T01:36:53.328093Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 24  (0.0):   2%|▏         | 24/1000 [00:01<00:31, 31.47it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 25  (0.0):   2%|▏         | 24/1000 [00:01<00:31, 31.47it/s]2024-10-14T01:36:53.590793Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 26  (0.0):   2%|▎         | 25/1000 [00:01<00:30, 31.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 27  (0.0):   3%|▎         | 26/1000 [00:01<00:30, 31.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 28  (0.0):   3%|▎         | 27/1000 [00:01<00:30, 31.47it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 29  (0.0):   3%|▎         | 29/1000 [00:01<00:35, 27.30it/s]] 24-10-14T01:36:53.631404Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 31  (0.0):   3%|▎         | 30/1000 [00:01<00:35, 27.30it/s]2024-10-14T01:36:53.657579Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 32  (0.0):   3%|▎         | 31/1000 [00:01<00:35, 27.30it/s]2024-10-14T01:36:53.664387Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 33  (0.0):   3%|▎         | 32/1000 [00:01<00:35, 27.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 34  (0.0):   3%|▎         | 33/1000 [00:01<00:35, 27.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 35  (0.0):   4%|▎         | 35/1000 [00:01<00:29, 32.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 36  (0.0):   4%|▎         | 35/1000 [00:01<00:29, 32.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 37  (0.0):   4%|▎         | 36/1000 [00:01<00:29, 32.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 38  (0.0):   4%|▎         | 37/1000 [00:01<00:29, 32.91it/s]2024-10-14T01:36:53.949786Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 39  (0.0):   4%|▍         | 38/1000 [00:01<00:29, 32.91it/s]2024-10-14T01:36:53.971947Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 40  (0.0):   4%|▍         | 40/1000 [00:01<00:31, 30.97it/s]2024-10-14T01:36:54.003289Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 41  (0.0):   4%|▍         | 40/1000 [00:01<00:31, 30.97it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 42  (0.0):   4%|▍         | 41/1000 [00:01<00:30, 30.97it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 44  (0.0):   4%|▍         | 44/1000 [00:02<00:29, 32.56it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 45  (0.0):   4%|▍         | 44/1000 [00:02<00:29, 32.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 46  (0.0):   4%|▍         | 45/1000 [00:02<00:29, 32.56it/s]2024-10-14T01:36:54.067352Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 47  (0.0):   5%|▍         | 46/1000 [00:02<00:29, 32.56it/s]2024-10-14T01:36:54.115572Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 48  (0.0):   5%|▍         | 47/1000 [00:02<00:29, 32.56it/s]2024-10-14T01:36:54.139848Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 49  (0.0):   5%|▍         | 48/1000 [00:02<00:29, 32.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 50  (0.0):   5%|▌         | 50/1000 [00:02<00:24, 38.73it/s]2024-10-14T01:36:54.308730Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 51  (0.0):   5%|▌         | 50/1000 [00:02<00:24, 38.73it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 52  (0.0):   5%|▌         | 51/1000 [00:02<00:24, 38.73it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 53  (0.0):   5%|▌         | 52/1000 [00:02<00:24, 38.73it/s]2024-10-14T01:36:54.362543Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 54  (0.0):   5%|▌         | 53/1000 [00:02<00:24, 38.73it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 56  (0.0):   6%|▌         | 55/1000 [00:02<00:31, 30.42it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 57  (0.0):   6%|▌         | 56/1000 [00:02<00:31, 30.42it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 58  (0.0):   6%|▌         | 57/1000 [00:02<00:30, 30.42it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 59  (0.0):   6%|▌         | 58/1000 [00:02<00:30, 30.42it/s]2024-10-14T01:36:54.419789Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 60  (0.0):   6%|▌         | 59/1000 [00:02<00:30, 30.42it/s]2024-10-14T01:36:54.433237Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 61  (0.0):   6%|▌         | 61/1000 [00:02<00:26, 36.05it/s]2024-10-14T01:36:54.449551Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 62  (0.0):   6%|▌         | 61/1000 [00:02<00:26, 36.05it/s]2024-10-14T01:36:54.483839Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 63  (0.0):   6%|▌         | 62/1000 [00:02<00:26, 36.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 64  (0.0):   6%|▋         | 63/1000 [00:02<00:25, 36.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 65  (0.0):   6%|▋         | 64/1000 [00:02<00:25, 36.05it/s]2024-10-14T01:36:54.716135Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 66  (0.0):   7%|▋         | 66/1000 [00:02<00:28, 33.22it/s]2024-10-14T01:36:54.739423Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 67  (0.0):   7%|▋         | 66/1000 [00:02<00:28, 33.22it/s]2024-10-14T01:36:54.755376Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 68  (0.0):   7%|▋         | 67/1000 [00:02<00:28, 33.22it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 69  (0.0):   7%|▋         | 68/1000 [00:02<00:28, 33.22it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 70  (0.0):   7%|▋         | 70/1000 [00:02<00:28, 32.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 71  (0.0):   7%|▋         | 70/1000 [00:02<00:28, 32.75it/s]2024-10-14T01:36:54.800708Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 72  (0.0):   7%|▋         | 71/1000 [00:02<00:28, 32.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 73  (0.0):   7%|▋         | 72/1000 [00:02<00:28, 32.75it/s]2024-10-14T01:36:54.818666Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 74  (0.0):   7%|▋         | 73/1000 [00:02<00:28, 32.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 75  (0.0):   7%|▋         | 74/1000 [00:02<00:28, 32.75it/s]2024-10-14T01:36:54.844819Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 76  (0.0):   8%|▊         | 76/1000 [00:02<00:23, 38.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 78  (0.0):   8%|▊         | 77/1000 [00:03<00:23, 38.66it/s]2024-10-14T01:36:55.101975Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 79  (0.0):   8%|▊         | 78/1000 [00:03<00:23, 38.66it/s]2024-10-14T01:36:55.111588Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 80  (0.0):   8%|▊         | 79/1000 [00:03<00:23, 38.66it/s]2024-10-14T01:36:55.117369Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 81  (0.0):   8%|▊         | 81/1000 [00:03<00:28, 31.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 82  (0.0):   8%|▊         | 81/1000 [00:03<00:28, 31.91it/s]2024-10-14T01:36:55.142936Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 83  (0.0):   8%|▊         | 82/1000 [00:03<00:28, 31.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 84  (0.0):   8%|▊         | 83/1000 [00:03<00:28, 31.91it/s]2024-10-14T01:36:55.173644Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 85  (0.0):   8%|▊         | 84/1000 [00:03<00:28, 31.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 86  (0.0):   8%|▊         | 85/1000 [00:03<00:28, 31.91it/s]2024-10-14T01:36:55.197705Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 87  (0.0):   9%|▊         | 87/1000 [00:03<00:24, 37.08it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 88  (0.0):   9%|▊         | 87/1000 [00:03<00:24, 37.08it/s]2024-10-14T01:36:55.422815Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 89  (0.0):   9%|▉         | 88/1000 [00:03<00:24, 37.08it/s]2024-10-14T01:36:55.426946Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 90  (0.0):   9%|▉         | 89/1000 [00:03<00:24, 37.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 91  (0.0):   9%|▉         | 90/1000 [00:03<00:24, 37.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 92  (0.0):   9%|▉         | 92/1000 [00:03<00:29, 30.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 93  (0.0):   9%|▉         | 92/1000 [00:03<00:29, 30.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 94  (0.0):   9%|▉         | 93/1000 [00:03<00:29, 30.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 95  (0.0):   9%|▉         | 94/1000 [00:03<00:29, 30.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 96  (0.0):  10%|▉         | 95/1000 [00:03<00:29, 30.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 97  (0.0):  10%|▉         | 96/1000 [00:03<00:29, 30.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 98  (0.0):  10%|▉         | 98/1000 [00:03<00:25, 35.74it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 100  (0.0):  10%|▉         | 99/1000 [00:03<00:25, 35.74it/s]2024-10-14T01:36:55.773237Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 102  (0.0):  10%|█         | 101/1000 [00:03<00:25, 35.74it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 103  (0.0):  10%|█         | 103/1000 [00:03<00:28, 31.19it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 104  (0.0):  10%|█         | 103/1000 [00:03<00:28, 31.19it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 105  (0.0):  10%|█         | 104/1000 [00:03<00:28, 31.19it/s]2024-10-14T01:36:55.812336Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 106  (0.0):  10%|█         | 105/1000 [00:03<00:28, 31.19it/s]2024-10-14T01:36:55.827003Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 107  (0.0):  11%|█         | 106/1000 [00:03<00:28, 31.19it/s]2024-10-14T01:36:55.842271Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 108  (0.0):  11%|█         | 107/1000 [00:03<00:28, 31.19it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 109  (0.0):  11%|█         | 109/1000 [00:03<00:24, 35.70it/s]2024-10-14T01:36:55.862737Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 110  (0.0):  11%|█         | 109/1000 [00:03<00:24, 35.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 111  (0.0):  11%|█         | 110/1000 [00:03<00:24, 35.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 112  (0.0):  11%|█         | 111/1000 [00:03<00:24, 35.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 115  (0.0):  11%|█▏        | 114/1000 [00:04<00:26, 33.06it/s]2024-10-14T01:36:56.158477Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 116  (0.0):  12%|█▏        | 115/1000 [00:04<00:26, 33.06it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 118  (0.0):  12%|█▏        | 117/1000 [00:04<00:26, 33.06it/s]linenor    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 0.0 / 119  (0.0):  12%|█▏        | 119/1000 [00:04<00:24, 36.30it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 120  (0.0):  12%|█▏        | 119/1000 [00:04<00:24, 36.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 121  (0.0):  12%|█▏        | 120/1000 [00:04<00:24, 36.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 122  (0.0):  12%|█▏        | 121/1000 [00:04<00:24, 36.30it/s]2024-10-14T01:36:56.603768Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 123  (0.0):  12%|█▏        | 122/1000 [00:04<00:24, 36.30it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 124  (0.0):  12%|█▏        | 124/1000 [00:04<00:42, 20.85it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 126  (0.0):  12%|█▎        | 125/1000 [00:04<00:41, 20.85it/s]2024-10-14T01:36:56.622171Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 129  (0.8):  13%|█▎        | 128/1000 [00:04<00:41, 20.85it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 130  (0.8):  13%|█▎        | 129/1000 [00:04<00:35, 24.60it/s]2024-10-14T01:36:56.681454Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 131  (0.8):  13%|█▎        | 130/1000 [00:04<00:35, 24.60it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 132  (0.8):  13%|█▎        | 131/1000 [00:04<00:35, 24.60it/s]2024-10-14T01:36:56.722600Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 133  (0.8):  13%|█▎        | 132/1000 [00:04<00:35, 24.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 134  (0.7):  13%|█▎        | 134/1000 [00:04<00:30, 28.73it/s]error    4T01:36:56.731997Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 135  (0.7):  13%|█▎        | 134/1000 [00:04<00:30, 28.73it/s]2024-10-14T01:36:56.741520Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 137  (0.7):  14%|█▎        | 136/1000 [00:04<00:30, 28.73it/s]dspy.evaluate.evaluate example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 138  (0.7):  14%|█▎        | 137/1000 [00:04<00:30, 28.73it/s]2024-10-14T01:36:56.758197Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 139  (0.7):  14%|█▍        | 138/1000 [00:04<00:30, 28.73it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 140  (0.7):  14%|█▍        | 140/1000 [00:05<00:25, 34.00it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 141  (0.7):  14%|█▍        | 140/1000 [00:05<00:25, 34.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 142  (0.7):  14%|█▍        | 141/1000 [00:05<00:25, 34.00it/s]2024-10-14T01:36:56.786368Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 143  (0.7):  14%|█▍        | 142/1000 [00:05<00:25, 34.00it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 144  (0.7):  14%|█▍        | 143/1000 [00:05<00:25, 34.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 145  (0.7):  14%|█▍        | 144/1000 [00:05<00:25, 34.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 146  (0.7):  15%|█▍        | 146/1000 [00:05<00:22, 38.37it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 147  (0.7):  15%|█▍        | 146/1000 [00:05<00:22, 38.37it/s]2024-10-14T01:36:56.851400Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 148  (0.7):  15%|█▍        | 147/1000 [00:05<00:22, 38.37it/s]2024-10-14T01:36:56.879859Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 149  (0.7):  15%|█▍        | 148/1000 [00:05<00:22, 38.37it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 150  (0.7):  15%|█▍        | 149/1000 [00:05<00:22, 38.37it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 151  (0.7):  15%|█▌        | 150/1000 [00:05<00:22, 38.37it/s]2024-10-14T01:36:56.929392Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 152  (0.7):  15%|█▌        | 152/1000 [00:05<00:19, 42.62it/s]] 24-10-14T01:36:56.937294Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 153  (0.7):  15%|█▌        | 152/1000 [00:05<00:19, 42.62it/s]2024-10-14T01:36:56.949927Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 154  (0.6):  15%|█▌        | 153/1000 [00:05<00:19, 42.62it/s]2024-10-14T01:36:56.975743Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 155  (0.6):  15%|█▌        | 154/1000 [00:05<00:19, 42.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 156  (0.6):  16%|█▌        | 155/1000 [00:05<00:19, 42.62it/s]2024-10-14T01:36:57.046372Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 157  (0.6):  16%|█▌        | 156/1000 [00:05<00:19, 42.62it/s]2024-10-14T01:36:57.067986Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 158  (0.6):  16%|█▌        | 158/1000 [00:05<00:18, 46.34it/s]2024-10-14T01:36:57.081996Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 159  (0.6):  16%|█▌        | 158/1000 [00:05<00:18, 46.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 160  (0.6):  16%|█▌        | 159/1000 [00:05<00:18, 46.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 161  (0.6):  16%|█▌        | 160/1000 [00:05<00:18, 46.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 163  (0.6):  16%|█▌        | 162/1000 [00:05<00:18, 46.34it/s]2024-10-14T01:36:57.634402Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 164  (0.6):  16%|█▋        | 164/1000 [00:05<00:23, 35.88it/s]2024-10-14T01:36:57.662480Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 166  (0.6):  16%|█▋        | 165/1000 [00:05<00:23, 35.88it/s]2024-10-14T01:36:57.669032Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 167  (0.6):  17%|█▋        | 166/1000 [00:05<00:23, 35.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 168  (0.6):  17%|█▋        | 167/1000 [00:05<00:23, 35.88it/s]2024-10-14T01:36:57.678038Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 169  (0.6):  17%|█▋        | 169/1000 [00:05<00:21, 38.80it/s]error    4T01:36:57.707746Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 170  (0.6):  17%|█▋        | 169/1000 [00:05<00:21, 38.80it/s]2024-10-14T01:36:57.729980Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 172  (0.6):  17%|█▋        | 171/1000 [00:05<00:21, 38.80it/s]2024-10-14T01:36:57.938025Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 173  (0.6):  17%|█▋        | 172/1000 [00:05<00:21, 38.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 174  (0.6):  17%|█▋        | 174/1000 [00:05<00:25, 31.92it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 175  (0.6):  17%|█▋        | 174/1000 [00:05<00:25, 31.92it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 176  (0.6):  18%|█▊        | 175/1000 [00:05<00:25, 31.92it/s]2024-10-14T01:36:58.017170Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 177  (0.6):  18%|█▊        | 176/1000 [00:05<00:25, 31.92it/s]2024-10-14T01:36:58.022941Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 178  (0.6):  18%|█▊        | 177/1000 [00:05<00:25, 31.92it/s]2024-10-14T01:36:58.040209Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 179  (0.6):  18%|█▊        | 179/1000 [00:06<00:23, 34.33it/s] [24-10-14T01:36:58.093684Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 180  (0.6):  18%|█▊        | 179/1000 [00:06<00:23, 34.33it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 181  (0.6):  18%|█▊        | 180/1000 [00:06<00:23, 34.33it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 182  (0.5):  18%|█▊        | 181/1000 [00:06<00:23, 34.33it/s]2024-10-14T01:36:58.127650Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 183  (0.5):  18%|█▊        | 182/1000 [00:06<00:23, 34.33it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 184  (0.5):  18%|█▊        | 183/1000 [00:06<00:23, 34.33it/s]2024-10-14T01:36:58.328283Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 185  (0.5):  18%|█▊        | 185/1000 [00:06<00:26, 30.52it/s]2024-10-14T01:36:58.359483Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 186  (0.5):  18%|█▊        | 185/1000 [00:06<00:26, 30.52it/s]2024-10-14T01:36:58.363536Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 187  (0.5):  19%|█▊        | 186/1000 [00:06<00:26, 30.52it/s]2024-10-14T01:36:58.368877Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 189  (0.5):  19%|█▉        | 189/1000 [00:06<00:26, 30.40it/s] [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 190  (0.5):  19%|█▉        | 189/1000 [00:06<00:26, 30.40it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 191  (0.5):  19%|█▉        | 190/1000 [00:06<00:26, 30.40it/s]2024-10-14T01:36:58.416981Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 192  (0.5):  19%|█▉        | 191/1000 [00:06<00:26, 30.40it/s]2024-10-14T01:36:58.421514Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 193  (0.5):  19%|█▉        | 192/1000 [00:06<00:26, 30.40it/s]2024-10-14T01:36:58.428056Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 194  (0.5):  19%|█▉        | 194/1000 [00:06<00:24, 33.16it/s]2024-10-14T01:36:58.441465Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 195  (0.5):  19%|█▉        | 194/1000 [00:06<00:24, 33.16it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 196  (0.5):  20%|█▉        | 195/1000 [00:06<00:24, 33.16it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 197  (0.5):  20%|█▉        | 196/1000 [00:06<00:24, 33.16it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 198  (0.5):  20%|█▉        | 197/1000 [00:06<00:24, 33.16it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 199  (0.5):  20%|█▉        | 198/1000 [00:06<00:24, 33.16it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 200  (0.5):  20%|█▉        | 199/1000 [00:06<00:24, 33.16it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 201  (0.5):  20%|██        | 201/1000 [00:06<00:20, 39.86it/s]2024-10-14T01:36:58.542202Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 202  (0.5):  20%|██        | 201/1000 [00:06<00:20, 39.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 203  (0.5):  20%|██        | 202/1000 [00:06<00:20, 39.86it/s]2024-10-14T01:36:58.584187Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 204  (0.5):  20%|██        | 203/1000 [00:06<00:19, 39.86it/s]2024-10-14T01:36:58.974358Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 205  (0.5):  20%|██        | 204/1000 [00:06<00:19, 39.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 207  (1.0):  21%|██        | 206/1000 [00:06<00:27, 29.01it/s]2024-10-14T01:36:59.040346Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 208  (1.0):  21%|██        | 207/1000 [00:06<00:27, 29.01it/s]2024-10-14T01:36:59.155474Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 209  (1.0):  21%|██        | 208/1000 [00:07<00:27, 29.01it/s]2024-10-14T01:36:59.181452Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 210  (1.0):  21%|██        | 210/1000 [00:07<00:30, 25.90it/s]2024-10-14T01:36:59.198516Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 211  (0.9):  21%|██        | 210/1000 [00:07<00:30, 25.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 213  (0.9):  21%|██        | 212/1000 [00:07<00:30, 25.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 214  (0.9):  21%|██▏       | 213/1000 [00:07<00:30, 25.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 215  (0.9):  22%|██▏       | 215/1000 [00:07<00:26, 29.68it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 216  (0.9):  22%|██▏       | 215/1000 [00:07<00:26, 29.68it/s]2024-10-14T01:36:59.254968Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 217  (0.9):  22%|██▏       | 216/1000 [00:07<00:26, 29.68it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 218  (0.9):  22%|██▏       | 217/1000 [00:07<00:26, 29.68it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 219  (0.9):  22%|██▏       | 218/1000 [00:07<00:26, 29.68it/s]2024-10-14T01:36:59.268622Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 220  (0.9):  22%|██▏       | 219/1000 [00:07<00:26, 29.68it/s]2024-10-14T01:36:59.276557Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 221  (0.9):  22%|██▏       | 221/1000 [00:07<00:21, 35.69it/s]2024-10-14T01:36:59.316236Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 222  (0.9):  22%|██▏       | 221/1000 [00:07<00:21, 35.69it/s]2024-10-14T01:36:59.544796Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 225  (0.9):  22%|██▏       | 224/1000 [00:07<00:21, 35.69it/s]2024-10-14T01:36:59.589768Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 226  (0.9):  23%|██▎       | 226/1000 [00:07<00:24, 32.14it/s]] 24-10-14T01:36:59.609339Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 227  (0.9):  23%|██▎       | 226/1000 [00:07<00:24, 32.14it/s]2024-10-14T01:36:59.633222Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 228  (0.9):  23%|██▎       | 227/1000 [00:07<00:24, 32.14it/s]2024-10-14T01:36:59.768388Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 230  (0.9):  23%|██▎       | 230/1000 [00:07<00:27, 28.45it/s]=[error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 2.0 / 232  (0.9):  23%|██▎       | 231/1000 [00:07<00:27, 28.45it/s]lineno0-14T01:36:59.778483Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 2.0 / 234  (0.9):  23%|██▎       | 233/1000 [00:07<00:26, 28.45it/s]2024-10-14T01:36:59.827378Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 235  (0.9):  24%|██▎       | 235/1000 [00:07<00:24, 31.32it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 236  (0.8):  24%|██▎       | 235/1000 [00:07<00:24, 31.32it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 237  (0.8):  24%|██▎       | 236/1000 [00:07<00:24, 31.32it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 238  (0.8):  24%|██▎       | 237/1000 [00:07<00:24, 31.32it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 239  (0.8):  24%|██▍       | 238/1000 [00:07<00:24, 31.32it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 240  (0.8):  24%|██▍       | 240/1000 [00:07<00:21, 35.18it/s]2024-10-14T01:36:59.942374Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 241  (0.8):  24%|██▍       | 240/1000 [00:07<00:21, 35.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 242  (0.8):  24%|██▍       | 241/1000 [00:07<00:21, 35.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 243  (0.8):  24%|██▍       | 242/1000 [00:08<00:21, 35.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 244  (0.8):  24%|██▍       | 243/1000 [00:08<00:21, 35.18it/s]2024-10-14T01:36:59.971847Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 245  (0.8):  24%|██▍       | 244/1000 [00:08<00:21, 35.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 246  (0.8):  25%|██▍       | 246/1000 [00:08<00:18, 40.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 248  (0.8):  25%|██▍       | 247/1000 [00:08<00:18, 40.69it/s]2024-10-14T01:37:00.246532Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 249  (0.8):  25%|██▍       | 248/1000 [00:08<00:18, 40.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 250  (0.8):  25%|██▍       | 249/1000 [00:08<00:18, 40.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 252  (0.8):  25%|██▌       | 251/1000 [00:08<00:22, 33.69it/s]2024-10-14T01:37:00.291687Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 253  (0.8):  25%|██▌       | 252/1000 [00:08<00:22, 33.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 254  (0.8):  25%|██▌       | 253/1000 [00:08<00:22, 33.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 255  (0.8):  25%|██▌       | 254/1000 [00:08<00:22, 33.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 256  (0.8):  26%|██▌       | 255/1000 [00:08<00:22, 33.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 257  (0.8):  26%|██▌       | 257/1000 [00:08<00:19, 38.75it/s]2024-10-14T01:37:00.378643Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 258  (0.8):  26%|██▌       | 257/1000 [00:08<00:19, 38.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 260  (0.8):  26%|██▌       | 259/1000 [00:08<00:19, 38.75it/s]2024-10-14T01:37:00.593411Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 262  (0.8):  26%|██▌       | 262/1000 [00:08<00:20, 36.30it/s]2024-10-14T01:37:00.638459Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 263  (0.8):  26%|██▌       | 262/1000 [00:08<00:20, 36.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 264  (0.8):  26%|██▋       | 263/1000 [00:08<00:20, 36.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 265  (0.8):  26%|██▋       | 264/1000 [00:08<00:20, 36.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 266  (0.8):  26%|██▋       | 265/1000 [00:08<00:20, 36.30it/s]2024-10-14T01:37:00.808610Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 267  (0.7):  27%|██▋       | 267/1000 [00:08<00:23, 31.86it/s]2024-10-14T01:37:00.845190Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 268  (0.7):  27%|██▋       | 267/1000 [00:08<00:23, 31.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 269  (0.7):  27%|██▋       | 268/1000 [00:08<00:22, 31.86it/s]2024-10-14T01:37:00.888375Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 270  (0.7):  27%|██▋       | 269/1000 [00:08<00:22, 31.86it/s]2024-10-14T01:37:00.922820Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 272  (0.7):  27%|██▋       | 271/1000 [00:08<00:23, 30.52it/s]] 24-10-14T01:37:00.929495Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 274  (0.7):  27%|██▋       | 273/1000 [00:08<00:23, 30.52it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 275  (0.7):  27%|██▋       | 274/1000 [00:08<00:23, 30.52it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 276  (0.7):  28%|██▊       | 275/1000 [00:08<00:23, 30.52it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 277  (0.7):  28%|██▊       | 276/1000 [00:08<00:23, 30.52it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 278  (0.7):  28%|██▊       | 278/1000 [00:09<00:19, 37.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 279  (0.7):  28%|██▊       | 278/1000 [00:09<00:19, 37.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 280  (0.7):  28%|██▊       | 279/1000 [00:09<00:19, 37.66it/s]2024-10-14T01:37:01.033500Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 281  (0.7):  28%|██▊       | 280/1000 [00:09<00:19, 37.66it/s]2024-10-14T01:37:01.221710Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 282  (0.7):  28%|██▊       | 281/1000 [00:09<00:19, 37.66it/s]2024-10-14T01:37:01.242003Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 284  (0.7):  28%|██▊       | 283/1000 [00:09<00:21, 33.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 285  (0.7):  28%|██▊       | 284/1000 [00:09<00:21, 33.51it/s]2024-10-14T01:37:01.265340Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 286  (0.7):  28%|██▊       | 285/1000 [00:09<00:21, 33.51it/s]2024-10-14T01:37:01.286183Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 287  (0.7):  29%|██▊       | 286/1000 [00:09<00:21, 33.51it/s]2024-10-14T01:37:01.318124Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 288  (0.7):  29%|██▊       | 287/1000 [00:09<00:21, 33.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 289  (0.7):  29%|██▉       | 289/1000 [00:09<00:18, 38.50it/s]2024-10-14T01:37:01.483233Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 290  (0.7):  29%|██▉       | 289/1000 [00:09<00:18, 38.50it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 291  (0.7):  29%|██▉       | 290/1000 [00:09<00:18, 38.50it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 292  (0.7):  29%|██▉       | 291/1000 [00:09<00:18, 38.50it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 293  (0.7):  29%|██▉       | 292/1000 [00:09<00:18, 38.50it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 294  (0.7):  29%|██▉       | 294/1000 [00:09<00:22, 31.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 295  (0.7):  29%|██▉       | 294/1000 [00:09<00:22, 31.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 296  (0.7):  30%|██▉       | 295/1000 [00:09<00:22, 31.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 297  (0.7):  30%|██▉       | 296/1000 [00:09<00:22, 31.62it/s]2024-10-14T01:37:01.575669Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 298  (0.7):  30%|██▉       | 297/1000 [00:09<00:22, 31.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 299  (0.7):  30%|██▉       | 298/1000 [00:09<00:22, 31.62it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 300  (0.7):  30%|███       | 300/1000 [00:09<00:19, 36.73it/s]2024-10-14T01:37:01.606393Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 301  (0.7):  30%|███       | 300/1000 [00:09<00:19, 36.73it/s]2024-10-14T01:37:01.846785Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 302  (0.7):  30%|███       | 301/1000 [00:09<00:19, 36.73it/s]2024-10-14T01:37:01.885551Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 304  (0.7):  30%|███       | 303/1000 [00:09<00:18, 36.73it/s]2024-10-14T01:37:01.897163Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 305  (0.7):  30%|███       | 305/1000 [00:09<00:22, 30.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 306  (0.7):  30%|███       | 305/1000 [00:09<00:22, 30.65it/s]2024-10-14T01:37:01.906303Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 307  (0.7):  31%|███       | 306/1000 [00:09<00:22, 30.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 308  (0.6):  31%|███       | 307/1000 [00:09<00:22, 30.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 309  (0.6):  31%|███       | 308/1000 [00:09<00:22, 30.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 310  (0.6):  31%|███       | 309/1000 [00:09<00:22, 30.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 311  (0.6):  31%|███       | 311/1000 [00:09<00:19, 35.36it/s]error    4T01:37:01.993578Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 313  (0.6):  31%|███       | 312/1000 [00:10<00:19, 35.36it/s]2024-10-14T01:37:02.225697Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 314  (0.6):  31%|███▏      | 313/1000 [00:10<00:19, 35.36it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 315  (0.6):  31%|███▏      | 314/1000 [00:10<00:19, 35.36it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 316  (0.6):  32%|███▏      | 316/1000 [00:10<00:22, 29.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 317  (0.6):  32%|███▏      | 316/1000 [00:10<00:22, 29.81it/s]2024-10-14T01:37:02.268258Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 318  (0.6):  32%|███▏      | 317/1000 [00:10<00:22, 29.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 319  (0.6):  32%|███▏      | 318/1000 [00:10<00:22, 29.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 320  (0.6):  32%|███▏      | 319/1000 [00:10<00:22, 29.81it/s]2024-10-14T01:37:02.281181Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 321  (0.6):  32%|███▏      | 320/1000 [00:10<00:22, 29.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 322  (0.6):  32%|███▏      | 322/1000 [00:10<00:19, 34.96it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 323  (0.6):  32%|███▏      | 322/1000 [00:10<00:19, 34.96it/s]2024-10-14T01:37:02.540520Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 324  (0.6):  32%|███▏      | 323/1000 [00:10<00:19, 34.96it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 325  (0.6):  32%|███▏      | 324/1000 [00:10<00:19, 34.96it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 326  (0.6):  32%|███▎      | 325/1000 [00:10<00:19, 34.96it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 327  (0.6):  33%|███▎      | 327/1000 [00:10<00:22, 30.27it/s]2024-10-14T01:37:02.601488Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 328  (0.6):  33%|███▎      | 327/1000 [00:10<00:22, 30.27it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 329  (0.6):  33%|███▎      | 328/1000 [00:10<00:22, 30.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 330  (0.6):  33%|███▎      | 329/1000 [00:10<00:22, 30.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 335  (0.9):  34%|███▎      | 335/1000 [00:11<00:29, 22.35it/s] 024-10-14T01:37:03.124416Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 3.0 / 336  (0.9):  34%|███▎      | 335/1000 [00:11<00:29, 22.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 338  (0.9):  34%|███▎      | 337/1000 [00:11<00:29, 22.35it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 340  (0.9):  34%|███▍      | 339/1000 [00:11<00:29, 22.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 342  (0.9):  34%|███▍      | 341/1000 [00:11<00:23, 28.16it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 343  (0.9):  34%|███▍      | 342/1000 [00:11<00:23, 28.16it/s]2024-10-14T01:37:03.180783Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 344  (0.9):  34%|███▍      | 343/1000 [00:11<00:23, 28.16it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 345  (0.9):  34%|███▍      | 344/1000 [00:11<00:23, 28.16it/s]2024-10-14T01:37:03.214557Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 346  (0.9):  35%|███▍      | 346/1000 [00:11<00:20, 32.25it/s]2024-10-14T01:37:03.218951Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 347  (0.9):  35%|███▍      | 346/1000 [00:11<00:20, 32.25it/s]2024-10-14T01:37:03.226011Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 348  (0.9):  35%|███▍      | 347/1000 [00:11<00:20, 32.25it/s]2024-10-14T01:37:03.238236Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 349  (0.9):  35%|███▍      | 348/1000 [00:11<00:20, 32.25it/s]2024-10-14T01:37:03.255765Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 350  (0.9):  35%|███▍      | 349/1000 [00:11<00:20, 32.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 351  (0.9):  35%|███▌      | 351/1000 [00:11<00:18, 35.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 352  (0.9):  35%|███▌      | 351/1000 [00:11<00:18, 35.38it/s]2024-10-14T01:37:03.307197Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 353  (0.8):  35%|███▌      | 352/1000 [00:11<00:18, 35.38it/s]2024-10-14T01:37:03.311493Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 354  (0.8):  35%|███▌      | 353/1000 [00:11<00:18, 35.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 355  (0.8):  35%|███▌      | 354/1000 [00:11<00:18, 35.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 356  (0.8):  36%|███▌      | 356/1000 [00:11<00:16, 38.56it/s]error    4T01:37:03.336883Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 357  (0.8):  36%|███▌      | 356/1000 [00:11<00:16, 38.56it/s]2024-10-14T01:37:03.357328Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 358  (0.8):  36%|███▌      | 357/1000 [00:11<00:16, 38.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 359  (0.8):  36%|███▌      | 358/1000 [00:11<00:16, 38.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 361  (0.8):  36%|███▌      | 360/1000 [00:11<00:16, 38.56it/s]filename   ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 362  (0.8):  36%|███▌      | 362/1000 [00:11<00:14, 43.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 363  (0.8):  36%|███▌      | 362/1000 [00:11<00:14, 43.24it/s]2024-10-14T01:37:03.450929Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 364  (0.8):  36%|███▋      | 363/1000 [00:11<00:14, 43.24it/s]2024-10-14T01:37:03.462671Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 365  (0.8):  36%|███▋      | 364/1000 [00:11<00:14, 43.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 366  (0.8):  36%|███▋      | 365/1000 [00:11<00:14, 43.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 367  (0.8):  37%|███▋      | 366/1000 [00:11<00:14, 43.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 368  (0.8):  37%|███▋      | 368/1000 [00:11<00:13, 47.11it/s]2024-10-14T01:37:03.534674Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 369  (0.8):  37%|███▋      | 368/1000 [00:11<00:13, 47.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 370  (0.8):  37%|███▋      | 369/1000 [00:11<00:13, 47.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 371  (0.8):  37%|███▋      | 370/1000 [00:11<00:13, 47.11it/s]2024-10-14T01:37:03.935977Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 372  (0.8):  37%|███▋      | 371/1000 [00:11<00:13, 47.11it/s]2024-10-14T01:37:03.959424Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 373  (0.8):  37%|███▋      | 372/1000 [00:11<00:13, 47.11it/s]2024-10-14T01:37:03.981305Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 374  (0.8):  37%|███▋      | 374/1000 [00:11<00:16, 39.06it/s]2024-10-14T01:37:04.005491Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 375  (0.8):  37%|███▋      | 374/1000 [00:11<00:16, 39.06it/s]2024-10-14T01:37:04.026953Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 376  (0.8):  38%|███▊      | 375/1000 [00:11<00:16, 39.06it/s]2024-10-14T01:37:04.140844Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 377  (0.8):  38%|███▊      | 376/1000 [00:12<00:15, 39.06it/s]2024-10-14T01:37:04.165104Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 378  (0.8):  38%|███▊      | 377/1000 [00:12<00:15, 39.06it/s]2024-10-14T01:37:04.168570Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 379  (0.8):  38%|███▊      | 379/1000 [00:12<00:18, 33.06it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 380  (0.8):  38%|███▊      | 379/1000 [00:12<00:18, 33.06it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 381  (0.8):  38%|███▊      | 380/1000 [00:12<00:18, 33.06it/s]2024-10-14T01:37:04.204997Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 382  (0.8):  38%|███▊      | 381/1000 [00:12<00:18, 33.06it/s]2024-10-14T01:37:04.355925Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 383  (0.8):  38%|███▊      | 383/1000 [00:12<00:20, 30.38it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 384  (0.8):  38%|███▊      | 383/1000 [00:12<00:20, 30.38it/s]2024-10-14T01:37:04.394690Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 385  (0.8):  38%|███▊      | 384/1000 [00:12<00:20, 30.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 386  (0.8):  38%|███▊      | 385/1000 [00:12<00:20, 30.38it/s]2024-10-14T01:37:04.402768Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 387  (0.8):  39%|███▊      | 387/1000 [00:12<00:20, 29.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 388  (0.8):  39%|███▊      | 387/1000 [00:12<00:20, 29.82it/s]2024-10-14T01:37:04.431752Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 389  (0.8):  39%|███▉      | 388/1000 [00:12<00:20, 29.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 390  (0.8):  39%|███▉      | 389/1000 [00:12<00:20, 29.82it/s]2024-10-14T01:37:04.462376Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 391  (0.8):  39%|███▉      | 390/1000 [00:12<00:20, 29.82it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 392  (0.8):  39%|███▉      | 392/1000 [00:12<00:17, 33.88it/s]error    4T01:37:04.478368Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 393  (0.8):  39%|███▉      | 392/1000 [00:12<00:17, 33.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 394  (0.8):  39%|███▉      | 393/1000 [00:12<00:17, 33.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 395  (0.8):  39%|███▉      | 394/1000 [00:12<00:17, 33.88it/s]2024-10-14T01:37:04.501575Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 396  (0.8):  40%|███▉      | 395/1000 [00:12<00:17, 33.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 397  (0.8):  40%|███▉      | 396/1000 [00:12<00:17, 33.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 398  (0.8):  40%|███▉      | 398/1000 [00:12<00:15, 39.60it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 399  (0.8):  40%|███▉      | 398/1000 [00:12<00:15, 39.60it/s]2024-10-14T01:37:04.547453Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 400  (0.8):  40%|███▉      | 399/1000 [00:12<00:15, 39.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 401  (0.7):  40%|████      | 400/1000 [00:12<00:15, 39.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 402  (0.7):  40%|████      | 401/1000 [00:12<00:15, 39.60it/s]2024-10-14T01:37:04.579768Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 403  (0.7):  40%|████      | 402/1000 [00:12<00:15, 39.60it/s]2024-10-14T01:37:04.919508Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 404  (0.7):  40%|████      | 404/1000 [00:12<00:16, 35.45it/s]2024-10-14T01:37:04.949713Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 405  (0.7):  40%|████      | 404/1000 [00:12<00:16, 35.45it/s]2024-10-14T01:37:04.955946Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 406  (0.7):  40%|████      | 405/1000 [00:12<00:16, 35.45it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 407  (0.7):  41%|████      | 406/1000 [00:12<00:16, 35.45it/s]2024-10-14T01:37:04.970711Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 408  (0.7):  41%|████      | 408/1000 [00:12<00:17, 33.48it/s]2024-10-14T01:37:04.985009Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 409  (0.7):  41%|████      | 408/1000 [00:13<00:17, 33.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 410  (0.7):  41%|████      | 409/1000 [00:13<00:17, 33.48it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 411  (0.7):  41%|████      | 410/1000 [00:13<00:17, 33.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 412  (0.7):  41%|████      | 411/1000 [00:13<00:17, 33.48it/s]2024-10-14T01:37:05.011964Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 413  (0.7):  41%|████      | 412/1000 [00:13<00:17, 33.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 414  (0.7):  41%|████▏     | 414/1000 [00:13<00:15, 38.61it/s]2024-10-14T01:37:05.059352Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 415  (0.7):  41%|████▏     | 414/1000 [00:13<00:15, 38.61it/s]2024-10-14T01:37:05.064996Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 416  (0.7):  42%|████▏     | 415/1000 [00:13<00:15, 38.61it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 417  (0.7):  42%|████▏     | 416/1000 [00:13<00:15, 38.61it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 418  (0.7):  42%|████▏     | 417/1000 [00:13<00:15, 38.61it/s]2024-10-14T01:37:05.359208Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 419  (0.7):  42%|████▏     | 419/1000 [00:13<00:17, 32.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 420  (0.7):  42%|████▏     | 419/1000 [00:13<00:17, 32.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 421  (0.7):  42%|████▏     | 420/1000 [00:13<00:17, 32.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 422  (0.7):  42%|████▏     | 421/1000 [00:13<00:17, 32.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 423  (0.7):  42%|████▏     | 423/1000 [00:13<00:17, 33.52it/s] [24-10-14T01:37:05.433956Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 424  (0.7):  42%|████▏     | 423/1000 [00:13<00:17, 33.52it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 425  (0.7):  42%|████▏     | 424/1000 [00:13<00:17, 33.52it/s]2024-10-14T01:37:05.458198Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 426  (0.7):  42%|████▎     | 425/1000 [00:13<00:17, 33.52it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 427  (0.7):  43%|████▎     | 426/1000 [00:13<00:17, 33.52it/s]2024-10-14T01:37:05.484144Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 428  (0.7):  43%|████▎     | 427/1000 [00:13<00:17, 33.52it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 429  (0.7):  43%|████▎     | 429/1000 [00:13<00:14, 38.95it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 430  (0.7):  43%|████▎     | 429/1000 [00:13<00:14, 38.95it/s]2024-10-14T01:37:05.509666Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 431  (0.7):  43%|████▎     | 430/1000 [00:13<00:14, 38.95it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 432  (0.7):  43%|████▎     | 431/1000 [00:13<00:14, 38.95it/s]2024-10-14T01:37:05.763276Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 434  (0.7):  43%|████▎     | 434/1000 [00:13<00:16, 34.26it/s]2024-10-14T01:37:05.803121Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 435  (0.7):  43%|████▎     | 434/1000 [00:13<00:16, 34.26it/s]2024-10-14T01:37:05.823926Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 437  (0.7):  44%|████▎     | 436/1000 [00:13<00:16, 34.26it/s]2024-10-14T01:37:05.841189Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 438  (0.7):  44%|████▍     | 438/1000 [00:13<00:16, 34.71it/s]2024-10-14T01:37:05.844119Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 439  (0.7):  44%|████▍     | 438/1000 [00:13<00:16, 34.71it/s]2024-10-14T01:37:05.849595Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 440  (0.7):  44%|████▍     | 439/1000 [00:13<00:16, 34.71it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 441  (0.7):  44%|████▍     | 440/1000 [00:13<00:16, 34.71it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 442  (0.7):  44%|████▍     | 441/1000 [00:13<00:16, 34.71it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 443  (0.7):  44%|████▍     | 442/1000 [00:13<00:16, 34.71it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 444  (0.7):  44%|████▍     | 444/1000 [00:13<00:14, 39.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 445  (0.7):  44%|████▍     | 444/1000 [00:13<00:14, 39.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 446  (0.7):  44%|████▍     | 445/1000 [00:13<00:13, 39.67it/s]2024-10-14T01:37:06.136835Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 447  (0.7):  45%|████▍     | 446/1000 [00:14<00:13, 39.67it/s]2024-10-14T01:37:06.163972Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 448  (0.7):  45%|████▍     | 447/1000 [00:14<00:13, 39.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 449  (0.7):  45%|████▍     | 449/1000 [00:14<00:15, 34.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 450  (0.7):  45%|████▍     | 449/1000 [00:14<00:15, 34.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 451  (0.7):  45%|████▌     | 450/1000 [00:14<00:15, 34.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 452  (0.7):  45%|████▌     | 451/1000 [00:14<00:15, 34.69it/s]2024-10-14T01:37:06.373421Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 454  (0.7):  45%|████▌     | 453/1000 [00:14<00:18, 29.30it/s]dspy.evaluate.evaluate example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 455  (0.7):  45%|████▌     | 454/1000 [00:14<00:18, 29.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 456  (0.7):  46%|████▌     | 455/1000 [00:14<00:18, 29.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 457  (0.7):  46%|████▌     | 456/1000 [00:14<00:18, 29.30it/s]2024-10-14T01:37:06.432089Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 458  (0.7):  46%|████▌     | 458/1000 [00:14<00:16, 32.66it/s]dspy.evaluate.evaluate example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 459  (0.7):  46%|████▌     | 458/1000 [00:14<00:16, 32.66it/s]2024-10-14T01:37:06.444724Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 460  (0.7):  46%|████▌     | 459/1000 [00:14<00:16, 32.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 461  (0.7):  46%|████▌     | 460/1000 [00:14<00:16, 32.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 462  (0.6):  46%|████▌     | 461/1000 [00:14<00:16, 32.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 463  (0.6):  46%|████▌     | 462/1000 [00:14<00:16, 32.66it/s]2024-10-14T01:37:06.484040Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 464  (0.6):  46%|████▋     | 464/1000 [00:14<00:13, 38.77it/s]] 24-10-14T01:37:06.504893Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 465  (0.6):  46%|████▋     | 464/1000 [00:14<00:13, 38.77it/s]2024-10-14T01:37:06.720464Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 466  (0.6):  46%|████▋     | 465/1000 [00:14<00:13, 38.77it/s]2024-10-14T01:37:06.748517Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 467  (0.6):  47%|████▋     | 466/1000 [00:14<00:13, 38.77it/s]2024-10-14T01:37:06.755191Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 468  (0.6):  47%|████▋     | 467/1000 [00:14<00:13, 38.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 470  (0.6):  47%|████▋     | 469/1000 [00:14<00:16, 31.42it/s]= Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 3.0 / 471  (0.6):  47%|████▋     | 470/1000 [00:14<00:16, 31.42it/s]2024-10-14T01:37:06.792861Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 472  (0.6):  47%|████▋     | 471/1000 [00:14<00:16, 31.42it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 473  (0.6):  47%|████▋     | 472/1000 [00:14<00:16, 31.42it/s]2024-10-14T01:37:06.803367Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 474  (0.6):  47%|████▋     | 473/1000 [00:14<00:16, 31.42it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 475  (0.6):  48%|████▊     | 475/1000 [00:14<00:14, 37.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 476  (0.6):  48%|████▊     | 475/1000 [00:14<00:14, 37.00it/s]2024-10-14T01:37:06.842184Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 477  (0.6):  48%|████▊     | 476/1000 [00:14<00:14, 37.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 478  (0.6):  48%|████▊     | 477/1000 [00:14<00:14, 37.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 479  (0.6):  48%|████▊     | 478/1000 [00:14<00:14, 37.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 480  (0.6):  48%|████▊     | 479/1000 [00:14<00:14, 37.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 481  (0.6):  48%|████▊     | 480/1000 [00:14<00:14, 37.00it/s]2024-10-14T01:37:07.187009Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 482  (0.6):  48%|████▊     | 482/1000 [00:15<00:15, 33.38it/s]2024-10-14T01:37:07.209133Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 484  (0.6):  48%|████▊     | 483/1000 [00:15<00:15, 33.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 486  (0.6):  48%|████▊     | 485/1000 [00:15<00:15, 33.38it/s]]rror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 487  (0.6):  49%|████▊     | 486/1000 [00:15<00:15, 33.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 489  (0.8):  49%|████▉     | 488/1000 [00:15<00:13, 37.43it/s]2024-10-14T01:37:07.429125Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 492  (0.8):  49%|████▉     | 491/1000 [00:15<00:13, 37.43it/s]linenofor example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 4.0 / 495  (0.8):  49%|████▉     | 494/1000 [00:15<00:15, 31.84it/s]=rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 4.0 / 496  (0.8):  50%|████▉     | 495/1000 [00:15<00:15, 31.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 497  (0.8):  50%|████▉     | 496/1000 [00:15<00:15, 31.84it/s]2024-10-14T01:37:07.499789Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 499  (0.8):  50%|████▉     | 499/1000 [00:15<00:13, 36.53it/s] 024-10-14T01:37:07.549399Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 500  (0.8):  50%|████▉     | 499/1000 [00:15<00:13, 36.53it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 502  (0.8):  50%|█████     | 501/1000 [00:15<00:13, 36.53it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 503  (0.8):  50%|█████     | 502/1000 [00:15<00:13, 36.53it/s]2024-10-14T01:37:07.599516Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 504  (0.8):  50%|█████     | 503/1000 [00:15<00:13, 36.53it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 505  (0.8):  50%|█████     | 504/1000 [00:15<00:13, 36.53it/s]2024-10-14T01:37:07.622604Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 506  (0.8):  51%|█████     | 506/1000 [00:15<00:11, 42.78it/s]2024-10-14T01:37:07.868358Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 507  (0.8):  51%|█████     | 506/1000 [00:15<00:11, 42.78it/s]2024-10-14T01:37:07.874337Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 508  (0.8):  51%|█████     | 507/1000 [00:15<00:11, 42.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 509  (0.8):  51%|█████     | 508/1000 [00:15<00:11, 42.78it/s]2024-10-14T01:37:07.887193Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 510  (0.8):  51%|█████     | 509/1000 [00:15<00:11, 42.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 511  (0.8):  51%|█████     | 511/1000 [00:15<00:14, 32.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 512  (0.8):  51%|█████     | 511/1000 [00:15<00:14, 32.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 513  (0.8):  51%|█████     | 512/1000 [00:15<00:14, 32.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 514  (0.8):  51%|█████▏    | 513/1000 [00:15<00:14, 32.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 515  (0.8):  51%|█████▏    | 514/1000 [00:16<00:14, 32.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 516  (0.8):  52%|█████▏    | 515/1000 [00:16<00:14, 32.81it/s]2024-10-14T01:37:07.976809Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 517  (0.8):  52%|█████▏    | 517/1000 [00:16<00:13, 36.90it/s]2024-10-14T01:37:07.979332Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 518  (0.8):  52%|█████▏    | 517/1000 [00:16<00:13, 36.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 519  (0.8):  52%|█████▏    | 518/1000 [00:16<00:13, 36.90it/s]2024-10-14T01:37:07.992229Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 520  (0.8):  52%|█████▏    | 519/1000 [00:16<00:13, 36.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 521  (0.8):  52%|█████▏    | 520/1000 [00:16<00:13, 36.90it/s]2024-10-14T01:37:08.645470Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 522  (0.8):  52%|█████▏    | 522/1000 [00:16<00:23, 20.72it/s]2024-10-14T01:37:08.671836Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 523  (0.8):  52%|█████▏    | 522/1000 [00:16<00:23, 20.72it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 525  (0.8):  52%|█████▏    | 524/1000 [00:16<00:22, 20.72it/s]2024-10-14T01:37:08.813231Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 526  (0.8):  53%|█████▎    | 526/1000 [00:16<00:23, 20.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 527  (0.8):  53%|█████▎    | 526/1000 [00:16<00:23, 20.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 529  (0.8):  53%|█████▎    | 528/1000 [00:16<00:23, 20.18it/s]198rror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 4.0 / 530  (0.8):  53%|█████▎    | 529/1000 [00:16<00:23, 20.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 531  (0.8):  53%|█████▎    | 530/1000 [00:16<00:23, 20.18it/s]2024-10-14T01:37:08.880392Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 532  (0.8):  53%|█████▎    | 532/1000 [00:16<00:18, 25.59it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 533  (0.8):  53%|█████▎    | 532/1000 [00:16<00:18, 25.59it/s]2024-10-14T01:37:08.895539Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 534  (0.7):  53%|█████▎    | 533/1000 [00:16<00:18, 25.59it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 535  (0.7):  53%|█████▎    | 534/1000 [00:16<00:18, 25.59it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 536  (0.7):  54%|█████▎    | 535/1000 [00:16<00:18, 25.59it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 538  (0.7):  54%|█████▍    | 538/1000 [00:17<00:16, 27.29it/s]2024-10-14T01:37:09.176566Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 539  (0.7):  54%|█████▍    | 538/1000 [00:17<00:16, 27.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 540  (0.7):  54%|█████▍    | 539/1000 [00:17<00:16, 27.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 541  (0.7):  54%|█████▍    | 540/1000 [00:17<00:16, 27.29it/s]2024-10-14T01:37:09.195408Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 542  (0.7):  54%|█████▍    | 541/1000 [00:17<00:16, 27.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 543  (0.7):  54%|█████▍    | 543/1000 [00:17<00:14, 31.06it/s]error    4T01:37:09.216674Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 545  (0.7):  54%|█████▍    | 544/1000 [00:17<00:14, 31.06it/s]2024-10-14T01:37:09.588159Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 546  (0.7):  55%|█████▍    | 545/1000 [00:17<00:14, 31.06it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 549  (0.7):  55%|█████▍    | 548/1000 [00:17<00:22, 19.79it/s]error    4T01:37:09.604700Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 551  (0.7):  55%|█████▌    | 550/1000 [00:17<00:22, 19.79it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 552  (0.7):  55%|█████▌    | 551/1000 [00:17<00:22, 19.79it/s]2024-10-14T01:37:09.674076Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 553  (0.7):  55%|█████▌    | 553/1000 [00:17<00:17, 25.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 555  (0.7):  55%|█████▌    | 554/1000 [00:17<00:17, 25.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 556  (0.7):  56%|█████▌    | 555/1000 [00:17<00:17, 25.49it/s]2024-10-14T01:37:09.719811Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 557  (0.7):  56%|█████▌    | 556/1000 [00:17<00:17, 25.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 558  (0.7):  56%|█████▌    | 557/1000 [00:17<00:17, 25.49it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 559  (0.7):  56%|█████▌    | 559/1000 [00:17<00:14, 30.60it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 561  (0.7):  56%|█████▌    | 560/1000 [00:17<00:14, 30.60it/s]filename14T01:37:09.748643Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 562  (0.7):  56%|█████▌    | 561/1000 [00:17<00:14, 30.60it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 563  (0.7):  56%|█████▌    | 562/1000 [00:17<00:14, 30.60it/s]2024-10-14T01:37:09.783171Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 564  (0.7):  56%|█████▋    | 563/1000 [00:17<00:14, 30.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 565  (0.7):  56%|█████▋    | 564/1000 [00:17<00:14, 30.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 566  (0.7):  57%|█████▋    | 566/1000 [00:17<00:11, 37.23it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 567  (0.7):  57%|█████▋    | 566/1000 [00:17<00:11, 37.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 568  (0.7):  57%|█████▋    | 567/1000 [00:17<00:11, 37.23it/s]2024-10-14T01:37:09.833933Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 569  (0.7):  57%|█████▋    | 568/1000 [00:18<00:11, 37.23it/s]2024-10-14T01:37:09.847896Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 570  (0.7):  57%|█████▋    | 569/1000 [00:18<00:11, 37.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 571  (0.7):  57%|█████▋    | 570/1000 [00:18<00:11, 37.23it/s]2024-10-14T01:37:09.882669Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 572  (0.7):  57%|█████▋    | 572/1000 [00:18<00:10, 41.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 573  (0.7):  57%|█████▋    | 572/1000 [00:18<00:10, 41.47it/s]2024-10-14T01:37:09.904596Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 574  (0.7):  57%|█████▋    | 573/1000 [00:18<00:10, 41.47it/s]2024-10-14T01:37:10.335785Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 575  (0.7):  57%|█████▋    | 574/1000 [00:18<00:10, 41.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 577  (0.7):  58%|█████▊    | 576/1000 [00:18<00:10, 41.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 578  (0.7):  58%|█████▊    | 578/1000 [00:18<00:12, 33.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 579  (0.7):  58%|█████▊    | 578/1000 [00:18<00:12, 33.67it/s]2024-10-14T01:37:10.433545Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 580  (0.7):  58%|█████▊    | 579/1000 [00:18<00:12, 33.67it/s]2024-10-14T01:37:10.587384Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 581  (0.7):  58%|█████▊    | 580/1000 [00:18<00:12, 33.67it/s]2024-10-14T01:37:10.595233Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 582  (0.7):  58%|█████▊    | 581/1000 [00:18<00:12, 33.67it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 583  (0.7):  58%|█████▊    | 583/1000 [00:18<00:15, 27.49it/s] [24-10-14T01:37:10.610612Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 584  (0.7):  58%|█████▊    | 583/1000 [00:18<00:15, 27.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 585  (0.7):  58%|█████▊    | 584/1000 [00:18<00:15, 27.49it/s]2024-10-14T01:37:10.634019Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 586  (0.7):  58%|█████▊    | 585/1000 [00:18<00:15, 27.49it/s]2024-10-14T01:37:10.666645Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 587  (0.7):  59%|█████▊    | 586/1000 [00:18<00:15, 27.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 588  (0.7):  59%|█████▉    | 588/1000 [00:18<00:13, 30.95it/s]2024-10-14T01:37:10.675410Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 589  (0.7):  59%|█████▉    | 588/1000 [00:18<00:13, 30.95it/s]2024-10-14T01:37:10.689919Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 590  (0.7):  59%|█████▉    | 589/1000 [00:18<00:13, 30.95it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 591  (0.7):  59%|█████▉    | 590/1000 [00:18<00:13, 30.95it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 592  (0.7):  59%|█████▉    | 591/1000 [00:18<00:13, 30.95it/s]2024-10-14T01:37:10.723616Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 593  (0.7):  59%|█████▉    | 592/1000 [00:18<00:13, 30.95it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 594  (0.7):  59%|█████▉    | 594/1000 [00:18<00:11, 36.30it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 595  (0.7):  59%|█████▉    | 594/1000 [00:18<00:11, 36.30it/s]2024-10-14T01:37:11.010585Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 596  (0.7):  60%|█████▉    | 595/1000 [00:18<00:11, 36.30it/s]2024-10-14T01:37:11.036213Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 597  (0.7):  60%|█████▉    | 596/1000 [00:18<00:11, 36.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 599  (0.7):  60%|█████▉    | 599/1000 [00:19<00:12, 31.93it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 600  (0.7):  60%|█████▉    | 599/1000 [00:19<00:12, 31.93it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 601  (0.7):  60%|██████    | 600/1000 [00:19<00:12, 31.93it/s]2024-10-14T01:37:11.083434Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 602  (0.7):  60%|██████    | 601/1000 [00:19<00:12, 31.93it/s]2024-10-14T01:37:11.107917Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 603  (0.7):  60%|██████    | 602/1000 [00:19<00:12, 31.93it/s]2024-10-14T01:37:11.113813Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 605  (0.7):  60%|██████    | 605/1000 [00:19<00:12, 30.90it/s]2024-10-14T01:37:11.315200Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 606  (0.7):  60%|██████    | 605/1000 [00:19<00:12, 30.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 607  (0.7):  61%|██████    | 606/1000 [00:19<00:12, 30.90it/s]2024-10-14T01:37:11.330421Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 608  (0.7):  61%|██████    | 607/1000 [00:19<00:12, 30.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 609  (0.7):  61%|██████    | 608/1000 [00:19<00:12, 30.90it/s]2024-10-14T01:37:11.349011Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 610  (0.7):  61%|██████    | 610/1000 [00:19<00:11, 33.46it/s]] 24-10-14T01:37:11.369475Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 611  (0.7):  61%|██████    | 610/1000 [00:19<00:11, 33.46it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 612  (0.7):  61%|██████    | 611/1000 [00:19<00:11, 33.46it/s]2024-10-14T01:37:11.415424Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 613  (0.7):  61%|██████    | 612/1000 [00:19<00:11, 33.46it/s]2024-10-14T01:37:11.582418Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 614  (0.7):  61%|██████▏   | 614/1000 [00:19<00:12, 29.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 615  (0.7):  61%|██████▏   | 614/1000 [00:19<00:12, 29.78it/s]2024-10-14T01:37:11.596453Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 617  (0.6):  62%|██████▏   | 616/1000 [00:19<00:12, 29.78it/s]error    4T01:37:11.622351Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 620  (0.8):  62%|██████▏   | 619/1000 [00:19<00:11, 33.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 621  (0.8):  62%|██████▏   | 620/1000 [00:19<00:11, 33.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 622  (0.8):  62%|██████▏   | 621/1000 [00:19<00:11, 33.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 623  (0.8):  62%|██████▏   | 622/1000 [00:19<00:11, 33.60it/s]2024-10-14T01:37:11.684756Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 624  (0.8):  62%|██████▏   | 623/1000 [00:19<00:11, 33.60it/s]2024-10-14T01:37:11.732806Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 625  (0.8):  62%|██████▏   | 624/1000 [00:19<00:11, 33.60it/s]2024-10-14T01:37:11.920945Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 627  (0.8):  63%|██████▎   | 626/1000 [00:19<00:11, 32.02it/s] [24-10-14T01:37:11.929306Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 629  (0.8):  63%|██████▎   | 628/1000 [00:19<00:11, 32.02it/s]2024-10-14T01:37:11.931670Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 630  (0.8):  63%|██████▎   | 629/1000 [00:19<00:11, 32.02it/s]2024-10-14T01:37:11.974152Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 631  (0.8):  63%|██████▎   | 631/1000 [00:19<00:10, 35.08it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 632  (0.8):  63%|██████▎   | 631/1000 [00:19<00:10, 35.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 633  (0.8):  63%|██████▎   | 632/1000 [00:20<00:10, 35.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 634  (0.8):  63%|██████▎   | 633/1000 [00:20<00:10, 35.08it/s]2024-10-14T01:37:12.042816Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 635  (0.8):  63%|██████▎   | 634/1000 [00:20<00:10, 35.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 636  (0.8):  64%|██████▎   | 635/1000 [00:20<00:10, 35.08it/s]2024-10-14T01:37:12.069563Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 637  (0.8):  64%|██████▎   | 637/1000 [00:20<00:09, 39.13it/s]2024-10-14T01:37:12.257733Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 639  (0.8):  64%|██████▍   | 638/1000 [00:20<00:09, 39.13it/s]2024-10-14T01:37:12.285179Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 640  (0.8):  64%|██████▍   | 639/1000 [00:20<00:09, 39.13it/s]2024-10-14T01:37:12.289327Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 641  (0.8):  64%|██████▍   | 640/1000 [00:20<00:09, 39.13it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 642  (0.8):  64%|██████▍   | 642/1000 [00:20<00:10, 33.66it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 645  (0.8):  64%|██████▍   | 644/1000 [00:20<00:10, 33.66it/s]2024-10-14T01:37:12.513209Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 646  (0.8):  65%|██████▍   | 646/1000 [00:20<00:11, 29.99it/s]2024-10-14T01:37:12.530925Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 647  (0.8):  65%|██████▍   | 646/1000 [00:20<00:11, 29.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 648  (0.8):  65%|██████▍   | 647/1000 [00:20<00:11, 29.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 649  (0.8):  65%|██████▍   | 648/1000 [00:20<00:11, 29.99it/s]2024-10-14T01:37:12.561103Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 650  (0.8):  65%|██████▍   | 649/1000 [00:20<00:11, 29.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 651  (0.8):  65%|██████▌   | 650/1000 [00:20<00:11, 29.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 653  (0.8):  65%|██████▌   | 652/1000 [00:20<00:09, 35.43it/s]2024-10-14T01:37:12.804265Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 654  (0.8):  65%|██████▌   | 653/1000 [00:20<00:09, 35.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 655  (0.8):  65%|██████▌   | 654/1000 [00:20<00:09, 35.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 656  (0.8):  66%|██████▌   | 656/1000 [00:20<00:11, 28.71it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 657  (0.8):  66%|██████▌   | 656/1000 [00:20<00:11, 28.71it/s]2024-10-14T01:37:12.848840Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 658  (0.8):  66%|██████▌   | 657/1000 [00:20<00:11, 28.71it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 659  (0.8):  66%|██████▌   | 658/1000 [00:20<00:11, 28.71it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 660  (0.8):  66%|██████▌   | 659/1000 [00:20<00:11, 28.71it/s]2024-10-14T01:37:13.069585Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 661  (0.8):  66%|██████▌   | 661/1000 [00:21<00:12, 26.61it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 663  (0.8):  66%|██████▌   | 662/1000 [00:21<00:12, 26.61it/s]2024-10-14T01:37:13.093757Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 664  (0.8):  66%|██████▋   | 663/1000 [00:21<00:12, 26.61it/s]2024-10-14T01:37:13.108265Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 666  (0.8):  67%|██████▋   | 666/1000 [00:21<00:11, 30.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 667  (0.7):  67%|██████▋   | 666/1000 [00:21<00:11, 30.34it/s]2024-10-14T01:37:13.137345Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 668  (0.7):  67%|██████▋   | 667/1000 [00:21<00:10, 30.34it/s]2024-10-14T01:37:13.161797Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 669  (0.7):  67%|██████▋   | 668/1000 [00:21<00:10, 30.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 670  (0.7):  67%|██████▋   | 669/1000 [00:21<00:10, 30.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 671  (0.7):  67%|██████▋   | 670/1000 [00:21<00:10, 30.34it/s]2024-10-14T01:37:13.401186Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 673  (0.7):  67%|██████▋   | 672/1000 [00:21<00:11, 29.53it/s]2024-10-14T01:37:13.406219Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 674  (0.7):  67%|██████▋   | 673/1000 [00:21<00:11, 29.53it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 676  (0.7):  68%|██████▊   | 675/1000 [00:21<00:11, 29.53it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 677  (0.7):  68%|██████▊   | 676/1000 [00:21<00:10, 29.53it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 678  (0.7):  68%|██████▊   | 678/1000 [00:21<00:09, 34.31it/s]] 24-10-14T01:37:13.475962Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 679  (0.7):  68%|██████▊   | 678/1000 [00:21<00:09, 34.31it/s]2024-10-14T01:37:13.485123Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 680  (0.7):  68%|██████▊   | 679/1000 [00:21<00:09, 34.31it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 681  (0.7):  68%|██████▊   | 680/1000 [00:21<00:09, 34.31it/s]2024-10-14T01:37:13.538035Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 682  (0.7):  68%|██████▊   | 681/1000 [00:21<00:09, 34.31it/s]2024-10-14T01:37:13.707856Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 684  (0.7):  68%|██████▊   | 683/1000 [00:21<00:09, 31.97it/s]2024-10-14T01:37:13.734821Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 685  (0.7):  68%|██████▊   | 684/1000 [00:21<00:09, 31.97it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 686  (0.7):  68%|██████▊   | 685/1000 [00:21<00:09, 31.97it/s]2024-10-14T01:37:13.768802Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 687  (0.7):  69%|██████▊   | 686/1000 [00:21<00:09, 31.97it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 688  (0.7):  69%|██████▉   | 688/1000 [00:21<00:08, 34.92it/s]2024-10-14T01:37:13.788789Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 689  (0.7):  69%|██████▉   | 688/1000 [00:21<00:08, 34.92it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 690  (0.7):  69%|██████▉   | 689/1000 [00:21<00:08, 34.92it/s]2024-10-14T01:37:13.978821Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 691  (0.7):  69%|██████▉   | 690/1000 [00:21<00:08, 34.92it/s]2024-10-14T01:37:14.009976Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 692  (0.7):  69%|██████▉   | 692/1000 [00:21<00:10, 29.79it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 693  (0.7):  69%|██████▉   | 692/1000 [00:21<00:10, 29.79it/s]2024-10-14T01:37:14.020232Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 694  (0.7):  69%|██████▉   | 693/1000 [00:22<00:10, 29.79it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 695  (0.7):  69%|██████▉   | 694/1000 [00:22<00:10, 29.79it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 696  (0.7):  70%|██████▉   | 696/1000 [00:22<00:09, 30.77it/s]error    4T01:37:14.061197Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 697  (0.7):  70%|██████▉   | 696/1000 [00:22<00:09, 30.77it/s]2024-10-14T01:37:14.064003Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 698  (0.7):  70%|██████▉   | 697/1000 [00:22<00:09, 30.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 699  (0.7):  70%|██████▉   | 698/1000 [00:22<00:09, 30.77it/s]2024-10-14T01:37:14.091771Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 700  (0.7):  70%|██████▉   | 699/1000 [00:22<00:09, 30.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 701  (0.7):  70%|███████   | 700/1000 [00:22<00:09, 30.77it/s]2024-10-14T01:37:14.102680Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 702  (0.7):  70%|███████   | 702/1000 [00:22<00:08, 36.82it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 703  (0.7):  70%|███████   | 702/1000 [00:22<00:08, 36.82it/s]2024-10-14T01:37:14.121566Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 704  (0.7):  70%|███████   | 703/1000 [00:22<00:08, 36.82it/s]2024-10-14T01:37:14.380850Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 707  (0.7):  71%|███████   | 707/1000 [00:22<00:08, 34.17it/s]2024-10-14T01:37:14.433462Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 708  (0.7):  71%|███████   | 707/1000 [00:22<00:08, 34.17it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 709  (0.7):  71%|███████   | 708/1000 [00:22<00:08, 34.17it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 710  (0.7):  71%|███████   | 709/1000 [00:22<00:08, 34.17it/s]2024-10-14T01:37:14.456289Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 711  (0.7):  71%|███████   | 710/1000 [00:22<00:08, 34.17it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 712  (0.7):  71%|███████   | 712/1000 [00:22<00:07, 37.47it/s]2024-10-14T01:37:14.639852Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 714  (0.7):  71%|███████▏  | 713/1000 [00:22<00:07, 37.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 6.0 / 716  (0.8):  72%|███████▏  | 715/1000 [00:22<00:07, 37.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 718  (1.0):  72%|███████▏  | 717/1000 [00:22<00:08, 31.65it/s]2024-10-14T01:37:14.660597Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 719  (1.0):  72%|███████▏  | 718/1000 [00:22<00:08, 31.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 720  (1.0):  72%|███████▏  | 719/1000 [00:22<00:08, 31.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 721  (1.0):  72%|███████▏  | 720/1000 [00:22<00:08, 31.65it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 722  (1.0):  72%|███████▏  | 721/1000 [00:22<00:08, 31.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 723  (1.0):  72%|███████▏  | 723/1000 [00:22<00:07, 36.77it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 724  (1.0):  72%|███████▏  | 723/1000 [00:22<00:07, 36.77it/s]2024-10-14T01:37:14.807826Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 725  (1.0):  72%|███████▏  | 724/1000 [00:22<00:07, 36.77it/s]2024-10-14T01:37:14.983612Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 727  (1.1):  73%|███████▎  | 726/1000 [00:22<00:07, 36.77it/s]2024-10-14T01:37:15.031772Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 728  (1.1):  73%|███████▎  | 728/1000 [00:22<00:08, 33.10it/s]2024-10-14T01:37:15.066072Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 729  (1.1):  73%|███████▎  | 728/1000 [00:22<00:08, 33.10it/s]2024-10-14T01:37:15.164748Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 731  (1.1):  73%|███████▎  | 730/1000 [00:23<00:08, 33.10it/s]2024-10-14T01:37:15.194406Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 732  (1.1):  73%|███████▎  | 732/1000 [00:23<00:09, 29.69it/s]2024-10-14T01:37:15.230049Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 733  (1.1):  73%|███████▎  | 732/1000 [00:23<00:09, 29.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 734  (1.1):  73%|███████▎  | 733/1000 [00:23<00:08, 29.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 736  (1.1):  74%|███████▎  | 736/1000 [00:23<00:09, 27.28it/s]2024-10-14T01:37:15.413695Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 738  (1.1):  74%|███████▎  | 737/1000 [00:23<00:09, 27.28it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 739  (1.1):  74%|███████▍  | 739/1000 [00:23<00:09, 27.80it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 740  (1.1):  74%|███████▍  | 739/1000 [00:23<00:09, 27.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 742  (1.1):  74%|███████▍  | 741/1000 [00:23<00:09, 27.80it/s]2024-10-14T01:37:15.478162Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 743  (1.1):  74%|███████▍  | 742/1000 [00:23<00:09, 27.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 744  (1.1):  74%|███████▍  | 743/1000 [00:23<00:09, 27.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 745  (1.1):  74%|███████▍  | 745/1000 [00:23<00:07, 33.78it/s] [24-10-14T01:37:15.511391Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 746  (1.1):  74%|███████▍  | 745/1000 [00:23<00:07, 33.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 747  (1.1):  75%|███████▍  | 746/1000 [00:23<00:07, 33.78it/s]2024-10-14T01:37:15.529261Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 748  (1.1):  75%|███████▍  | 747/1000 [00:23<00:07, 33.78it/s]2024-10-14T01:37:15.536634Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 749  (1.1):  75%|███████▍  | 748/1000 [00:23<00:07, 33.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 750  (1.1):  75%|███████▍  | 749/1000 [00:23<00:07, 33.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 751  (1.1):  75%|███████▌  | 750/1000 [00:23<00:07, 33.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 752  (1.1):  75%|███████▌  | 752/1000 [00:23<00:06, 40.36it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 754  (1.1):  75%|███████▌  | 753/1000 [00:23<00:06, 40.36it/s]2024-10-14T01:37:15.872049Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 755  (1.1):  75%|███████▌  | 754/1000 [00:23<00:06, 40.36it/s]2024-10-14T01:37:15.886089Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 756  (1.1):  76%|███████▌  | 755/1000 [00:23<00:06, 40.36it/s]2024-10-14T01:37:15.931135Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 757  (1.1):  76%|███████▌  | 757/1000 [00:23<00:07, 33.56it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 760  (1.1):  76%|███████▌  | 759/1000 [00:23<00:07, 33.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 762  (1.0):  76%|███████▌  | 761/1000 [00:23<00:07, 33.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 764  (1.0):  76%|███████▋  | 763/1000 [00:24<00:07, 33.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 766  (1.0):  76%|███████▋  | 765/1000 [00:24<00:06, 33.78it/s]2024-10-14T01:37:16.022478Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 767  (1.0):  77%|███████▋  | 766/1000 [00:24<00:06, 33.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 768  (1.0):  77%|███████▋  | 768/1000 [00:24<00:05, 40.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 769  (1.0):  77%|███████▋  | 768/1000 [00:24<00:05, 40.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 770  (1.0):  77%|███████▋  | 769/1000 [00:24<00:05, 40.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 771  (1.0):  77%|███████▋  | 770/1000 [00:24<00:05, 40.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 772  (1.0):  77%|███████▋  | 771/1000 [00:24<00:05, 40.63it/s]2024-10-14T01:37:16.117896Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 773  (1.0):  77%|███████▋  | 772/1000 [00:24<00:05, 40.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 774  (1.0):  77%|███████▋  | 774/1000 [00:24<00:04, 45.24it/s]2024-10-14T01:37:16.410880Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 775  (1.0):  77%|███████▋  | 774/1000 [00:24<00:04, 45.24it/s]2024-10-14T01:37:16.445001Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 776  (1.0):  78%|███████▊  | 775/1000 [00:24<00:04, 45.24it/s]2024-10-14T01:37:16.485033Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 777  (1.0):  78%|███████▊  | 776/1000 [00:24<00:04, 45.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 778  (1.0):  78%|███████▊  | 777/1000 [00:24<00:04, 45.24it/s]2024-10-14T01:37:16.496999Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 779  (1.0):  78%|███████▊  | 779/1000 [00:24<00:06, 32.81it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 780  (1.0):  78%|███████▊  | 779/1000 [00:24<00:06, 32.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 781  (1.0):  78%|███████▊  | 780/1000 [00:24<00:06, 32.81it/s]2024-10-14T01:37:16.589331Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 782  (1.0):  78%|███████▊  | 781/1000 [00:24<00:06, 32.81it/s]2024-10-14T01:37:16.742422Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 783  (1.0):  78%|███████▊  | 783/1000 [00:24<00:07, 27.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 784  (1.0):  78%|███████▊  | 783/1000 [00:24<00:07, 27.75it/s]2024-10-14T01:37:16.794230Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 785  (1.0):  78%|███████▊  | 784/1000 [00:24<00:07, 27.75it/s]2024-10-14T01:37:16.820379Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 787  (1.1):  79%|███████▊  | 787/1000 [00:24<00:07, 28.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 9.0 / 788  (1.1):  79%|███████▊  | 787/1000 [00:24<00:07, 28.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 789  (1.1):  79%|███████▉  | 788/1000 [00:24<00:07, 28.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 791  (1.1):  79%|███████▉  | 790/1000 [00:24<00:07, 28.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 792  (1.1):  79%|███████▉  | 791/1000 [00:24<00:07, 28.38it/s]2024-10-14T01:37:16.882504Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 793  (1.1):  79%|███████▉  | 793/1000 [00:24<00:06, 33.64it/s]error    4T01:37:16.903480Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 794  (1.1):  79%|███████▉  | 793/1000 [00:24<00:06, 33.64it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 795  (1.1):  79%|███████▉  | 794/1000 [00:24<00:06, 33.64it/s]2024-10-14T01:37:16.926739Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 796  (1.1):  80%|███████▉  | 795/1000 [00:24<00:06, 33.64it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 797  (1.1):  80%|███████▉  | 796/1000 [00:24<00:06, 33.64it/s]2024-10-14T01:37:16.943814Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 798  (1.1):  80%|███████▉  | 797/1000 [00:25<00:06, 33.64it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 799  (1.1):  80%|███████▉  | 799/1000 [00:25<00:05, 39.21it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 800  (1.1):  80%|███████▉  | 799/1000 [00:25<00:05, 39.21it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 801  (1.1):  80%|████████  | 800/1000 [00:25<00:05, 39.21it/s]2024-10-14T01:37:17.262528Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 802  (1.1):  80%|████████  | 801/1000 [00:25<00:05, 39.21it/s]2024-10-14T01:37:17.285948Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 804  (1.1):  80%|████████  | 804/1000 [00:25<00:05, 34.00it/s]2024-10-14T01:37:17.397256Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 805  (1.1):  80%|████████  | 804/1000 [00:25<00:05, 34.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 806  (1.1):  80%|████████  | 805/1000 [00:25<00:05, 34.00it/s]2024-10-14T01:37:17.408046Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 807  (1.1):  81%|████████  | 806/1000 [00:25<00:05, 34.00it/s]2024-10-14T01:37:17.447960Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 808  (1.1):  81%|████████  | 808/1000 [00:25<00:06, 30.64it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 809  (1.1):  81%|████████  | 808/1000 [00:25<00:06, 30.64it/s]2024-10-14T01:37:17.593979Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 813  (1.1):  81%|████████  | 812/1000 [00:25<00:06, 29.29it/s]2024-10-14T01:37:17.656055Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 814  (1.1):  81%|████████▏ | 813/1000 [00:25<00:06, 29.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 815  (1.1):  81%|████████▏ | 814/1000 [00:25<00:06, 29.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 816  (1.1):  82%|████████▏ | 815/1000 [00:25<00:06, 29.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 817  (1.1):  82%|████████▏ | 817/1000 [00:25<00:05, 32.95it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 818  (1.1):  82%|████████▏ | 817/1000 [00:25<00:05, 32.95it/s]2024-10-14T01:37:17.708404Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 819  (1.1):  82%|████████▏ | 818/1000 [00:25<00:05, 32.95it/s]2024-10-14T01:37:17.872875Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 821  (1.1):  82%|████████▏ | 821/1000 [00:25<00:05, 30.65it/s]2024-10-14T01:37:17.908211Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 822  (1.1):  82%|████████▏ | 821/1000 [00:25<00:05, 30.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 823  (1.1):  82%|████████▏ | 822/1000 [00:25<00:05, 30.65it/s]2024-10-14T01:37:17.941519Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 824  (1.1):  82%|████████▏ | 823/1000 [00:25<00:05, 30.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 825  (1.1):  82%|████████▏ | 824/1000 [00:25<00:05, 30.65it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 826  (1.1):  83%|████████▎ | 826/1000 [00:25<00:05, 33.95it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 828  (1.1):  83%|████████▎ | 827/1000 [00:26<00:05, 33.95it/s]2024-10-14T01:37:18.140940Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 830  (1.1):  83%|████████▎ | 830/1000 [00:26<00:05, 29.46it/s]2024-10-14T01:37:18.150133Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 831  (1.1):  83%|████████▎ | 830/1000 [00:26<00:05, 29.46it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 832  (1.1):  83%|████████▎ | 831/1000 [00:26<00:05, 29.46it/s]2024-10-14T01:37:18.189521Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 833  (1.1):  83%|████████▎ | 832/1000 [00:26<00:05, 29.46it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 834  (1.1):  83%|████████▎ | 833/1000 [00:26<00:05, 29.46it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 835  (1.1):  84%|████████▎ | 835/1000 [00:26<00:04, 33.07it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 836  (1.1):  84%|████████▎ | 835/1000 [00:26<00:04, 33.07it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 837  (1.1):  84%|████████▎ | 836/1000 [00:26<00:04, 33.07it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 839  (1.1):  84%|████████▍ | 839/1000 [00:26<00:07, 20.19it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 841  (1.1):  84%|████████▍ | 840/1000 [00:26<00:07, 20.19it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 842  (1.1):  84%|████████▍ | 841/1000 [00:26<00:07, 20.19it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 843  (1.1):  84%|████████▍ | 842/1000 [00:26<00:07, 20.19it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 844  (1.1):  84%|████████▍ | 844/1000 [00:26<00:06, 24.19it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 847  (1.1):  85%|████████▍ | 846/1000 [00:26<00:06, 24.19it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 849  (1.1):  85%|████████▍ | 848/1000 [00:26<00:06, 24.19it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 850  (1.1):  85%|████████▍ | 849/1000 [00:26<00:06, 24.19it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 851  (1.1):  85%|████████▌ | 851/1000 [00:26<00:04, 31.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 852  (1.1):  85%|████████▌ | 851/1000 [00:26<00:04, 31.70it/s]2024-10-14T01:37:18.764223Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 853  (1.1):  85%|████████▌ | 852/1000 [00:26<00:04, 31.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 854  (1.1):  85%|████████▌ | 853/1000 [00:26<00:04, 31.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 855  (1.1):  85%|████████▌ | 854/1000 [00:26<00:04, 31.70it/s]2024-10-14T01:37:18.782362Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 856  (1.1):  86%|████████▌ | 855/1000 [00:26<00:04, 31.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 857  (1.1):  86%|████████▌ | 857/1000 [00:26<00:03, 36.33it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 858  (1.0):  86%|████████▌ | 857/1000 [00:27<00:03, 36.33it/s]2024-10-14T01:37:18.819025Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 859  (1.0):  86%|████████▌ | 858/1000 [00:27<00:03, 36.33it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 860  (1.0):  86%|████████▌ | 859/1000 [00:27<00:03, 36.33it/s]2024-10-14T01:37:18.843665Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 861  (1.0):  86%|████████▌ | 860/1000 [00:27<00:03, 36.33it/s]2024-10-14T01:37:18.924020Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 862  (1.0):  86%|████████▌ | 862/1000 [00:27<00:03, 39.15it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 863  (1.0):  86%|████████▌ | 862/1000 [00:27<00:03, 39.15it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 864  (1.0):  86%|████████▋ | 863/1000 [00:27<00:03, 39.15it/s]2024-10-14T01:37:19.020873Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 865  (1.0):  86%|████████▋ | 864/1000 [00:27<00:03, 39.15it/s]2024-10-14T01:37:19.073334Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 866  (1.0):  86%|████████▋ | 865/1000 [00:27<00:03, 39.15it/s]2024-10-14T01:37:19.130632Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 867  (1.0):  87%|████████▋ | 866/1000 [00:27<00:03, 39.15it/s]2024-10-14T01:37:19.164803Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 868  (1.0):  87%|████████▋ | 868/1000 [00:27<00:03, 42.72it/s]2024-10-14T01:37:19.219277Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 869  (1.0):  87%|████████▋ | 868/1000 [00:27<00:03, 42.72it/s]2024-10-14T01:37:19.316954Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 870  (1.0):  87%|████████▋ | 869/1000 [00:27<00:03, 42.72it/s]2024-10-14T01:37:19.438387Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 872  (1.0):  87%|████████▋ | 871/1000 [00:27<00:03, 42.72it/s]2024-10-14T01:37:19.578480Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 873  (1.0):  87%|████████▋ | 873/1000 [00:27<00:04, 28.47it/s]error    4T01:37:19.585586Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 874  (1.0):  87%|████████▋ | 873/1000 [00:27<00:04, 28.47it/s]2024-10-14T01:37:19.600442Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 875  (1.0):  87%|████████▋ | 874/1000 [00:27<00:04, 28.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 876  (1.0):  88%|████████▊ | 875/1000 [00:27<00:04, 28.47it/s]2024-10-14T01:37:19.610154Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 877  (1.0):  88%|████████▊ | 876/1000 [00:27<00:04, 28.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 878  (1.0):  88%|████████▊ | 877/1000 [00:27<00:04, 28.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 879  (1.0):  88%|████████▊ | 879/1000 [00:27<00:03, 34.10it/s]2024-10-14T01:37:19.963655Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 880  (1.0):  88%|████████▊ | 879/1000 [00:27<00:03, 34.10it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 881  (1.0):  88%|████████▊ | 880/1000 [00:27<00:03, 34.10it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 882  (1.0):  88%|████████▊ | 881/1000 [00:27<00:03, 34.10it/s]2024-10-14T01:37:19.999093Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 883  (1.0):  88%|████████▊ | 882/1000 [00:28<00:03, 34.10it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 884  (1.0):  88%|████████▊ | 884/1000 [00:28<00:05, 22.91it/s]error    4T01:37:20.018136Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 885  (1.0):  88%|████████▊ | 884/1000 [00:28<00:05, 22.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 886  (1.0):  88%|████████▊ | 885/1000 [00:28<00:05, 22.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 887  (1.0):  89%|████████▊ | 886/1000 [00:28<00:04, 22.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 888  (1.0):  89%|████████▊ | 887/1000 [00:28<00:04, 22.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 889  (1.0):  89%|████████▉ | 888/1000 [00:28<00:04, 22.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 890  (1.0):  89%|████████▉ | 889/1000 [00:28<00:04, 22.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 891  (1.0):  89%|████████▉ | 891/1000 [00:28<00:03, 29.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 892  (1.0):  89%|████████▉ | 891/1000 [00:28<00:03, 29.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 893  (1.0):  89%|████████▉ | 892/1000 [00:28<00:03, 29.39it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 894  (1.0):  89%|████████▉ | 893/1000 [00:28<00:03, 29.39it/s]2024-10-14T01:37:20.113810Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 895  (1.0):  89%|████████▉ | 894/1000 [00:28<00:03, 29.39it/s]2024-10-14T01:37:20.399014Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 896  (1.0):  90%|████████▉ | 896/1000 [00:28<00:03, 29.08it/s]2024-10-14T01:37:20.422261Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 897  (1.0):  90%|████████▉ | 896/1000 [00:28<00:03, 29.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 898  (1.0):  90%|████████▉ | 897/1000 [00:28<00:03, 29.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 899  (1.0):  90%|████████▉ | 898/1000 [00:28<00:03, 29.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 900  (1.0):  90%|█████████ | 900/1000 [00:28<00:03, 30.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 901  (1.0):  90%|█████████ | 900/1000 [00:28<00:03, 30.63it/s]2024-10-14T01:37:20.465986Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 902  (1.0):  90%|█████████ | 901/1000 [00:28<00:03, 30.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 903  (1.0):  90%|█████████ | 902/1000 [00:28<00:03, 30.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 904  (1.0):  90%|█████████ | 903/1000 [00:28<00:03, 30.63it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 905  (1.0):  90%|█████████ | 904/1000 [00:28<00:03, 30.63it/s]2024-10-14T01:37:20.723980Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 906  (1.0):  91%|█████████ | 906/1000 [00:28<00:03, 28.89it/s] [Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 907  (1.0):  91%|█████████ | 906/1000 [00:28<00:03, 28.89it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 908  (1.0):  91%|█████████ | 907/1000 [00:28<00:03, 28.89it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 909  (1.0):  91%|█████████ | 908/1000 [00:28<00:03, 28.89it/s]2024-10-14T01:37:20.747931Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 910  (1.0):  91%|█████████ | 909/1000 [00:28<00:03, 28.89it/s]2024-10-14T01:37:20.760559Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 911  (1.0):  91%|█████████ | 911/1000 [00:28<00:02, 31.97it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 912  (1.0):  91%|█████████ | 911/1000 [00:28<00:02, 31.97it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 913  (1.0):  91%|█████████ | 912/1000 [00:28<00:02, 31.97it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 914  (1.0):  91%|█████████▏| 913/1000 [00:28<00:02, 31.97it/s]2024-10-14T01:37:20.837754Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 915  (1.0):  91%|█████████▏| 914/1000 [00:28<00:02, 31.97it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 916  (1.0):  92%|█████████▏| 915/1000 [00:28<00:02, 31.97it/s]2024-10-14T01:37:21.062027Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 917  (1.0):  92%|█████████▏| 917/1000 [00:29<00:02, 30.78it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 918  (1.0):  92%|█████████▏| 917/1000 [00:29<00:02, 30.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 919  (1.0):  92%|█████████▏| 918/1000 [00:29<00:02, 30.78it/s]2024-10-14T01:37:21.101302Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 920  (1.0):  92%|█████████▏| 919/1000 [00:29<00:02, 30.78it/s]2024-10-14T01:37:21.137204Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 921  (1.0):  92%|█████████▏| 920/1000 [00:29<00:02, 30.78it/s]2024-10-14T01:37:21.172480Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 922  (1.0):  92%|█████████▏| 922/1000 [00:29<00:02, 33.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 923  (1.0):  92%|█████████▏| 922/1000 [00:29<00:02, 33.80it/s]2024-10-14T01:37:21.322639Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 924  (1.0):  92%|█████████▏| 923/1000 [00:29<00:02, 33.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 925  (1.0):  92%|█████████▏| 924/1000 [00:29<00:02, 33.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 927  (1.1):  93%|█████████▎| 926/1000 [00:29<00:02, 28.78it/s] ror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 10.0 / 928  (1.1):  93%|█████████▎| 927/1000 [00:29<00:02, 28.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 929  (1.1):  93%|█████████▎| 928/1000 [00:29<00:02, 28.78it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 930  (1.1):  93%|█████████▎| 929/1000 [00:29<00:02, 28.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 931  (1.1):  93%|█████████▎| 931/1000 [00:29<00:02, 32.58it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 932  (1.1):  93%|█████████▎| 931/1000 [00:29<00:02, 32.58it/s]2024-10-14T01:37:21.440178Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 933  (1.1):  93%|█████████▎| 932/1000 [00:29<00:02, 32.58it/s]2024-10-14T01:37:21.640971Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 934  (1.1):  93%|█████████▎| 933/1000 [00:29<00:02, 32.58it/s]2024-10-14T01:37:21.646727Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 936  (1.2):  94%|█████████▎| 935/1000 [00:29<00:02, 27.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 938  (1.3):  94%|█████████▎| 937/1000 [00:29<00:02, 27.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 939  (1.3):  94%|█████████▍| 938/1000 [00:29<00:02, 27.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 940  (1.3):  94%|█████████▍| 939/1000 [00:29<00:02, 27.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 941  (1.3):  94%|█████████▍| 941/1000 [00:29<00:01, 33.66it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 942  (1.3):  94%|█████████▍| 941/1000 [00:29<00:01, 33.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 943  (1.3):  94%|█████████▍| 942/1000 [00:29<00:01, 33.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 944  (1.3):  94%|█████████▍| 943/1000 [00:29<00:01, 33.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 945  (1.3):  94%|█████████▍| 944/1000 [00:29<00:01, 33.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 946  (1.3):  94%|█████████▍| 945/1000 [00:29<00:01, 33.66it/s]2024-10-14T01:37:22.108996Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 947  (1.3):  95%|█████████▍| 947/1000 [00:30<00:01, 26.94it/s]2024-10-14T01:37:22.132452Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 949  (1.4):  95%|█████████▍| 948/1000 [00:30<00:01, 26.94it/s]2024-10-14T01:37:22.180460Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 950  (1.4):  95%|█████████▍| 949/1000 [00:30<00:01, 26.94it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 952  (1.4):  95%|█████████▌| 951/1000 [00:30<00:01, 27.89it/s]2024-10-14T01:37:22.214172Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 954  (1.4):  95%|█████████▌| 953/1000 [00:30<00:01, 27.89it/s]]024-10-14T01:37:22.230839Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 956  (1.5):  96%|█████████▌| 955/1000 [00:30<00:01, 27.89it/s]2024-10-14T01:37:22.245109Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 958  (1.5):  96%|█████████▌| 957/1000 [00:30<00:01, 27.89it/s]2024-10-14T01:37:22.254507Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 959  (1.5):  96%|█████████▌| 958/1000 [00:30<00:01, 27.89it/s]2024-10-14T01:37:22.257741Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 960  (1.5):  96%|█████████▌| 959/1000 [00:30<00:01, 27.89it/s]2024-10-14T01:37:22.272656Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 962  (1.5):  96%|█████████▌| 962/1000 [00:30<00:00, 43.58it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 963  (1.5):  96%|█████████▌| 962/1000 [00:30<00:00, 43.58it/s]2024-10-14T01:37:22.298409Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 964  (1.5):  96%|█████████▋| 963/1000 [00:30<00:00, 43.58it/s]2024-10-14T01:37:22.301706Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 965  (1.5):  96%|█████████▋| 964/1000 [00:30<00:00, 43.58it/s]2024-10-14T01:37:22.306113Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 966  (1.4):  96%|█████████▋| 965/1000 [00:30<00:00, 43.58it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 967  (1.4):  97%|█████████▋| 966/1000 [00:30<00:00, 43.58it/s]2024-10-14T01:37:22.355199Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 968  (1.4):  97%|█████████▋| 967/1000 [00:30<00:00, 43.58it/s]2024-10-14T01:37:22.373639Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 969  (1.4):  97%|█████████▋| 968/1000 [00:30<00:00, 43.58it/s]2024-10-14T01:37:22.402240Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 970  (1.4):  97%|█████████▋| 970/1000 [00:30<00:00, 51.12it/s]error    4T01:37:22.409755Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 971  (1.4):  97%|█████████▋| 970/1000 [00:30<00:00, 51.12it/s]2024-10-14T01:37:22.415452Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 972  (1.4):  97%|█████████▋| 971/1000 [00:30<00:00, 51.12it/s]2024-10-14T01:37:22.420746Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 973  (1.4):  97%|█████████▋| 972/1000 [00:30<00:00, 51.12it/s]2024-10-14T01:37:22.502928Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 975  (1.4):  97%|█████████▋| 974/1000 [00:30<00:00, 51.12it/s]2024-10-14T01:37:22.515514Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 976  (1.4):  98%|█████████▊| 975/1000 [00:30<00:00, 51.12it/s]2024-10-14T01:37:22.530163Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 977  (1.4):  98%|█████████▊| 977/1000 [00:30<00:00, 52.63it/s]error    4T01:37:22.537594Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 978  (1.4):  98%|█████████▊| 977/1000 [00:30<00:00, 52.63it/s]2024-10-14T01:37:22.548917Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 979  (1.4):  98%|█████████▊| 978/1000 [00:30<00:00, 52.63it/s]2024-10-14T01:37:22.565814Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 980  (1.4):  98%|█████████▊| 979/1000 [00:30<00:00, 52.63it/s]2024-10-14T01:37:22.570404Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 981  (1.4):  98%|█████████▊| 980/1000 [00:30<00:00, 52.63it/s]2024-10-14T01:37:22.581038Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 982  (1.4):  98%|█████████▊| 981/1000 [00:30<00:00, 52.63it/s]2024-10-14T01:37:22.584731Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 983  (1.4):  98%|█████████▊| 982/1000 [00:30<00:00, 52.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 984  (1.4):  98%|█████████▊| 983/1000 [00:30<00:00, 52.63it/s]2024-10-14T01:37:22.682873Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 990  (1.7):  99%|█████████▉| 989/1000 [00:32<00:00, 57.25it/s]2024-10-14T01:37:24.910761Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 992  (1.7):  99%|█████████▉| 992/1000 [00:32<00:00,  9.20it/s]2024-10-14T01:37:25.024482Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 998  (1.7): 100%|█████████▉| 997/1000 [00:35<00:00,  5.94it/s]2024-10-14T01:37:27.558131Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 1000  (1.7): 100%|██████████| 1000/1000 [00:36<00:00, 27.73it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s] rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 2 / 8  (25.0):   1%|          | 8/1000 [00:00<01:23, 11.93it/s]evaluate.pyxample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename= lineno=198\n",
      "Average Metric: 4 / 14  (28.6):   1%|▏         | 14/1000 [00:01<01:26, 11.37it/s]=rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 8 / 21  (38.1):   2%|▏         | 20/1000 [00:01<01:14, 13.23it/s] 024-10-14T01:37:28.682912Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filenameevaluate.pylineno=198\n",
      "Average Metric: 12 / 29  (41.4):   3%|▎         | 28/1000 [00:01<00:45, 21.33it/s] spy.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filenameevaluate.pylineno=198\n",
      "Average Metric: 14 / 35  (40.0):   3%|▎         | 34/1000 [00:01<00:32, 30.11it/s]lineno0-14T01:37:28.741329Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py =198\n",
      "Average Metric: 20 / 43  (46.5):   4%|▍         | 43/1000 [00:02<00:25, 37.17it/s]=[24-10-14T01:37:28.779135Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename=evaluate.py lineno198\n",
      "Average Metric: 22 / 49  (44.9):   5%|▍         | 48/1000 [00:02<00:26, 36.29it/s]198luate.py01:37:28.790029Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename= lineno=\n",
      "Average Metric: 26 / 57  (45.6):   6%|▌         | 56/1000 [00:02<00:22, 42.47it/s]=ilename 4T01:37:28.805825Z] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate =evaluate.py lineno198\n",
      "Average Metric: 29 / 63  (46.0):   6%|▋         | 63/1000 [00:02<00:22, 41.11it/s]= 24-10-14T01:37:28.812131Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filenameevaluate.pylineno198\n",
      "Average Metric: 35 / 71  (49.3):   7%|▋         | 70/1000 [00:02<00:22, 41.11it/s]198enofor example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py=\n",
      "Average Metric: 40.0 / 79  (50.6):   8%|▊         | 78/1000 [00:02<00:18, 50.93it/s] or    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.pylineno=198\n",
      "Average Metric: 47.0 / 87  (54.0):   9%|▊         | 86/1000 [00:02<00:15, 57.38it/s] ilename14T01:37:28.872974Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] evaluate.pylineno=198\n",
      "Average Metric: 53.0 / 96  (55.2):  10%|▉         | 95/1000 [00:03<00:15, 57.38it/s]evaluate.pyxample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 57.0 / 106  (53.8):  10%|█         | 105/1000 [00:03<00:15, 57.38it/s]linenote.pyte.evaluate30Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. = =198\n",
      "Average Metric: 64.0 / 115  (55.7):  11%|█▏        | 114/1000 [00:03<00:15, 57.38it/s]lineno0-14T01:37:28.924791Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 72.0 / 124  (58.1):  12%|█▏        | 123/1000 [00:03<00:15, 57.38it/s]1984-10-14T01:37:28.953016Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.pylineno=\n",
      "Average Metric: 78.0 / 132  (59.1):  13%|█▎        | 131/1000 [00:03<00:05, 147.83it/s] 24-10-14T01:37:28.953408Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filenameevaluate.pylineno=198\n",
      "Average Metric: 85.0 / 141  (60.3):  14%|█▍        | 140/1000 [00:03<00:05, 147.83it/s] spy.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.pylineno=198\n",
      "Average Metric: 91.0 / 152  (59.9):  15%|█▌        | 151/1000 [00:03<00:05, 147.83it/s]] 24-10-14T01:37:29.004847Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 97.0 / 164  (59.1):  16%|█▋        | 163/1000 [00:03<00:05, 147.83it/s]=ilenameluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] =evaluate.pylineno198\n",
      "Average Metric: 102.0 / 172  (59.3):  17%|█▋        | 171/1000 [00:03<00:05, 147.83it/s] ror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 110.0 / 182  (60.4):  18%|█▊        | 181/1000 [00:03<00:05, 147.83it/s]=spy.evaluate.evaluate5598Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filenameevaluate.py lineno=198\n",
      "Average Metric: 114.0 / 188  (60.6):  19%|█▊        | 187/1000 [00:03<00:02, 276.38it/s]linenote.pyte.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename= =198\n",
      "Average Metric: 115.0 / 197  (58.4):  20%|█▉        | 196/1000 [00:03<00:02, 276.38it/s]evaluate.py01:37:29.282675Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] = lineno=198\n",
      "Average Metric: 120.0 / 205  (58.5):  20%|██        | 204/1000 [00:03<00:02, 276.38it/s]=spy.evaluate.evaluate6765Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno198\n",
      "Average Metric: 125.0 / 215  (58.1):  21%|██▏       | 214/1000 [00:03<00:02, 276.38it/s]linenote.py01:37:29.363144Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename= =198\n",
      "Average Metric: 130.0 / 225  (57.8):  22%|██▏       | 224/1000 [00:03<00:02, 276.38it/s]=rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno198\n",
      "Average Metric: 134.0 / 234  (57.3):  23%|██▎       | 233/1000 [00:03<00:02, 276.38it/s]lineno0-14T01:37:29.444199Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename=evaluate.py =198\n",
      "Average Metric: 141.0 / 243  (58.0):  24%|██▍       | 242/1000 [00:03<00:02, 276.38it/s]198y.evaluate.evaluate3930Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=\n",
      "Average Metric: 147.0 / 251  (58.6):  25%|██▌       | 250/1000 [00:03<00:02, 358.85it/s] spy.evaluate.evaluate3573Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename=evaluate.pylineno=198\n",
      "Average Metric: 150.0 / 260  (57.7):  26%|██▌       | 259/1000 [00:03<00:02, 358.85it/s] 024-10-14T01:37:29.543034Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 151.0 / 271  (55.7):  27%|██▋       | 270/1000 [00:03<00:02, 358.85it/s]evaluate.py01:37:29.587405Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 151.0 / 279  (54.1):  28%|██▊       | 278/1000 [00:03<00:02, 358.85it/s] ilename14T01:37:29.593467Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] =evaluate.pylineno=198\n",
      "Average Metric: 151.0 / 288  (52.4):  29%|██▉       | 288/1000 [00:03<00:01, 384.34it/s]198enote.py01:37:29.644019Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= =\n",
      "Average Metric: 153.0 / 297  (51.5):  30%|██▉       | 296/1000 [00:03<00:01, 384.34it/s]]spy.evaluate.evaluate4418Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [ filename=evaluate.py lineno=198\n",
      "Average Metric: 154.0 / 307  (50.2):  31%|███       | 306/1000 [00:03<00:01, 384.34it/s]1984-10-14T01:37:29.937226Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 154.0 / 316  (48.7):  32%|███▏      | 315/1000 [00:03<00:01, 384.34it/s]dspy.evaluate.evaluate8379Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 154.0 / 328  (47.0):  33%|███▎      | 327/1000 [00:03<00:01, 384.34it/s]lineno   4T01:37:29.990598Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py=198\n",
      "Average Metric: 155.0 / 337  (46.0):  34%|███▎      | 336/1000 [00:03<00:01, 384.34it/s]198y.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=\n",
      "Average Metric: 157.0 / 346  (45.4):  34%|███▍      | 345/1000 [00:03<00:01, 384.34it/s]evaluate.pyte.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename= lineno=198\n",
      "Average Metric: 157.0 / 353  (44.5):  35%|███▌      | 352/1000 [00:03<00:01, 440.02it/s]=spy.evaluate.evaluatexample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filenameevaluate.py lineno198\n",
      "Average Metric: 158.0 / 363  (43.5):  36%|███▌      | 362/1000 [00:03<00:01, 440.02it/s]=rror    4T01:37:30.066588Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno198\n",
      "Average Metric: 162.0 / 371  (43.7):  37%|███▋      | 370/1000 [00:03<00:01, 440.02it/s] ilenameluate.evaluatexample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] =evaluate.pylineno=198\n",
      "Average Metric: 164.0 / 382  (42.9):  38%|███▊      | 381/1000 [00:03<00:01, 440.02it/s]lineno   4T01:37:30.122483Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filenameevaluate.py =198\n",
      "Average Metric: 168.0 / 393  (42.7):  39%|███▉      | 392/1000 [00:03<00:01, 440.02it/s]linenovaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename=evaluate.py =198\n",
      "Average Metric: 175.0 / 404  (43.3):  40%|████      | 403/1000 [00:03<00:01, 440.02it/s]=spy.evaluate.evaluate7424Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno198\n",
      "Average Metric: 177.0 / 411  (43.1):  41%|████      | 410/1000 [00:03<00:01, 491.07it/s]=rror    4T01:37:30.149693Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno198\n",
      "Average Metric: 180.0 / 420  (42.9):  42%|████▏     | 419/1000 [00:03<00:01, 491.07it/s]linenote.py01:37:30.245097Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename= =198\n",
      "Average Metric: 182.0 / 430  (42.3):  43%|████▎     | 429/1000 [00:03<00:01, 491.07it/s]198enote.py01:37:30.359810Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= =\n",
      "Average Metric: 185.0 / 441  (42.0):  44%|████▍     | 440/1000 [00:03<00:01, 491.07it/s]filenamer example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 186.0 / 451  (41.2):  45%|████▌     | 450/1000 [00:03<00:01, 491.07it/s]filename14T01:37:30.736514Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 189.0 / 461  (41.0):  46%|████▌     | 460/1000 [00:03<00:01, 491.07it/s] ilenamer example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.pylineno=198\n",
      "Average Metric: 189.0 / 469  (40.3):  47%|████▋     | 468/1000 [00:03<00:01, 491.07it/s]2024-10-14T01:37:31.140607Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 189.0 / 477  (39.6):  48%|████▊     | 476/1000 [00:03<00:00, 525.77it/s]]024-10-14T01:37:31.158965Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 189.0 / 486  (38.9):  48%|████▊     | 485/1000 [00:03<00:00, 525.77it/s]=rror    4T01:37:31.185788Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filenameevaluate.pylineno198\n",
      "Average Metric: 192.0 / 495  (38.8):  49%|████▉     | 494/1000 [00:03<00:00, 525.77it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 197.0 / 504  (39.1):  50%|█████     | 503/1000 [00:03<00:00, 525.77it/s]=ilename14T01:37:31.203582Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] =evaluate.pylineno198\n",
      "Average Metric: 201.0 / 514  (39.1):  51%|█████▏    | 513/1000 [00:03<00:00, 525.77it/s]linenome14T01:37:31.213179Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py =198\n",
      "Average Metric: 202.0 / 525  (38.5):  52%|█████▏    | 524/1000 [00:03<00:00, 525.77it/s] spy.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename=evaluate.py lineno=198\n",
      "Average Metric: 202.0 / 536  (37.7):  54%|█████▎    | 535/1000 [00:03<00:00, 553.44it/s]=rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filenameevaluate.pylineno198\n",
      "Average Metric: 202.0 / 547  (36.9):  55%|█████▍    | 546/1000 [00:03<00:00, 553.44it/s] [24-10-14T01:37:31.472972Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 351.0 / 1000  (35.1): 100%|██████████| 1000/1000 [00:04<00:00, 238.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating meta-llama/Llama-3.2-1B-Instruct:epochs-5-total-trained-steps-192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 63  (12.7):   6%|▌         | 62/1000 [00:07<02:05,  7.49it/s]2024-10-14T01:37:40.378553Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 236.0 / 1000  (23.6): 100%|██████████| 1000/1000 [01:26<00:00, 11.53it/s]\n",
      "Average Metric: 5 / 7  (71.4):   1%|          | 7/1000 [00:01<04:27,  3.71it/s]]rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 10 / 13  (76.9):   1%|▏         | 13/1000 [00:02<02:11,  7.49it/s]valuate.py:39:00.764158Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate = lineno=198\n",
      "Average Metric: 13 / 18  (72.2):   2%|▏         | 17/1000 [00:03<02:24,  6.81it/s]dspy.evaluate.evaluate5896Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 20 / 26  (76.9):   2%|▎         | 25/1000 [00:03<02:19,  6.99it/s]] 24-10-14T01:39:01.230898Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 26 / 34  (76.5):   3%|▎         | 33/1000 [00:03<02:18,  6.99it/s]1984-10-14T01:39:01.255466Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno=\n",
      "Average Metric: 33 / 42  (78.6):   4%|▍         | 41/1000 [00:03<02:17,  6.99it/s]=ilename14T01:39:01.263289Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno198\n",
      "Average Metric: 42 / 52  (80.8):   5%|▌         | 51/1000 [00:03<02:15,  6.99it/s]=spy.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filenameevaluate.py lineno=198\n",
      "Average Metric: 48 / 60  (80.0):   6%|▌         | 59/1000 [00:03<00:11, 83.92it/s]198y.evaluate.evaluate7615Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=\n",
      "Average Metric: 54 / 68  (79.4):   7%|▋         | 67/1000 [00:03<00:11, 83.92it/s]=[24-10-14T01:39:01.411909Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filenameevaluate.py lineno=198\n",
      "Average Metric: 63 / 79  (79.7):   8%|▊         | 78/1000 [00:03<00:10, 83.92it/s]linenofor example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 73 / 90  (81.1):   9%|▉         | 89/1000 [00:03<00:10, 83.92it/s]=[24-10-14T01:39:01.540584Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename=evaluate.py lineno198\n",
      "Average Metric: 80 / 99  (80.8):  10%|▉         | 98/1000 [00:03<00:10, 83.92it/s]linenote.py01:39:01.608588Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename= =198\n",
      "Average Metric: 87 / 108  (80.6):  11%|█         | 107/1000 [00:03<00:10, 83.92it/s]dspy.evaluate.evaluate327Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 96 / 117  (82.1):  12%|█▏        | 116/1000 [00:03<00:10, 83.92it/s]evaluate.pyte.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename= lineno=198\n",
      "Average Metric: 105 / 127  (82.7):  13%|█▎        | 126/1000 [00:03<00:04, 212.40it/s]=24-10-14T01:39:01.811464Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filenameevaluate.py lineno=198\n",
      "Average Metric: 113 / 136  (83.1):  14%|█▎        | 135/1000 [00:03<00:04, 212.40it/s]=[24-10-14T01:39:01.834442Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filenameevaluate.py lineno198\n",
      "Average Metric: 120 / 144  (83.3):  14%|█▍        | 143/1000 [00:03<00:04, 212.40it/s]  24-10-14T01:39:01.878390Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 128 / 154  (83.1):  15%|█▌        | 153/1000 [00:03<00:03, 212.40it/s]filename 4T01:39:01.919847Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate =evaluate.py lineno=198\n",
      "Average Metric: 133 / 160  (83.1):  16%|█▌        | 159/1000 [00:03<00:03, 212.40it/s]dspy.evaluate.evaluate5011Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 138 / 166  (83.1):  16%|█▋        | 165/1000 [00:03<00:03, 212.40it/s]=024-10-14T01:39:01.997490Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 141 / 171  (82.5):  17%|█▋        | 171/1000 [00:03<00:02, 294.32it/s]lineno0-14T01:39:02.009858Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filename=evaluate.py =198\n",
      "Average Metric: 144 / 178  (80.9):  18%|█▊        | 177/1000 [00:03<00:02, 294.32it/s] [24-10-14T01:39:02.024994Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 149 / 185  (80.5):  18%|█▊        | 184/1000 [00:03<00:02, 294.32it/s]filenameluate.evaluate4016Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] =evaluate.py lineno=198\n",
      "Average Metric: 151 / 196  (77.0):  20%|█▉        | 195/1000 [00:03<00:02, 294.32it/s]198ename14T01:39:02.434007Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]=evaluate.py lineno=\n",
      "Average Metric: 154 / 204  (75.5):  20%|██        | 203/1000 [00:03<00:02, 294.32it/s]=[24-10-14T01:39:02.897269Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 157 / 214  (73.4):  21%|██▏       | 213/1000 [00:03<00:02, 294.32it/s]1984-10-14T01:39:02.949118Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=\n",
      "Average Metric: 161 / 222  (72.5):  22%|██▏       | 221/1000 [00:03<00:02, 348.67it/s] ilename14T01:39:02.983594Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] =evaluate.pylineno=198\n",
      "Average Metric: 162 / 231  (70.1):  23%|██▎       | 230/1000 [00:03<00:02, 348.67it/s]=[24-10-14T01:39:03.014493Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 167 / 240  (69.6):  24%|██▍       | 239/1000 [00:03<00:02, 348.67it/s]lineno0-14T01:39:03.018697Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filenameevaluate.py =198\n",
      "Average Metric: 171 / 248  (69.0):  25%|██▍       | 247/1000 [00:03<00:02, 348.67it/s]=valuate.pyte.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename= lineno198\n",
      "Average Metric: 177 / 259  (68.3):  26%|██▌       | 258/1000 [00:03<00:02, 348.67it/s]= 24-10-14T01:39:03.228869Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 503.0 / 1000  (50.3): 100%|██████████| 1000/1000 [00:04<00:00, 233.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# Now we need to evaluate the test set\n",
    "best_non_base_model = max([x for x in ft_results.keys() if x != \"base\"], key=lambda x: ft_results[x][\"bfrs\"][\"devset\"])\n",
    "print(\"Best non-base model:\", best_non_base_model)\n",
    "base_and_best = {\"base\": all_llamas[\"base\"], best_non_base_model: all_llamas[best_non_base_model]}\n",
    "\n",
    "for folder, llama in base_and_best.items():\n",
    "    print(\"Evaluating\", folder)\n",
    "    vanilla_program = IntentClassificationModule()\n",
    "    \n",
    "    with dspy.context(lm=llama):\n",
    "        testset_result_vanilla = evaluate_testset(vanilla_program)\n",
    "        ft_results[folder][\"vanilla\"][\"testset\"] = testset_result_vanilla\n",
    "        vanilla_program.load(f\"simpleintent_1b_32_ft_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}_{folder.split('/')[-1]}.json\")\n",
    "        testset_result = evaluate_testset(vanilla_program)\n",
    "        ft_results[folder][\"bfrs\"][\"testset\"] = testset_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if False:\n",
    "    ft_results = json.load(open(\"ft_results.json\"))\n",
    "    print(ft_results)\n",
    "else:\n",
    "    with open(\"ft_results.json\", \"w\") as f:\n",
    "        json.dump(ft_results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base vanilla_devset 2.7 bfrs_devset 35.3 vanilla_testset 1.7 bfrs_testset 35.1\n",
      "Epoch 0 vanilla_devset 14.8 bfrs_devset 28.7 vanilla_testset None bfrs_testset None\n",
      "Epoch 1 vanilla_devset 14.5 bfrs_devset 34.9 vanilla_testset None bfrs_testset None\n",
      "Epoch 2 vanilla_devset 15.2 bfrs_devset 39.3 vanilla_testset None bfrs_testset None\n",
      "Epoch 3 vanilla_devset 18.1 bfrs_devset 47.3 vanilla_testset None bfrs_testset None\n",
      "Epoch 4 vanilla_devset 17.9 bfrs_devset 47.5 vanilla_testset None bfrs_testset None\n",
      "Epoch 5 vanilla_devset 19.0 bfrs_devset 50.2 vanilla_testset 23.6 bfrs_testset 50.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.2 Epoch 5 50.2\n",
      "best_vanilla_testset 23.6 best_bfrs_testset 50.3\n",
      "base_vanilla_testset 1.7 base_bfrs_testset 35.1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data for plotting\n",
    "models = []\n",
    "vanilla_devset = []\n",
    "bfrs_devset = []\n",
    "vanilla_testset = []\n",
    "bfrs_testset = []\n",
    "\n",
    "for model, results in ft_results.items():\n",
    "    if model == \"base\":\n",
    "        models.append(\"base\")\n",
    "    else:\n",
    "        models.append(\"Epoch \" + model.split(':')[1].split('-')[1])  # Extract epoch information\n",
    "    vanilla_devset.append(results['vanilla']['devset'])\n",
    "    bfrs_devset.append(results['bfrs']['devset'])\n",
    "    vanilla_testset.append(results['vanilla'].get('testset', None))\n",
    "    bfrs_testset.append(results['bfrs'].get('testset', None))\n",
    "\n",
    "# Sort the data by epoch, keeping \"base\" at the beginning\n",
    "sorted_data = sorted(zip(models, vanilla_devset, bfrs_devset, vanilla_testset, bfrs_testset),\n",
    "                     key=lambda x: (x[0] != \"base\", x[0]))\n",
    "models, vanilla_devset, bfrs_devset, vanilla_testset, bfrs_testset = zip(*sorted_data)\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(models[i], \"vanilla_devset\", vanilla_devset[i], \"bfrs_devset\", bfrs_devset[i], \"vanilla_testset\", vanilla_testset[i], \"bfrs_testset\", bfrs_testset[i])\n",
    "\n",
    "# Set up the plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "# Adjust bar positions and width\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "# Plot bars for Dev Set (top graph)\n",
    "ax1.bar(x - width/2, vanilla_devset, width, label='No Prompt Optimization', color='skyblue')\n",
    "ax1.bar(x + width/2, bfrs_devset, width, label='BootstrapFewShotRandomSearch', color='lightgreen')\n",
    "\n",
    "# Add value labels on top of each bar for Dev Set\n",
    "for i, v in enumerate(vanilla_devset):\n",
    "    ax1.text(i - width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "for i, v in enumerate(bfrs_devset):\n",
    "    ax1.text(i + width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Customize the Dev Set plot\n",
    "ax1.set_ylabel('Dev Set Scores')\n",
    "ax1.set_title('Model Performance Comparison Across Epochs (Synthetic Dev Set; N=1000)')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Find the highest devset score and its corresponding model\n",
    "highest_devset_score = max(bfrs_devset)\n",
    "highest_score_model = models[bfrs_devset.index(highest_devset_score)]\n",
    "\n",
    "print(highest_devset_score, highest_score_model, bfrs_devset[models.index(highest_score_model)])\n",
    "\n",
    "# Prepare data for the bottom graph\n",
    "# Prepare data for the bottom graph (Test Set)\n",
    "base_vanilla_testset = vanilla_testset[models.index(\"base\")]\n",
    "base_bfrs_testset = bfrs_testset[models.index(\"base\")]\n",
    "\n",
    "best_model_index = bfrs_devset.index(highest_devset_score)\n",
    "best_vanilla_testset = vanilla_testset[best_model_index]\n",
    "best_bfrs_testset = bfrs_testset[best_model_index]\n",
    "\n",
    "print(\"best_vanilla_testset\", best_vanilla_testset, \"best_bfrs_testset\", best_bfrs_testset)\n",
    "print(\"base_vanilla_testset\", base_vanilla_testset, \"base_bfrs_testset\", base_bfrs_testset)\n",
    "\n",
    "# Plot bars for Test Set (bottom graph)\n",
    "models_to_plot = [\"Base Model\", f\"Best Model ({highest_score_model})\"]\n",
    "x_test = np.arange(len(models_to_plot))\n",
    "\n",
    "ax2.bar(x_test - width/2, [base_vanilla_testset, best_vanilla_testset], width, label='No Prompt Optimization', color='skyblue')\n",
    "ax2.bar(x_test + width/2, [base_bfrs_testset, best_bfrs_testset], width, label='BootstrapFewShotRandomSearch', color='lightgreen')\n",
    "\n",
    "# Add value labels on top of each bar for Test Set\n",
    "for i, v in enumerate([base_vanilla_testset, best_vanilla_testset]):\n",
    "    ax2.text(i - width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "for i, v in enumerate([base_bfrs_testset, best_bfrs_testset]):\n",
    "    ax2.text(i + width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Customize the Test Set plot\n",
    "ax2.set_ylabel('Test Set Scores')\n",
    "ax2.set_title('Model Performance Comparison (Real Test Set; N=1000)')\n",
    "ax2.set_xticks(x_test)\n",
    "ax2.set_xticklabels(models_to_plot)\n",
    "ax2.legend()\n",
    "ax2.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, lets give the base 8B model a fair chance by prompt optimizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can compare all iterations of this pipeline\n",
    "print(f\"Results for HotPotQA fine-tuning LLaMa 8B with a starting trainset\")\n",
    "print(f\"    70B model (vanilla program): {llama_70b_base_eval}\")\n",
    "print(f\"    70B model (bfrs program): {llama_70b_bfrs_eval}\")\n",
    "print(f\"    8B model (vanilla program): {vanilla_8b_base_eval}\")\n",
    "print(f\"    8B model (bfrs program): {llama_8b_bfrs_eval}\")\n",
    "print(f\"    8B model (finetuned program): {llama_8b_finetuned_eval}\")\n",
    "print(f\"    8B model (finetuned bfrs program): {llama_8b_bfrs_finetuned_eval}\")\n",
    "print(f\"    8B model (finetuned mipro program): {llama_8b_ft_mipro_eval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"Stop here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving\n",
    "\n",
    "This is the second biggest unknown\n",
    "I imagine it to be easy, but crazier things have happened\n",
    "\n",
    "I need to keep a reference or link to the LLM forge job inside the LM.finetune method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how do I get the ray llm image!\n",
    "\n",
    "We'll start by running the rayllm CLI command below to start the workflow to generate the service yaml configuration:\n",
    "```bash\n",
    "mkdir /home/ray/default/deploy/services\n",
    "cd /home/ray/default/deploy/services\n",
    "rayllm gen-config \n",
    "```\n",
    "\n",
    "<img src=\"assets/cli.png\" width=500 alt=\"todo! get this inage of what I need to serve\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"background-color: yellow;\">&nbsp;🛑 IMPORTANT&nbsp;</b>: Please `Terminate` your service from the Service page to avoid depleting your free trial credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "!python src/clear_cell_nums.py\n",
    "!find . | grep -E \".ipynb_checkpoints\" | xargs rm -rf\n",
    "!find . | grep -E \"(__pycache__|\\.pyc|\\.pyo)\" | xargs rm -rf\n",
    "!rm -rf __pycache__ data .HF_TOKEN deploy/services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MARK: Ensemble - To Be Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import Ensemble\n",
    "\n",
    "# testing ensemble\n",
    "top_programs = []\n",
    "\n",
    "for folder, llama in all_llamas.items():\n",
    "    with dspy.context(lm=llama):\n",
    "        vanilla_program = IntentClassificationModule()\n",
    "        bfrs_finetuned_program = bfrs_optimizer.compile(vanilla_program, trainset=optimizer_trainset, valset=optimizer_valset)\n",
    "        devset_result = evaluate_devset(bfrs_finetuned_program)\n",
    "\n",
    "        def wrapped_program(*args, **kwargs):\n",
    "            with dspy.context(lm=llama):\n",
    "                return bfrs_finetuned_program(*args, **kwargs)\n",
    "        top_programs.append((wrapped_program, llama, devset_result))\n",
    "\n",
    "top_3_devset = sorted(top_programs, key=lambda x: x[2], reverse=True)[:3]\n",
    "\n",
    "teleprompter = Ensemble(reduce_fn=dspy.majority, size=None)\n",
    "# print(top_3_devset)\n",
    "programs = [p[0] for p in top_3_devset]\n",
    "# print(programs)\n",
    "compiled_program = teleprompter.compile(programs)\n",
    "# # print(compiled_program)\n",
    "eval_result = evaluate_devset(compiled_program)\n",
    "eval_testset = evaluate_testset(compiled_program)\n",
    "print(f\"result for best_ensemble: {eval_result}, {eval_true_labels}, {eval_testset}\")\n",
    "ft_results[folder][\"best_ensemble\"] = {\"devset\": eval_result, \"true_labels\": eval_true_labels, \"testset\": eval_testset}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MARK: Prediction no CoT - To Be Removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(experimental=True)\n",
    "\n",
    "from dspy.teleprompt.finetune_teleprompter import bootstrap_data, bootstrap_data_for_round, convert_to_module_level_message_data    \n",
    "\n",
    "class IntentClassificationPredictModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.intent_classifier = dspy.Predict(IntentClassification)\n",
    "        self.valid_labels = set([\"activate_my_card\", \"cancel_transfer\", \"cash_withdrawal_charge\", \"declined_card_payment\", \"declined_cash_withdrawal\", \"direct_debit_payment_not_recognised\", \"extra_charge_on_statement\", \"pending_card_payment\", \"pending_top_up\", \"Refund_not_showing_up\", \"request_refund\", \"reverted_card_payment\", \"transaction_charged_twice\", \"transfer_fee_charged\", \"transfer_not_received_by_recipient\", \"wrong_amount_of_cash_received\", \"wrong_exchange_rate_for_cash_withdrawal\"])\n",
    "\n",
    "    def forward(self, text):\n",
    "        prediction = self.intent_classifier(intent=text)\n",
    "        sanitized_prediction = dspy.Prediction(label=prediction.label.lower().strip().replace(\" \", \"_\"))\n",
    "        # if sanitized_prediction.label not in self.valid_labels:\n",
    "        #     for label in self.valid_labels:\n",
    "        #         if label in sanitized_prediction.label:\n",
    "        #             sanitized_prediction.label = label\n",
    "        #             break\n",
    "        #     # this means that the prediction was not in the valid labels\n",
    "        #     # Could do edit distance or something more sophisticated here\n",
    "        #     # but for now just take the first\n",
    "        #     sanitized_prediction.label = self.valid_labels[0]\n",
    "        return sanitized_prediction\n",
    "\n",
    "def convert_examples_to_messages(examples):\n",
    "    manual_traces = []\n",
    "    module = IntentClassificationPredictModule()\n",
    "    for example in examples:\n",
    "        example[\"intent\"] = example[\"text\"]\n",
    "        example = example.with_inputs(\"intent\")\n",
    "        manual_traces.append((module.intent_classifier, example.inputs(), example))\n",
    "\n",
    "    data = []\n",
    "    # traces are (pred, inputs, outputs)\n",
    "    adapter = dspy.ChatAdapter()\n",
    "    for pred, inputs, outputs in manual_traces:\n",
    "        messages = adapter.format(pred.signature, [], inputs)\n",
    "        formatted_completion = adapter.format_completion(pred.signature, outputs)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": formatted_completion})\n",
    "        data.append({\"messages\": messages})\n",
    "\n",
    "    return data\n",
    "\n",
    "train_path = f\"ft_trainset_data_banking_no_cot_{len(ft_trainset)}.jsonl\"\n",
    "eval_path = f\"ft_valset_data_banking_no_cot_{len(devset)}.jsonl\"\n",
    "\n",
    "write_jsonl(train_path, convert_examples_to_messages(ft_trainset))\n",
    "write_jsonl(eval_path, convert_examples_to_messages(devset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.modules.lm import TrainingMethod\n",
    "\n",
    "\n",
    "method = TrainingMethod.SFT\n",
    "\n",
    "kwargs = {\n",
    "    \"hyperparameters\": {\n",
    "        \"num_devices\": 4,\n",
    "        \"trainer_resources\": None,\n",
    "        \"worker_resources\": None,\n",
    "        \"generation_config\": {\n",
    "            \"prompt_format\": {\n",
    "                \"system\": \"<|start_header_id|>system<|end_header_id|>\\n\\n{instruction}<|eot_id|>\",\n",
    "                \"user\": \"<|start_header_id|>user<|end_header_id|>\\n{instruction}<|eot_id|>\",\n",
    "                \"assistant\": \"<|start_header_id|>assistant<|end_header_id|>\\n\\n{instruction}<|eot_id|>\",\n",
    "                \"trailing_assistant\": \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    "                \"bos\": \"<|begin_of_text|>\",\n",
    "                \"system_in_user\": False,\n",
    "                \"default_system_message\": \"\"\n",
    "            },\n",
    "        },\n",
    "        \"learning_rate\": 3e-5,\n",
    "        \"num_epochs\": 6,\n",
    "        \"train_batch_size_per_device\": 32\n",
    "    },\n",
    "    \"use_lora\": True,\n",
    "    # TODO: I think this needs to be set dynamically\n",
    "    # \"lora_dynamic_folder\": \"dspy/lora_weights/prodjob_qmulcjw4x8z599m8hkyja8tbmi/meta-llama/Llama-3.2-1B-Instruct\"\n",
    "}\n",
    "\n",
    "SKIP_FT = False\n",
    "if not SKIP_FT:\n",
    "    # TODO: Get job working with LLMForge\n",
    "    student_llama_1b = dspy.TrainableAnyscale(model=\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "    future = student_llama_1b.get_finetune(method, train_path, eval_path, **kwargs)\n",
    "    checkpoint_names = future.result()\n",
    "\n",
    "    model_names = checkpoint_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "if True:\n",
    "    with open(\"model_names_predict.json\", \"r\") as f:\n",
    "        model_names = json.load(f)\n",
    "else:\n",
    "    with open(\"model_names_predict.json\", \"w\") as f:\n",
    "        json.dump(checkpoint_names, f)\n",
    "    # model_names = checkpoint_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command for easy copying: \n",
    "\n",
    "llama_1b = dspy.LM(model=\"openai/meta-llama/Llama-3.2-1B-Instruct\", **LOCAL_API_PARAMETERS, **MODEL_PARAMETERS)\n",
    "finetuned_llamas_1b = {f: dspy.LM(model=\"openai/\" + f, **LOCAL_API_PARAMETERS, **MODEL_PARAMETERS) for f in model_names}\n",
    "all_llamas = {**finetuned_llamas_1b, \"base\": llama_1b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x.model for x in all_llamas.values()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collected_data_filtered[0]\n",
    "def collected_data_to_example(data):\n",
    "    return dspy.Example(text=data[\"example\"][\"text\"], label=data[\"prediction\"][\"label\"]).with_inputs(\"text\")\n",
    "\n",
    "collected_data_examples = [collected_data_to_example(x) for x in collected_data_filtered]\n",
    "# collected_data_examples[0]\n",
    "\n",
    "devset_synthetic = collected_data_examples[:DEV_SIZE]\n",
    "ft_optimizer_devset = collected_data_examples[DEV_SIZE:DEV_SIZE+OPTIMIZER_NUM_VAL]\n",
    "ft_optimizer_trainset = collected_data_examples[DEV_SIZE+OPTIMIZER_NUM_VAL:]\n",
    "\n",
    "evaluate_devset = Evaluate(devset=devset_synthetic, metric=metric, num_threads=NUM_THREADS, display_progress=True, max_errors=10000)\n",
    "\n",
    "print(len(devset_synthetic), len(ft_optimizer_trainset), len(ft_optimizer_devset))\n",
    "print(devset_synthetic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPILE_PROGRAM = True\n",
    "\n",
    "dspy.settings.configure(experimental=True, lm=None)\n",
    "\n",
    "ft_results = {}\n",
    "for folder, llama in all_llamas.items():\n",
    "    ft_results[folder] = {}\n",
    "    vanilla_program = IntentClassificationModule()\n",
    "    with dspy.context(lm=llama):\n",
    "        devset_result = evaluate_devset(vanilla_program)\n",
    "        ft_results[folder][\"vanilla\"] = {\"devset\": devset_result, \"testset\": None}\n",
    "\n",
    "        if COMPILE_PROGRAM:\n",
    "            bfrs_finetuned_program = bfrs_optimizer.compile(vanilla_program, trainset=ft_optimizer_trainset, valset=ft_optimizer_devset)\n",
    "            bfrs_finetuned_program.save(f\"simpleintent_predict_1b_32_ft_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}_{folder.split('/')[-1]}.json\")\n",
    "        else:\n",
    "            bfrs_finetuned_program = IntentClassificationModule()\n",
    "            bfrs_finetuned_program.load(f\"simpleintent_predict_1b_32_ft_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}_{folder.split('/')[-1]}.json\")\n",
    "        \n",
    "        llama_8b_bfrs_finetuned_eval = evaluate_devset(bfrs_finetuned_program)\n",
    "        ft_results[folder][\"bfrs\"] = {\"devset\": llama_8b_bfrs_finetuned_eval, \"true_labels\": None, \"testset\": None}\n",
    "        print(f\"result for {folder}: {llama_8b_bfrs_finetuned_eval}, None, None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_ft_results = json.load(open(\"ft_results.json\", \"r\"))\n",
    "combined_ft_results = {\"cot\": original_ft_results, \"no_cot\": ft_results}\n",
    "\n",
    "combined_ft_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data for plotting\n",
    "models = []\n",
    "vanilla_devset = []\n",
    "bfrs_devset = []\n",
    "vanilla_testset = []\n",
    "bfrs_testset = []\n",
    "\n",
    "for model, results in ft_results.items():\n",
    "    if model == \"base\":\n",
    "        models.append(\"base\")\n",
    "    else:\n",
    "        models.append(\"Epoch \" + model.split(':')[1].split('-')[1])  # Extract epoch information\n",
    "    vanilla_devset.append(results['vanilla']['devset'])\n",
    "    bfrs_devset.append(results['bfrs']['devset'])\n",
    "    vanilla_testset.append(results['vanilla']['testset'])\n",
    "    bfrs_testset.append(results['bfrs']['testset'])\n",
    "\n",
    "# Sort the data by epoch, keeping \"base\" at the beginning\n",
    "sorted_data = sorted(zip(models, vanilla_devset, bfrs_devset, vanilla_testset, bfrs_testset),\n",
    "                     key=lambda x: (x[0] != \"base\", x[0]))\n",
    "models, vanilla_devset, bfrs_devset, vanilla_testset, bfrs_testset = zip(*sorted_data)\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(models[i], \"vanilla_devset\", vanilla_devset[i], \"bfrs_devset\", bfrs_devset[i], \"vanilla_testset\", vanilla_testset[i], \"bfrs_testset\", bfrs_testset[i])\n",
    "\n",
    "# Set up the plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "# Adjust bar positions and width\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "# Plot bars for Dev Set (top graph)\n",
    "ax1.bar(x - width/2, vanilla_devset, width, label='Vanilla Dev', color='skyblue')\n",
    "ax1.bar(x + width/2, bfrs_devset, width, label='BFRS Dev', color='lightgreen')\n",
    "\n",
    "# Add value labels on top of each bar for Dev Set\n",
    "for i, v in enumerate(vanilla_devset):\n",
    "    ax1.text(i - width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "for i, v in enumerate(bfrs_devset):\n",
    "    ax1.text(i + width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Customize the Dev Set plot\n",
    "ax1.set_ylabel('Dev Set Scores')\n",
    "ax1.set_title('Model Performance Comparison Across Epochs (Dev Set)')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Find the highest devset score and its corresponding model\n",
    "highest_devset_score = max(bfrs_devset)\n",
    "highest_score_model = models[bfrs_devset.index(highest_devset_score)]\n",
    "\n",
    "print(highest_devset_score, highest_score_model, bfrs_devset[models.index(highest_score_model)])\n",
    "\n",
    "# Prepare data for the bottom graph\n",
    "# Prepare data for the bottom graph (Test Set)\n",
    "base_vanilla_testset = vanilla_testset[models.index(\"base\")]\n",
    "base_bfrs_testset = bfrs_testset[models.index(\"base\")]\n",
    "\n",
    "best_model_index = bfrs_devset.index(highest_devset_score)\n",
    "best_vanilla_testset = vanilla_testset[best_model_index]\n",
    "best_bfrs_testset = bfrs_testset[best_model_index]\n",
    "\n",
    "print(\"best_vanilla_testset\", best_vanilla_testset, \"best_bfrs_testset\", best_bfrs_testset)\n",
    "print(\"base_vanilla_testset\", base_vanilla_testset, \"base_bfrs_testset\", base_bfrs_testset)\n",
    "\n",
    "# Plot bars for Test Set (bottom graph)\n",
    "models_to_plot = [\"Base Model\", f\"Best Model ({highest_score_model})\"]\n",
    "x_test = np.arange(len(models_to_plot))\n",
    "\n",
    "ax2.bar(x_test - width/2, [base_vanilla_testset, best_vanilla_testset], width, label='Vanilla Test', color='coral')\n",
    "ax2.bar(x_test + width/2, [base_bfrs_testset, best_bfrs_testset], width, label='BFRS Test', color='lightseagreen')\n",
    "\n",
    "# Add value labels on top of each bar for Test Set\n",
    "for i, v in enumerate([base_vanilla_testset, best_vanilla_testset]):\n",
    "    ax2.text(i - width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "for i, v in enumerate([base_bfrs_testset, best_bfrs_testset]):\n",
    "    ax2.text(i + width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Customize the Test Set plot\n",
    "ax2.set_ylabel('Test Set Scores')\n",
    "ax2.set_title('Model Performance Comparison (Test Set)')\n",
    "ax2.set_xticks(x_test)\n",
    "ax2.set_xticklabels(models_to_plot)\n",
    "ax2.legend()\n",
    "ax2.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # {'cot': {'meta-llama/Llama-3.2-1B-Instruct:epochs-2-total-trained-steps-69': {'vanilla': {'devset': 26.2,\n",
    "#     'testset': 28.4},\n",
    "#    'bfrs': {'devset': 32.4, 'true_labels': None, 'testset': 32.4}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-5-total-trained-steps-138': {'vanilla': {'devset': 28.8,\n",
    "#     'testset': 32.3},\n",
    "#    'bfrs': {'devset': 42.0, 'true_labels': None, 'testset': 43.1}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-4-total-trained-steps-115': {'vanilla': {'devset': 28.2,\n",
    "#     'testset': 32.5},\n",
    "#    'bfrs': {'devset': 37.2, 'true_labels': None, 'testset': 38.6}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-3-total-trained-steps-92': {'vanilla': {'devset': 30.2,\n",
    "#     'testset': 34.1},\n",
    "#    'bfrs': {'devset': 38.4, 'true_labels': None, 'testset': 37.5}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-1-total-trained-steps-46': {'vanilla': {'devset': 15.6,\n",
    "#     'testset': 14.6},\n",
    "#    'bfrs': {'devset': 27.6, 'true_labels': None, 'testset': 29.0}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-0-total-trained-steps-23': {'vanilla': {'devset': 22.6,\n",
    "#     'testset': 20.4},\n",
    "#    'bfrs': {'devset': 29.0, 'true_labels': None, 'testset': 32.1}},\n",
    "#   'base': {'vanilla': {'devset': 1.4, 'testset': 1.9},\n",
    "#    'bfrs': {'devset': 27.8, 'true_labels': None, 'testset': 28.9}}},\n",
    "#  'no_cot': {'meta-llama/Llama-3.2-1B-Instruct:epochs-0-total-trained-steps-29': {'vanilla': {'devset': 21.4,\n",
    "#     'testset': 22.2},\n",
    "#    'bfrs': {'devset': 34.8, 'true_labels': None, 'testset': 37.9}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-5-total-trained-steps-174': {'vanilla': {'devset': 43.8,\n",
    "#     'testset': 45.1},\n",
    "#    'bfrs': {'devset': 43.8, 'true_labels': None, 'testset': 45.1}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-1-total-trained-steps-58': {'vanilla': {'devset': 14.6,\n",
    "#     'testset': 16.3},\n",
    "#    'bfrs': {'devset': 34.4, 'true_labels': None, 'testset': 36.2}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-2-total-trained-steps-87': {'vanilla': {'devset': 37.8,\n",
    "#     'testset': 41.8},\n",
    "#    'bfrs': {'devset': 37.8, 'true_labels': None, 'testset': 41.8}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-4-total-trained-steps-145': {'vanilla': {'devset': 45.0,\n",
    "#     'testset': 46.3},\n",
    "#    'bfrs': {'devset': 45.0, 'true_labels': None, 'testset': 46.3}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-3-total-trained-steps-116': {'vanilla': {'devset': 45.2,\n",
    "#     'testset': 45.9},\n",
    "#    'bfrs': {'devset': 45.2, 'true_labels': None, 'testset': 45.9}},\n",
    "#   'base': {'vanilla': {'devset': 9.4, 'testset': 8.6},\n",
    "#    'bfrs': {'devset': 36.4, 'true_labels': None, 'testset': 38.8}}}}\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def extract_data(results, key):\n",
    "    return {\n",
    "        model: {\n",
    "            'vanilla': data['vanilla'][key],\n",
    "            'bfrs': data['bfrs'][key]\n",
    "        }\n",
    "        for model, data in results.items()\n",
    "    }\n",
    "\n",
    "cot_devset = extract_data(combined_ft_results['cot'], 'devset')\n",
    "no_cot_devset = extract_data(combined_ft_results['no_cot'], 'devset')\n",
    "print(no_cot_devset)\n",
    "\n",
    "# Prepare data for plotting\n",
    "models = list(cot_devset.keys())\n",
    "x = np.arange(len(models))\n",
    "width = 0.2\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 20))\n",
    "\n",
    "# Top graph\n",
    "ax1.bar(x - 1.5*width, [cot_devset[m]['vanilla'] for m in models], width, label='CoT Vanilla')\n",
    "ax1.bar(x - 0.5*width, [cot_devset[m]['bfrs'] for m in models], width, label='CoT BFRS')\n",
    "ax1.bar(x + 0.5*width, [no_cot_devset[m]['vanilla'] for m in models], width, label='No CoT Vanilla')\n",
    "ax1.bar(x + 1.5*width, [no_cot_devset[m]['bfrs'] for m in models], width, label='No CoT BFRS')\n",
    "\n",
    "ax1.set_ylabel('Devset Score')\n",
    "ax1.set_title('CoT vs No CoT: Vanilla and BFRS on Devset')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "\n",
    "# Find best models\n",
    "best_cot = max(cot_devset.items(), key=lambda x: x[1]['bfrs'])[0]\n",
    "best_no_cot = max(no_cot_devset.items(), key=lambda x: x[1]['bfrs'])[0]\n",
    "\n",
    "# Bottom graph\n",
    "models = ['Best CoT', 'Best No CoT']\n",
    "x = np.arange(len(models))\n",
    "\n",
    "cot_data = ft_results['cot'][best_cot]\n",
    "no_cot_data = ft_results['no_cot'][best_no_cot]\n",
    "\n",
    "ax2.bar(x - 1.5*width, [cot_data['vanilla']['devset'], no_cot_data['vanilla']['devset']], width, label='Vanilla Devset')\n",
    "ax2.bar(x - 0.5*width, [cot_data['bfrs']['devset'], no_cot_data['bfrs']['devset']], width, label='BFRS Devset')\n",
    "ax2.bar(x + 0.5*width, [cot_data['vanilla']['testset'], no_cot_data['vanilla']['testset']], width, label='Vanilla Testset')\n",
    "ax2.bar(x + 1.5*width, [cot_data['bfrs']['testset'], no_cot_data['bfrs']['testset']], width, label='BFRS Testset')\n",
    "\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.set_title('Best CoT vs Best No CoT: Devset and Testset Results')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(models)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MARK: Mipro\n",
    "# from dspy.teleprompt import MIPROv2\n",
    "\n",
    "# eval_kwargs = dict(display_progress=True, display_table=0, num_threads=NUM_THREADS)\n",
    "# teleprompter = MIPROv2(prompt_model=llama_70b, task_model=llama_70b, metric=metric, num_candidates=10, init_temperature=0.9, verbose=True)\n",
    "\n",
    "# COMPILE_PROGRAM = True\n",
    "# if COMPILE_PROGRAM:\n",
    "#     with dspy.context(lm=llama_70b):\n",
    "#         compiled_program = teleprompter.compile(vanilla_program, trainset=optimizer_trainset, valset=optimizer_valset, num_batches=30, max_bootstrapped_demos=MAX_BOOTSTRAPPED_DEMOS,max_labeled_demos=MAX_LABELED_DEMOS, eval_kwargs=eval_kwargs, requires_permission_to_run=False)\n",
    "#         compiled_program.save(f\"t2sql_70b_31_MIPROv2_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}.json\")\n",
    "# else:\n",
    "#     compiled_program = TextToSQLModule()\n",
    "#     compiled_program.load(f\"t2sql_70b_31_MIPROv2_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}.json\")\n",
    "\n",
    "# with dspy.context(lm=llama_70b):\n",
    "#     llama_70b_mipro_eval = evaluate_devset(compiled_program)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
