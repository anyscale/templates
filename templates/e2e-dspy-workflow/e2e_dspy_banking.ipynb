{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end DSPy Workflows Guide "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Motivation - have this problem and going to solve it with dspy and that is why we believe ti is the right solution\n",
    "\n",
    "This guide will cover the following topics:\n",
    "\n",
    "## Creating a Multi-stage LLM Pipeline\n",
    "- Building a pipeline with an untuned model in DSPy\n",
    "- Implementing batch inference (using Ray data)\n",
    "\n",
    "## Improving the Pipeline\n",
    "1. Prompt optimization\n",
    "2. Fine-tuning\n",
    "    - How to make an 8B model perform almost as well as a 70B model in your pipeline\n",
    "3. Combining fine-tuning with prompt optimization\n",
    "\n",
    "## Deployment\n",
    "- Steps to deploy the optimized pipeline and fine-tuned model to production\n",
    "\n",
    "## Future Work and Open Questions\n",
    "- Efficient batch inference with a DSPy pipeline\n",
    "- Exploring different fine-tuning methods and hyperparameter sweeps\n",
    "\n",
    "This guide aims to provide a comprehensive overview of building, optimizing, and deploying LLM pipelines using DSPy and Anyscale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node Set up:\n",
    "\n",
    "We will be running everything on a head node that uses 4xA100-80GB GPUs. I find that L4s are usually available and suitable for this usecase. You can also use any more powerful node.\n",
    "\n",
    "To change to use A100 GPUs, click the \"1 active node\" in the top right corner, then for workspace node, click the pencil icon and navigate to the A100 tab and select the 4xA100 option. If you do not see A100 in the list of GPUs, they may not be available on your cloud. Choose another kind of GPU (This notebook has been tested on X, and Y as alternatives) (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(work): DSPy installation cell\n",
    "# TODO(decision): are these changes going to be merged into DSPy main\n",
    "\n",
    "# TODO: look at my own init file to see all the stupid extra pip installs\n",
    "\n",
    "# !pip install -e dspy-d\n",
    "# !pip install -r dspy-d/requirements.txt\n",
    "# !pip install vllm\n",
    "\n",
    "# ignore future warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "import dsp\n",
    "import os\n",
    "import ujson\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# TODO: include cache in notebook\n",
    "cache_dir = \"/home/ray/default/dspy/cache\"\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "# I have included a .env.example with the necessary environment variables to be set\n",
    "# You can also set them manually if you prefer\n",
    "\n",
    "os.environ[\"DSP_CACHEDIR\"] = cache_dir\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "necessary_env_vars = [\n",
    "    \"DSP_CACHEDIR\",\n",
    "    \"HF_TOKEN\",\n",
    "    \"HF_HOME\"\n",
    "]\n",
    "\n",
    "for var in necessary_env_vars:\n",
    "    assert os.environ[var], f\"{var} is not set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 23:47:29,464\tINFO worker.py:1601 -- Connecting to existing Ray cluster at address: 10.0.15.218:6379...\n",
      "2024-10-07 23:47:29,473\tINFO worker.py:1777 -- Connected to Ray cluster. View the dashboard at https://session-fkvdirx4bzefi53sjl55m7asad.i.anyscaleuserdata.com \n",
      "2024-10-07 23:47:29,499\tINFO packaging.py:531 -- Creating a file package for local directory '/home/ray/default/dspy/dspy'.\n",
      "2024-10-07 23:47:29,531\tINFO packaging.py:359 -- Pushing file package 'gcs://_ray_pkg_6743b1324906ffbb.zip' (0.89MiB) to Ray cluster...\n",
      "2024-10-07 23:47:29,541\tINFO packaging.py:372 -- Successfully pushed file package 'gcs://_ray_pkg_6743b1324906ffbb.zip'.\n",
      "2024-10-07 23:47:29,554\tINFO packaging.py:531 -- Creating a file package for local directory '/home/ray/default/dspy/dsp'.\n",
      "2024-10-07 23:47:29,576\tINFO packaging.py:359 -- Pushing file package 'gcs://_ray_pkg_bb60ed915e68a449.zip' (0.64MiB) to Ray cluster...\n",
      "2024-10-07 23:47:29,579\tINFO packaging.py:372 -- Successfully pushed file package 'gcs://_ray_pkg_bb60ed915e68a449.zip'.\n",
      "2024-10-07 23:47:30,016\tINFO packaging.py:359 -- Pushing file package 'gcs://_ray_pkg_fb5662e481777cf8365085d64d31d2c1a0cf4667.zip' (154.16MiB) to Ray cluster...\n",
      "2024-10-07 23:47:31,743\tINFO packaging.py:372 -- Successfully pushed file package 'gcs://_ray_pkg_fb5662e481777cf8365085d64d31d2c1a0cf4667.zip'.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "if not ray.is_initialized():\n",
    "    ray.init(runtime_env={\"env_vars\": os.environ, \"py_modules\": [dspy, dsp]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of a random number generator in this notebook. We are creating a Random object here to ensure that our notebook is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rng = random.Random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating your multi-stage LLM pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.datasets import HotPotQA\n",
    "from dspy.evaluate import Evaluate\n",
    "from dsp.utils.utils import deduplicate\n",
    "\n",
    "\n",
    "# We are setting the experimental flag to True to make use of the fine-tuning\n",
    "# features that are still in development.\n",
    "dspy.settings.configure(experimental=True)\n",
    "\n",
    "class IntentExtraction(dspy.Signature):\n",
    "    \"\"\"Extract the intent of a natural language query.\"\"\"\n",
    "\n",
    "    text = dspy.InputField(desc=\"Natural language query\")\n",
    "    intent = dspy.OutputField(desc=\"Intent of the query\")\n",
    "\n",
    "class IntentClassification(dspy.Signature):\n",
    "    \"\"\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
    "    The intent should exactly match one of the following:\n",
    "    ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
    "    \"\"\"\n",
    "\n",
    "    intent = dspy.InputField(desc=\"Intent of the query\")\n",
    "    label = dspy.OutputField(desc=\"Type of the intent; Should just be one of the 25 labels with no other text\")\n",
    "\n",
    "\n",
    "class UnifiedIntentClassification(dspy.Signature):\n",
    "    \"\"\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
    "    The intent should exactly match one of the following:\n",
    "    ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
    "    \"\"\"\n",
    "\n",
    "    text = dspy.InputField(desc=\"Natural language query\")\n",
    "    description = dspy.OutputField(desc=\"Description of the intent; Should be 4-5 words of what the user wants\")\n",
    "    label = dspy.OutputField(desc=\"Type of the intent; Should just be one of the 25 labels with no other text\")\n",
    "\n",
    "class SimpleIntentClassificationModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.intent_classifier = dspy.ChainOfThought(IntentClassification)\n",
    "        self.valid_labels = set([\"activate_my_card\", \"cancel_transfer\", \"cash_withdrawal_charge\", \"declined_card_payment\", \"declined_cash_withdrawal\", \"direct_debit_payment_not_recognised\", \"extra_charge_on_statement\", \"pending_card_payment\", \"pending_top_up\", \"Refund_not_showing_up\", \"request_refund\", \"reverted_card_payment\", \"transaction_charged_twice\", \"transfer_fee_charged\", \"transfer_not_received_by_recipient\", \"wrong_amount_of_cash_received\", \"wrong_exchange_rate_for_cash_withdrawal\"])\n",
    "\n",
    "    def forward(self, text):\n",
    "        prediction = self.intent_classifier(intent=text)\n",
    "\n",
    "        sanitized_prediction = dspy.Prediction(label=prediction.label.lower().strip().replace(\" \", \"_\"))\n",
    "        # if sanitized_prediction.label not in self.valid_labels:\n",
    "        #     for label in self.valid_labels:\n",
    "        #         if label in sanitized_prediction.label:\n",
    "        #             sanitized_prediction.label = label\n",
    "        #             break\n",
    "        #     # this means that the prediction was not in the valid labels\n",
    "        #     # Could do edit distance or something more sophisticated here\n",
    "        #     # but for now just take the first\n",
    "        #     sanitized_prediction.label = self.valid_labels[0]\n",
    "        return sanitized_prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's break down the Text to SQL program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we load the dataset using a built in `HotPotQA` dataset class from DSPy.\n",
    "\n",
    "We set the `train_seed` and `eval_seed` to `0` for reproducibility and the `test_size` to `0` because we do not need a test set for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({15: 187, 28: 182, 6: 181, 75: 180, 19: 177, 63: 175, 26: 173, 64: 172, 66: 171, 5: 171, 52: 169, 16: 168, 17: 167, 34: 166, 76: 163, 51: 162, 53: 161, 20: 160, 45: 159, 0: 159, 8: 157, 7: 156, 11: 153, 25: 153, 47: 149, 48: 148, 61: 146, 59: 145, 46: 143, 13: 139, 35: 137, 73: 135, 27: 133, 54: 129, 39: 129, 9: 129, 24: 129, 67: 128, 4: 127, 36: 126, 71: 126, 2: 126, 21: 122, 30: 121, 74: 121, 29: 121, 42: 121, 31: 121, 43: 120, 33: 118, 49: 115, 58: 114, 57: 114, 70: 113, 65: 113, 32: 112, 12: 112, 14: 112, 56: 111, 1: 110, 55: 108, 38: 106, 44: 105, 69: 104, 62: 103, 68: 102, 40: 98, 60: 97, 37: 97, 50: 95, 3: 87, 22: 86, 41: 82, 18: 61, 10: 59, 72: 41, 23: 35})\n",
      "Dataset filtered to top 25 labels. New sizes:\n",
      "Training set: 4171\n",
      "Test set: 1000\n",
      "Top 25 labels: 0, 5, 6, 7, 8, 11, 15, 16, 17, 19, 20, 25, 26, 28, 34, 45, 47, 51, 52, 53, 63, 64, 66, 75, 76\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset\n",
    "from dspy.datasets import DataLoader\n",
    "\n",
    "dl = DataLoader()\n",
    "full_trainset = dl.from_huggingface(\n",
    "    dataset_name=\"PolyAI/banking77\", # Dataset name from Huggingface\n",
    "    fields=(\"label\", \"text\"), # Fields needed\n",
    "    input_keys=(\"text\",), # What our model expects to recieve to generate an output\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "full_testset = dl.from_huggingface(\n",
    "    dataset_name=\"PolyAI/banking77\", # Dataset name from Huggingface\n",
    "    fields=(\"label\", \"text\"), # Fields needed\n",
    "    input_keys=(\"text\",), # What our model expects to recieve to generate an output\n",
    "    split=\"test\"\n",
    ")\n",
    "\n",
    "# Find the 15 most common class labels\n",
    "from collections import Counter\n",
    "\n",
    "# Count occurrences of each label\n",
    "label_counts = Counter(example['label'] for example in full_trainset)\n",
    "print(label_counts)\n",
    "\n",
    "# Get the 15 most common labels\n",
    "top_25_labels = set([label for label, _ in label_counts.most_common(25)])\n",
    "\n",
    "# Filter the datasets to only include examples with the top 15 labels\n",
    "full_trainset_filtered = [example for example in full_trainset if example['label'] in top_25_labels]\n",
    "full_testset_filtered = [example for example in full_testset if example['label'] in top_25_labels]\n",
    "\n",
    "# Replace the original datasets with the filtered versions\n",
    "full_trainset = full_trainset_filtered\n",
    "full_testset = full_testset_filtered\n",
    "\n",
    "print(f\"Dataset filtered to top 25 labels. New sizes:\")\n",
    "print(f\"Training set: {len(full_trainset)}\")\n",
    "print(f\"Test set: {len(full_testset)}\")\n",
    "print(f\"Top 25 labels: {', '.join(str(label) for label in top_25_labels)}\")\n",
    "\n",
    "\n",
    "TRAIN_SIZE = 2000\n",
    "DEV_SIZE = 1500\n",
    "trainset = full_trainset[:TRAIN_SIZE]\n",
    "devset = full_trainset[TRAIN_SIZE:TRAIN_SIZE+DEV_SIZE]\n",
    "testset = full_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_label_dict = {\n",
    "    0: \"activate_my_card\",\n",
    "    1: \"age_limit\",\n",
    "    2: \"apple_pay_or_google_pay\",\n",
    "    3: \"atm_support\",\n",
    "    4: \"automatic_top_up\",\n",
    "    5: \"balance_not_updated_after_bank_transfer\",\n",
    "    6: \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "    7: \"beneficiary_not_allowed\",\n",
    "    8: \"cancel_transfer\",\n",
    "    9: \"card_about_to_expire\",\n",
    "    10: \"card_acceptance\",\n",
    "    11: \"card_arrival\",\n",
    "    12: \"card_delivery_estimate\",\n",
    "    13: \"card_linking\",\n",
    "    14: \"card_not_working\",\n",
    "    15: \"card_payment_fee_charged\",\n",
    "    16: \"card_payment_not_recognised\",\n",
    "    17: \"card_payment_wrong_exchange_rate\",\n",
    "    18: \"card_swallowed\",\n",
    "    19: \"cash_withdrawal_charge\",\n",
    "    20: \"cash_withdrawal_not_recognised\",\n",
    "    21: \"change_pin\",\n",
    "    22: \"compromised_card\",\n",
    "    23: \"contactless_not_working\",\n",
    "    24: \"country_support\",\n",
    "    25: \"declined_card_payment\",\n",
    "    26: \"declined_cash_withdrawal\",\n",
    "    27: \"declined_transfer\",\n",
    "    28: \"direct_debit_payment_not_recognised\",\n",
    "    29: \"disposable_card_limits\",\n",
    "    30: \"edit_personal_details\",\n",
    "    31: \"exchange_charge\",\n",
    "    32: \"exchange_rate\",\n",
    "    33: \"exchange_via_app\",\n",
    "    34: \"extra_charge_on_statement\",\n",
    "    35: \"failed_transfer\",\n",
    "    36: \"fiat_currency_support\",\n",
    "    37: \"get_disposable_virtual_card\",\n",
    "    38: \"get_physical_card\",\n",
    "    39: \"getting_spare_card\",\n",
    "    40: \"getting_virtual_card\",\n",
    "    41: \"lost_or_stolen_card\",\n",
    "    42: \"lost_or_stolen_phone\",\n",
    "    43: \"order_physical_card\",\n",
    "    44: \"passcode_forgotten\",\n",
    "    45: \"pending_card_payment\",\n",
    "    46: \"pending_cash_withdrawal\",\n",
    "    47: \"pending_top_up\",\n",
    "    48: \"pending_transfer\",\n",
    "    49: \"pin_blocked\",\n",
    "    50: \"receiving_money\",\n",
    "    51: \"Refund_not_showing_up\",\n",
    "    52: \"request_refund\",\n",
    "    53: \"reverted_card_payment\",\n",
    "    54: \"supported_cards_and_currencies\",\n",
    "    55: \"terminate_account\",\n",
    "    56: \"top_up_by_bank_transfer_charge\",\n",
    "    57: \"top_up_by_card_charge\",\n",
    "    58: \"top_up_by_cash_or_cheque\",\n",
    "    59: \"top_up_failed\",\n",
    "    60: \"top_up_limits\",\n",
    "    61: \"top_up_reverted\",\n",
    "    62: \"topping_up_by_card\",\n",
    "    63: \"transaction_charged_twice\",\n",
    "    64: \"transfer_fee_charged\",\n",
    "    65: \"transfer_into_account\",\n",
    "    66: \"transfer_not_received_by_recipient\",\n",
    "    67: \"transfer_timing\",\n",
    "    68: \"unable_to_verify_identity\",\n",
    "    69: \"verify_my_identity\",\n",
    "    70: \"verify_source_of_funds\",\n",
    "    71: \"verify_top_up\",\n",
    "    72: \"virtual_card_not_working\",\n",
    "    73: \"visa_or_mastercard\",\n",
    "    74: \"why_verify_identity\",\n",
    "    75: \"wrong_amount_of_cash_received\",\n",
    "    76: \"wrong_exchange_rate_for_cash_withdrawal\"\n",
    "}\n",
    "\n",
    "label_to_int_dict = {v: k for k, v in int_to_label_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "Example({'label': 'card_arrival', 'text': 'I am still waiting on my card?'}) (input_keys={'text'})\n"
     ]
    }
   ],
   "source": [
    "labels_in_use = [int_to_label_dict[label] for label in top_25_labels]\n",
    "\n",
    "print(labels_in_use)\n",
    "\n",
    "def convert_int_to_label(example):\n",
    "    example[\"label\"] = int_to_label_dict[example[\"label\"]]\n",
    "    return example\n",
    "\n",
    "trainset = [convert_int_to_label(example) for example in trainset]\n",
    "devset = [convert_int_to_label(example) for example in devset]\n",
    "testset = [convert_int_to_label(example) for example in testset]\n",
    "\n",
    "print(trainset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set up the metric and evaluator. We will be using the answer exact match metric.\n",
    "\n",
    "The evaluator is what we will consider as our test set.\n",
    "\n",
    "We choose `num_threads=90` because we are bottlenecked by the retrieval server, and through testing this is the maximum number of concurrent threads that can be run without causing issues for other people using the retrieval server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the metric and evaluator\n",
    "NUM_THREADS = 250\n",
    "def answer_exact_match(example, pred, trace=None, frac=1.0):\n",
    "    try:\n",
    "        example.answer = example.label\n",
    "        pred.answer = pred.label\n",
    "        if type(example.answer) is str:\n",
    "            return dsp.answer_match(pred.answer, [example.answer], frac=frac)\n",
    "        else: # type(example.answer) is list\n",
    "            return dsp.answer_match(pred.answer, example.answer, frac=frac)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in answer_exact_match: {e}\")\n",
    "        print(f\"Example: {example}\")\n",
    "        print(f\"Prediction: {pred}\")\n",
    "        return False\n",
    "\n",
    "metric = answer_exact_match\n",
    "\n",
    "evaluation_devset = devset.copy()\n",
    "rng.shuffle(evaluation_devset)\n",
    "evaluate_devset = Evaluate(devset=evaluation_devset[:DEV_SIZE], metric=metric, num_threads=NUM_THREADS, display_progress=True, max_errors=10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO(optional): Implement LLM as judge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering baseline performance\n",
    "\n",
    "run evaluate on a base pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 1000\n",
    "MODEL_PARAMETERS = {\n",
    "  \"max_tokens\": MAX_TOKENS,\n",
    "  \"temperature\": 0,\n",
    "}\n",
    "\n",
    "LOCAL_API_PARAMETERS = {\n",
    "  \"api_base\": \"http://localhost:8000/v1\",\n",
    "  \"api_key\": \"fake-key-doesnt-matter\"\n",
    "}\n",
    "vanilla_program = SimpleIntentClassificationModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Run above this to do all setup without launching any models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a local VLLM instance to run the initial benchmarks and data collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model to run is the 8B model in order to collect a baseline of performance.\n",
    "\n",
    "You can run the local VLLM instance with the following command:\n",
    "\n",
    "Make sure to set your HF_TOKEN and HF_HOME environment variables\n",
    "\n",
    "For Anyscale, putting models into /mnt/local_storage is a typical pattern.\n",
    "\n",
    "\n",
    "`vllm serve meta-llama/Meta-Llama-3.1-8B-Instruct --port 8000 --pipeline_parallel_size 4 --enable_prefix_caching`\n",
    "\n",
    "Lets break down what this command does:\n",
    "- `vllm serve` is the command to run the VLLM server\n",
    "- `meta-llama/Meta-Llama-3.1-8B-Instruct` is the model to run\n",
    "- `--port 8000` is the port to run the server on\n",
    "- `--pipeline_parallel_size 4` is the number of pipeline parallel size to run the server with. We are using 4 because we have 4 GPUs all of which can hold an instance of the model.\n",
    "- `--enable_prefix_caching` is the flag to enable the prefix caching. This will store and reuse the beginnings of prompts to avoid repeating the same computation. This is especially useful for DSPy since we are almost always using prompts with the same beginning parts in the form of few shot demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command for easy copying: \n",
    "# `vllm serve meta-llama/Meta-Llama-3.1-8B-Instruct --port 8000 --pipeline_parallel_size 4 --enable_prefix_caching`\n",
    "# `vllm serve meta-llama/Llama-3.2-1B-Instruct --port 8000 --pipeline_parallel_size 4 --enable_prefix_caching`\n",
    "input(\"Press Enter once you have the vllm server running...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: switch to offline model\n",
    "llama_8b = dspy.LM(model=\"openai/meta-llama/Meta-Llama-3.1-8B-Instruct\", **MODEL_PARAMETERS, **LOCAL_API_PARAMETERS)\n",
    "llama_1b = dspy.LM(model=\"openai/meta-llama/Llama-3.2-1B-Instruct\", **MODEL_PARAMETERS, **LOCAL_API_PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example({'label': 'card_arrival', 'text': 'Do you have info about the card on delivery?'}) (input_keys={'text'})\n",
      "{label}_-_'do_you_have_info_about_the_card_on_delivery?'\n"
     ]
    }
   ],
   "source": [
    "import litellm\n",
    "\n",
    "litellm.set_verbose=False\n",
    "litellm.suppress_debug_info=True\n",
    "# Quick sanity check to see if the program is working\n",
    "with dspy.context(lm=llama_1b):\n",
    "    test_predictor = SimpleIntentClassificationModule()\n",
    "    sample_input = trainset[6]\n",
    "    print(sample_input)\n",
    "    print(test_predictor(**sample_input.inputs()).label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the vanilla program on the devset using the model to be trained (llama 1B)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07T23:49:12.970878Z ["
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-07T23:49:13.110629Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-07T23:49:13.114760Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-07T23:49:13.198886Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-07T23:49:13.204514Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-07T23:49:13.291525Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-07T23:49:13.342250Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-07T23:49:13.355531Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1 / 3  (33.3):   0%|          | 2/1500 [00:00<00:05, 277.21it/s]inenoeasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py =198\n",
      "Average Metric: 3 / 15  (20.0):   1%|          | 14/1500 [00:00<00:04, 315.75it/s]=or for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno198\n",
      "Average Metric: 5 / 24  (20.8):   2%|▏         | 23/1500 [00:00<00:05, 277.49it/s]1984-10-07T23:49:13.556717Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=\n",
      "Average Metric: 8 / 33  (24.2):   2%|▏         | 32/1500 [00:00<00:05, 272.56it/s]198y.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=\n",
      "Average Metric: 8 / 41  (19.5):   3%|▎         | 40/1500 [00:00<00:05, 272.56it/s]=valuate.py23:49:13.582202Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename= lineno198\n",
      "Average Metric: 11 / 50  (22.0):   3%|▎         | 49/1500 [00:00<00:05, 272.56it/s] valuate.py3:49:13.600525Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate =lineno=198\n",
      "Average Metric: 14 / 59  (23.7):   4%|▍         | 58/1500 [00:00<00:05, 272.56it/s]198eno0-07T23:49:13.665158Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename=evaluate.py =\n",
      "Average Metric: 15 / 66  (22.7):   4%|▍         | 65/1500 [00:00<00:04, 300.99it/s]linenote.pyxample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] = =198\n",
      "Average Metric: 18 / 77  (23.4):   5%|▌         | 76/1500 [00:00<00:04, 300.99it/s]2024-10-07T23:49:13.704450Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19 / 86  (22.1):   6%|▌         | 85/1500 [00:00<00:04, 300.99it/s] spy.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filenameevaluate.pylineno=198\n",
      "Average Metric: 21 / 96  (21.9):   6%|▋         | 95/1500 [00:00<00:04, 305.52it/s]=valuate.py23:49:13.738756Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate =lineno198\n",
      "Average Metric: 24 / 105  (22.9):   7%|▋         | 104/1500 [00:00<00:04, 305.52it/s]198.evaluate.evaluatev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.pylineno=\n",
      "Average Metric: 24.0 / 116  (20.7):   8%|▊         | 115/1500 [00:00<00:04, 305.52it/s]=ename07T23:49:14.056246Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate =evaluate.py lineno198\n",
      "Average Metric: 26.0 / 125  (20.8):   8%|▊         | 124/1500 [00:00<00:04, 305.52it/s]evaluate.py23:49:14.146626Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 31.0 / 134  (23.1):   9%|▉         | 133/1500 [00:00<00:03, 341.88it/s]=valuate.pyxample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno198\n",
      "Average Metric: 34.0 / 143  (23.8):   9%|▉         | 142/1500 [00:00<00:03, 341.88it/s]=rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.pylineno198\n",
      "Average Metric: 36.0 / 152  (23.7):  10%|█         | 151/1500 [00:00<00:03, 341.88it/s]198eno0-07T23:49:14.465035Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =\n",
      "Average Metric: 38.0 / 160  (23.8):  11%|█         | 159/1500 [00:00<00:03, 341.88it/s]=ilename   ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno198\n",
      "Average Metric: 38.0 / 170  (22.4):  11%|█▏        | 169/1500 [00:00<00:03, 341.88it/s] [24-10-07T23:49:14.779444Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filenameevaluate.pylineno=198\n",
      "Average Metric: 44.0 / 179  (24.6):  12%|█▏        | 178/1500 [00:00<00:03, 353.73it/s] ilename07T23:49:14.826044Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] =evaluate.pylineno=198\n",
      "Average Metric: 46.0 / 189  (24.3):  13%|█▎        | 188/1500 [00:00<00:03, 353.73it/s]linenote.pyError for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] = =198\n",
      "Average Metric: 47.0 / 201  (23.4):  13%|█▎        | 200/1500 [00:00<00:03, 353.73it/s]198eno0-07T23:49:14.890427Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py =\n",
      "Average Metric: 48.0 / 209  (23.0):  14%|█▍        | 208/1500 [00:00<00:03, 330.16it/s]198eno0-07T23:49:15.052009Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filenameevaluate.py =\n",
      "Average Metric: 54.0 / 220  (24.5):  15%|█▍        | 219/1500 [00:00<00:03, 330.16it/s]][24-10-07T23:49:15.070486Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 55.0 / 228  (24.1):  15%|█▌        | 227/1500 [00:00<00:03, 330.16it/s]198enote.py23:49:15.210730Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename= =\n",
      "Average Metric: 58.0 / 236  (24.6):  16%|█▌        | 235/1500 [00:00<00:03, 330.16it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 242  (24.8):  16%|█▌        | 241/1500 [00:00<00:04, 313.76it/s]linenovaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filenameevaluate.py =198\n",
      "Average Metric: 62.0 / 252  (24.6):  17%|█▋        | 251/1500 [00:00<00:03, 313.76it/s]198eno0-07T23:49:15.627619Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py =\n",
      "Average Metric: 64.0 / 260  (24.6):  17%|█▋        | 259/1500 [00:00<00:03, 313.76it/s]2024-10-07T23:49:15.627997Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 271  (24.0):  18%|█▊        | 270/1500 [00:00<00:03, 313.76it/s]lineno   7T23:49:15.646092Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 67.0 / 279  (24.0):  19%|█▊        | 278/1500 [00:00<00:04, 299.18it/s]dspy.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 70.0 / 286  (24.5):  19%|█▉        | 285/1500 [00:00<00:04, 299.18it/s]198ename07T23:49:15.770516Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate =evaluate.py lineno=\n",
      "Average Metric: 70.0 / 294  (23.8):  20%|█▉        | 293/1500 [00:00<00:04, 299.18it/s]= 24-10-07T23:49:15.795515Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno198\n",
      "Average Metric: 73.0 / 303  (24.1):  20%|██        | 302/1500 [00:00<00:04, 299.18it/s]198enote.py23:49:16.336434Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] = =\n",
      "Average Metric: 76.0 / 314  (24.2):  21%|██        | 313/1500 [00:00<00:03, 316.01it/s]evaluate.py23:49:16.389577Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename lineno=198\n",
      "Average Metric: 79.0 / 325  (24.3):  22%|██▏       | 324/1500 [00:01<00:03, 316.01it/s] valuate.py23:49:16.396722Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filename=lineno=198\n",
      "Average Metric: 80.0 / 333  (24.0):  22%|██▏       | 332/1500 [00:01<00:03, 316.01it/s]filename   ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate =evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 342  (23.4):  23%|██▎       | 341/1500 [00:01<00:03, 316.01it/s] rror    7T23:49:16.429341Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 81.0 / 351  (23.1):  23%|██▎       | 350/1500 [00:01<00:03, 322.71it/s]=valuate.py23:49:16.434349Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate = lineno198\n",
      "Average Metric: 81.0 / 360  (22.5):  24%|██▍       | 359/1500 [00:01<00:03, 322.71it/s]198enofor example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =\n",
      "Average Metric: 83.0 / 369  (22.5):  25%|██▍       | 368/1500 [00:01<00:03, 322.71it/s]dspy.evaluate.evaluate8068Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 84.0 / 377  (22.3):  25%|██▌       | 376/1500 [00:01<00:03, 322.71it/s]=ilename07T23:49:16.496092Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno198\n",
      "Average Metric: 85.0 / 386  (22.0):  26%|██▌       | 385/1500 [00:01<00:03, 336.10it/s] [24-10-07T23:49:16.908655Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 87.0 / 395  (22.0):  26%|██▋       | 394/1500 [00:01<00:03, 336.10it/s] rror    7T23:49:16.915255Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno=198\n",
      "Average Metric: 89.0 / 405  (22.0):  27%|██▋       | 404/1500 [00:01<00:03, 336.10it/s]filename07T23:49:17.459269Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate =evaluate.py lineno=198\n",
      "Average Metric: 92.0 / 413  (22.3):  27%|██▋       | 412/1500 [00:01<00:03, 336.10it/s]linenote.pyxample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] = =198\n",
      "Average Metric: 93.0 / 420  (22.1):  28%|██▊       | 419/1500 [00:01<00:03, 295.98it/s]198or    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filenameevaluate.pylineno=\n",
      "Average Metric: 96.0 / 431  (22.3):  29%|██▊       | 430/1500 [00:01<00:03, 295.98it/s]1984-10-07T23:49:18.002793Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno\n",
      "Average Metric: 99.0 / 441  (22.4):  29%|██▉       | 440/1500 [00:01<00:03, 295.98it/s]198or for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filenameevaluate.pylineno=\n",
      "Average Metric: 100.0 / 449  (22.3):  30%|██▉       | 448/1500 [00:01<00:03, 294.79it/s]=spy.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filenameevaluate.py lineno=198\n",
      "Average Metric: 107.0 / 550  (19.5):  37%|███▋      | 549/1500 [00:01<00:02, 457.78it/s]2024-10-07T23:49:18.493746Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 107.0 / 555  (19.3):  37%|███▋      | 554/1500 [00:01<00:02, 457.78it/s]2024-10-07T23:49:18.675117Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 107.0 / 557  (19.2):  37%|███▋      | 556/1500 [00:02<00:02, 457.78it/s]2024-10-07T23:49:18.690666Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 107.0 / 558  (19.2):  37%|███▋      | 557/1500 [00:02<00:02, 457.78it/s]2024-10-07T23:49:18.763819Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 107.0 / 559  (19.1):  37%|███▋      | 558/1500 [00:02<00:02, 457.78it/s]2024-10-07T23:49:18.865233Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 107.0 / 561  (19.1):  37%|███▋      | 560/1500 [00:02<00:02, 457.78it/s]2024-10-07T23:49:19.025326Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 108.0 / 565  (19.1):  38%|███▊      | 564/1500 [00:02<00:02, 457.78it/s]2024-10-07T23:49:19.323581Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 108.0 / 567  (19.0):  38%|███▊      | 566/1500 [00:02<00:02, 457.78it/s]2024-10-07T23:49:19.535199Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 108.0 / 568  (19.0):  38%|███▊      | 567/1500 [00:02<00:02, 457.78it/s]2024-10-07T23:49:19.547947Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 112.0 / 589  (19.0):  39%|███▉      | 588/1500 [00:02<00:09, 97.43it/s]dspy.evaluate.evaluate54331Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 114.0 / 596  (19.1):  40%|███▉      | 595/1500 [00:03<00:09, 97.43it/s]2024-10-07T23:49:19.925605Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 116.0 / 605  (19.2):  40%|████      | 604/1500 [00:03<00:09, 97.43it/s]2024-10-07T23:49:20.038719Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 116.0 / 606  (19.1):  40%|████      | 605/1500 [00:03<00:09, 97.43it/s]2024-10-07T23:49:20.139765Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 117.0 / 611  (19.1):  41%|████      | 610/1500 [00:03<00:09, 97.43it/s]2024-10-07T23:49:20.184967Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 118.0 / 618  (19.1):  41%|████      | 617/1500 [00:03<00:09, 97.43it/s]=ilename ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno198\n",
      "Average Metric: 119.0 / 620  (19.2):  41%|████▏     | 619/1500 [00:03<00:10, 84.34it/s]2024-10-07T23:49:20.243381Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 119.0 / 630  (18.9):  42%|████▏     | 629/1500 [00:03<00:10, 84.34it/s]198eno   7T23:49:20.266935Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py =\n",
      "Average Metric: 119.0 / 635  (18.7):  42%|████▏     | 634/1500 [00:03<00:10, 84.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 119.0 / 644  (18.5):  43%|████▎     | 643/1500 [00:03<00:10, 84.34it/s]] ror    7T23:49:20.356851Z [Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 119.0 / 645  (18.4):  43%|████▎     | 644/1500 [00:03<00:09, 91.48it/s]2024-10-07T23:49:20.437615Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 122.0 / 658  (18.5):  44%|████▍     | 657/1500 [00:03<00:09, 91.48it/s]2024-10-07T23:49:20.745467Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 127.0 / 670  (19.0):  45%|████▍     | 669/1500 [00:04<00:10, 79.62it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 127.0 / 672  (18.9):  45%|████▍     | 671/1500 [00:04<00:10, 79.62it/s]2024-10-07T23:49:21.001747Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 127.0 / 673  (18.9):  45%|████▍     | 672/1500 [00:04<00:10, 79.62it/s]2024-10-07T23:49:21.014070Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 130.0 / 685  (19.0):  46%|████▌     | 685/1500 [00:04<00:11, 72.57it/s]2024-10-07T23:49:21.228887Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 134.0 / 696  (19.3):  46%|████▋     | 695/1500 [00:05<00:11, 72.57it/s]2024-10-07T23:49:21.755938Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 137.0 / 701  (19.5):  47%|████▋     | 700/1500 [00:05<00:14, 54.12it/s]=[error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 138.0 / 707  (19.5):  47%|████▋     | 706/1500 [00:05<00:14, 54.12it/s]2024-10-07T23:49:21.928122Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 145.0 / 729  (19.9):  49%|████▊     | 728/1500 [00:05<00:16, 45.94it/s]2024-10-07T23:49:22.631852Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 148.0 / 739  (20.0):  49%|████▉     | 738/1500 [00:06<00:16, 47.11it/s]2024-10-07T23:49:22.709760Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 149.0 / 744  (20.0):  50%|████▉     | 743/1500 [00:06<00:16, 47.11it/s]evaluate.py] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] = lineno=198\n",
      "Average Metric: 150.0 / 747  (20.1):  50%|████▉     | 746/1500 [00:06<00:14, 52.99it/s]]024-10-07T23:49:22.789043Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 152.0 / 751  (20.2):  50%|█████     | 750/1500 [00:06<00:14, 52.99it/s]2024-10-07T23:49:22.865074Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 154.0 / 761  (20.2):  51%|█████     | 760/1500 [00:06<00:14, 50.77it/s]2024-10-07T23:49:23.098139Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 154.0 / 764  (20.2):  51%|█████     | 763/1500 [00:06<00:14, 50.77it/s]2024-10-07T23:49:23.111350Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 154.0 / 767  (20.1):  51%|█████     | 766/1500 [00:06<00:14, 50.77it/s]] ror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 155.0 / 776  (20.0):  52%|█████▏    | 776/1500 [00:07<00:26, 26.91it/s]2024-10-07T23:49:23.912447Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 156.0 / 782  (19.9):  52%|█████▏    | 781/1500 [00:07<00:26, 26.91it/s]2024-10-07T23:49:23.949766Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 156.0 / 785  (19.9):  52%|█████▏    | 784/1500 [00:07<00:26, 26.91it/s]2024-10-07T23:49:23.970745Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 159.0 / 799  (19.9):  53%|█████▎    | 798/1500 [00:07<00:16, 41.79it/s]2024-10-07T23:49:24.167135Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 163.0 / 811  (20.1):  54%|█████▍    | 810/1500 [00:07<00:14, 47.89it/s]]024-10-07T23:49:24.271625Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 163.0 / 816  (20.0):  54%|█████▍    | 815/1500 [00:07<00:14, 47.89it/s]2024-10-07T23:49:24.322476Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 165.0 / 825  (20.0):  55%|█████▍    | 824/1500 [00:07<00:10, 62.28it/s]2024-10-07T23:49:24.407275Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 174.0 / 852  (20.4):  57%|█████▋    | 852/1500 [00:08<00:10, 61.15it/s]2024-10-07T23:49:24.942230Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 175.0 / 859  (20.4):  57%|█████▋    | 858/1500 [00:08<00:10, 61.15it/s] [24-10-07T23:49:25.110505Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 175.0 / 862  (20.3):  57%|█████▋    | 861/1500 [00:08<00:11, 54.75it/s] [24-10-07T23:49:25.147352Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 175.0 / 863  (20.3):  57%|█████▋    | 862/1500 [00:08<00:11, 54.75it/s]2024-10-07T23:49:25.160847Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 184.0 / 899  (20.5):  60%|█████▉    | 898/1500 [00:09<00:08, 73.67it/s]2024-10-07T23:49:25.677762Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 184.0 / 902  (20.4):  60%|██████    | 901/1500 [00:09<00:08, 73.67it/s]2024-10-07T23:49:25.711371Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 185.0 / 907  (20.4):  60%|██████    | 906/1500 [00:09<00:09, 60.72it/s]dspy.evaluate.evaluate0939Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 187.0 / 911  (20.5):  61%|██████    | 910/1500 [00:09<00:09, 60.72it/s]2024-10-07T23:49:25.863467Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 199.0 / 961  (20.7):  64%|██████▍   | 961/1500 [00:10<00:12, 43.40it/s]2024-10-07T23:49:27.139819Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 199.0 / 962  (20.7):  64%|██████▍   | 961/1500 [00:10<00:12, 43.40it/s]2024-10-07T23:49:27.153022Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 199.0 / 964  (20.6):  64%|██████▍   | 963/1500 [00:10<00:12, 43.40it/s]2024-10-07T23:49:27.187017Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 200.0 / 969  (20.6):  65%|██████▍   | 968/1500 [00:10<00:13, 40.32it/s]2024-10-07T23:49:27.352785Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 201.0 / 980  (20.5):  65%|██████▌   | 979/1500 [00:10<00:09, 54.86it/s]=rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filenameevaluate.py lineno198\n",
      "Average Metric: 201.0 / 985  (20.4):  66%|██████▌   | 984/1500 [00:10<00:09, 54.86it/s] [24-10-07T23:49:27.463389Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 202.0 / 992  (20.4):  66%|██████▌   | 991/1500 [00:11<00:12, 42.31it/s]2024-10-07T23:49:27.869740Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 204.0 / 1006  (20.3):  67%|██████▋   | 1005/1500 [00:11<00:12, 39.51it/s]evaluate.py3:49:28.065216Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename= lineno=198\n",
      "Average Metric: 204.0 / 1009  (20.2):  67%|██████▋   | 1008/1500 [00:11<00:12, 39.51it/s]2024-10-07T23:49:28.100788Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 205.0 / 1015  (20.2):  68%|██████▊   | 1014/1500 [00:11<00:09, 53.01it/s]error    7T23:49:28.187329Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 210.0 / 1027  (20.4):  68%|██████▊   | 1026/1500 [00:11<00:08, 58.68it/s]2024-10-07T23:49:28.419469Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 212.0 / 1038  (20.4):  69%|██████▉   | 1037/1500 [00:11<00:08, 52.67it/s]2024-10-07T23:49:28.659011Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 212.0 / 1042  (20.3):  69%|██████▉   | 1041/1500 [00:12<00:08, 53.93it/s]2024-10-07T23:49:28.720975Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 213.0 / 1049  (20.3):  70%|██████▉   | 1048/1500 [00:12<00:08, 53.93it/s]=024-10-07T23:49:28.739080Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno198\n",
      "Average Metric: 213.0 / 1050  (20.3):  70%|██████▉   | 1049/1500 [00:12<00:08, 53.93it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 213.0 / 1051  (20.3):  70%|███████   | 1050/1500 [00:12<00:08, 53.93it/s]2024-10-07T23:49:28.795095Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 219.0 / 1075  (20.4):  72%|███████▏  | 1074/1500 [00:12<00:05, 72.88it/s]] 24-10-07T23:49:29.057775Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 221.0 / 1099  (20.1):  73%|███████▎  | 1098/1500 [00:12<00:05, 71.11it/s] 024-10-07T23:49:29.372590Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 223.0 / 1107  (20.1):  74%|███████▎  | 1106/1500 [00:12<00:04, 84.15it/s]198or    7T23:49:29.427556Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.pylineno=\n",
      "Average Metric: 235.0 / 1157  (20.3):  77%|███████▋  | 1157/1500 [00:13<00:06, 54.24it/s]2024-10-07T23:49:30.467616Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 235.0 / 1158  (20.3):  77%|███████▋  | 1157/1500 [00:13<00:06, 54.24it/s]2024-10-07T23:49:30.497398Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 239.0 / 1166  (20.5):  78%|███████▊  | 1165/1500 [00:13<00:05, 58.03it/s]2024-10-07T23:49:30.573998Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 240.0 / 1169  (20.5):  78%|███████▊  | 1168/1500 [00:13<00:05, 58.03it/s]2024-10-07T23:49:30.601917Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 242.0 / 1178  (20.5):  78%|███████▊  | 1177/1500 [00:14<00:05, 56.52it/s]2024-10-07T23:49:30.872626Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 242.0 / 1181  (20.5):  79%|███████▊  | 1180/1500 [00:14<00:07, 45.23it/s]2024-10-07T23:49:30.983693Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 242.0 / 1184  (20.4):  79%|███████▉  | 1183/1500 [00:14<00:07, 45.23it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 243.0 / 1202  (20.2):  80%|████████  | 1201/1500 [00:14<00:06, 46.56it/s]2024-10-07T23:49:31.254520Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 243.0 / 1203  (20.2):  80%|████████  | 1203/1500 [00:14<00:04, 61.59it/s]2024-10-07T23:49:31.269774Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 244.0 / 1214  (20.1):  81%|████████  | 1213/1500 [00:14<00:04, 66.57it/s]2024-10-07T23:49:31.421549Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 244.0 / 1215  (20.1):  81%|████████  | 1214/1500 [00:14<00:04, 66.57it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 246.0 / 1220  (20.2):  81%|████████▏ | 1220/1500 [00:14<00:04, 65.02it/s]] 24-10-07T23:49:31.504391Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 248.0 / 1231  (20.1):  82%|████████▏ | 1230/1500 [00:14<00:04, 66.83it/s]2024-10-07T23:49:31.658958Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 251.0 / 1238  (20.3):  82%|████████▏ | 1237/1500 [00:15<00:04, 64.27it/s]2024-10-07T23:49:31.778667Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 254.0 / 1247  (20.4):  83%|████████▎ | 1246/1500 [00:15<00:04, 50.94it/s]2024-10-07T23:49:32.015379Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 254.0 / 1248  (20.4):  83%|████████▎ | 1247/1500 [00:15<00:04, 50.94it/s]2024-10-07T23:49:32.029566Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 255.0 / 1251  (20.4):  83%|████████▎ | 1250/1500 [00:15<00:04, 50.94it/s]2024-10-07T23:49:32.046585Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 259.0 / 1258  (20.6):  84%|████████▍ | 1257/1500 [00:15<00:04, 52.64it/s]2024-10-07T23:49:32.224912Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 261.0 / 1264  (20.6):  84%|████████▍ | 1263/1500 [00:15<00:06, 37.00it/s]2024-10-07T23:49:32.666430Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 262.0 / 1272  (20.6):  85%|████████▍ | 1271/1500 [00:16<00:07, 32.26it/s]2024-10-07T23:49:32.946394Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 264.0 / 1280  (20.6):  85%|████████▌ | 1279/1500 [00:16<00:08, 24.96it/s]2024-10-07T23:49:33.409837Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 266.0 / 1286  (20.7):  86%|████████▌ | 1285/1500 [00:16<00:08, 24.60it/s]2024-10-07T23:49:33.705616Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 269.0 / 1291  (20.8):  86%|████████▌ | 1291/1500 [00:17<00:09, 22.28it/s]2024-10-07T23:49:33.967196Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 274.0 / 1306  (21.0):  87%|████████▋ | 1306/1500 [00:17<00:09, 20.35it/s]2024-10-07T23:49:34.666640Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 275.0 / 1311  (21.0):  87%|████████▋ | 1310/1500 [00:18<00:09, 20.35it/s]2024-10-07T23:49:34.834591Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 288.0 / 1378  (20.9):  92%|█████████▏| 1377/1500 [00:21<00:04, 27.76it/s]2024-10-07T23:49:37.800196Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 295.0 / 1403  (21.0):  94%|█████████▎| 1403/1500 [00:22<00:04, 20.04it/s]2024-10-07T23:49:38.923702Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 296.0 / 1442  (20.5):  96%|█████████▌| 1442/1500 [00:28<00:21,  2.72it/s]2024-10-07T23:49:45.954292Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 296.0 / 1446  (20.5):  96%|█████████▋| 1446/1500 [00:29<00:15,  3.52it/s]2024-10-07T23:49:46.545765Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 297.0 / 1462  (20.3):  97%|█████████▋| 1462/1500 [01:01<01:31,  2.40s/it]2024-10-07T23:50:18.472613Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 298.0 / 1471  (20.3):  98%|█████████▊| 1470/1500 [01:02<00:10,  2.95it/s]2024-10-07T23:50:19.207494Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 300.0 / 1488  (20.2):  99%|█████████▉| 1487/1500 [01:03<00:00, 15.04it/s]2024-10-07T23:50:20.500400Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 300.0 / 1500  (20.0): 100%|██████████| 1500/1500 [01:05<00:00, 23.07it/s]\n"
     ]
    }
   ],
   "source": [
    "with dspy.context(lm=llama_1b):\n",
    "  vanilla_program = SimpleIntentClassificationModule()\n",
    "  print(\"Evaluating the vanilla program on the devset using the model to be trained (llama 1B)...\")\n",
    "  vanilla_1b_base_eval = evaluate_devset(vanilla_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dspy.context(lm=llama_1b):\n",
    "  print(\"Evaluating the vanilla program on the devset using the model to be trained (llama 1B)...\")\n",
    "  vanilla_1b_base_eval = evaluate_devset(vanilla_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the 70B Model\n",
    "\n",
    "Now that we have a baseline for the 8B model, let's run the 70B model and compare its performance.\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Before running the 70B model:\n",
    "1. Kill the 8B server (use `Ctrl+C`) to free up memory.\n",
    "2. Remember to set your HF_TOKEN and HF_HOME environment variables\n",
    "3. Use the following command to start the 70B server:\n",
    "\n",
    "   ```\n",
    "   vllm serve meta-llama/Meta-Llama-3.1-70B-Instruct --port 8000 --pipeline_parallel_size 2 --enable_prefix_caching --tensor_parallel_size 2\n",
    "   ```\n",
    "\n",
    "## Parallelism Configuration\n",
    "\n",
    "We've chosen pipeline parallelism and tensor parallelism of 2 for the 70B model based on our current setup. Here's the reasoning:\n",
    "\n",
    "1. Model size: The 70B model has 30 parts of ~5 GB each (based on [HuggingFace documentation](https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct/tree/main)).\n",
    "   - Total size: 30 * 5 GB = 150 GB\n",
    "\n",
    "2. Available VRAM:\n",
    "   - Our GPUs: 80 GB VRAM x 4 = 320 GB\n",
    "   - Tensor parallelism: floor(320/150) = 2\n",
    "   - Pipeline parallelism: floor(num_gpus/2) = 2\n",
    "   - To use all 4 GPUs efficiently:\n",
    "     - Pipeline parallel size: 2\n",
    "     - Tensor parallelism: 2\n",
    "\n",
    "3. Alternative setup (8x24GB GPUs):\n",
    "   - Pipeline parallel size: 1\n",
    "   - Tensor parallelism: ceil(150/24) = 7\n",
    "\n",
    "This configuration allows us to run the 70B model efficiently across our available GPU resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I needed to add the HF_HOME var to my serve config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command for easy copying: \n",
    "# `export HF_HOME=/mnt/local_storage/huggingface`\n",
    "# `vllm serve meta-llama/Meta-Llama-3.1-70B-Instruct --port 8000 --pipeline_parallel_size 2 --enable_prefix_caching --tensor_parallel_size 2`\n",
    "\n",
    "# input(\"Press Enter once you have the vllm server running...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_70b = dspy.LM(model=\"openai/meta-llama/Meta-Llama-3.1-70B-Instruct\", **MODEL_PARAMETERS, **LOCAL_API_PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another sanity check\n",
    "with dspy.context(lm=llama_70b):\n",
    "    test_predictor = SimpleIntentClassificationModule()\n",
    "    sample_input = trainset[0]\n",
    "    print(sample_input)\n",
    "    print(test_predictor(**sample_input.inputs()).label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_program = SimpleIntentClassificationModule()\n",
    "with dspy.context(lm=llama_70b):\n",
    "  print(\"Evaluating the vanilla program on the devset using llama 70B...\")\n",
    "  llama_70b_base_eval = evaluate_devset(vanilla_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope to bring the 8B performance up to at least 70B level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the LLaMa 70B pipeline\n",
    "\n",
    "Now we are ready to optimize the pipeline. We want to optimize the 70B pipeline in order to get the best possible data to then train our 8B model.\n",
    "\n",
    "We will use Bootstrap Few Shot with Random Search (BFRS) to optimize the pipeline.\n",
    "\n",
    "The essence of BFRS is to try out different configurations of few shot demonstrations per step and see which one works best on the validation set.\n",
    "\n",
    "The cool part about BFRs is that it will automatically collect the \"good\" chains of thought for us and add them to the examples at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how well the base pipeline performs, let's run prompt optimization on the pipeline in order to juice up the performance.\n",
    "\n",
    "Let's go over what the hyperparameters mean:\n",
    "- MAX_BOOTSTRAPPED_DEMOS: DSPy will \"bootstrap\" the program by collecting examples at each step that are successful and reusing those in the pipeline. This means that it will automatically collect and add chains of thought to the pipeline.\n",
    "- MAX_LABELED_DEMOS: DSPy will also insert some labeled demonstrations from the training set. These would be unmodified examples from the training set that are just using the gold answer.\n",
    "- NUM_CANDIDATE_PROGRAMS: This is the number of candidate programs that the optimizer will generate. The actual number of programs that are created is this plus three, as DSPy will also try a program with no examples, a program with TODO (check)\n",
    "- OPTIMIZER_NUM_TRAIN and OPTIMIZER_NUM_VAL: These are the number of examples that the optimizer will use for training and validation. Note that we will be taking the \"validation\" set from the trainset so as the actual validation set is untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization hyperparameters\n",
    "from dspy.teleprompt.random_search import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# Define the hyperparameters for prompt optimization\n",
    "MAX_BOOTSTRAPPED_DEMOS = 3\n",
    "MAX_LABELED_DEMOS = 3\n",
    "NUM_CANDIDATE_PROGRAMS = 6\n",
    "OPTIMIZER_NUM_TRAIN = 100\n",
    "OPTIMIZER_NUM_VAL = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training and validation sets for the optimizer using the original\n",
    "# trainset. This ensures that our actual devset is left untouched.\n",
    "shuffled_trainset = [d for d in trainset]\n",
    "rng.shuffle(shuffled_trainset)\n",
    "\n",
    "shuffled_devset = [d for d in devset]\n",
    "rng.shuffle(shuffled_devset)\n",
    "\n",
    "def get_optimizer_train_val_set(dataset, num_train, num_val):\n",
    "    shuffled_dataset = [d for d in dataset]\n",
    "    rng.shuffle(shuffled_dataset)\n",
    "    return shuffled_dataset[:num_train], shuffled_dataset[num_train:num_train+num_val]\n",
    "\n",
    "optimizer_trainset, optimizer_valset = get_optimizer_train_val_set(shuffled_trainset, OPTIMIZER_NUM_TRAIN, OPTIMIZER_NUM_VAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 3 traces per predictor.\n",
      "Will attempt to bootstrap 6 candidate sets.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the optimizer\n",
    "bfrs_optimizer = BootstrapFewShotWithRandomSearch(\n",
    "    metric=metric,\n",
    "    max_bootstrapped_demos=MAX_BOOTSTRAPPED_DEMOS,\n",
    "    max_labeled_demos=MAX_LABELED_DEMOS,\n",
    "    num_candidate_programs=NUM_CANDIDATE_PROGRAMS,\n",
    "    num_threads=NUM_THREADS,\n",
    "    max_errors=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have added this flag to save you some compute and time while running the notebook\n",
    "COMPILE_PROGRAM = False\n",
    "EVAL_PROGRAM = False\n",
    "\n",
    "optimizer_trainset, optimizer_valset = get_optimizer_train_val_set(trainset, OPTIMIZER_NUM_TRAIN, OPTIMIZER_NUM_VAL)\n",
    "# Compile the optimizer and evaluate\n",
    "with dspy.context(lm=llama_70b):\n",
    "    vanilla_program = SimpleIntentClassificationModule()\n",
    "    if COMPILE_PROGRAM:\n",
    "        bfrs_base_program = bfrs_optimizer.compile(vanilla_program, trainset=optimizer_trainset, valset=optimizer_valset)\n",
    "        bfrs_base_program.save(f\"b25_70b_31_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}.json\")\n",
    "    else:\n",
    "        bfrs_base_program = SimpleIntentClassificationModule()\n",
    "        bfrs_base_program.load(f\"b25_70b_31_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}.json\")\n",
    "    if EVAL_PROGRAM:\n",
    "        llama_70b_bfrs_eval = evaluate_devset(bfrs_base_program)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import MIPROv2\n",
    "\n",
    "eval_kwargs = dict(display_progress=True, display_table=0, num_threads=NUM_THREADS)\n",
    "teleprompter = MIPROv2(prompt_model=llama_70b, task_model=llama_70b, metric=metric, num_candidates=10, init_temperature=0.9, verbose=True)\n",
    "\n",
    "COMPILE_PROGRAM = True\n",
    "if COMPILE_PROGRAM:\n",
    "    with dspy.context(lm=llama_70b):\n",
    "        compiled_program = teleprompter.compile(vanilla_program, trainset=optimizer_trainset, valset=optimizer_valset, num_batches=30, max_bootstrapped_demos=MAX_BOOTSTRAPPED_DEMOS,max_labeled_demos=MAX_LABELED_DEMOS, eval_kwargs=eval_kwargs, requires_permission_to_run=False)\n",
    "        compiled_program.save(f\"t2sql_70b_31_MIPROv2_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}.json\")\n",
    "else:\n",
    "    compiled_program = TextToSQLModule()\n",
    "    compiled_program.load(f\"t2sql_70b_31_MIPROv2_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}.json\")\n",
    "\n",
    "with dspy.context(lm=llama_70b):\n",
    "    llama_70b_mipro_eval = evaluate_devset(compiled_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Data\n",
    "\n",
    "\n",
    "In this section, we bootstrap data for fine-tuning. In the code block below, we are deciding which program should be used to collect the bootstraps. We are setting this to the prompt optimized program, but one could also set this to the vanilla program, though doing so would lead to lower quality bootstraps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_program = bfrs_base_program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do something that kind of looks like rejection sampling here. For 3 rounds, we will run the model on the dataset and collect any \n",
    "examples that are solved. We then remove the solved examples from the dataset and repeat.\n",
    "\n",
    "In the [Large Language Monkeys paper](https://arxiv.org/pdf/2407.21787), they show that sampling up to 100 times can still get you a single correct answe in domains with ground truth or a verifier, so we can get away with this form of rejection sampling. Three rounds puts us at a decent spot on the curve of sampling up to N times. If we were in a domain where getting any correct answers was extremely hard, we may consider doing more rounds of sampling, but for now 3 rounds works.\n",
    "\n",
    "We did some experiments to see what the sampling curve looks like:\n",
    "\n",
    "<!-- ![Sampling Curve](./sampling_curve.png) -->\n",
    "<img src=\"./sampling_curve.png\" alt=\"Sampling Curve\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 1500\n",
    "EVAL_SIZE = int(TRAIN_SIZE/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return [ujson.loads(line) for line in f]\n",
    "\n",
    "def write_jsonl(filename, data):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for item in data:\n",
    "            f.write(ujson.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt.finetune_teleprompter import bootstrap_data_for_round, convert_to_module_level_message_data    \n",
    "import ujson\n",
    "\n",
    "# This should be moved inside the finetune_teleprompter class\n",
    "def write_data(program, data, filename):\n",
    "    print(\"Bootstrapping and writing data to\", filename)\n",
    "    correct_data = []\n",
    "    unsolved_examples = data.copy()\n",
    "    sampling_temperature = 0.902\n",
    "    sampling_temperature_delta = 0.0001\n",
    "    \n",
    "    for i in range(1):\n",
    "        if len(unsolved_examples) == 0:\n",
    "            break\n",
    "        data = bootstrap_data_for_round(program, unsolved_examples, metric=metric, num_threads=NUM_THREADS, sampling_round=i, sampling_temperature=sampling_temperature, sampling_temperature_delta=sampling_temperature_delta, max_errors=10000)\n",
    "        correct_data_round = [x for x in data if x[\"score\"]]\n",
    "        correct_examples_round = set([x[\"example\"] for x in correct_data_round])\n",
    "        print(f\"Round {i} complete. Solved {len(correct_data_round)} of {len(unsolved_examples)} examples. {len(unsolved_examples) - len(correct_examples_round)} examples remain unsolved.\")\n",
    "        unsolved_examples = [x for x in unsolved_examples if x not in correct_examples_round]\n",
    "\n",
    "        correct_data.extend(correct_data_round)\n",
    "        sampling_temperature += sampling_temperature_delta\n",
    "    \n",
    "    # Convert the data to prompt completion format\n",
    "    dataset = convert_to_module_level_message_data(correct_data, program=program, exclude_demos=True)\n",
    "\n",
    "    messages_format = [{\"messages\": data_dict} for data_dict in dataset]\n",
    "    # Format the data for finetuning using the LM\n",
    "    print(\"Writing dataset with length\", len(dataset), \"to\", filename)\n",
    "    write_jsonl(filename, messages_format)\n",
    "\n",
    "\n",
    "\n",
    "# Note: Maybe dont use devset here\n",
    "dataset_filenames = {f\"trainset_data_banking_{TRAIN_SIZE}.jsonl\": shuffled_trainset[:TRAIN_SIZE], f\"trainset_val_data_banking_{EVAL_SIZE}.jsonl\": shuffled_devset[:EVAL_SIZE]}\n",
    "\n",
    "dspy.settings.configure(lm=llama_70b)\n",
    "\n",
    "WRITE_DATA = True\n",
    "if WRITE_DATA:\n",
    "    for filename, data in dataset_filenames.items():\n",
    "        write_data(bootstrap_program, data, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at an example prompt completion pair!\n",
    "# with open(f\"trainset_data_banking_{TRAIN_SIZE}.json\", \"r\") as f:\n",
    "#     data_example = ujson.load(f)\n",
    "from pprint import pprint\n",
    "data_example = read_jsonl(f\"trainset_data_banking_{TRAIN_SIZE}.jsonl\")[0]\n",
    "\n",
    "print(\"Example prompt:\")\n",
    "pprint(data_example[\"messages\"][:-1])\n",
    "print(\"<end prompt>\\n\"+\"-\"*50)\n",
    "print(\"Example completion:\")\n",
    "pprint(data_example[\"messages\"][-1])\n",
    "print(\"<end completion>\\n\"+\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should kill your 70B vllm server so that you can use your GPUs for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press enter once you have killed the 70B vllm server\n",
    "input(\"Press Enter once you have killed the 70B vllm server (press Ctrl+C to kill)...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning\n",
    "\n",
    "We will use LLM Forge to fine-tune the 8B model.\n",
    "\n",
    "In order to do this, we need to format our data into the correct format (Follows OpenAI messaging format placed in a jsonl file).\n",
    "\n",
    "We initially saved the data into a json file in prompt-completion format.\n",
    "\n",
    "In order to prepare for finetuning, we need to do three steps:\n",
    "1. Format the data into the correct format and verify that the data is valid\n",
    "2. Upload the data to GCP\n",
    "3. Generate the compute configuration file\n",
    "\n",
    "After the compute configuration file is generated, we can submit the job to LLM Forge, using either the command line or using the anyscale jobs sdk.\n",
    "TODO: Add the anyscale jobs sdk submit method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to checkout the fine-tuning documentation for the latest on how to use our [API](https://docs.anyscale.com/llms/finetuning/intro) and additional [capabilities](https://docs.anyscale.com/category/fine-tuning-beta/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_llama_8b = dspy.TrainableAnyscale(model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "student_llama_1b = dspy.TrainableAnyscale(model=\"meta-llama/Llama-3.2-1B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: All this should be moved into the TrainableAnyscaleLM class. You should instead just call a finetune method with your datasets, hparams, compute config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.modules.lm import TrainingMethod\n",
    "\n",
    "train_path = f\"trainset_data_banking_{TRAIN_SIZE}.jsonl\"\n",
    "eval_path = f\"trainset_val_data_banking_{EVAL_SIZE}.jsonl\"\n",
    "method = TrainingMethod.SFT\n",
    "kwargs = {\n",
    "    \"hyperparameters\": {\n",
    "        \"num_devices\": 4,\n",
    "        \"trainer_resources\": None,\n",
    "        \"worker_resources\": None,\n",
    "        \"generation_config\": {\n",
    "            \"prompt_format\": {\n",
    "                \"system\": \"<|start_header_id|>system<|end_header_id|>\\n\\n{instruction}<|eot_id|>\",\n",
    "                \"user\": \"<|start_header_id|>user<|end_header_id|>\\n{instruction}<|eot_id|>\",\n",
    "                \"assistant\": \"<|start_header_id|>assistant<|end_header_id|>\\n\\n{instruction}<|eot_id|>\",\n",
    "                \"trailing_assistant\": \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\", # inference-only\n",
    "                \"bos\": \"<|begin_of_text|>\",\n",
    "                \"system_in_user\": False,\n",
    "                \"default_system_message\": \"\"\n",
    "            },\n",
    "        },\n",
    "        \"learning_rate\": 4.5e-5,\n",
    "        \"num_epochs\": 6,\n",
    "        \"train_batch_size_per_device\": 32\n",
    "    },\n",
    "    \"use_lora\": True\n",
    "}\n",
    "\n",
    "if method != TrainingMethod.SFT:\n",
    "    raise NotImplementedError(\"Only SFT training is supported at the moment.\")\n",
    "\n",
    "# train_dataset = student_llama_1b._format_data_for_vanilla_finetuning(train_path)\n",
    "# val_dataset = student_llama_1b._format_data_for_vanilla_finetuning(eval_path) if eval_path else None\n",
    "\n",
    "train_dataset = read_jsonl(train_path)\n",
    "val_dataset = read_jsonl(eval_path) if eval_path else None\n",
    "\n",
    "if not student_llama_1b._verify_datasets(train_dataset, val_dataset):\n",
    "    print(\"Unable to verify arguments\")\n",
    "    raise RuntimeError(\"Unable to verify argument\")\n",
    "\n",
    "# TODO: This should be a function inside the TrainableAnyscaleLM class\n",
    "formatted_paths = {}\n",
    "for path, dataset in [(train_path, train_dataset), (eval_path, val_dataset)]:\n",
    "    if not (path and dataset):\n",
    "        continue\n",
    "    formatted_path = path.split(\".\")[0] + \"_formatted.jsonl\"\n",
    "    with open(formatted_path, \"w\") as f:\n",
    "        for item in dataset:\n",
    "            f.write(ujson.dumps(item) + \"\\n\")\n",
    "\n",
    "    formatted_paths[path] = formatted_path\n",
    "\n",
    "# print(formatted_paths[train_path])\n",
    "remote_train_path, remote_eval_path = student_llama_1b._submit_data(train_path=formatted_paths[train_path], eval_path=formatted_paths[eval_path])\n",
    "compute_config_path, compute_config = student_llama_1b._generate_config_files(train_path=remote_train_path, eval_path=remote_eval_path, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fine-tune our LLM by choosing a set of configurations. We have created recipes for different LLMs in the [`training configs`](configs/training/lora/llama-3-8b.yaml) folder which can be used as is or modified for experiments. These configurations provide flexibility over a broad range of parameters such as model, data paths, compute to use for training, number of training epochs, how often to save checkpoints, padding, loss, etc. We also include several [DeepSpeed](https://github.com/microsoft/DeepSpeed) [configurations](configs/deepspeed/zero_3_offload_optim+param.json) to choose from for further optimizations around data/model parallelism, mixed precision, checkpointing, etc.\n",
    "\n",
    "We also have recipes for [LoRA](https://arxiv.org/abs/2106.09685) (where we train a set of small low ranked matrices instead of the original attention and feed forward layers) or full parameter fine-tuning. We recommend starting with LoRA as it's less resource intensive and quicker to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the compute config\n",
    "print(\"Compute config:\", compute_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anyscale\n",
    "\n",
    "SKIP_FT = False\n",
    "if not SKIP_FT:\n",
    "    # TODO: Get job working with LLMForge\n",
    "    # prodjob_idbtjgp6lrggxsjas5snj1jiv2\n",
    "    job_id: str = anyscale.job.submit(\n",
    "        compute_config\n",
    "    )\n",
    "    anyscale.job.wait(id=job_id, timeout_s=18000)\n",
    "    print(f\"Job {job_id} succeeded!\")\n",
    "\n",
    "\n",
    "    # command = compute_config.entrypoint\n",
    "    # print(command)\n",
    "    # os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input(\"Press Enter once you have copied the path from the logs...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_gcp_bucket(bucket_name, source_folder, destination_folder):\n",
    "    \"\"\"Downloads a folder from a GCP bucket to a local folder.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the GCP bucket.\n",
    "        source_folder (str): The path to the folder in the bucket.\n",
    "        destination_folder (str): The local path where files should be saved.\n",
    "\n",
    "    Returns:\n",
    "        str: The path to the downloaded folder.\n",
    "    \"\"\"\n",
    "    import google.cloud.storage as storage\n",
    "    \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=source_folder)\n",
    "\n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith('/'):\n",
    "            continue  # Skip directories\n",
    "        \n",
    "        relative_path = os.path.relpath(blob.name, source_folder)\n",
    "        local_file_path = os.path.join(destination_folder, relative_path)\n",
    "        \n",
    "        os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "        # only download if the file doesn't exist\n",
    "        if not os.path.exists(local_file_path):\n",
    "            blob.download_to_filename(local_file_path)\n",
    "            print(f\"Downloaded {blob.name} to {local_file_path}\")\n",
    "\n",
    "    print(f\"Folder {source_folder} downloaded to {destination_folder}.\")\n",
    "    return destination_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to get all the checkpoints somehow\n",
    "# bucket: storage-bucket-cld-tffbxe9ia5phqr1unxhz4f7e1e and path: org_4snvy99zwbmh4gbtk64jfqggmj/cld_tffbxe9ia5phqr1unxhz4f7e1e/artifact_storage/lora_fine_tuning/meta-llama/Meta-Llama-3.1-8B-Instruct:isaac:vblcs\n",
    "\n",
    "# download_from_gcp_bucket(\"storage-bucket-cld-tffbxe9ia5phqr1unxhz4f7e1e\", \"org_4snvy99zwbmh4gbtk64jfqggmj/cld_tffbxe9ia5phqr1unxhz4f7e1e/artifact_storage/lora_fine_tuning/meta-llama/Meta-Llama-3.1-8B-Instruct:isaac:vblcs\", \"llama_8b_checkpoints\")\n",
    "\n",
    "# storage-bucket-cld-tffbxe9ia5phqr1unxhz4f7e1e/org_4snvy99zwbmh4gbtk64jfqggmj/cld_tffbxe9ia5phqr1unxhz4f7e1e/artifact_storage/isaac__miller/llmforge-finetuning/meta-llama/Meta-Llama-3.1-8B-Instruct/TorchTrainer_2024-09-26_17-26-38\n",
    "\n",
    "# download_from_gcp_bucket(\"storage-bucket-cld-tffbxe9ia5phqr1unxhz4f7e1e\", \"org_4snvy99zwbmh4gbtk64jfqggmj/cld_tffbxe9ia5phqr1unxhz4f7e1e/artifact_storage/isaac__miller/llmforge-finetuning/meta-llama/Meta-Llama-3.1-8B-Instruct/TorchTrainer_2024-09-26_17-26-38\", \"llama_8b_checkpoints_torchtrainer\")\n",
    "\n",
    "\n",
    "# gs://storage-bucket-cld-tffbxe9ia5phqr1unxhz4f7e1e/org_4snvy99zwbmh4gbtk64jfqggmj/cld_tffbxe9ia5phqr1unxhz4f7e1e/artifact_storage/isaac__miller/llmforge-finetuning/meta-llama/Llama-3.2-1B-Instruct/TorchTrainer_2024-10-06_12-32-25/\n",
    "\n",
    "download_from_gcp_bucket(\"storage-bucket-cld-tffbxe9ia5phqr1unxhz4f7e1e\", \"org_4snvy99zwbmh4gbtk64jfqggmj/cld_tffbxe9ia5phqr1unxhz4f7e1e/artifact_storage/isaac__miller/llmforge-finetuning/meta-llama/Llama-3.2-1B-Instruct/TorchTrainer_2024-10-06_12-32-25/\", \"llama_1b_checkpoints_banking_torchtrainer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets sanity check the finetuned model. We need to download it first.\n",
    "# After the finetuning is complete, the logs will say something like \"Note: Best LoRA weights forwarded to gs://storage-bucket...\"\n",
    "# Update that link below with the correct path.\n",
    "if job_id:\n",
    "    model_info = anyscale.llm.model.get(job_id=job_id).to_dict()\n",
    "\n",
    "model_id = model_info[\"base_model_id\"] if job_id else \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "lora_source_path = model_info['storage_uri'] if job_id else \"\"\n",
    "\n",
    "# lora_source_path = \"gs://storage-bucket-cld-tffbxe9ia5phqr1unxhz4f7e1e/org_4snvy99zwbmh4gbtk64jfqggmj/cld_tffbxe9ia5phqr1unxhz4f7e1e/artifact_storage/lora_fine_tuning/meta-llama/Meta-Llama-3.1-8B-Instruct:isaac:yuxwd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parse the GCS path\n",
    "bucket_name = lora_source_path.split('/')[2]\n",
    "source_folder = '/'.join(lora_source_path.split('/')[3:])\n",
    "\n",
    "# Download the LoRA model folder locally\n",
    "local_lora_path = download_from_gcp_bucket(bucket_name, source_folder, \"/mnt/local_storage/dspy/mhqa-lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Throughout this section, anything using 8B model (or technically 70B too) should use the new evaluate with ray data batch offline(or technically online) inference.\n",
    "\n",
    "Probably worth testing offline with 8x8 threads vs just 64 threads to see if it makes a meaningful difference.\n",
    "\n",
    "## Performance comparisons\n",
    "\n",
    "- 70B\n",
    "- 70B BSFS\n",
    "- 8B\n",
    "- 8B BSFT\n",
    "- 8B BSFT + BSFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to serve the base model and tell VLLM where to find the LoRA weights\n",
    "\n",
    "Run the following command:\n",
    "\n",
    "```\n",
    "vllm serve meta-llama/Meta-Llama-3.1-8B-Instruct --port 8000 --pipeline_parallel_size 4 --enable_prefix_caching --enable_lora --lora_modules mhqa-lora=/mnt/local_storage/dspy/mhqa-lora\n",
    "```\n",
    "\n",
    "# Explanation:\n",
    "This command starts a VLLM server to serve the Meta-Llama-3-8B-Instruct model with LoRA fine-tuning.\n",
    "Here's a breakdown of the command:\n",
    "- 'vllm serve': Starts the VLLM server\n",
    "- 'meta-llama/Meta-Llama-3.1-8B-Instruct': Specifies the base model to use\n",
    "- '--port 8000': Sets the server port to 8000\n",
    "- '--pipeline_parallel_size 4': Enables pipeline parallelism with 4 stages\n",
    "- '--enable_prefix_caching': Enables caching of prefixes for faster inference\n",
    "- '--enable_lora': Enables LoRA (Low-Rank Adaptation) for fine-tuning\n",
    "- '--lora_modules mhqa-lora=/mnt/local_storage/dspy/mhqa-lora': Specifies the name of the LoRA module and the path to the LoRA weights. We use the name instead of the base model name when trying to use the LoRA weights. If we just use the base model name, the server will ignore the LoRA weights.\n",
    "\n",
    "This setup allows us to serve a fine-tuned version of the 8B model, which we'll use for subsequent evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs-1-total-trained-steps-20': '/home/ray/default/templates/templates/e2e-dspy-workflow/llama_1b_checkpoints_banking_torchtrainer/epochs-1-total-trained-steps-20',\n",
       " 'epochs-5-total-trained-steps-60': '/home/ray/default/templates/templates/e2e-dspy-workflow/llama_1b_checkpoints_banking_torchtrainer/epochs-5-total-trained-steps-60',\n",
       " 'epochs-2-total-trained-steps-30': '/home/ray/default/templates/templates/e2e-dspy-workflow/llama_1b_checkpoints_banking_torchtrainer/epochs-2-total-trained-steps-30',\n",
       " 'epochs-3-total-trained-steps-40': '/home/ray/default/templates/templates/e2e-dspy-workflow/llama_1b_checkpoints_banking_torchtrainer/epochs-3-total-trained-steps-40',\n",
       " 'epochs-4-total-trained-steps-50': '/home/ray/default/templates/templates/e2e-dspy-workflow/llama_1b_checkpoints_banking_torchtrainer/epochs-4-total-trained-steps-50',\n",
       " 'epochs-0-total-trained-steps-10': '/home/ray/default/templates/templates/e2e-dspy-workflow/llama_1b_checkpoints_banking_torchtrainer/epochs-0-total-trained-steps-10'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# All checkpoints are inside llama_8b_checkpoints_torchtrainer\n",
    "# get all folders inside llama_8b_checkpoints_torchtrainer\n",
    "folders = os.listdir(\"llama_1b_checkpoints_banking_torchtrainer\")\n",
    "folders = [f for f in folders if os.path.isdir(os.path.join(\"llama_1b_checkpoints_banking_torchtrainer\", f)) and f.startswith(\"epoch\")]\n",
    "\n",
    "# Get the current working directory\n",
    "current_working_path = os.getcwd()\n",
    "\n",
    "folder_lora_location = {f: os.path.join(current_working_path, \"llama_1b_checkpoints_banking_torchtrainer\", f) for f in folders}\n",
    "folder_lora_location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['openai/vllm/epochs-1-total-trained-steps-20', 'openai/vllm/epochs-5-total-trained-steps-60', 'openai/vllm/epochs-2-total-trained-steps-30', 'openai/vllm/epochs-3-total-trained-steps-40', 'openai/vllm/epochs-4-total-trained-steps-50', 'openai/vllm/epochs-0-total-trained-steps-10']\n"
     ]
    }
   ],
   "source": [
    "# Command for easy copying: \n",
    "\n",
    "# `vllm serve meta-llama/Meta-Llama-3.1-8B-Instruct --port 8000 --pipeline_parallel_size 4 --enable_prefix_caching --enable_lora --lora_modules mhqa-lora=/mnt/local_storage/dspy/mhqa-lora`\n",
    "# LOCAL_API_PARAMETERS[\"api_base\"] = \"http://localhost:6942/v1\"\n",
    "llama_1b = dspy.LM(model=\"openai/meta-llama/Llama-3.2-1B-Instruct\", **LOCAL_API_PARAMETERS, **MODEL_PARAMETERS)\n",
    "# mhqa_llama_8b = dspy.MultiOpenAI(model=\"mhqa-lora\", **LOCAL_API_PARAMETERS, **MODEL_PARAMETERS)\n",
    "mhqa_finetuned_llamas_8b = {f: dspy.LM(model=\"openai/vllm/\" + f, **LOCAL_API_PARAMETERS, **MODEL_PARAMETERS) for f in folder_lora_location.keys()}\n",
    "print([lm.model for lm in mhqa_finetuned_llamas_8b.values()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets dynamically generate a vllm command that will load all the models\n",
    "base = \"vllm serve meta-llama/Llama-3.2-1B-Instruct --port 8000 --pipeline_parallel_size 4 --enable_prefix_caching --enable_lora --lora_modules\"\n",
    "for folder, path in folder_lora_location.items():\n",
    "    base += f\" vllm/{folder}={path}\"\n",
    "print(base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhqa_finetuned_llamas_8b[\"base_model\"] = llama_1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mhqa_finetuned_llamas_8b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai/vllm/epochs-5-total-trained-steps-60\n",
      "Example({'label': 'card_arrival', 'text': 'Why has my new card still not come?'}) (input_keys={'text'})\n",
      "card_arrival\n"
     ]
    }
   ],
   "source": [
    "# Sanity check that the finetuned models are working\n",
    "llama1 = list(mhqa_finetuned_llamas_8b.values())[1]\n",
    "with dspy.context(lm=llama1):\n",
    "    print(llama1.model)\n",
    "    test_predictor = SimpleIntentClassificationModule()\n",
    "    sample_input = trainset[10]\n",
    "    print(sample_input)\n",
    "    print(test_predictor(**sample_input.inputs()).label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the vanilla program on the devset using the model to be trained (epochs-1-total-trained-steps-20)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07T23:51:32.665482Z [error    ] Error for example in dev set: \t\t Expected ['rationale', 'label'] but got dict_keys(['rationale']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 125.0 / 736  (17.0):  49%|████▉     | 735/1500 [00:07<00:11, 67.50it/s]2024-10-07T23:51:40.570339Z [error    ] Error for example in dev set: \t\t Expected ['rationale', 'label'] but got dict_keys(['rationale']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 185.0 / 1086  (17.0):  72%|███████▏  | 1085/1500 [00:13<00:14, 27.72it/s]2024-10-07T23:51:47.014158Z [error    ] Error for example in dev set: \t\t Expected ['rationale', 'label'] but got dict_keys(['rationale']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 187.0 / 1107  (16.9):  74%|███████▎  | 1106/1500 [00:14<00:13, 28.26it/s]2024-10-07T23:51:47.491744Z [error    ] Error for example in dev set: \t\t Expected ['rationale', 'label'] but got dict_keys(['rationale']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 221.0 / 1245  (17.8):  83%|████████▎ | 1244/1500 [00:18<00:05, 43.01it/s]evaluate.py23:51:51.130006Z [error    ] Error for example in dev set: \t\t Expected ['rationale', 'label'] but got dict_keys(['rationale']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate = lineno=198\n",
      "Average Metric: 264.0 / 1498  (17.6): 100%|█████████▉| 1498/1500 [00:30<00:01,  1.93it/s]2024-10-07T23:52:09.543067Z [error    ] Error for example in dev set: \t\t Expected ['rationale', 'label'] but got dict_keys(['rationale']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 264.0 / 1499  (17.6): 100%|█████████▉| 1498/1500 [00:36<00:01,  1.93it/s]2024-10-07T23:52:09.566533Z [error    ] Error for example in dev set: \t\t Expected ['rationale', 'label'] but got dict_keys(['rationale']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 264.0 / 1500  (17.6): 100%|██████████| 1500/1500 [00:36<00:00, 41.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for epochs-1-total-trained-steps-20: 17.6\n",
      "Evaluating the vanilla program on the devset using the model to be trained (epochs-5-total-trained-steps-60)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07T23:52:10.402034Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 259.0 / 1244  (20.8):  83%|████████▎ | 1243/1500 [00:17<00:18, 13.77it/s]=[24-10-07T23:52:30.622252Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno198\n",
      "Average Metric: 304.0 / 1498  (20.3): 100%|█████████▉| 1497/1500 [00:50<00:03,  1.33s/it] 2024-10-07T23:53:03.423945Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 304.0 / 1500  (20.3): 100%|██████████| 1500/1500 [00:50<00:00, 29.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for epochs-5-total-trained-steps-60: 20.27\n",
      "Evaluating the vanilla program on the devset using the model to be trained (epochs-2-total-trained-steps-30)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 194 / 731  (26.5):  49%|████▊     | 730/1500 [00:07<00:10, 75.57it/s] 2024-10-07T23:53:15.070101Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 343.0 / 1486  (23.1):  99%|█████████▉| 1485/1500 [00:49<00:11,  1.26it/s] 2024-10-07T23:53:56.264823Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 343.0 / 1500  (22.9): 100%|██████████| 1500/1500 [00:50<00:00, 29.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for epochs-2-total-trained-steps-30: 22.87\n",
      "Evaluating the vanilla program on the devset using the model to be trained (epochs-3-total-trained-steps-40)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 207 / 731  (28.3):  49%|████▊     | 730/1500 [00:08<00:12, 63.10it/s] 2024-10-07T23:54:09.647399Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 413.0 / 1494  (27.6): 100%|█████████▉| 1494/1500 [00:38<00:04,  1.32it/s] 2024-10-07T23:54:40.018966Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 413.0 / 1500  (27.5): 100%|██████████| 1500/1500 [00:39<00:00, 37.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for epochs-3-total-trained-steps-40: 27.53\n",
      "Evaluating the vanilla program on the devset using the model to be trained (epochs-4-total-trained-steps-50)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07T23:54:41.568020Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 262.0 / 1242  (21.1):  83%|████████▎ | 1241/1500 [00:16<00:12, 20.43it/s] 2024-10-07T23:55:01.779626Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 309.0 / 1500  (20.6): 100%|██████████| 1500/1500 [00:37<00:00, 40.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for epochs-4-total-trained-steps-50: 20.6\n",
      "Evaluating the vanilla program on the devset using the model to be trained (epochs-0-total-trained-steps-10)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07T23:55:22.668723Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-07T23:55:23.147101Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-07T23:55:23.768110Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-07T23:55:24.920445Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1 / 4  (25.0):   0%|          | 3/1500 [00:00<02:21, 10.62it/s]spy.evaluate.evaluate\t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filenameevaluate.py lineno=198\n",
      "Average Metric: 2 / 11  (18.2):   1%|          | 10/1500 [00:00<01:13, 20.21it/s]=luate.py23:55:25.422891Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno198\n",
      "Average Metric: 3.0 / 20  (15.0):   1%|▏         | 19/1500 [00:00<01:13, 20.21it/s]=[-10-07T23:55:25.477300Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filenameevaluate.py lineno=198\n",
      "Average Metric: 127.0 / 521  (24.4):  35%|███▍      | 520/1500 [00:01<00:01, 818.24it/s]2024-10-07T23:55:27.130996Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 127.0 / 522  (24.3):  35%|███▍      | 522/1500 [00:01<00:02, 359.15it/s]2024-10-07T23:55:28.865745Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 127.0 / 523  (24.3):  35%|███▍      | 522/1500 [00:03<00:02, 359.15it/s]2024-10-07T23:55:28.881843Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 127.0 / 526  (24.1):  35%|███▌      | 525/1500 [00:03<00:02, 359.15it/s]2024-10-07T23:55:28.918448Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 127.0 / 531  (23.9):  35%|███▌      | 530/1500 [00:03<00:02, 359.15it/s]2024-10-07T23:55:28.984640Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 127.0 / 532  (23.9):  35%|███▌      | 531/1500 [00:03<00:02, 359.15it/s]2024-10-07T23:55:29.057218Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 127.0 / 536  (23.7):  36%|███▌      | 535/1500 [00:03<00:02, 359.15it/s]2024-10-07T23:55:29.682852Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 166.0 / 693  (24.0):  46%|████▌     | 692/1500 [00:07<00:13, 58.36it/s] 2024-10-07T23:55:33.066833Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 180.0 / 736  (24.5):  49%|████▉     | 735/1500 [00:08<00:13, 57.21it/s]lineno0-07T23:55:33.885122Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py =198\n",
      "Average Metric: 188.0 / 752  (25.0):  50%|█████     | 752/1500 [00:08<00:13, 56.37it/s]filename07T23:55:34.159096Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 199.0 / 788  (25.3):  52%|█████▏    | 787/1500 [00:09<00:11, 60.35it/s]dspy.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 215.0 / 851  (25.3):  57%|█████▋    | 850/1500 [00:10<00:15, 41.22it/s]2024-10-07T23:55:35.984171Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 252.0 / 999  (25.2):  67%|██████▋   | 998/1500 [00:14<00:16, 30.70it/s]2024-10-07T23:55:39.782681Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 264.0 / 1049  (25.2):  70%|██████▉   | 1048/1500 [00:15<00:08, 51.40it/s] [24-10-07T23:55:40.772916Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 267.0 / 1066  (25.0):  71%|███████   | 1065/1500 [00:15<00:14, 30.43it/s]2024-10-07T23:55:41.489821Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 267.0 / 1076  (24.8):  72%|███████▏  | 1075/1500 [00:15<00:10, 39.94it/s]2024-10-07T23:55:41.572504Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 271.0 / 1097  (24.7):  73%|███████▎  | 1096/1500 [00:16<00:08, 49.89it/s]2024-10-07T23:55:42.040099Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 296.0 / 1184  (25.0):  79%|███████▉  | 1184/1500 [00:18<00:06, 47.57it/s]2024-10-07T23:55:43.712645Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 297.0 / 1186  (25.0):  79%|███████▉  | 1185/1500 [00:18<00:06, 47.57it/s]2024-10-07T23:55:43.750477Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 303.0 / 1207  (25.1):  80%|████████  | 1206/1500 [00:18<00:05, 57.44it/s]2024-10-07T23:55:44.186382Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 303.0 / 1210  (25.0):  81%|████████  | 1209/1500 [00:18<00:06, 47.83it/s]2024-10-07T23:55:44.292514Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 333.0 / 1301  (25.6):  87%|████████▋ | 1300/1500 [00:21<00:06, 31.66it/s]2024-10-07T23:55:47.123183Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 334.0 / 1313  (25.4):  87%|████████▋ | 1312/1500 [00:22<00:12, 15.66it/s]2024-10-07T23:55:48.143583Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 365.0 / 1484  (24.6):  99%|█████████▉| 1483/1500 [00:54<00:22,  1.30s/it]2024-10-07T23:56:20.527661Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 365.0 / 1500  (24.3): 100%|██████████| 1500/1500 [00:57<00:00, 26.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for epochs-0-total-trained-steps-10: 24.33\n"
     ]
    }
   ],
   "source": [
    "ft_vanilla_results = {}\n",
    "for folder, llama in mhqa_finetuned_llamas_8b.items():\n",
    "    vanilla_program = SimpleIntentClassificationModule()\n",
    "    dspy.settings.configure(lm=llama)\n",
    "    with dspy.context(lm=llama):\n",
    "        print(f\"Evaluating the vanilla program on the devset using the model to be trained ({folder})...\")\n",
    "        eval_result = evaluate_devset(vanilla_program)\n",
    "        print(f\"result for {folder}: {eval_result}\")\n",
    "        ft_vanilla_results[folder] = eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs-1-total-trained-steps-20': 17.6,\n",
       " 'epochs-5-total-trained-steps-60': 20.27,\n",
       " 'epochs-2-total-trained-steps-30': 22.87,\n",
       " 'epochs-3-total-trained-steps-40': 27.53,\n",
       " 'epochs-4-total-trained-steps-50': 20.6,\n",
       " 'epochs-0-total-trained-steps-10': 24.33}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_vanilla_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try optimizing the program with the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPILE_PROGRAM = True\n",
    "ft_bfrs_results = {}\n",
    "\n",
    "# optimizer_trainset, optimizer_valset = get_optimizer_train_val_set(shuffled_trainset, OPTIMIZER_NUM_TRAIN, OPTIMIZER_NUM_VAL)\n",
    "for folder, llama in mhqa_finetuned_llamas_8b.items():\n",
    "    with dspy.context(lm=llama):\n",
    "        vanilla_program = SimpleIntentClassificationModule()\n",
    "        if COMPILE_PROGRAM:\n",
    "            bfrs_finetuned_program = bfrs_optimizer.compile(vanilla_program, trainset=optimizer_trainset, valset=optimizer_valset)\n",
    "            bfrs_finetuned_program.save(f\"simpleintent_1b_32_ft_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}_{folder}.json\")\n",
    "        else:\n",
    "            bfrs_finetuned_program = SimpleIntentClassificationModule()\n",
    "            bfrs_finetuned_program.load(f\"simpleintent_1b_32_ft_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}_{folder}.json\")\n",
    "        llama_8b_bfrs_finetuned_eval = evaluate_devset(bfrs_finetuned_program)\n",
    "        ft_bfrs_results[folder] = llama_8b_bfrs_finetuned_eval\n",
    "        print(f\"result for {folder}: {llama_8b_bfrs_finetuned_eval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08T00:28:55.023197Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-08T00:28:55.087138Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label', 'reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-08T00:28:55.180420Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-08T00:28:55.226832Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-08T00:28:55.349403Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0 / 5  (0.0):   2%|▏         | 5/300 [00:00<00:06, 47.81it/s]=ted ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno198\n",
      "Average Metric: 0 / 14  (0.0):   4%|▍         | 13/300 [00:00<00:06, 47.81it/s] y.evaluate.evaluate4526Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.pylineno=198\n",
      "Average Metric: 3.0 / 24  (12.5):   8%|▊         | 23/300 [00:00<00:05, 47.81it/s]98ote.py00:28:55.736737Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate = =\n",
      "Average Metric: 3.0 / 32  (9.4):  10%|█         | 31/300 [00:00<00:05, 47.81it/s]19824-10-08T00:28:55.797590Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno=\n",
      "Average Metric: 4.0 / 40  (10.0):  13%|█▎        | 39/300 [00:00<00:01, 198.05it/s]=ilenameT00:28:56.338221Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate =evaluate.pylineno198\n",
      "Average Metric: 7.0 / 52  (13.5):  17%|█▋        | 51/300 [00:00<00:01, 198.05it/s]linenomer example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate evaluate.py =198\n",
      "Average Metric: 8.0 / 61  (13.1):  20%|██        | 60/300 [00:00<00:01, 198.05it/s]linenofor example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filenameevaluate.py =198\n",
      "Average Metric: 8.0 / 70  (11.4):  23%|██▎       | 69/300 [00:00<00:01, 198.05it/s]198enote.py00:28:56.521314Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate = =\n",
      "Average Metric: 10.0 / 79  (12.7):  26%|██▌       | 78/300 [00:00<00:01, 198.05it/s]evaluate.py0:28:56.574202Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] = lineno=198\n",
      "Average Metric: 10.0 / 86  (11.6):  28%|██▊       | 85/300 [00:00<00:01, 198.05it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 96  (13.5):  32%|███▏      | 95/300 [00:00<00:01, 198.05it/s]evaluate.py00:28:56.691808Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] = lineno=198\n",
      "Average Metric: 19.0 / 169  (11.2):  56%|█████▌    | 168/300 [00:00<00:00, 382.98it/s]2024-10-08T00:28:56.997104Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 170  (11.2):  57%|█████▋    | 170/300 [00:00<00:00, 500.24it/s]2024-10-08T00:28:57.228189Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 171  (11.1):  57%|█████▋    | 170/300 [00:00<00:00, 500.24it/s]2024-10-08T00:28:57.748136Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 172  (11.0):  57%|█████▋    | 171/300 [00:01<00:00, 500.24it/s]2024-10-08T00:28:57.813595Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 173  (11.0):  57%|█████▋    | 172/300 [00:01<00:00, 500.24it/s]2024-10-08T00:28:57.959887Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 174  (10.9):  58%|█████▊    | 173/300 [00:01<00:00, 500.24it/s]2024-10-08T00:28:57.974964Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 175  (10.9):  58%|█████▊    | 174/300 [00:01<00:00, 500.24it/s]2024-10-08T00:28:58.005766Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 176  (10.8):  58%|█████▊    | 175/300 [00:01<00:00, 500.24it/s]2024-10-08T00:28:58.025181Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 177  (10.7):  59%|█████▊    | 176/300 [00:01<00:00, 500.24it/s]2024-10-08T00:28:58.126905Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 178  (10.7):  59%|█████▉    | 177/300 [00:01<00:00, 500.24it/s]2024-10-08T00:28:58.144788Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 179  (10.6):  59%|█████▉    | 178/300 [00:01<00:00, 500.24it/s]2024-10-08T00:28:58.464269Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 181  (10.5):  60%|██████    | 180/300 [00:01<00:00, 500.24it/s]2024-10-08T00:28:58.598844Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 184  (10.3):  61%|██████    | 183/300 [00:02<00:00, 500.24it/s]2024-10-08T00:28:58.994572Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 186  (10.2):  62%|██████▏   | 185/300 [00:02<00:00, 500.24it/s]2024-10-08T00:28:59.162181Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 191  (9.9):  63%|██████▎   | 190/300 [00:02<00:00, 500.24it/s] 2024-10-08T00:28:59.283647Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 201  (10.4):  67%|██████▋   | 200/300 [00:02<00:00, 500.24it/s]2024-10-08T00:28:59.568231Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 206  (10.2):  68%|██████▊   | 205/300 [00:03<00:00, 500.24it/s]2024-10-08T00:28:59.718281Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 240  (10.8):  80%|███████▉  | 239/300 [00:03<00:01, 45.64it/s] 2024-10-08T00:29:00.357625Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 29.0 / 265  (10.9):  88%|████████▊ | 264/300 [00:04<00:00, 44.68it/s]2024-10-08T00:29:01.105387Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 295  (11.2):  98%|█████████▊| 295/300 [00:20<00:00, 16.02it/s]2024-10-08T00:29:22.462552Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 300  (11.0): 100%|██████████| 300/300 [00:28<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 11.0 for seed -3\n",
      "Scores so far: [11.0]\n",
      "Best score so far: 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08T00:29:24.717248Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-08T00:29:24.718617Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label', 'reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1 / 2  (50.0):   0%|          | 1/300 [00:00<00:00, 552.75it/s]=d ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno198\n",
      "Average Metric: 2 / 12  (16.7):   4%|▎         | 11/300 [00:00<00:00, 705.69it/s]19810-08T00:29:24.735423Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filenameevaluate.py lineno=\n",
      "Average Metric: 2 / 22  (9.1):   7%|▋         | 21/300 [00:00<00:00, 634.26it/s]198neno0-08T00:29:24.741689Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filenameevaluate.py =\n",
      "Average Metric: 3.0 / 32  (9.4):  10%|█         | 31/300 [00:00<00:00, 669.69it/s]  -10-08T00:29:24.745241Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 40  (12.5):  13%|█▎        | 39/300 [00:00<00:00, 679.34it/s]=ilenameluate.evaluate861Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] =evaluate.pylineno198\n",
      "Average Metric: 8.0 / 49  (16.3):  16%|█▌        | 48/300 [00:00<00:00, 644.87it/s]lineno0-08T00:29:24.752302Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 10.0 / 59  (16.9):  19%|█▉        | 58/300 [00:00<00:00, 660.95it/s]198note.py00:29:24.754381Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename= =\n",
      "Average Metric: 12.0 / 67  (17.9):  22%|██▏       | 66/300 [00:00<00:00, 649.03it/s]198eno0-08T00:29:24.754970Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filenameevaluate.py=\n",
      "Average Metric: 12.0 / 77  (15.6):  25%|██▌       | 76/300 [00:00<00:00, 649.03it/s]=[24-10-08T00:29:24.763107Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filenameevaluate.pylineno198\n",
      "Average Metric: 12.0 / 86  (14.0):  28%|██▊       | 85/300 [00:00<00:00, 649.03it/s]198enote.py00:29:24.771790Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate = =\n",
      "Average Metric: 12.0 / 94  (12.8):  31%|███       | 93/300 [00:00<00:00, 649.03it/s]198enovaluate.evaluate2063Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename=evaluate.py =\n",
      "Average Metric: 12.0 / 103  (11.7):  34%|███▍      | 102/300 [00:00<00:00, 649.03it/s]198luate.pymple in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate = lineno=\n",
      "Average Metric: 14.0 / 112  (12.5):  37%|███▋      | 111/300 [00:00<00:00, 649.03it/s]198enote.py00:29:24.787638Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filename= =\n",
      "Average Metric: 16.0 / 122  (13.1):  40%|████      | 121/300 [00:00<00:00, 649.03it/s]198y.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. []filenameevaluate.pylineno=\n",
      "Average Metric: 16.0 / 131  (12.2):  44%|████▎     | 131/300 [00:00<00:00, 635.66it/s]2024-10-08T00:29:24.797206Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 139  (12.2):  46%|████▌     | 138/300 [00:00<00:00, 635.66it/s]=ilenameluate.evaluate8778Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] =evaluate.pylineno198\n",
      "Average Metric: 20.0 / 148  (13.5):  49%|████▉     | 147/300 [00:00<00:00, 635.66it/s] spy.evaluate.evaluate4621Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filenameevaluate.pylineno=198\n",
      "Average Metric: 21.0 / 155  (13.5):  51%|█████▏    | 154/300 [00:00<00:00, 635.66it/s]filename08T00:29:24.805677Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 163  (13.5):  54%|█████▍    | 162/300 [00:00<00:00, 635.66it/s]198enote.py00:29:24.807321Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= =\n",
      "Average Metric: 22.0 / 171  (12.9):  57%|█████▋    | 170/300 [00:00<00:00, 635.66it/s]=valuate.py00:29:24.816577Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] = lineno198\n",
      "Average Metric: 23.0 / 180  (12.8):  60%|█████▉    | 179/300 [00:00<00:00, 635.66it/s]198or    8T00:29:24.817973Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=\n",
      "Average Metric: 23.0 / 190  (12.1):  63%|██████▎   | 189/300 [00:00<00:00, 635.66it/s] [24-10-08T00:29:24.819238Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluatefilename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 198  (11.6):  66%|██████▌   | 197/300 [00:00<00:00, 616.12it/s]=ilenameluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] =evaluate.py lineno198\n",
      "Average Metric: 24.0 / 207  (11.6):  69%|██████▊   | 206/300 [00:00<00:00, 616.12it/s]198enote.py00:29:24.829741Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename= =\n",
      "Average Metric: 25.0 / 214  (11.7):  71%|███████   | 213/300 [00:00<00:00, 616.12it/s]]rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 222  (11.3):  74%|███████▎  | 221/300 [00:00<00:00, 616.12it/s]dspy.evaluate.evaluate1648Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 231  (11.7):  77%|███████▋  | 230/300 [00:00<00:00, 616.12it/s]=[24-10-08T00:29:24.836942Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno198\n",
      "Average Metric: 28.0 / 241  (11.6):  80%|████████  | 240/300 [00:00<00:00, 616.12it/s]linenote.py00:29:24.843591Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= =198\n",
      "Average Metric: 30.0 / 249  (12.0):  83%|████████▎ | 248/300 [00:00<00:00, 616.12it/s]198or for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 30.0 / 257  (11.7):  86%|████████▌ | 257/300 [00:00<00:00, 606.17it/s]198y.evaluate.evaluate0136Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename=evaluate.py lineno=\n",
      "Average Metric: 33.0 / 270  (12.2):  90%|████████▉ | 269/300 [00:00<00:00, 606.17it/s]=[24-10-08T00:29:24.852248Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename=evaluate.pylineno198\n",
      "Average Metric: 33.0 / 279  (11.8):  93%|█████████▎| 278/300 [00:00<00:00, 606.17it/s]=spy.evaluate.evaluate5727Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filenameevaluate.py lineno=198\n",
      "Average Metric: 33.0 / 287  (11.5):  95%|█████████▌| 286/300 [00:00<00:00, 606.17it/s]linenote.pyte.evaluate9435Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename= =198\n",
      "Average Metric: 33.0 / 296  (11.1):  98%|█████████▊| 295/300 [00:00<00:00, 606.17it/s] [24-10-08T00:29:24.869789Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 300  (11.0): 100%|██████████| 300/300 [00:00<00:00, 619.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [11.0, 11.0]\n",
      "Best score so far: 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]2024-10-08T00:29:25.375502Z [error    ] Failed to run or to evaluate example Example({'label': 'direct_debit_payment_not_recognised', 'text': 'Why is there a direct debit set up in my name?'}) (input_keys={'text'}) with <function answer_exact_match at 0x785a700a7670> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  9%|▉         | 9/100 [00:02<00:29,  3.07it/s]2024-10-08T00:29:28.478132Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_cheque_or_cash_deposit', 'text': \"Why is my check still not showing up on my account? It's been a week already\"}) (input_keys={'text'}) with <function answer_exact_match at 0x785a700a7670> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 21%|██        | 21/100 [00:23<01:29,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 22 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 2  (0.0):   0%|          | 1/300 [00:00<00:49,  6.08it/s]2024-10-08T00:29:54.235049Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 3/300 [00:00<01:10,  4.20it/s]2024-10-08T00:29:54.629932Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|▏         | 4/300 [00:01<01:26,  3.42it/s]2024-10-08T00:29:54.793198Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   2%|▏         | 5/300 [00:01<01:13,  4.00it/s]2024-10-08T00:29:54.865809Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   2%|▏         | 5/300 [00:01<01:13,  4.00it/s]2024-10-08T00:29:54.982967Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   2%|▏         | 7/300 [00:01<00:51,  5.74it/s]2024-10-08T00:29:55.056294Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   2%|▏         | 7/300 [00:01<00:51,  5.74it/s]2024-10-08T00:29:55.437180Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 10  (0.0):   3%|▎         | 9/300 [00:01<00:57,  5.03it/s]2024-10-08T00:29:56.074463Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 11  (0.0):   4%|▎         | 11/300 [00:02<01:09,  4.16it/s]2024-10-08T00:29:56.522493Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 12  (0.0):   4%|▍         | 12/300 [00:02<01:21,  3.54it/s]2024-10-08T00:29:56.576208Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 13  (0.0):   4%|▍         | 12/300 [00:03<01:21,  3.54it/s]2024-10-08T00:29:56.923981Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 14  (0.0):   5%|▍         | 14/300 [00:03<01:12,  3.94it/s]2024-10-08T00:29:56.970004Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 16  (0.0):   5%|▌         | 15/300 [00:03<01:12,  3.94it/s]2024-10-08T00:29:57.023681Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 24  (8.3):   8%|▊         | 24/300 [00:04<00:34,  8.10it/s]2024-10-08T00:29:58.015006Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 25  (8.0):   8%|▊         | 24/300 [00:04<00:34,  8.10it/s]2024-10-08T00:29:58.111842Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 60  (18.3):  20%|█▉        | 59/300 [00:06<00:10, 23.63it/s]2024-10-08T00:29:59.855305Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 55.0 / 195  (28.2):  65%|██████▍   | 194/300 [00:08<00:01, 58.00it/s]2024-10-08T00:30:02.127204Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 300  (28.7): 100%|██████████| 300/300 [00:10<00:00, 29.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 28.67 for seed -1\n",
      "Scores so far: [11.0, 11.0, 28.67]\n",
      "Best score so far: 28.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<00:56,  1.77it/s]2024-10-08T00:30:04.630201Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_wrong_exchange_rate', 'text': 'Why was I charged extra on my last UK pound to Russian ruble exchange?', 'answer': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function answer_exact_match at 0x785a700a7670> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 12%|█▏        | 12/100 [00:01<00:09,  9.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08T00:30:06.686153Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "  0%|          | 0/300 [00:00<?, ?it/s]198ror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/300 [00:00<00:14, 20.37it/s]2024-10-08T00:30:09.092384Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 3/300 [00:00<01:06,  4.47it/s]2024-10-08T00:30:09.406726Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|▏         | 4/300 [00:00<01:15,  3.90it/s]2024-10-08T00:30:09.615882Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   2%|▏         | 5/300 [00:01<01:11,  4.14it/s]2024-10-08T00:30:09.737789Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   2%|▏         | 6/300 [00:01<01:00,  4.90it/s]2024-10-08T00:30:09.842318Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   2%|▏         | 7/300 [00:01<00:50,  5.76it/s]2024-10-08T00:30:10.144930Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   3%|▎         | 8/300 [00:01<01:02,  4.70it/s]2024-10-08T00:30:10.378002Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 9  (0.0):   3%|▎         | 9/300 [00:01<01:03,  4.57it/s]2024-10-08T00:30:10.474421Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 10  (0.0):   3%|▎         | 9/300 [00:02<01:03,  4.57it/s]2024-10-08T00:30:10.584508Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 11  (0.0):   4%|▎         | 11/300 [00:02<00:47,  6.05it/s]2024-10-08T00:30:10.612435Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 13  (0.0):   4%|▍         | 13/300 [00:02<00:59,  4.86it/s]2024-10-08T00:30:11.144086Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 15  (6.7):   5%|▌         | 15/300 [00:02<00:46,  6.07it/s]2024-10-08T00:30:11.462564Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 17  (5.9):   5%|▌         | 16/300 [00:03<00:46,  6.05it/s] [24-10-08T00:30:11.476002Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 18  (5.6):   6%|▌         | 17/300 [00:03<00:46,  6.05it/s]2024-10-08T00:30:11.540265Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 19  (5.3):   6%|▌         | 18/300 [00:03<00:46,  6.05it/s]2024-10-08T00:30:11.598432Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 20  (5.0):   7%|▋         | 20/300 [00:03<00:25, 10.81it/s]2024-10-08T00:30:11.642282Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 21  (4.8):   7%|▋         | 20/300 [00:03<00:25, 10.81it/s]2024-10-08T00:30:11.699475Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 22  (4.5):   7%|▋         | 22/300 [00:03<00:22, 12.28it/s]2024-10-08T00:30:11.809060Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 23  (4.3):   7%|▋         | 22/300 [00:03<00:22, 12.28it/s]2024-10-08T00:30:11.819366Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 24  (4.2):   8%|▊         | 24/300 [00:03<00:21, 12.76it/s]2024-10-08T00:30:11.825275Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 26  (3.8):   8%|▊         | 25/300 [00:03<00:21, 12.76it/s]2024-10-08T00:30:11.959439Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 27  (3.7):   9%|▉         | 27/300 [00:03<00:17, 15.67it/s]2024-10-08T00:30:12.015448Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 29  (3.4):   9%|▉         | 28/300 [00:03<00:17, 15.67it/s]2024-10-08T00:30:12.063231Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 34  (5.9):  11%|█         | 33/300 [00:03<00:14, 18.46it/s]2024-10-08T00:30:12.432552Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 35  (5.7):  11%|█▏        | 34/300 [00:04<00:14, 18.46it/s]2024-10-08T00:30:12.542900Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 38  (5.3):  12%|█▏        | 37/300 [00:04<00:18, 14.07it/s]2024-10-08T00:30:12.651269Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 50  (10.0):  16%|█▋        | 49/300 [00:04<00:12, 19.88it/s]2024-10-08T00:30:13.075591Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 69  (13.0):  23%|██▎       | 68/300 [00:05<00:08, 28.17it/s]2024-10-08T00:30:13.786624Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 103  (18.4):  34%|███▍      | 102/300 [00:06<00:04, 40.10it/s]2024-10-08T00:30:14.555636Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 208  (22.1):  69%|██████▉   | 207/300 [00:07<00:01, 89.05it/s]2024-10-08T00:30:15.794820Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 48.0 / 214  (22.4):  71%|███████   | 213/300 [00:07<00:01, 76.95it/s]2024-10-08T00:30:15.853509Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 300  (25.0): 100%|██████████| 300/300 [00:08<00:00, 34.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [11.0, 11.0, 28.67, 25.0]\n",
      "Best score so far: 28.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:00<00:10,  8.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<01:09,  4.33it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|          | 2/300 [00:00<00:53,  5.56it/s]2024-10-08T00:30:21.197011Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 3/300 [00:00<01:01,  4.82it/s]2024-10-08T00:30:21.645530Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|▏         | 4/300 [00:01<01:29,  3.32it/s]2024-10-08T00:30:21.687941Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   1%|▏         | 4/300 [00:01<01:29,  3.32it/s]2024-10-08T00:30:21.897486Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   2%|▏         | 6/300 [00:01<01:00,  4.83it/s]2024-10-08T00:30:21.998297Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   3%|▎         | 8/300 [00:01<00:41,  6.97it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 9  (0.0):   3%|▎         | 8/300 [00:01<00:41,  6.97it/s]2024-10-08T00:30:22.136288Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 10  (0.0):   3%|▎         | 10/300 [00:01<00:32,  8.96it/s]2024-10-08T00:30:22.191250Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 11  (0.0):   3%|▎         | 10/300 [00:01<00:32,  8.96it/s]2024-10-08T00:30:22.391102Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 12  (0.0):   4%|▍         | 12/300 [00:01<00:33,  8.48it/s]2024-10-08T00:30:22.429738Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 19  (5.3):   6%|▋         | 19/300 [00:02<00:28,  9.95it/s]2024-10-08T00:30:23.112367Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 21  (4.8):   7%|▋         | 20/300 [00:02<00:28,  9.95it/s]2024-10-08T00:30:23.220075Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 23  (4.3):   7%|▋         | 22/300 [00:02<00:23, 11.65it/s] [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 27  (7.4):   9%|▉         | 27/300 [00:02<00:19, 13.68it/s]2024-10-08T00:30:23.600817Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 33  (12.1):  11%|█         | 32/300 [00:03<00:16, 15.77it/s]2024-10-08T00:30:23.891094Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 35  (14.3):  12%|█▏        | 35/300 [00:03<00:15, 17.13it/s]2024-10-08T00:30:23.979741Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 89  (24.7):  29%|██▉       | 88/300 [00:04<00:03, 61.38it/s]2024-10-08T00:30:25.139132Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 66.0 / 244  (27.0):  81%|████████  | 243/300 [00:05<00:00, 114.77it/s]2024-10-08T00:30:26.307716Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 66.0 / 248  (26.6):  82%|████████▏ | 247/300 [00:05<00:00, 114.77it/s]2024-10-08T00:30:26.414958Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 83.0 / 300  (27.7): 100%|██████████| 300/300 [00:06<00:00, 45.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [11.0, 11.0, 28.67, 25.0, 27.67]\n",
      "Best score so far: 28.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]2024-10-08T00:30:27.283947Z [error    ] Failed to run or to evaluate example Example({'label': 'direct_debit_payment_not_recognised', 'text': 'Why is there a direct debit set up in my name?'}) (input_keys={'text'}) with <function answer_exact_match at 0x785a700a7670> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 4/100 [00:01<00:40,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-08T00:30:32.530733Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<03:57,  1.26it/s]2024-10-08T00:30:32.560182Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/300 [00:00<03:57,  1.26it/s]2024-10-08T00:30:33.890031Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   2%|▏         | 5/300 [00:02<02:23,  2.05it/s]2024-10-08T00:30:34.538121Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   2%|▏         | 6/300 [00:02<02:23,  2.05it/s]2024-10-08T00:30:34.586160Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 9  (11.1):   3%|▎         | 8/300 [00:02<01:05,  4.46it/s]2024-10-08T00:30:34.658022Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 11  (9.1):   3%|▎         | 10/300 [00:02<01:05,  4.46it/s]2024-10-08T00:30:34.843880Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 15  (13.3):   5%|▍         | 14/300 [00:03<00:34,  8.20it/s]024-10-08T00:30:35.019966Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 19  (10.5):   6%|▌         | 18/300 [00:03<00:25, 10.97it/s]2024-10-08T00:30:35.321744Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 222  (24.3):  74%|███████▎  | 221/300 [00:06<00:00, 140.14it/s]2024-10-08T00:30:38.044915Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 76.0 / 300  (25.3): 100%|██████████| 300/300 [00:07<00:00, 40.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [11.0, 11.0, 28.67, 25.0, 27.67, 25.33]\n",
      "Best score so far: 28.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<00:45,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08T00:30:40.809611Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-08T00:30:41.033720Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/300 [00:00<00:23, 12.77it/s]2024-10-08T00:30:43.665633Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 3/300 [00:00<00:42,  6.96it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 3/300 [00:00<00:42,  6.96it/s]2024-10-08T00:30:43.872315Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   1%|▏         | 4/300 [00:00<00:42,  6.96it/s]2024-10-08T00:30:43.911757Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   2%|▏         | 5/300 [00:00<00:42,  6.96it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   2%|▏         | 6/300 [00:00<00:42,  6.96it/s]2024-10-08T00:30:43.997207Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   3%|▎         | 8/300 [00:00<00:16, 17.25it/s]2024-10-08T00:30:44.095520Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 9  (0.0):   3%|▎         | 8/300 [00:00<00:16, 17.25it/s]2024-10-08T00:30:44.257132Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 10  (0.0):   3%|▎         | 9/300 [00:00<00:16, 17.25it/s]2024-10-08T00:30:44.667413Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 11  (0.0):   4%|▎         | 11/300 [00:01<00:34,  8.31it/s]2024-10-08T00:30:44.959001Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 12  (0.0):   4%|▎         | 11/300 [00:01<00:34,  8.31it/s]2024-10-08T00:30:44.973656Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 14  (0.0):   4%|▍         | 13/300 [00:01<00:37,  7.65it/s]2024-10-08T00:30:45.137973Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 15  (0.0):   5%|▌         | 15/300 [00:01<00:33,  8.61it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 16  (0.0):   5%|▌         | 15/300 [00:01<00:33,  8.61it/s]2024-10-08T00:30:45.526479Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 18  (0.0):   6%|▌         | 17/300 [00:02<00:39,  7.21it/s]2024-10-08T00:30:45.607086Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 19  (0.0):   6%|▌         | 18/300 [00:02<00:39,  7.21it/s]2024-10-08T00:30:45.615651Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 20  (0.0):   6%|▋         | 19/300 [00:02<00:38,  7.21it/s]2024-10-08T00:30:45.773924Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 21  (0.0):   7%|▋         | 21/300 [00:02<00:28,  9.65it/s]2024-10-08T00:30:45.871446Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 22  (0.0):   7%|▋         | 21/300 [00:02<00:28,  9.65it/s]2024-10-08T00:30:45.949851Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 25  (4.0):   8%|▊         | 25/300 [00:02<00:29,  9.42it/s]2024-10-08T00:30:46.225006Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 80  (25.0):  26%|██▋       | 79/300 [00:04<00:05, 40.34it/s]2024-10-08T00:30:48.158025Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 55.0 / 192  (28.6):  64%|██████▎   | 191/300 [00:05<00:01, 105.49it/s]2024-10-08T00:30:49.326353Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 194  (28.9):  64%|██████▍   | 193/300 [00:05<00:01, 105.49it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 63.0 / 224  (28.1):  74%|███████▍  | 223/300 [00:06<00:00, 109.21it/s] 024-10-08T00:30:49.583120Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 87.0 / 300  (29.0): 100%|██████████| 300/300 [00:07<00:00, 41.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 29.0 for seed 3\n",
      "Scores so far: [11.0, 11.0, 28.67, 25.0, 27.67, 25.33, 29.0]\n",
      "Best score so far: 29.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<00:00, 357.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]2024-10-08T00:30:54.123593Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/300 [00:00<03:18,  1.50it/s]2024-10-08T00:30:54.476581Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|          | 2/300 [00:01<02:23,  2.08it/s]2024-10-08T00:30:54.666450Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 3/300 [00:01<01:43,  2.87it/s]2024-10-08T00:30:54.713657Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 3/300 [00:01<01:43,  2.87it/s]2024-10-08T00:30:54.726380Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 6  (16.7):   2%|▏         | 6/300 [00:01<00:43,  6.68it/s]2024-10-08T00:30:55.137712Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 7  (14.3):   2%|▏         | 6/300 [00:01<00:43,  6.68it/s]2024-10-08T00:30:55.561850Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 10  (30.0):   3%|▎         | 9/300 [00:02<01:08,  4.22it/s]024-10-08T00:30:55.620735Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 15  (40.0):   5%|▌         | 15/300 [00:02<00:27, 10.48it/s]2024-10-08T00:30:55.817152Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 20  (45.0):   6%|▋         | 19/300 [00:02<00:22, 12.29it/s]2024-10-08T00:30:56.075685Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 22  (45.5):   7%|▋         | 21/300 [00:02<00:22, 12.29it/s][error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 28  (50.0):   9%|▉         | 27/300 [00:02<00:14, 18.33it/s]2024-10-08T00:30:56.238972Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 34  (44.1):  11%|█         | 33/300 [00:02<00:10, 25.07it/s]2024-10-08T00:30:56.373518Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 35  (42.9):  11%|█▏        | 34/300 [00:02<00:10, 25.07it/s]2024-10-08T00:30:56.398078Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 37  (40.5):  12%|█▏        | 36/300 [00:03<00:08, 29.34it/s]2024-10-08T00:30:56.558265Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 52  (48.1):  17%|█▋        | 51/300 [00:03<00:08, 30.49it/s]2024-10-08T00:30:56.983789Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 63  (52.4):  21%|██        | 62/300 [00:03<00:07, 33.58it/s]2024-10-08T00:30:57.151913Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 71  (53.5):  23%|██▎       | 70/300 [00:03<00:04, 47.55it/s]]024-10-08T00:30:57.245858Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 86  (51.2):  28%|██▊       | 85/300 [00:04<00:04, 49.00it/s]2024-10-08T00:30:57.553995Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 49.0 / 99  (49.5):  33%|███▎      | 98/300 [00:04<00:03, 63.36it/s]2024-10-08T00:30:57.685401Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 61.0 / 121  (50.4):  40%|████      | 121/300 [00:04<00:02, 83.40it/s]2024-10-08T00:30:57.914486Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 88.0 / 162  (54.3):  54%|█████▎    | 161/300 [00:04<00:01, 85.77it/s]2024-10-08T00:30:58.305953Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 119.0 / 221  (53.8):  73%|███████▎  | 220/300 [00:05<00:00, 140.29it/s] 024-10-08T00:30:58.685375Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 128.0 / 248  (51.6):  82%|████████▏ | 247/300 [00:05<00:00, 125.38it/s]2024-10-08T00:30:58.948668Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 149.0 / 300  (49.7): 100%|██████████| 300/300 [00:06<00:00, 48.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 49.67 for seed 4\n",
      "Scores so far: [11.0, 11.0, 28.67, 25.0, 27.67, 25.33, 29.0, 49.67]\n",
      "Best score so far: 49.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:00<00:09, 10.53it/s]2024-10-08T00:31:00.309260Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_fee_charged', 'text': 'How did the extra charge on my card come in effect?'}) (input_keys={'text'}) with <function answer_exact_match at 0x785a700a7670> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-08T00:31:00.550534Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_not_recognised', 'text': 'Why is there a random payment in my statement?'}) (input_keys={'text'}) with <function answer_exact_match at 0x785a700a7670> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 20%|██        | 20/100 [00:01<00:04, 18.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 21 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08T00:31:02.391208Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 0/300 [00:00<?, ?it/s]2024-10-08T00:31:05.155308Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|          | 2/300 [00:00<01:12,  4.10it/s]2024-10-08T00:31:05.519045Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 3/300 [00:00<01:25,  3.46it/s]2024-10-08T00:31:05.710737Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|▏         | 4/300 [00:01<01:14,  3.95it/s]2024-10-08T00:31:05.973541Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   2%|▏         | 5/300 [00:01<01:17,  3.82it/s]2024-10-08T00:31:06.147902Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   2%|▏         | 6/300 [00:01<01:08,  4.31it/s]2024-10-08T00:31:06.191834Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   2%|▏         | 6/300 [00:01<01:08,  4.31it/s]2024-10-08T00:31:06.782095Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   3%|▎         | 8/300 [00:02<01:19,  3.68it/s]2024-10-08T00:31:07.111139Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 10  (0.0):   3%|▎         | 10/300 [00:02<01:08,  4.22it/s]2024-10-08T00:31:07.645868Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 11  (0.0):   4%|▎         | 11/300 [00:02<01:25,  3.39it/s]2024-10-08T00:31:07.821602Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 12  (0.0):   4%|▍         | 12/300 [00:03<01:14,  3.86it/s]2024-10-08T00:31:07.859367Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 15  (0.0):   5%|▌         | 15/300 [00:03<00:53,  5.29it/s]2024-10-08T00:31:08.327674Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 32  (18.8):  10%|█         | 31/300 [00:04<00:21, 12.47it/s]2024-10-08T00:31:09.632797Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 43  (18.6):  14%|█▍        | 42/300 [00:05<00:14, 17.38it/s]2024-10-08T00:31:10.448117Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 115  (20.9):  38%|███▊      | 114/300 [00:08<00:04, 42.91it/s]2024-10-08T00:31:12.789016Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 300  (26.7): 100%|██████████| 300/300 [00:11<00:00, 26.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [11.0, 11.0, 28.67, 25.0, 27.67, 25.33, 29.0, 49.67, 26.67]\n",
      "Best score so far: 49.67\n",
      "9 candidate programs found.\n",
      "[('intent_classifier', Predict(StringSignature(intent -> reasoning, label\n",
      "    instructions=\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\\nThe intent should exactly match one of the following:\\n['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\"\n",
      "    intent = Field(annotation=str required=True json_schema_extra={'desc': 'Intent of the query', '__dspy_field_type': 'input', 'prefix': 'Intent:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    label = Field(annotation=str required=True json_schema_extra={'desc': 'Type of the intent; Should just be one of the 25 labels with no other text', '__dspy_field_type': 'output', 'prefix': 'Label:'})\n",
      ")))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1500 [00:00<?, ?it/s]2024-10-08T00:31:18.824062Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/1500 [00:00<05:55,  4.22it/s]2024-10-08T00:31:19.194016Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 2/1500 [00:00<05:35,  4.47it/s]2024-10-08T00:31:19.478398Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   0%|          | 3/1500 [00:00<06:17,  3.97it/s]2024-10-08T00:31:19.656970Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   0%|          | 4/1500 [00:00<05:32,  4.50it/s]2024-10-08T00:31:19.781618Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   0%|          | 5/1500 [00:01<04:41,  5.31it/s]2024-10-08T00:31:19.950280Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 7  (14.3):   0%|          | 7/1500 [00:01<04:27,  5.58it/s]2024-10-08T00:31:20.178273Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 8  (12.5):   0%|          | 7/1500 [00:01<04:27,  5.58it/s]2024-10-08T00:31:20.489272Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 11  (18.2):   1%|          | 10/1500 [00:01<04:19,  5.75it/s]2024-10-08T00:31:20.807274Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 14  (21.4):   1%|          | 14/1500 [00:02<02:44,  9.02it/s]2024-10-08T00:31:20.975499Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 15  (20.0):   1%|          | 14/1500 [00:02<02:44,  9.02it/s]2024-10-08T00:31:20.999540Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 18  (16.7):   1%|          | 17/1500 [00:02<01:58, 12.48it/s]2024-10-08T00:31:21.148164Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 19  (15.8):   1%|          | 18/1500 [00:02<01:58, 12.48it/s]2024-10-08T00:31:21.174775Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 22  (13.6):   1%|▏         | 21/1500 [00:02<01:34, 15.67it/s]2024-10-08T00:31:21.334823Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 24  (16.7):   2%|▏         | 23/1500 [00:02<01:34, 15.67it/s]2024-10-08T00:31:21.404928Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 28  (25.0):   2%|▏         | 27/1500 [00:02<01:18, 18.78it/s]2024-10-08T00:31:21.597008Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 31  (25.8):   2%|▏         | 30/1500 [00:02<01:18, 18.80it/s] [24-10-08T00:31:21.609561Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 38  (34.2):   2%|▏         | 37/1500 [00:03<01:02, 23.48it/s]2024-10-08T00:31:22.015685Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 40  (35.0):   3%|▎         | 39/1500 [00:03<01:09, 20.98it/s] rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 14.0 / 42  (33.3):   3%|▎         | 41/1500 [00:03<01:09, 20.98it/s]2024-10-08T00:31:22.116288Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 45  (33.3):   3%|▎         | 45/1500 [00:03<00:51, 28.06it/s] 024-10-08T00:31:22.158942Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 17.0 / 48  (35.4):   3%|▎         | 47/1500 [00:03<00:51, 28.06it/s]2024-10-08T00:31:22.196887Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 49  (34.7):   3%|▎         | 48/1500 [00:03<00:51, 28.06it/s]2024-10-08T00:31:22.261048Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 50  (34.0):   3%|▎         | 49/1500 [00:03<00:51, 28.06it/s]2024-10-08T00:31:22.296649Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 69  (36.2):   5%|▍         | 68/1500 [00:04<00:39, 36.33it/s]2024-10-08T00:31:22.784289Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 30.0 / 85  (35.3):   6%|▌         | 84/1500 [00:04<00:28, 49.26it/s]2024-10-08T00:31:23.079728Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 165  (35.8):  11%|█         | 164/1500 [00:05<00:22, 59.65it/s]2024-10-08T00:31:24.691016Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 175  (34.3):  12%|█▏        | 174/1500 [00:06<00:23, 57.20it/s]2024-10-08T00:31:24.857585Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 189  (33.9):  13%|█▎        | 188/1500 [00:06<00:22, 58.97it/s]2024-10-08T00:31:25.117443Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 67.0 / 203  (33.0):  13%|█▎        | 202/1500 [00:06<00:20, 63.10it/s]2024-10-08T00:31:25.333751Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 220  (32.3):  15%|█▍        | 219/1500 [00:06<00:20, 61.26it/s]2024-10-08T00:31:25.599266Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 73.0 / 224  (32.6):  15%|█▍        | 223/1500 [00:06<00:20, 61.26it/s]2024-10-08T00:31:25.689891Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 228  (32.9):  15%|█▌        | 227/1500 [00:07<00:22, 56.53it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 82.0 / 247  (33.2):  16%|█▋        | 247/1500 [00:07<00:27, 45.15it/s]2024-10-08T00:31:26.223870Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 82.0 / 252  (32.5):  17%|█▋        | 251/1500 [00:07<00:27, 45.15it/s]2024-10-08T00:31:26.691900Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 83.0 / 256  (32.4):  17%|█▋        | 255/1500 [00:08<00:47, 26.27it/s]2024-10-08T00:31:26.918365Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 84.0 / 260  (32.3):  17%|█▋        | 259/1500 [00:08<00:52, 23.79it/s]2024-10-08T00:31:26.991818Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 87.0 / 270  (32.2):  18%|█▊        | 270/1500 [00:08<00:41, 29.80it/s]2024-10-08T00:31:27.367420Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 88.0 / 276  (31.9):  18%|█▊        | 275/1500 [00:08<00:42, 29.01it/s]2024-10-08T00:31:27.663570Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 88.0 / 279  (31.5):  19%|█▊        | 278/1500 [00:09<02:05,  9.73it/s]2024-10-08T00:31:28.592934Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 89.0 / 282  (31.6):  19%|█▉        | 282/1500 [00:09<01:41, 11.97it/s]2024-10-08T00:31:28.713005Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 96.0 / 293  (32.8):  19%|█▉        | 292/1500 [00:10<01:14, 16.31it/s]dspy.evaluate.evaluate1645Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 97.0 / 296  (32.8):  20%|█▉        | 295/1500 [00:10<01:13, 16.31it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 101.0 / 303  (33.3):  20%|██        | 302/1500 [00:10<00:55, 21.47it/s]2024-10-08T00:31:29.549020Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 108.0 / 318  (34.0):  21%|██        | 317/1500 [00:11<00:43, 26.92it/s]2024-10-08T00:31:30.087138Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 111.0 / 333  (33.3):  22%|██▏       | 332/1500 [00:11<00:31, 37.67it/s]2024-10-08T00:31:30.468625Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 117.0 / 348  (33.6):  23%|██▎       | 348/1500 [00:12<00:28, 40.80it/s]evaluate.py00:31:30.797534Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 128.0 / 375  (34.1):  25%|██▍       | 374/1500 [00:12<00:30, 37.47it/s]2024-10-08T00:31:31.565609Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 133.0 / 388  (34.3):  26%|██▌       | 388/1500 [00:13<00:26, 42.28it/s]2024-10-08T00:31:31.865753Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 138.0 / 399  (34.6):  27%|██▋       | 398/1500 [00:13<00:24, 44.96it/s]2024-10-08T00:31:32.061891Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 139.0 / 406  (34.2):  27%|██▋       | 406/1500 [00:13<00:22, 47.64it/s]dspy.evaluate.evaluate1595Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 154.0 / 456  (33.8):  30%|███       | 455/1500 [00:14<00:27, 38.66it/s] [24-10-08T00:31:33.341817Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 154.0 / 458  (33.6):  30%|███       | 457/1500 [00:14<00:25, 41.28it/s]2024-10-08T00:31:33.373002Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 164.0 / 494  (33.2):  33%|███▎      | 493/1500 [00:15<00:29, 33.87it/s]lineno0-08T00:31:34.356599Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 164.0 / 495  (33.1):  33%|███▎      | 494/1500 [00:15<00:29, 33.87it/s]2024-10-08T00:31:34.433294Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 166.0 / 498  (33.3):  33%|███▎      | 497/1500 [00:15<00:29, 33.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 174.0 / 514  (33.9):  34%|███▍      | 514/1500 [00:16<00:29, 33.14it/s]2024-10-08T00:31:35.213795Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 175.0 / 519  (33.7):  35%|███▍      | 519/1500 [00:16<00:37, 26.49it/s]=024-10-08T00:31:35.356445Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filenameevaluate.py lineno=198\n",
      "Average Metric: 178.0 / 523  (34.0):  35%|███▍      | 522/1500 [00:16<00:36, 26.49it/s]2024-10-08T00:31:35.462584Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 187.0 / 543  (34.4):  36%|███▌      | 542/1500 [00:17<00:30, 31.87it/s]2024-10-08T00:31:36.013366Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 187.0 / 547  (34.2):  36%|███▋      | 546/1500 [00:17<00:27, 34.53it/s]2024-10-08T00:31:36.100758Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 194.0 / 569  (34.1):  38%|███▊      | 569/1500 [00:17<00:21, 43.72it/s]2024-10-08T00:31:36.647527Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 194.0 / 572  (33.9):  38%|███▊      | 571/1500 [00:17<00:21, 43.72it/s]2024-10-08T00:31:36.761960Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 196.0 / 577  (34.0):  38%|███▊      | 576/1500 [00:18<00:24, 37.49it/s]2024-10-08T00:31:37.003686Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 197.0 / 581  (33.9):  39%|███▊      | 580/1500 [00:18<00:29, 31.12it/s]2024-10-08T00:31:37.067590Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 199.0 / 585  (34.0):  39%|███▉      | 584/1500 [00:19<01:37,  9.36it/s] rror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 202.0 / 590  (34.2):  39%|███▉      | 589/1500 [00:19<01:09, 13.08it/s]=024-10-08T00:31:38.333277Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 216.0 / 619  (34.9):  41%|████      | 618/1500 [00:20<00:23, 37.87it/s]2024-10-08T00:31:38.922019Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 219.0 / 625  (35.0):  42%|████▏     | 624/1500 [00:20<00:21, 41.15it/s]linenome08T00:31:38.927323Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py =198\n",
      "Average Metric: 220.0 / 629  (35.0):  42%|████▏     | 628/1500 [00:20<00:21, 41.15it/s]2024-10-08T00:31:39.011834Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 231.0 / 669  (34.5):  45%|████▍     | 668/1500 [00:20<00:13, 60.96it/s]2024-10-08T00:31:39.714808Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 234.0 / 674  (34.7):  45%|████▍     | 673/1500 [00:21<00:13, 60.96it/s]1984-10-08T00:31:39.726354Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 239.0 / 688  (34.7):  46%|████▌     | 687/1500 [00:21<00:12, 64.41it/s]2024-10-08T00:31:40.003100Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 239.0 / 691  (34.6):  46%|████▌     | 690/1500 [00:21<00:12, 64.33it/s] 024-10-08T00:31:40.012094Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 239.0 / 695  (34.4):  46%|████▋     | 694/1500 [00:21<00:12, 64.33it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 239.0 / 699  (34.2):  47%|████▋     | 698/1500 [00:21<00:13, 59.85it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 245.0 / 713  (34.4):  47%|████▋     | 712/1500 [00:21<00:12, 62.90it/s]=024-10-08T00:31:40.383277Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 249.0 / 727  (34.3):  48%|████▊     | 726/1500 [00:21<00:11, 64.58it/s]2024-10-08T00:31:40.625269Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 252.0 / 736  (34.2):  49%|████▉     | 735/1500 [00:22<00:12, 61.23it/s]2024-10-08T00:31:40.781441Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 258.0 / 755  (34.2):  50%|█████     | 754/1500 [00:22<00:11, 62.63it/s]2024-10-08T00:31:41.133189Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 266.0 / 794  (33.5):  53%|█████▎    | 793/1500 [00:23<00:25, 28.06it/s]2024-10-08T00:31:42.479774Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 267.0 / 796  (33.5):  53%|█████▎    | 795/1500 [00:23<00:22, 31.54it/s]2024-10-08T00:31:42.618807Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 277.0 / 823  (33.7):  55%|█████▍    | 822/1500 [00:24<00:19, 35.50it/s]2024-10-08T00:31:43.347979Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 277.0 / 825  (33.6):  55%|█████▍    | 824/1500 [00:24<00:19, 35.50it/s]2024-10-08T00:31:43.474741Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 277.0 / 829  (33.4):  55%|█████▌    | 828/1500 [00:24<00:22, 29.24it/s]2024-10-08T00:31:43.690406Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 281.0 / 836  (33.6):  56%|█████▌    | 836/1500 [00:25<00:28, 23.54it/s]2024-10-08T00:31:44.011334Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 284.0 / 842  (33.7):  56%|█████▌    | 841/1500 [00:25<00:24, 27.36it/s]2024-10-08T00:31:44.212923Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 284.0 / 843  (33.7):  56%|█████▌    | 842/1500 [00:25<00:24, 27.36it/s]2024-10-08T00:31:44.291450Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 286.0 / 847  (33.8):  56%|█████▋    | 847/1500 [00:25<00:28, 22.99it/s]2024-10-08T00:31:44.466499Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 288.0 / 858  (33.6):  57%|█████▋    | 857/1500 [00:26<00:25, 25.02it/s]2024-10-08T00:31:44.903922Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 290.0 / 862  (33.6):  57%|█████▋    | 861/1500 [00:26<00:25, 25.48it/s]2024-10-08T00:31:45.063579Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 299.0 / 879  (34.0):  59%|█████▊    | 878/1500 [00:26<00:18, 33.84it/s]2024-10-08T00:31:45.462206Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 303.0 / 889  (34.1):  59%|█████▉    | 888/1500 [00:26<00:17, 35.52it/s]2024-10-08T00:31:45.749186Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 303.0 / 892  (34.0):  59%|█████▉    | 892/1500 [00:27<00:15, 39.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 303.0 / 895  (33.9):  60%|█████▉    | 894/1500 [00:27<00:15, 39.88it/s]2024-10-08T00:31:45.864247Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 305.0 / 904  (33.7):  60%|██████    | 903/1500 [00:27<00:14, 41.37it/s] [24-10-08T00:31:46.029451Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 307.0 / 924  (33.2):  62%|██████▏   | 923/1500 [00:27<00:12, 46.41it/s]2024-10-08T00:31:46.474431Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 313.0 / 939  (33.3):  63%|██████▎   | 938/1500 [00:28<00:12, 46.60it/s]2024-10-08T00:31:46.778378Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 313.0 / 944  (33.2):  63%|██████▎   | 943/1500 [00:28<00:11, 49.44it/s]2024-10-08T00:31:46.944081Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 315.0 / 954  (33.0):  64%|██████▎   | 953/1500 [00:28<00:11, 46.69it/s]2024-10-08T00:31:47.149441Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 315.0 / 956  (32.9):  64%|██████▎   | 955/1500 [00:28<00:11, 46.69it/s]2024-10-08T00:31:47.190363Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 333.0 / 1005  (33.1):  67%|██████▋   | 1004/1500 [00:29<00:10, 46.05it/s]2024-10-08T00:31:48.369694Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 342.0 / 1034  (33.1):  69%|██████▉   | 1033/1500 [00:30<00:12, 36.20it/s]2024-10-08T00:31:49.184756Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 342.0 / 1036  (33.0):  69%|██████▉   | 1035/1500 [00:30<00:12, 36.20it/s]2024-10-08T00:31:49.226057Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 348.0 / 1049  (33.2):  70%|██████▉   | 1048/1500 [00:30<00:11, 38.50it/s]2024-10-08T00:31:49.584587Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 348.0 / 1051  (33.1):  70%|███████   | 1050/1500 [00:30<00:11, 38.50it/s]2024-10-08T00:31:49.699829Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 349.0 / 1061  (32.9):  71%|███████   | 1060/1500 [00:31<00:11, 37.23it/s]2024-10-08T00:31:50.088198Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 350.0 / 1067  (32.8):  71%|███████   | 1067/1500 [00:31<00:14, 29.24it/s]2024-10-08T00:31:50.252786Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 354.0 / 1078  (32.8):  72%|███████▏  | 1077/1500 [00:31<00:13, 31.00it/s]2024-10-08T00:31:50.717728Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 355.0 / 1082  (32.8):  72%|███████▏  | 1081/1500 [00:32<00:17, 24.03it/s]2024-10-08T00:31:50.790507Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 356.0 / 1086  (32.8):  72%|███████▏  | 1085/1500 [00:32<00:13, 30.53it/s]2024-10-08T00:31:50.882093Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 358.0 / 1089  (32.9):  73%|███████▎  | 1089/1500 [00:32<00:13, 29.41it/s]2024-10-08T00:31:51.002081Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 360.0 / 1093  (32.9):  73%|███████▎  | 1092/1500 [00:32<00:13, 29.41it/s]evaluate.py00:31:51.009504Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 364.0 / 1110  (32.8):  74%|███████▍  | 1110/1500 [00:32<00:11, 35.36it/s]=024-10-08T00:31:51.494485Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 367.0 / 1114  (32.9):  74%|███████▍  | 1113/1500 [00:32<00:10, 35.36it/s] 024-10-08T00:31:51.541979Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 370.0 / 1120  (33.0):  75%|███████▍  | 1119/1500 [00:33<00:09, 39.94it/s]2024-10-08T00:31:51.847962Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 371.0 / 1124  (33.0):  75%|███████▍  | 1123/1500 [00:33<00:11, 33.36it/s]lineno0-08T00:31:51.899594Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 375.0 / 1135  (33.0):  76%|███████▌  | 1134/1500 [00:33<00:13, 27.37it/s]2024-10-08T00:31:52.365154Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 376.0 / 1137  (33.1):  76%|███████▌  | 1136/1500 [00:33<00:13, 27.37it/s]filename08T00:31:52.370856Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 377.0 / 1139  (33.1):  76%|███████▌  | 1138/1500 [00:33<00:13, 27.37it/s]2024-10-08T00:31:52.489928Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 379.0 / 1142  (33.2):  76%|███████▌  | 1141/1500 [00:33<00:12, 29.11it/s]198luate.py00:31:52.505069Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=\n",
      "Average Metric: 386.0 / 1166  (33.1):  78%|███████▊  | 1165/1500 [00:34<00:09, 35.40it/s]=024-10-08T00:31:53.120096Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 393.0 / 1179  (33.3):  79%|███████▊  | 1178/1500 [00:34<00:07, 45.85it/s]2024-10-08T00:31:53.342883Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 393.0 / 1181  (33.3):  79%|███████▊  | 1180/1500 [00:34<00:06, 49.58it/s]2024-10-08T00:31:53.364903Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 396.0 / 1191  (33.2):  79%|███████▉  | 1190/1500 [00:34<00:08, 38.09it/s]2024-10-08T00:31:53.708462Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 398.0 / 1197  (33.2):  80%|███████▉  | 1196/1500 [00:35<00:07, 42.10it/s]2024-10-08T00:31:53.872812Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 407.0 / 1217  (33.4):  81%|████████  | 1216/1500 [00:35<00:07, 37.54it/s]2024-10-08T00:31:54.367533Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 407.0 / 1219  (33.4):  81%|████████  | 1218/1500 [00:35<00:07, 37.54it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 407.0 / 1221  (33.3):  81%|████████▏ | 1220/1500 [00:35<00:06, 41.27it/s]lineno   8T00:31:54.425587Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 409.0 / 1234  (33.1):  82%|████████▏ | 1233/1500 [00:36<00:07, 35.38it/s]2024-10-08T00:31:54.812874Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 410.0 / 1237  (33.1):  82%|████████▏ | 1237/1500 [00:36<00:06, 39.72it/s]2024-10-08T00:31:54.908541Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 410.0 / 1239  (33.1):  83%|████████▎ | 1238/1500 [00:36<00:06, 39.72it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 416.0 / 1255  (33.1):  84%|████████▎ | 1254/1500 [00:36<00:05, 44.46it/s]]024-10-08T00:31:55.242063Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 420.0 / 1277  (32.9):  85%|████████▌ | 1276/1500 [00:36<00:04, 49.67it/s]2024-10-08T00:31:55.700466Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 422.0 / 1281  (32.9):  85%|████████▌ | 1280/1500 [00:37<00:04, 54.68it/s]2024-10-08T00:31:55.767216Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 423.0 / 1283  (33.0):  85%|████████▌ | 1282/1500 [00:37<00:03, 54.68it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 426.0 / 1292  (33.0):  86%|████████▌ | 1291/1500 [00:37<00:04, 48.67it/s]2024-10-08T00:31:55.947665Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 428.0 / 1301  (32.9):  87%|████████▋ | 1300/1500 [00:37<00:03, 63.94it/s]2024-10-08T00:31:56.056900Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 432.0 / 1308  (33.0):  87%|████████▋ | 1307/1500 [00:37<00:03, 63.60it/s]2024-10-08T00:31:56.149585Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 433.0 / 1310  (33.1):  87%|████████▋ | 1309/1500 [00:37<00:03, 63.60it/s]evaluate.py] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 433.0 / 1313  (33.0):  87%|████████▋ | 1312/1500 [00:37<00:02, 67.28it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 433.0 / 1314  (33.0):  88%|████████▊ | 1313/1500 [00:37<00:02, 67.28it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 435.0 / 1319  (33.0):  88%|████████▊ | 1319/1500 [00:37<00:02, 61.46it/s]2024-10-08T00:31:56.355995Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 435.0 / 1323  (32.9):  88%|████████▊ | 1322/1500 [00:37<00:02, 61.46it/s]2024-10-08T00:31:56.530949Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 435.0 / 1324  (32.9):  88%|████████▊ | 1323/1500 [00:37<00:02, 61.46it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 440.0 / 1336  (32.9):  89%|████████▉ | 1335/1500 [00:38<00:03, 47.29it/s]2024-10-08T00:31:56.855355Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 445.0 / 1354  (32.9):  90%|█████████ | 1353/1500 [00:38<00:02, 52.31it/s]2024-10-08T00:31:57.081829Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 448.0 / 1362  (32.9):  91%|█████████ | 1361/1500 [00:38<00:02, 58.61it/s]2024-10-08T00:31:57.156434Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 448.0 / 1363  (32.9):  91%|█████████ | 1362/1500 [00:38<00:02, 58.61it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 449.0 / 1369  (32.8):  91%|█████████ | 1368/1500 [00:38<00:01, 73.83it/s]2024-10-08T00:31:57.268353Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 491.0 / 1500  (32.7): 100%|██████████| 1500/1500 [00:40<00:00, 37.43it/s] \n"
     ]
    }
   ],
   "source": [
    "COMPILE_PROGRAM = True\n",
    "\n",
    "optimizer_trainset, optimizer_valset = get_optimizer_train_val_set(shuffled_trainset, OPTIMIZER_NUM_TRAIN, OPTIMIZER_NUM_VAL)\n",
    "\n",
    "with dspy.context(lm=llama_1b):\n",
    "    vanilla_program = SimpleIntentClassificationModule()\n",
    "    if COMPILE_PROGRAM:\n",
    "        bfrs_program = bfrs_optimizer.compile(vanilla_program, trainset=optimizer_trainset, valset=optimizer_valset)\n",
    "        bfrs_program.save(f\"simpleintent_1b_32_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}.json\")\n",
    "    else:\n",
    "        bfrs_program = SimpleIntentClassificationModule()\n",
    "        bfrs_program.load(f\"simpleintent_1b_32_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}.json\")\n",
    "    llama_1b_bfrs_eval = evaluate_devset(bfrs_program)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ft_bfrs_results)\n",
    "# print(ft_vanilla_results)\n",
    "# ft_bfrs_results = {'epochs-1-total-trained-steps-20': 29.53, 'epochs-5-total-trained-steps-60': 38.13, 'epochs-2-total-trained-steps-30': 33.87, 'epochs-3-total-trained-steps-40': 46.07, 'epochs-4-total-trained-steps-50': 42.27, 'epochs-0-total-trained-steps-10': 35.13}\n",
    "# ft_vanilla_results = {'epochs-1-total-trained-steps-20': 17.6,\n",
    "#  'epochs-5-total-trained-steps-60': 20.27,\n",
    "#  'epochs-2-total-trained-steps-30': 22.87,\n",
    "#  'epochs-3-total-trained-steps-40': 27.53,\n",
    "#  'epochs-4-total-trained-steps-50': 20.6,\n",
    "#  'epochs-0-total-trained-steps-10': 24.33}\n",
    "\n",
    "def shorten_epoch_name(epoch_name):\n",
    "    # Remove the prefix and keep the number\n",
    "    return \"Epoch \" + epoch_name.split('-')[1]\n",
    "\n",
    "ft_bfrs_results_named = {shorten_epoch_name(epoch): score for epoch, score in ft_bfrs_results.items()}\n",
    "ft_vanilla_results_named = {shorten_epoch_name(epoch): score for epoch, score in ft_vanilla_results.items()}\n",
    "\n",
    "ft_vanilla_results_named[\"Base Model\"] = vanilla_1b_base_eval # 20\n",
    "ft_bfrs_results_named[\"Base Model\"] = llama_1b_bfrs_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Process the data\n",
    "epochs = []\n",
    "vanilla_scores = []\n",
    "bfrs_scores = []\n",
    "\n",
    "for epoch, vanilla_score in ft_vanilla_results_named.items():\n",
    "    if epoch in ft_bfrs_results_named:\n",
    "        epochs.append(epoch)\n",
    "        vanilla_scores.append(vanilla_score)\n",
    "        bfrs_scores.append(ft_bfrs_results_named[epoch])\n",
    "\n",
    "# Sort the data by epoch\n",
    "sorted_data = sorted(zip(epochs, vanilla_scores, bfrs_scores), key=lambda x: x[0])\n",
    "epochs, vanilla_scores, bfrs_scores = zip(*sorted_data)\n",
    "\n",
    "# Create the bar chart\n",
    "x = np.arange(len(epochs))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "rects1 = ax.bar(x - width/2, vanilla_scores, width, label='Vanilla', color='skyblue')\n",
    "rects2 = ax.bar(x + width/2, bfrs_scores, width, label='BFRS', color='orange')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title(f'Comparison of Vanilla and BFRS Results by Epoch (N={len(devset)})')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(epochs, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "# Add value labels on top of each bar\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning MIPROv2 optimization process...\n",
      "\n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "These will be used for as few-shot examples candidates for our program and for creating instructions.\n",
      "\n",
      "Bootstrapping N=10 sets of demonstrations...\n",
      "Bootstrapping set 1/10\n",
      "Bootstrapping set 2/10\n",
      "Bootstrapping set 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [00:23<00:50,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 33 examples in round 0.\n",
      "Bootstrapping set 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:01<00:10,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 14 examples in round 0.\n",
      "Bootstrapping set 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:02<00:20,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 11 examples in round 0.\n",
      "Bootstrapping set 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:00<00:05, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 15 examples in round 0.\n",
      "Bootstrapping set 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:00<00:14,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n",
      "Bootstrapping set 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [00:04<00:10,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 29 examples in round 0.\n",
      "Bootstrapping set 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:04<00:17,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 22 examples in round 0.\n",
      "Bootstrapping set 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:02<00:09,  8.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 20 examples in round 0.\n",
      "\n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "In this step, by default we will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n",
      "SOURCE CODE: StringSignature(intent -> reasoning, label\n",
      "    instructions=\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\\nThe intent should exactly match one of the following:\\n['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\"\n",
      "    intent = Field(annotation=str required=True json_schema_extra={'desc': 'Intent of the query', '__dspy_field_type': 'input', 'prefix': 'Intent:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    label = Field(annotation=str required=True json_schema_extra={'desc': 'Type of the intent; Should just be one of the 25 labels with no other text', '__dspy_field_type': 'output', 'prefix': 'Label:'})\n",
      ")\n",
      "\n",
      "class SimpleIntentClassificationModule(dspy.Module):\n",
      "    def __init__(self):\n",
      "        self.intent_classifier = dspy.ChainOfThought(IntentClassification)\n",
      "        self.valid_labels = set([\"activate_my_card\", \"cancel_transfer\", \"cash_withdrawal_charge\", \"declined_card_payment\", \"declined_cash_withdrawal\", \"direct_debit_payment_not_recognised\", \"extra_charge_on_statement\", \"pending_card_payment\", \"pending_top_up\", \"Refund_not_showing_up\", \"request_refund\", \"reverted_card_payment\", \"transaction_charged_twice\", \"transfer_fee_charged\", \"transfer_not_received_by_recipient\", \"wrong_amount_of_cash_received\", \"wrong_exchange_rate_for_cash_withdrawal\"])\n",
      "\n",
      "    def forward(self, text):\n",
      "        prediction = self.intent_classifier(intent=text)\n",
      "\n",
      "        sanitized_prediction = dspy.Prediction(label=prediction.label.lower().strip().replace(\" \", \"_\"))\n",
      "        # if sanitized_prediction.label not in self.valid_labels:\n",
      "        #     for label in self.valid_labels:\n",
      "        #         if label in sanitized_prediction.label:\n",
      "        #             sanitized_prediction.label = label\n",
      "        #             break\n",
      "        #     # this means that the prediction was not in the valid labels\n",
      "        #     # Could do edit distance or something more sophisticated here\n",
      "        #     # but for now just take the first\n",
      "        #     sanitized_prediction.label = self.valid_labels[0]\n",
      "        return sanitized_prediction\n",
      "\n",
      "DATA SUMMARY: The two major issues identified that were present across all users during the login screen of the banking app are:\n",
      "\n",
      "1.   **Incorrect card details or missing documentation**: This likely encompasses most instances of both common card authentication errors and missing documentation errors.\n",
      "2.  **Password protection errors**: This issue generally receives the most attention, with many users having a correct and strong password, yet still exhibiting error due to insignificant spelling mistakes.\n",
      "\n",
      "The provided dataset including all observations highlighting trends in the type of issues encountered supports these observations.\n",
      "\n",
      "Proposing instructions...\n",
      "\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: description\n",
      "PROGRAM DESCRIPTION: The program appears to be designed to classify the intent of a natural language query into one of the 25 labels in a banking issue tracing system.\n",
      "task_demos \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `program_code` (str): Language model program designed to solve a particular task.\n",
      "3. `program_description` (str): Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "4. `module` (str): The module to create an instruction for.\n",
      "5. `task_demos` (str): Example inputs/outputs of our module.\n",
      "6. `basic_instruction` (str): Basic instruction.\n",
      "7. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "{program_code}\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "{program_description}\n",
      "\n",
      "[[ ## module ## ]]\n",
      "{module}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The two major issues identified that were present across all users during the login screen of the banking app are:\n",
      "\n",
      "1.   **Incorrect card details or missing documentation**: This likely encompasses most instances of both common card authentication errors and missing documentation errors.\n",
      "2.  **Password protection errors**: This issue generally receives the most attention, with many users having a correct and strong password, yet still exhibiting error due to insignificant spelling mistakes.\n",
      "\n",
      "The provided dataset including all observations highlighting trends in the type of issues encountered supports these observations.\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "StringSignature(intent -> reasoning, label\n",
      "    instructions=\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\\nThe intent should exactly match one of the following:\\n['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\"\n",
      "    intent = Field(annotation=str required=True json_schema_extra={'desc': 'Intent of the query', '__dspy_field_type': 'input', 'prefix': 'Intent:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    label = Field(annotation=str required=True json_schema_extra={'desc': 'Type of the intent; Should just be one of the 25 labels with no other text', '__dspy_field_type': 'output', 'prefix': 'Label:'})\n",
      ")\n",
      "\n",
      "class SimpleIntentClassificationModule(dspy.Module):\n",
      "    def __init__(self):\n",
      "        self.intent_classifier = dspy.ChainOfThought(IntentClassification)\n",
      "        self.valid_labels = set([\"activate_my_card\", \"cancel_transfer\", \"cash_withdrawal_charge\", \"declined_card_payment\", \"declined_cash_withdrawal\", \"direct_debit_payment_not_recognised\", \"extra_charge_on_statement\", \"pending_card_payment\", \"pending_top_up\", \"Refund_not_showing_up\", \"request_refund\", \"reverted_card_payment\", \"transaction_charged_twice\", \"transfer_fee_charged\", \"transfer_not_received_by_recipient\", \"wrong_amount_of_cash_received\", \"wrong_exchange_rate_for_cash_withdrawal\"])\n",
      "\n",
      "    def forward(self, text):\n",
      "        prediction = self.intent_classifier(intent=text)\n",
      "\n",
      "        sanitized_prediction = dspy.Prediction(label=prediction.label.lower().strip().replace(\" \", \"_\"))\n",
      "        # if sanitized_prediction.label not in self.valid_labels:\n",
      "        #     for label in self.valid_labels:\n",
      "        #         if label in sanitized_prediction.label:\n",
      "        #             sanitized_prediction.label = label\n",
      "        #             break\n",
      "        #     # this means that the prediction was not in the valid labels\n",
      "        #     # Could do edit distance or something more sophisticated here\n",
      "        #     # but for now just take the first\n",
      "        #     sanitized_prediction.label = self.valid_labels[0]\n",
      "        return sanitized_prediction\n",
      "\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "The program appears to be designed to classify the intent of a natural language query into one of the 25 labels in a banking issue tracing system.\n",
      "\n",
      "[[ ## module ## ]]\n",
      "Predict(intent) -> reasoning, label\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Make sure your instruction is very informative and descriptive.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "Here are the proposed instructions based on the input provided:\n",
      "\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "Validate the input given in the first example of a dataset where the intent can be activated the card, a bank account has not been updated by another person, a payment has been charged for the wrong exchange rate, or if the card payment was rejected.\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal'.\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Make sure your instruction is very informative and descriptive.\n",
      "\n",
      "Completed.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "Proposed Instructions for Predictor 0:\n",
      "\n",
      "0: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "\n",
      "Evaluating the default program...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 50 / 300  (16.7): 100%|██████████| 300/300 [00:22<00:00, 13.32it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default program score: 16.67\n",
      "\n",
      "==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "In this step, we will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination. Bayesian Optimization will be used for this search process.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.9/site-packages/optuna/_experimental.py:30: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Minibatch Trial 1 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6 / 25  (24.0): 100%|██████████| 25/25 [00:00<00:00, 1227.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1179.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a discrepancy between the expected and actual exchange rates.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a discrepancy between the expected and actual exchange rates.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 24.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 1'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 2 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]2024-10-08T00:53:31.414835Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   4%|▍         | 1/25 [00:00<00:20,  1.18it/s]08T00:53:31.425364Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   4%|▍         | 1/25 [00:00<00:20,  1.18it/s]2024-10-08T00:53:31.857916Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 25  (20.0): 100%|██████████| 25/25 [00:02<00:00, 11.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Please cancel my most recent transfer, it was a mistake. This is an emergency. It needs to be canceled before it goes through.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing a sense of urgency and is requesting immediate cancellation of their most recent transfer, which they believe was a mistake. They are also indicating that this is an emergency situation.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{cancel_transfer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I've been charged an extra £1 and I don't know why\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an extra charge on their statement, which they don't understand why it was added.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "extra_charge_on_statement\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating that the rate is not correct.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Please cancel my most recent transfer, it was a mistake. This is an emergency. It needs to be canceled before it goes through.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing a sense of urgency and is requesting immediate cancellation of their most recent transfer, which they believe was a mistake. They are also indicating that this is an emergency situation.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{cancel_transfer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I've been charged an extra £1 and I don't know why\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an extra charge on their statement, which they don't understand why it was added.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "extra_charge_on_statement\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating that the rate is not correct.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 20.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 2'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 3 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]2024-10-08T00:53:34.187469Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   4%|▍         | 1/25 [00:00<00:18,  1.31it/s]2024-10-08T00:53:34.206561Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   4%|▍         | 1/25 [00:00<00:18,  1.31it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 25  (36.0): 100%|██████████| 25/25 [00:10<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 36.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 6'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 4 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 3  (0.0):   8%|▊         | 2/25 [00:00<00:00, 44.56it/s] 2024-10-08T00:53:45.076370Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):  16%|█▌        | 4/25 [00:00<00:04,  4.60it/s]2024-10-08T00:53:45.113924Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 25  (16.0): 100%|██████████| 25/25 [00:01<00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1095.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Please cancel my most recent transfer, it was a mistake. This is an emergency. It needs to be canceled before it goes through.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing a sense of urgency and is requesting immediate cancellation of their most recent transfer, which they believe was a mistake. They are also indicating that this is an emergency situation.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{cancel_transfer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I've been charged an extra £1 and I don't know why\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an extra charge on their statement, which they don't understand why it was added.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "extra_charge_on_statement\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating that the rate is not correct.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Please cancel my most recent transfer, it was a mistake. This is an emergency. It needs to be canceled before it goes through.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing a sense of urgency and is requesting immediate cancellation of their most recent transfer, which they believe was a mistake. They are also indicating that this is an emergency situation.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{cancel_transfer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I've been charged an extra £1 and I don't know why\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an extra charge on their statement, which they don't understand why it was added.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "extra_charge_on_statement\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating that the rate is not correct.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 16.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 2'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 5 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]2024-10-08T00:53:46.966558Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   4%|▍         | 1/25 [00:00<00:16,  1.43it/s]2024-10-08T00:53:47.043542Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   4%|▍         | 1/25 [00:00<00:16,  1.43it/s]2024-10-08T00:53:47.129484Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 25  (28.0): 100%|██████████| 25/25 [00:02<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why did I get less cash than what I asked in the ATM?\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing frustration and confusion about receiving less cash than they asked for at an ATM, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{wrong_amount_of_cash_received}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "If I make a mistake can I cancel the transaction?\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the possibility of cancelling a transaction due to a potential mistake.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cancel_transfer\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I'm still waiting for the top-up!\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing frustration and is waiting for a top-up on their account, indicating a potential issue with the transaction or the bank's processing.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "pending_top_up\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the accuracy of the exchange rate for a card payment, indicating a potential issue with the transaction or the bank's processing.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why did I get less cash than what I asked in the ATM?\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing frustration and confusion about receiving less cash than they asked for at an ATM, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{wrong_amount_of_cash_received}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "If I make a mistake can I cancel the transaction?\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the possibility of cancelling a transaction due to a potential mistake.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cancel_transfer\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I'm still waiting for the top-up!\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing frustration and is waiting for a top-up on their account, indicating a potential issue with the transaction or the bank's processing.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "pending_top_up\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the accuracy of the exchange rate for a card payment, indicating a potential issue with the transaction or the bank's processing.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 28.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 8'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 6 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0):   0%|          | 0/25 [00:00<?, ?it/s]\t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 25  (28.0): 100%|██████████| 25/25 [00:01<00:00, 14.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1152.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 28.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 6'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 7 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5 / 25  (20.0): 100%|██████████| 25/25 [00:01<00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I'm still waiting for the top-up!\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing frustration and is waiting for a top-up on their account, indicating a potential issue with the transaction or the bank's processing.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "pending_top_up\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the bank's exchange rate or the transaction itself.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I'm still waiting for the top-up!\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing frustration and is waiting for a top-up on their account, indicating a potential issue with the transaction or the bank's processing.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "pending_top_up\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the bank's exchange rate or the transaction itself.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 20.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 4'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 8 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 4  (25.0):  12%|█▏        | 3/25 [00:00<00:00, 113.25it/s]2024-10-08T00:53:54.156271Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 5  (20.0):  20%|██        | 5/25 [00:00<00:02,  8.52it/s]2024-10-08T00:53:54.512455Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 25  (36.0): 100%|██████████| 25/25 [00:01<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1040.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 36.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 5'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 9 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]2024-10-08T00:53:56.460355Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 25  (36.0): 100%|██████████| 25/25 [00:01<00:00, 13.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I received the wrong amount of cash back\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting a discrepancy in the amount of cash they received back after a cash withdrawal.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_amount_of_cash_received\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "There is a €1 extra fee in my statement\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an extra fee in their statement, which suggests a potential issue with their account.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "extra_charge_on_statement\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an issue with the exchange rate of their card payment, which suggests a potential problem with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I received the wrong amount of cash back\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting a discrepancy in the amount of cash they received back after a cash withdrawal.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_amount_of_cash_received\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "There is a €1 extra fee in my statement\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an extra fee in their statement, which suggests a potential issue with their account.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "extra_charge_on_statement\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an issue with the exchange rate of their card payment, which suggests a potential problem with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 36.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 3'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 10 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 2  (50.0):   4%|▍         | 1/25 [00:00<00:00, 71.20it/s]2024-10-08T00:53:58.530231Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 3  (33.3):  12%|█▏        | 3/25 [00:00<00:05,  4.28it/s]2024-10-08T00:53:58.635114Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 25  (32.0): 100%|██████████| 25/25 [00:01<00:00, 12.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1148.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why did I get less cash than what I asked in the ATM?\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing frustration and confusion about receiving less cash than they asked for at an ATM, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{wrong_amount_of_cash_received}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "If I make a mistake can I cancel the transaction?\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the possibility of cancelling a transaction due to a potential mistake.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cancel_transfer\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I'm still waiting for the top-up!\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing frustration and is waiting for a top-up on their account, indicating a potential issue with the transaction or the bank's processing.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "pending_top_up\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the accuracy of the exchange rate for a card payment, indicating a potential issue with the transaction or the bank's processing.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why did I get less cash than what I asked in the ATM?\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing frustration and confusion about receiving less cash than they asked for at an ATM, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{wrong_amount_of_cash_received}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "If I make a mistake can I cancel the transaction?\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the possibility of cancelling a transaction due to a potential mistake.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cancel_transfer\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I'm still waiting for the top-up!\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing frustration and is waiting for a top-up on their account, indicating a potential issue with the transaction or the bank's processing.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "pending_top_up\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the accuracy of the exchange rate for a card payment, indicating a potential issue with the transaction or the bank's processing.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 32.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 8'].\n",
      "\n",
      "\n",
      "===== Full Eval 1 =====\n",
      "Doing full eval on next top averaging program (Avg Score: 36.0) so far from mini-batch trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08T00:53:59.910414Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-08T00:54:00.023008Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-08T00:54:01.400189Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-08T00:54:01.868485Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 6  (16.7):   2%|▏         | 5/300 [00:00<00:09, 30.33it/s]=d ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 24.0 / 70  (34.3):  23%|██▎       | 69/300 [00:00<00:06, 33.08it/s]2024-10-08T00:54:03.640980Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 71  (33.8):  24%|██▎       | 71/300 [00:01<00:04, 50.28it/s]2024-10-08T00:54:03.728533Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 72  (33.3):  24%|██▎       | 71/300 [00:01<00:04, 50.28it/s]2024-10-08T00:54:04.337986Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 73  (32.9):  24%|██▍       | 72/300 [00:02<00:04, 50.28it/s]2024-10-08T00:54:04.453611Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 74  (32.4):  24%|██▍       | 73/300 [00:02<00:04, 50.28it/s]2024-10-08T00:54:04.469089Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 75  (32.0):  25%|██▍       | 74/300 [00:02<00:04, 50.28it/s]2024-10-08T00:54:04.530636Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 76  (31.6):  25%|██▌       | 76/300 [00:02<00:07, 28.55it/s]2024-10-08T00:54:04.567031Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 77  (31.2):  25%|██▌       | 76/300 [00:02<00:07, 28.55it/s]2024-10-08T00:54:04.585132Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 78  (30.8):  26%|██▌       | 77/300 [00:02<00:07, 28.55it/s]2024-10-08T00:54:04.592658Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 79  (30.4):  26%|██▌       | 78/300 [00:02<00:07, 28.55it/s]2024-10-08T00:54:04.611988Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 80  (30.0):  26%|██▋       | 79/300 [00:02<00:07, 28.55it/s]2024-10-08T00:54:04.637757Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 81  (29.6):  27%|██▋       | 81/300 [00:02<00:07, 29.71it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 82  (29.3):  27%|██▋       | 81/300 [00:02<00:07, 29.71it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 83  (28.9):  27%|██▋       | 82/300 [00:02<00:07, 29.71it/s]2024-10-08T00:54:04.702812Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 84  (28.6):  28%|██▊       | 83/300 [00:02<00:07, 29.71it/s]2024-10-08T00:54:04.942269Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 85  (28.2):  28%|██▊       | 85/300 [00:02<00:08, 26.01it/s]2024-10-08T00:54:04.988875Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 86  (27.9):  28%|██▊       | 85/300 [00:02<00:08, 26.01it/s]2024-10-08T00:54:05.279086Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 87  (27.6):  29%|██▊       | 86/300 [00:03<00:08, 26.01it/s]2024-10-08T00:54:05.323933Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 88  (27.3):  29%|██▉       | 88/300 [00:03<00:10, 20.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 89  (27.0):  29%|██▉       | 88/300 [00:03<00:10, 20.43it/s]2024-10-08T00:54:05.391860Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 90  (26.7):  30%|██▉       | 89/300 [00:03<00:10, 20.43it/s]2024-10-08T00:54:05.416822Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 91  (26.4):  30%|███       | 90/300 [00:03<00:10, 20.43it/s]2024-10-08T00:54:06.135257Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 92  (26.1):  31%|███       | 92/300 [00:03<00:15, 13.12it/s]2024-10-08T00:54:06.335538Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 93  (25.8):  31%|███       | 92/300 [00:04<00:15, 13.12it/s]2024-10-08T00:54:06.582556Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 94  (25.5):  31%|███▏      | 94/300 [00:04<00:19, 10.76it/s]2024-10-08T00:54:07.031691Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 95  (25.3):  31%|███▏      | 94/300 [00:04<00:19, 10.76it/s]2024-10-08T00:54:07.232284Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 105.0 / 300  (35.0): 100%|██████████| 300/300 [00:07<00:00, 40.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best full eval score so far! Score: 35.0\n",
      "=======================\n",
      "\n",
      "\n",
      "== Minibatch Trial 11 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]2024-10-08T00:54:10.554331Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   4%|▍         | 1/25 [00:00<00:19,  1.24it/s]2024-10-08T00:54:10.748266Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   8%|▊         | 2/25 [00:01<00:10,  2.22it/s]error    8T00:54:10.762331Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   8%|▊         | 2/25 [00:01<00:10,  2.22it/s]2024-10-08T00:54:10.814437Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 25  (28.0): 100%|██████████| 25/25 [00:02<00:00, 11.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I received the wrong amount of cash back\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting a discrepancy in the amount of cash they received back after a cash withdrawal.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_amount_of_cash_received\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Please cancel my most recent transfer, it was a mistake. This is an emergency. It needs to be canceled before it goes through.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing a sense of urgency and is requesting immediate cancellation of their most recent transfer, which they believe was a mistake. They are also indicating that this is an emergency situation.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{cancel_transfer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "If I make a mistake can I cancel the transaction?\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the possibility of cancelling a transaction due to a potential mistake.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cancel_transfer\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating that it is not in their favor.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{exchange_rate_not_in_favor}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I received the wrong amount of cash back\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting a discrepancy in the amount of cash they received back after a cash withdrawal.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_amount_of_cash_received\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Please cancel my most recent transfer, it was a mistake. This is an emergency. It needs to be canceled before it goes through.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing a sense of urgency and is requesting immediate cancellation of their most recent transfer, which they believe was a mistake. They are also indicating that this is an emergency situation.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{cancel_transfer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "If I make a mistake can I cancel the transaction?\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the possibility of cancelling a transaction due to a potential mistake.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cancel_transfer\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating that it is not in their favor.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{exchange_rate_not_in_favor}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 28.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 9'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 12 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 2  (50.0):   4%|▍         | 1/25 [00:00<00:00, 696.15it/s] ed ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filenameevaluate.pylineno=198\n",
      "Average Metric: 6 / 11  (54.5):  40%|████      | 10/25 [00:00<00:00, 618.62it/s]24-10-08T00:54:12.595369Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno=198\n",
      "Average Metric: 10 / 21  (47.6):  80%|████████  | 20/25 [00:00<00:00, 590.31it/s]198name08T00:54:12.599580Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate =evaluate.py lineno\n",
      "Average Metric: 10.0 / 25  (40.0): 100%|██████████| 25/25 [00:00<00:00, 643.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1060.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 40.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 5'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 13 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 6  (33.3):  20%|██        | 5/25 [00:00<00:00, 751.10it/s]=ilenameasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate =evaluate.pylineno198\n",
      "Average Metric: 9.0 / 25  (36.0): 100%|██████████| 25/25 [00:00<00:00, 956.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1114.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 36.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 6'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 14 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 3  (66.7):   8%|▊         | 2/25 [00:00<00:00, 786.33it/s]198 ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.pylineno=\n",
      "Average Metric: 5 / 13  (38.5):  48%|████▊     | 12/25 [00:00<00:00, 782.88it/s]=or for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno198\n",
      "Average Metric: 8 / 21  (38.1):  80%|████████  | 20/25 [00:00<00:00, 617.27it/s]linenote.pyte.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] = =198\n",
      "Average Metric: 8.0 / 25  (32.0): 100%|██████████| 25/25 [00:00<00:00, 664.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1015.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 32.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 5'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 15 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9 / 25  (36.0): 100%|██████████| 25/25 [00:02<00:00, 12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0): 100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The cheque I deposited isn't showing in my account\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting that they deposited a cheque but it hasn't appeared in their account, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing concern that the exchange rate for their card payment is incorrect, which could be affecting the amount they received.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_wrong_exchange_rate\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The cheque I deposited isn't showing in my account\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting that they deposited a cheque but it hasn't appeared in their account, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing concern that the exchange rate for their card payment is incorrect, which could be affecting the amount they received.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_wrong_exchange_rate\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 36.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 7'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 16 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4 / 25  (16.0): 100%|██████████| 25/25 [00:00<00:00, 1240.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1097.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a discrepancy between the expected and actual exchange rates.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a discrepancy between the expected and actual exchange rates.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 16.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 0'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 17 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 5  (20.0):  16%|█▌        | 4/25 [00:00<00:00, 820.32it/s]=ed ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filename=evaluate.pylineno198\n",
      "Average Metric: 3 / 15  (20.0):  56%|█████▌    | 14/25 [00:00<00:00, 638.35it/s]linenote.py:54:15.731369Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] = =198\n",
      "Average Metric: 5.0 / 25  (20.0): 100%|██████████| 25/25 [00:00<00:00, 789.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1137.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 20.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 5'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 18 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 4  (25.0):  12%|█▏        | 3/25 [00:00<00:00, 771.82it/s]198enote.pyning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename= =\n",
      "Average Metric: 6 / 14  (42.9):  52%|█████▏    | 13/25 [00:00<00:00, 607.10it/s]=ineno08T00:54:15.839680Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py 198\n",
      "Average Metric: 7.0 / 22  (31.8):  84%|████████▍ | 21/25 [00:00<00:00, 661.55it/s]lename08T00:54:15.840876Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate =evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 23  (30.4):  88%|████████▊ | 22/25 [00:00<00:00, 602.16it/s]2024-10-08T00:54:15.843578Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 24  (29.2):  92%|█████████▏| 23/25 [00:00<00:00, 505.85it/s]2024-10-08T00:54:15.845260Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 25  (28.0): 100%|██████████| 25/25 [00:00<00:00, 438.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Why was I charged a fee for using my card\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the reason for a fee being charged to their card, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_fee_charged\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cash_withdrawal_not_recognised\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 28.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 6'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 19 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 25  (28.0): 100%|██████████| 25/25 [00:01<00:00, 14.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1053.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I received the wrong amount of cash back\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting a discrepancy in the amount of cash they received back after a cash withdrawal.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_amount_of_cash_received\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Please cancel my most recent transfer, it was a mistake. This is an emergency. It needs to be canceled before it goes through.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing a sense of urgency and is requesting immediate cancellation of their most recent transfer, which they believe was a mistake. They are also indicating that this is an emergency situation.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{cancel_transfer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "If I make a mistake can I cancel the transaction?\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the possibility of cancelling a transaction due to a potential mistake.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cancel_transfer\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating that it is not in their favor.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{exchange_rate_not_in_favor}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I received the wrong amount of cash back\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting a discrepancy in the amount of cash they received back after a cash withdrawal.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_amount_of_cash_received\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "Please cancel my most recent transfer, it was a mistake. This is an emergency. It needs to be canceled before it goes through.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing a sense of urgency and is requesting immediate cancellation of their most recent transfer, which they believe was a mistake. They are also indicating that this is an emergency situation.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{cancel_transfer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "If I make a mistake can I cancel the transaction?\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is inquiring about the possibility of cancelling a transaction due to a potential mistake.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "cancel_transfer\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating that it is not in their favor.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{exchange_rate_not_in_favor}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 28.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 9'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 20 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 2  (100.0):   4%|▍         | 1/25 [00:00<00:00, 380.64it/s]2024-10-08T00:54:18.786558Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 3  (66.7):  12%|█▏        | 3/25 [00:00<00:06,  3.27it/s]2024-10-08T00:54:19.013389Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 4  (50.0):  16%|█▌        | 4/25 [00:01<00:05,  3.57it/s]2024-10-08T00:54:19.324724Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 25  (40.0): 100%|██████████| 25/25 [00:01<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1154.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I received the wrong amount of cash back\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting a discrepancy in the amount of cash they received back after a cash withdrawal.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_amount_of_cash_received\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "There is a €1 extra fee in my statement\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an extra fee in their statement, which suggests a potential issue with their account.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "extra_charge_on_statement\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an issue with the exchange rate of their card payment, which suggests a potential problem with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I received the wrong amount of cash back\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting a discrepancy in the amount of cash they received back after a cash withdrawal.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_amount_of_cash_received\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "There is a €1 extra fee in my statement\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an extra fee in their statement, which suggests a potential issue with their account.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "extra_charge_on_statement\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an issue with the exchange rate of their card payment, which suggests a potential problem with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 40.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 3'].\n",
      "\n",
      "\n",
      "===== Full Eval 2 =====\n",
      "Doing full eval on next top averaging program (Avg Score: 38.0) so far from mini-batch trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08T00:54:19.931218Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-08T00:54:21.548412Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-08T00:54:21.711081Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-08T00:54:21.849957Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-08T00:54:21.883169Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-08T00:54:22.559361Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-08T00:54:22.785738Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 55  (30.9):  18%|█▊        | 54/300 [00:01<00:05, 46.26it/s] 024-10-08T00:54:25.675550Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 57  (29.8):  19%|█▉        | 57/300 [00:01<00:08, 29.57it/s]2024-10-08T00:54:25.746001Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 59  (28.8):  19%|█▉        | 58/300 [00:01<00:08, 29.57it/s]2024-10-08T00:54:25.780633Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 65  (30.8):  21%|██▏       | 64/300 [00:02<00:11, 20.21it/s]2024-10-08T00:54:26.400220Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 70  (28.6):  23%|██▎       | 69/300 [00:02<00:10, 23.04it/s]2024-10-08T00:54:26.483286Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 71  (28.2):  23%|██▎       | 70/300 [00:02<00:09, 23.04it/s]2024-10-08T00:54:26.629670Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 72  (27.8):  24%|██▍       | 72/300 [00:02<00:10, 22.14it/s]2024-10-08T00:54:26.698217Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 73  (27.4):  24%|██▍       | 72/300 [00:02<00:10, 22.14it/s]2024-10-08T00:54:26.714424Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 75  (28.0):  25%|██▌       | 75/300 [00:03<00:13, 16.47it/s]2024-10-08T00:54:27.030452Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 80  (28.8):  27%|██▋       | 80/300 [00:03<00:12, 18.21it/s]evaluate.py00:54:27.219738Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 23.0 / 82  (28.0):  27%|██▋       | 81/300 [00:03<00:12, 18.21it/s]2024-10-08T00:54:27.248863Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 83  (27.7):  27%|██▋       | 82/300 [00:03<00:11, 18.21it/s]2024-10-08T00:54:27.262839Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 84  (27.4):  28%|██▊       | 83/300 [00:03<00:11, 18.21it/s]2024-10-08T00:54:27.330522Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 85  (27.1):  28%|██▊       | 85/300 [00:03<00:09, 22.37it/s]2024-10-08T00:54:27.697552Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 86  (26.7):  28%|██▊       | 85/300 [00:03<00:09, 22.37it/s]2024-10-08T00:54:28.009936Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 87  (26.4):  29%|██▊       | 86/300 [00:04<00:09, 22.37it/s]2024-10-08T00:54:28.302991Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 88  (26.1):  29%|██▉       | 88/300 [00:04<00:21,  9.74it/s]2024-10-08T00:54:28.779349Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 84.0 / 300  (28.0): 100%|██████████| 300/300 [00:08<00:00, 37.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full eval score: 28.0\n",
      "Best full eval score so far: 35.0\n",
      "=======================\n",
      "\n",
      "\n",
      "== Minibatch Trial 21 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 7  (42.9):  24%|██▍       | 6/25 [00:00<00:00, 658.98it/s]linenote.pyning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate= =198\n",
      "Average Metric: 8 / 14  (57.1):  52%|█████▏    | 13/25 [00:00<00:00, 704.74it/s] 4-10-08T00:54:32.152119Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 23  (34.8):  88%|████████▊ | 22/25 [00:00<00:00, 690.50it/s]24-10-08T00:54:32.155455Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 25  (32.0): 100%|██████████| 25/25 [00:00<00:00, 660.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1140.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I received the wrong amount of cash back\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting a discrepancy in the amount of cash they received back after a cash withdrawal.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_amount_of_cash_received\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "There is a €1 extra fee in my statement\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an extra fee in their statement, which suggests a potential issue with their account.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "extra_charge_on_statement\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an issue with the exchange rate of their card payment, which suggests a potential problem with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I received the wrong amount of cash back\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting a discrepancy in the amount of cash they received back after a cash withdrawal.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_amount_of_cash_received\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "There is a €1 extra fee in my statement\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an extra fee in their statement, which suggests a potential issue with their account.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "extra_charge_on_statement\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an issue with the exchange rate of their card payment, which suggests a potential problem with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 32.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 3'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 22 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 3  (33.3):   8%|▊         | 2/25 [00:00<00:00, 729.63it/s]ineno'reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] = =198\n",
      "Average Metric: 3 / 12  (25.0):  44%|████▍     | 11/25 [00:00<00:00, 747.08it/s]linenoe.py0:54:32.281417Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate = =198\n",
      "Average Metric: 9 / 20  (45.0):  76%|███████▌  | 19/25 [00:00<00:00, 712.61it/s]linenote.py00:54:32.287528Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate = =198\n",
      "Average Metric: 9.0 / 23  (39.1):  88%|████████▊ | 22/25 [00:00<00:00, 656.11it/s]2024-10-08T00:54:32.288492Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 24  (37.5):  92%|█████████▏| 23/25 [00:00<00:00, 543.71it/s]2024-10-08T00:54:32.289806Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 25  (36.0): 100%|██████████| 25/25 [00:00<00:00, 468.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1110.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I received the wrong amount of cash back\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting a discrepancy in the amount of cash they received back after a cash withdrawal.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_amount_of_cash_received\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "There is a €1 extra fee in my statement\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an extra fee in their statement, which suggests a potential issue with their account.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "extra_charge_on_statement\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an issue with the exchange rate of their card payment, which suggests a potential problem with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "I received the wrong amount of cash back\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting a discrepancy in the amount of cash they received back after a cash withdrawal.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_amount_of_cash_received\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "There is a €1 extra fee in my statement\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an extra fee in their statement, which suggests a potential issue with their account.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "extra_charge_on_statement\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting an issue with the exchange rate of their card payment, which suggests a potential problem with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "wrong_exchange_rate_for_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 36.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 3'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 23 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 25  (8.0): 100%|██████████| 25/25 [00:00<00:00, 1201.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1109.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a discrepancy between the expected and actual exchange rates.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a discrepancy between the expected and actual exchange rates.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 8.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 1'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 24 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7 / 25  (28.0): 100%|██████████| 25/25 [00:00<00:00, 1230.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 1  (0.0): 100%|██████████| 1/1 [00:00<00:00, 1121.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a discrepancy between the expected and actual exchange rates.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing dissatisfaction with the exchange rate of their card payment, indicating a discrepancy between the expected and actual exchange rates.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cash_withdrawal\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 28.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 0'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 25 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 14 / 25  (56.0): 100%|██████████| 25/25 [00:02<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0): 100%|██████████| 1/1 [00:00<00:00, 1110.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The cheque I deposited isn't showing in my account\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting that they deposited a cheque but it hasn't appeared in their account, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing concern that the exchange rate for their card payment is incorrect, which could be affecting the amount they received.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_wrong_exchange_rate\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The cheque I deposited isn't showing in my account\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting that they deposited a cheque but it hasn't appeared in their account, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing concern that the exchange rate for their card payment is incorrect, which could be affecting the amount they received.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_wrong_exchange_rate\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 56.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 7'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 26 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 12 / 25  (48.0): 100%|██████████| 25/25 [00:01<00:00, 14.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0): 100%|██████████| 1/1 [00:00<00:00, 1065.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The cheque I deposited isn't showing in my account\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting that they deposited a cheque but it hasn't appeared in their account, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing concern that the exchange rate for their card payment is incorrect, which could be affecting the amount they received.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_wrong_exchange_rate\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The cheque I deposited isn't showing in my account\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting that they deposited a cheque but it hasn't appeared in their account, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing concern that the exchange rate for their card payment is incorrect, which could be affecting the amount they received.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_wrong_exchange_rate\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 48.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 7'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 27 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 14 / 25  (56.0): 100%|██████████| 25/25 [00:01<00:00, 16.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0): 100%|██████████| 1/1 [00:00<00:00, 1106.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The cheque I deposited isn't showing in my account\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting that they deposited a cheque but it hasn't appeared in their account, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing concern that the exchange rate for their card payment is incorrect, which could be affecting the amount they received.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_wrong_exchange_rate\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The cheque I deposited isn't showing in my account\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting that they deposited a cheque but it hasn't appeared in their account, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing concern that the exchange rate for their card payment is incorrect, which could be affecting the amount they received.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_wrong_exchange_rate\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 56.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 7'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 28 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 25  (32.0): 100%|██████████| 25/25 [00:01<00:00, 16.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0): 100%|██████████| 1/1 [00:00<00:00, 1027.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The cheque I deposited isn't showing in my account\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting that they deposited a cheque but it hasn't appeared in their account, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing concern that the exchange rate for their card payment is incorrect, which could be affecting the amount they received.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_wrong_exchange_rate\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The cheque I deposited isn't showing in my account\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting that they deposited a cheque but it hasn't appeared in their account, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing concern that the exchange rate for their card payment is incorrect, which could be affecting the amount they received.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_wrong_exchange_rate\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 32.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 7'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 29 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10 / 25  (40.0): 100%|██████████| 25/25 [00:01<00:00, 14.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0): 100%|██████████| 1/1 [00:00<00:00, 1052.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The cheque I deposited isn't showing in my account\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting that they deposited a cheque but it hasn't appeared in their account, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing concern that the exchange rate for their card payment is incorrect, which could be affecting the amount they received.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_wrong_exchange_rate\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The cheque I deposited isn't showing in my account\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting that they deposited a cheque but it hasn't appeared in their account, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing concern that the exchange rate for their card payment is incorrect, which could be affecting the amount they received.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_wrong_exchange_rate\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 40.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 7'].\n",
      "\n",
      "\n",
      "== Minibatch Trial 30 / 30 ==\n",
      "Evaluating the following candidate program...\n",
      "\n",
      "Predictor 0\n",
      "i: As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "The intent should exactly match one of the following:\n",
      "['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "p: Label:\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 13 / 25  (52.0): 100%|██████████| 25/25 [00:01<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full trace of prompts in use on an example...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0): 100%|██████████| 1/1 [00:00<00:00, 1154.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The cheque I deposited isn't showing in my account\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting that they deposited a cheque but it hasn't appeared in their account, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing concern that the exchange rate for their card payment is incorrect, which could be affecting the amount they received.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_wrong_exchange_rate\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "System message:\n",
      "\n",
      "Your input fields are:\n",
      "1. `intent` (str): Intent of the query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `label` (str): Type of the intent; Should just be one of the 25 labels with no other text\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "{intent}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## label ## ]]\n",
      "{label}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
      "        The intent should exactly match one of the following:\n",
      "        ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The cheque I deposited isn't showing in my account\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Assistant message:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is reporting that they deposited a cheque but it hasn't appeared in their account, indicating a potential issue with the transaction.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "balance_not_updated_after_cheque_or_cash_deposit\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "User message:\n",
      "\n",
      "[[ ## intent ## ]]\n",
      "The exchange rate from my card payment isn't right.\n",
      "\n",
      "Respond with the corresponding output fields using the proper format of [[ ## <field_name> ## ]] followed by the field value. Start with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]`, and then ending with the marker for `completed`.\n",
      "\n",
      "\n",
      "Response:\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "The user is expressing concern that the exchange rate for their card payment is incorrect, which could be affecting the amount they received.\n",
      "\n",
      "[[ ## label ## ]]\n",
      "card_payment_wrong_exchange_rate\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Score: 52.0 on minibatch of size 25 with parameters ['Predictor 1: Instruction 0', 'Predictor 1: Few-Shot Set 7'].\n",
      "\n",
      "\n",
      "===== Full Eval 3 =====\n",
      "Doing full eval on next top averaging program (Avg Score: 45.714285714285715) so far from mini-batch trials...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 64 / 136  (47.1):  45%|████▌     | 135/300 [00:00<00:00, 433.88it/s]2024-10-08T00:54:46.827348Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 137  (46.7):  45%|████▌     | 136/300 [00:02<00:00, 433.88it/s]2024-10-08T00:54:46.956160Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 138  (46.4):  46%|████▌     | 137/300 [00:02<00:00, 433.88it/s]2024-10-08T00:54:47.603658Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 146.0 / 300  (48.7): 100%|██████████| 300/300 [00:06<00:00, 49.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best full eval score so far! Score: 48.67\n",
      "=======================\n",
      "\n",
      "\n",
      "[('intent_classifier', Predict(StringSignature(intent -> reasoning, label\n",
      "    instructions=\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\\nThe intent should exactly match one of the following:\\n['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\"\n",
      "    intent = Field(annotation=str required=True json_schema_extra={'desc': 'Intent of the query', '__dspy_field_type': 'input', 'prefix': 'Intent:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${reasoning}', '__dspy_field_type': 'output'})\n",
      "    label = Field(annotation=str required=True json_schema_extra={'desc': 'Type of the intent; Should just be one of the 25 labels with no other text', '__dspy_field_type': 'output', 'prefix': 'Label:'})\n",
      ")))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1500 [00:00<?, ?it/s]2024-10-08T00:54:55.207542Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/1500 [00:01<40:42,  1.63s/it]2024-10-08T00:54:56.307849Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 2/1500 [00:02<32:54,  1.32s/it]2024-10-08T00:54:56.751005Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   0%|          | 3/1500 [00:03<22:54,  1.09it/s]2024-10-08T00:54:57.234340Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   0%|          | 4/1500 [00:03<18:34,  1.34it/s]2024-10-08T00:54:57.770666Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   0%|          | 5/1500 [00:04<16:41,  1.49it/s]2024-10-08T00:54:57.903604Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   0%|          | 6/1500 [00:04<12:11,  2.04it/s]2024-10-08T00:54:58.297018Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 51.0 / 120  (42.5):   8%|▊         | 119/1500 [00:09<00:41, 33.52it/s]2024-10-08T00:55:03.213293Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 146  (37.0):  10%|▉         | 145/1500 [00:10<00:33, 40.24it/s]=rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 82.0 / 236  (34.7):  16%|█▌        | 235/1500 [00:14<01:03, 19.98it/s]2024-10-08T00:55:07.806735Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 85.0 / 243  (35.0):  16%|█▌        | 242/1500 [00:14<01:16, 16.44it/s]2024-10-08T00:55:08.228208Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 246  (35.0):  16%|█▋        | 246/1500 [00:14<01:13, 16.98it/s]2024-10-08T00:55:08.521846Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 247  (34.8):  16%|█▋        | 246/1500 [00:14<01:13, 16.98it/s]2024-10-08T00:55:08.530841Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 92.0 / 267  (34.5):  18%|█▊        | 267/1500 [00:19<06:16,  3.28it/s]2024-10-08T00:55:13.346381Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 184.0 / 502  (36.7):  33%|███▎      | 501/1500 [00:29<01:23, 11.91it/s]2024-10-08T00:55:23.216760Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 186.0 / 507  (36.7):  34%|███▍      | 507/1500 [00:29<01:35, 10.38it/s]2024-10-08T00:55:23.635817Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 189.0 / 513  (36.8):  34%|███▍      | 512/1500 [00:31<03:08,  5.24it/s]2024-10-08T00:55:25.044756Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 248.0 / 657  (37.7):  44%|████▍     | 657/1500 [00:38<00:34, 24.62it/s]2024-10-08T00:55:32.490443Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 250.0 / 671  (37.3):  45%|████▍     | 670/1500 [00:39<00:27, 29.85it/s]2024-10-08T00:55:32.721219Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 258.0 / 696  (37.1):  46%|████▋     | 695/1500 [00:40<00:29, 27.29it/s]2024-10-08T00:55:33.709861Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 260.0 / 705  (36.9):  47%|████▋     | 704/1500 [00:40<00:30, 26.42it/s]2024-10-08T00:55:34.169682Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 274.0 / 751  (36.5):  50%|█████     | 750/1500 [00:43<01:11, 10.51it/s]2024-10-08T00:55:37.190511Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 288.0 / 793  (36.3):  53%|█████▎    | 793/1500 [00:47<00:57, 12.39it/s]2024-10-08T00:55:41.512204Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 317.0 / 885  (35.8):  59%|█████▉    | 884/1500 [00:52<00:20, 29.84it/s]=rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 323.0 / 910  (35.5):  61%|██████    | 909/1500 [00:53<00:37, 15.67it/s]2024-10-08T00:55:47.461104Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 323.0 / 911  (35.5):  61%|██████    | 910/1500 [00:53<00:37, 15.67it/s]2024-10-08T00:55:47.534320Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 333.0 / 944  (35.3):  63%|██████▎   | 943/1500 [00:55<00:22, 24.64it/s]]024-10-08T00:55:48.655155Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 336.0 / 951  (35.3):  63%|██████▎   | 950/1500 [00:55<00:19, 28.51it/s]2024-10-08T00:55:48.824513Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 345.0 / 989  (34.9):  66%|██████▌   | 988/1500 [00:57<00:19, 25.61it/s]2024-10-08T00:55:50.904489Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 345.0 / 991  (34.8):  66%|██████▌   | 990/1500 [00:57<00:19, 25.61it/s]2024-10-08T00:55:51.020189Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 346.0 / 996  (34.7):  66%|██████▋   | 995/1500 [00:57<00:17, 28.63it/s]2024-10-08T00:55:51.540561Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 355.0 / 1034  (34.3):  69%|██████▉   | 1033/1500 [01:00<00:41, 11.31it/s]2024-10-08T00:55:54.659733Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 377.0 / 1089  (34.6):  73%|███████▎  | 1088/1500 [01:05<00:18, 22.01it/s]]024-10-08T00:55:58.774799Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 410.0 / 1181  (34.7):  79%|███████▊  | 1180/1500 [01:10<00:31, 10.24it/s]2024-10-08T00:56:04.005756Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 436.0 / 1279  (34.1):  85%|████████▌ | 1278/1500 [01:16<00:09, 23.77it/s]2024-10-08T00:56:10.069875Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 437.0 / 1284  (34.0):  86%|████████▌ | 1284/1500 [01:16<00:08, 25.63it/s]2024-10-08T00:56:10.243726Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 452.0 / 1334  (33.9):  89%|████████▉ | 1333/1500 [01:17<00:03, 46.53it/s]]024-10-08T00:56:11.439988Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 495.0 / 1500  (33.0): 100%|██████████| 1500/1500 [01:20<00:00, 18.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import MIPROv2\n",
    "gpt4o = dspy.LM(model=\"gpt-4o\", **MODEL_PARAMETERS)\n",
    "\n",
    "COMPILE_PROGRAM = True\n",
    "current_best = mhqa_finetuned_llamas_8b[\"epochs-2-total-trained-steps-30\"]\n",
    "with dspy.context(lm=current_best):\n",
    "    vanilla_program = SimpleIntentClassificationModule()\n",
    "    if COMPILE_PROGRAM:\n",
    "        # eval_kwargs = dict(display_progress=True, display_table=0, num_threads=NUM_THREADS)\n",
    "        teleprompter = MIPROv2(prompt_model=gpt4o, task_model=current_best, metric=metric, num_candidates=10, init_temperature=0.9, verbose=True, num_threads=NUM_THREADS, max_errors=1000)\n",
    "        compiled_program = teleprompter.compile(vanilla_program, trainset=optimizer_trainset, valset=optimizer_valset, num_trials=30, max_bootstrapped_demos=MAX_BOOTSTRAPPED_DEMOS,max_labeled_demos=MAX_LABELED_DEMOS, requires_permission_to_run=False)\n",
    "        compiled_program.save(f\"simpleintent_1b_32_ft_mipro_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}.json\")\n",
    "    else:\n",
    "        compiled_program = SimpleIntentClassificationModule()\n",
    "        compiled_program.load(f\"simpleintent_1b_32_ft_mipro_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}.json\")\n",
    "    llama_8b_ft_mipro_eval = evaluate_devset(compiled_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, lets give the base 8B model a fair chance by prompt optimizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can compare all iterations of this pipeline\n",
    "print(f\"Results for HotPotQA fine-tuning LLaMa 8B with a starting trainset\")\n",
    "print(f\"    70B model (vanilla program): {llama_70b_base_eval}\")\n",
    "print(f\"    70B model (bfrs program): {llama_70b_bfrs_eval}\")\n",
    "print(f\"    8B model (vanilla program): {vanilla_8b_base_eval}\")\n",
    "print(f\"    8B model (bfrs program): {llama_8b_bfrs_eval}\")\n",
    "print(f\"    8B model (finetuned program): {llama_8b_finetuned_eval}\")\n",
    "print(f\"    8B model (finetuned bfrs program): {llama_8b_bfrs_finetuned_eval}\")\n",
    "print(f\"    8B model (finetuned mipro program): {llama_8b_ft_mipro_eval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Let's now use the new offline batch inference to evaluate the finetuned model with optimized program on the entire devset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement once done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"Stop here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving\n",
    "\n",
    "This is the second biggest unknown\n",
    "I imagine it to be easy, but crazier things have happened\n",
    "\n",
    "I need to keep a reference or link to the LLM forge job inside the LM.finetune method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how do I get the ray llm image!\n",
    "\n",
    "We'll start by running the rayllm CLI command below to start the workflow to generate the service yaml configuration:\n",
    "```bash\n",
    "mkdir /home/ray/default/deploy/services\n",
    "cd /home/ray/default/deploy/services\n",
    "rayllm gen-config \n",
    "```\n",
    "\n",
    "<img src=\"assets/cli.png\" width=500 alt=\"todo! get this inage of what I need to serve\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch offline inference\n",
    "- Compare running inference using \n",
    "    - Ray Data \n",
    "    - multithreading on local VLLM thru HTTP\n",
    "    - Multithreading to Ray Serve instance thru HTTP\n",
    "- Dev time estimate: 7 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"background-color: yellow;\">&nbsp;🛑 IMPORTANT&nbsp;</b>: Please `Terminate` your service from the Service page to avoid depleting your free trial credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "!python src/clear_cell_nums.py\n",
    "!find . | grep -E \".ipynb_checkpoints\" | xargs rm -rf\n",
    "!find . | grep -E \"(__pycache__|\\.pyc|\\.pyo)\" | xargs rm -rf\n",
    "!rm -rf __pycache__ data .HF_TOKEN deploy/services"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
