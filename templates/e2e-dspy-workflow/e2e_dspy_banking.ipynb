{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end DSPy Workflows Guide "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Motivation - have this problem and going to solve it with dspy and that is why we believe ti is the right solution\n",
    "\n",
    "This guide will cover the following topics:\n",
    "\n",
    "## Creating a Multi-stage LLM Pipeline\n",
    "- Building a pipeline with an untuned model in DSPy\n",
    "- Implementing batch inference (using Ray data)\n",
    "\n",
    "## Improving the Pipeline\n",
    "1. Prompt optimization\n",
    "2. Fine-tuning\n",
    "    - How to make an 8B model perform almost as well as a 70B model in your pipeline\n",
    "3. Combining fine-tuning with prompt optimization\n",
    "\n",
    "## Deployment\n",
    "- Steps to deploy the optimized pipeline and fine-tuned model to production\n",
    "\n",
    "## Future Work and Open Questions\n",
    "- Efficient batch inference with a DSPy pipeline\n",
    "- Exploring different fine-tuning methods and hyperparameter sweeps\n",
    "\n",
    "This guide aims to provide a comprehensive overview of building, optimizing, and deploying LLM pipelines using DSPy and Anyscale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node Set up:\n",
    "\n",
    "We will be running everything on a head node that uses 4xA100-80GB GPUs. I find that L4s are usually available and suitable for this usecase. You can also use any more powerful node.\n",
    "\n",
    "To change to use A100 GPUs, click the \"1 active node\" in the top right corner, then for workspace node, click the pencil icon and navigate to the A100 tab and select the 4xA100 option. If you do not see A100 in the list of GPUs, they may not be available on your cloud. Choose another kind of GPU (This notebook has been tested on X, and Y as alternatives) (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(work): DSPy installation cell\n",
    "\n",
    "# TODO: look at my own init file to see all the stupid extra pip installs\n",
    "\n",
    "# !pip install -e dspy\n",
    "\n",
    "# ignore future warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import dsp\n",
    "import os\n",
    "import ujson\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "# TODO: include cache in notebook\n",
    "cache_dir = \"/home/ray/default/dspy/cache\"\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)\n",
    "# I have included a .env.example with the necessary environment variables to be set\n",
    "# You can also set them manually if you prefer\n",
    "\n",
    "os.environ[\"DSP_CACHEDIR\"] = cache_dir\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "dspy.settings.configure(experimental=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import litellm\n",
    "\n",
    "litellm.set_verbose=False\n",
    "litellm.suppress_debug_info=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "necessary_env_vars = [\n",
    "    \"DSP_CACHEDIR\",\n",
    "    \"HF_TOKEN\",\n",
    "    \"HF_HOME\"\n",
    "]\n",
    "\n",
    "for var in necessary_env_vars:\n",
    "    assert os.environ[var], f\"{var} is not set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(autoscaler +1h5m47s) Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "if not ray.is_initialized():\n",
    "    ray.init(runtime_env={\"env_vars\": os.environ, \"py_modules\": [dspy, dsp]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of a random number generator in this notebook. We are creating a Random object here to ensure that our notebook is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "rng = random.Random(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating your multi-stage LLM pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.datasets import HotPotQA\n",
    "from dspy.evaluate import Evaluate\n",
    "from dsp.utils.utils import deduplicate\n",
    "\n",
    "\n",
    "# We are setting the experimental flag to True to make use of the fine-tuning\n",
    "# features that are still in development.\n",
    "dspy.settings.configure(experimental=True)\n",
    "\n",
    "class IntentClassification(dspy.Signature):\n",
    "    \"\"\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\n",
    "    The intent should exactly match one of the following:\n",
    "    ['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\n",
    "    \"\"\"\n",
    "\n",
    "    intent = dspy.InputField(desc=\"Intent of the query\")\n",
    "    label = dspy.OutputField(desc=\"Type of the intent; Should just be one of the 25 labels with no other text\")\n",
    "\n",
    "class IntentClassificationModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.intent_classifier = dspy.ChainOfThought(IntentClassification)\n",
    "        self.valid_labels = set([\"activate_my_card\", \"cancel_transfer\", \"cash_withdrawal_charge\", \"declined_card_payment\", \"declined_cash_withdrawal\", \"direct_debit_payment_not_recognised\", \"extra_charge_on_statement\", \"pending_card_payment\", \"pending_top_up\", \"Refund_not_showing_up\", \"request_refund\", \"reverted_card_payment\", \"transaction_charged_twice\", \"transfer_fee_charged\", \"transfer_not_received_by_recipient\", \"wrong_amount_of_cash_received\", \"wrong_exchange_rate_for_cash_withdrawal\"])\n",
    "\n",
    "    def forward(self, text):\n",
    "        prediction = self.intent_classifier(intent=text)\n",
    "        sanitized_prediction = dspy.Prediction(label=prediction.label.lower().strip().replace(\" \", \"_\"), reasoning=prediction.reasoning)\n",
    "        # if sanitized_prediction.label not in self.valid_labels:\n",
    "        #     for label in self.valid_labels:\n",
    "        #         if label in sanitized_prediction.label:\n",
    "        #             sanitized_prediction.label = label\n",
    "        #             break\n",
    "        #     # this means that the prediction was not in the valid labels\n",
    "        #     # Could do edit distance or something more sophisticated here\n",
    "        #     # but for now just take the first\n",
    "        #     sanitized_prediction.label = self.valid_labels[0]\n",
    "        return sanitized_prediction\n",
    "\n",
    "class IntentClassificationPredictModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.intent_classifier = dspy.Predict(IntentClassification)\n",
    "        self.valid_labels = set([\"activate_my_card\", \"cancel_transfer\", \"cash_withdrawal_charge\", \"declined_card_payment\", \"declined_cash_withdrawal\", \"direct_debit_payment_not_recognised\", \"extra_charge_on_statement\", \"pending_card_payment\", \"pending_top_up\", \"Refund_not_showing_up\", \"request_refund\", \"reverted_card_payment\", \"transaction_charged_twice\", \"transfer_fee_charged\", \"transfer_not_received_by_recipient\", \"wrong_amount_of_cash_received\", \"wrong_exchange_rate_for_cash_withdrawal\"])\n",
    "\n",
    "    def forward(self, text):\n",
    "        prediction = self.intent_classifier(intent=text)\n",
    "        sanitized_prediction = dspy.Prediction(label=prediction.label.lower().strip().replace(\" \", \"_\"), reasoning=prediction.reasoning)\n",
    "        # if sanitized_prediction.label not in self.valid_labels:\n",
    "        #     for label in self.valid_labels:\n",
    "        #         if label in sanitized_prediction.label:\n",
    "        #             sanitized_prediction.label = label\n",
    "        #             break\n",
    "        #     # this means that the prediction was not in the valid labels\n",
    "        #     # Could do edit distance or something more sophisticated here\n",
    "        #     # but for now just take the first\n",
    "        #     sanitized_prediction.label = self.valid_labels[0]\n",
    "        return sanitized_prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's break down the Text to SQL program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we load the dataset using a built in `HotPotQA` dataset class from DSPy.\n",
    "\n",
    "We set the `train_seed` and `eval_seed` to `0` for reproducibility and the `test_size` to `0` because we do not need a test set for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "from dspy.datasets import DataLoader\n",
    "\n",
    "dl = DataLoader()\n",
    "full_trainset = dl.from_huggingface(\n",
    "    dataset_name=\"PolyAI/banking77\", # Dataset name from Huggingface\n",
    "    fields=(\"label\", \"text\"), # Fields needed\n",
    "    input_keys=(\"text\",), # What our model expects to recieve to generate an output\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "full_testset = dl.from_huggingface(\n",
    "    dataset_name=\"PolyAI/banking77\", # Dataset name from Huggingface\n",
    "    fields=(\"label\", \"text\"), # Fields needed\n",
    "    input_keys=(\"text\",), # What our model expects to recieve to generate an output\n",
    "    split=\"test\"\n",
    ")\n",
    "\n",
    "# Find the 15 most common class labels\n",
    "from collections import Counter\n",
    "\n",
    "# Count occurrences of each label\n",
    "label_counts = Counter(example['label'] for example in full_trainset)\n",
    "print(label_counts)\n",
    "\n",
    "# Get the 15 most common labels\n",
    "top_25_labels = set([label for label, _ in label_counts.most_common(25)])\n",
    "\n",
    "# Filter the datasets to only include examples with the top 15 labels\n",
    "full_trainset_filtered = [example for example in full_trainset if example['label'] in top_25_labels]\n",
    "full_testset_filtered = [example for example in full_testset if example['label'] in top_25_labels]\n",
    "\n",
    "# Replace the original datasets with the filtered versions\n",
    "full_trainset = full_trainset_filtered\n",
    "full_testset = full_testset_filtered\n",
    "\n",
    "print(f\"Dataset filtered to top 25 labels. New sizes:\")\n",
    "print(f\"Training set: {len(full_trainset)}\")\n",
    "print(f\"Test set: {len(full_testset)}\")\n",
    "print(f\"Top 25 labels: {', '.join(str(label) for label in top_25_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_label_dict = {\n",
    "    0: \"activate_my_card\",\n",
    "    1: \"age_limit\",\n",
    "    2: \"apple_pay_or_google_pay\",\n",
    "    3: \"atm_support\",\n",
    "    4: \"automatic_top_up\",\n",
    "    5: \"balance_not_updated_after_bank_transfer\",\n",
    "    6: \"balance_not_updated_after_cheque_or_cash_deposit\",\n",
    "    7: \"beneficiary_not_allowed\",\n",
    "    8: \"cancel_transfer\",\n",
    "    9: \"card_about_to_expire\",\n",
    "    10: \"card_acceptance\",\n",
    "    11: \"card_arrival\",\n",
    "    12: \"card_delivery_estimate\",\n",
    "    13: \"card_linking\",\n",
    "    14: \"card_not_working\",\n",
    "    15: \"card_payment_fee_charged\",\n",
    "    16: \"card_payment_not_recognised\",\n",
    "    17: \"card_payment_wrong_exchange_rate\",\n",
    "    18: \"card_swallowed\",\n",
    "    19: \"cash_withdrawal_charge\",\n",
    "    20: \"cash_withdrawal_not_recognised\",\n",
    "    21: \"change_pin\",\n",
    "    22: \"compromised_card\",\n",
    "    23: \"contactless_not_working\",\n",
    "    24: \"country_support\",\n",
    "    25: \"declined_card_payment\",\n",
    "    26: \"declined_cash_withdrawal\",\n",
    "    27: \"declined_transfer\",\n",
    "    28: \"direct_debit_payment_not_recognised\",\n",
    "    29: \"disposable_card_limits\",\n",
    "    30: \"edit_personal_details\",\n",
    "    31: \"exchange_charge\",\n",
    "    32: \"exchange_rate\",\n",
    "    33: \"exchange_via_app\",\n",
    "    34: \"extra_charge_on_statement\",\n",
    "    35: \"failed_transfer\",\n",
    "    36: \"fiat_currency_support\",\n",
    "    37: \"get_disposable_virtual_card\",\n",
    "    38: \"get_physical_card\",\n",
    "    39: \"getting_spare_card\",\n",
    "    40: \"getting_virtual_card\",\n",
    "    41: \"lost_or_stolen_card\",\n",
    "    42: \"lost_or_stolen_phone\",\n",
    "    43: \"order_physical_card\",\n",
    "    44: \"passcode_forgotten\",\n",
    "    45: \"pending_card_payment\",\n",
    "    46: \"pending_cash_withdrawal\",\n",
    "    47: \"pending_top_up\",\n",
    "    48: \"pending_transfer\",\n",
    "    49: \"pin_blocked\",\n",
    "    50: \"receiving_money\",\n",
    "    51: \"refund_not_showing_up\",\n",
    "    52: \"request_refund\",\n",
    "    53: \"reverted_card_payment\",\n",
    "    54: \"supported_cards_and_currencies\",\n",
    "    55: \"terminate_account\",\n",
    "    56: \"top_up_by_bank_transfer_charge\",\n",
    "    57: \"top_up_by_card_charge\",\n",
    "    58: \"top_up_by_cash_or_cheque\",\n",
    "    59: \"top_up_failed\",\n",
    "    60: \"top_up_limits\",\n",
    "    61: \"top_up_reverted\",\n",
    "    62: \"topping_up_by_card\",\n",
    "    63: \"transaction_charged_twice\",\n",
    "    64: \"transfer_fee_charged\",\n",
    "    65: \"transfer_into_account\",\n",
    "    66: \"transfer_not_received_by_recipient\",\n",
    "    67: \"transfer_timing\",\n",
    "    68: \"unable_to_verify_identity\",\n",
    "    69: \"verify_my_identity\",\n",
    "    70: \"verify_source_of_funds\",\n",
    "    71: \"verify_top_up\",\n",
    "    72: \"virtual_card_not_working\",\n",
    "    73: \"visa_or_mastercard\",\n",
    "    74: \"why_verify_identity\",\n",
    "    75: \"wrong_amount_of_cash_received\",\n",
    "    76: \"wrong_exchange_rate_for_cash_withdrawal\"\n",
    "}\n",
    "\n",
    "label_to_int_dict = {v: k for k, v in int_to_label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_in_use = [int_to_label_dict[label] for label in top_25_labels]\n",
    "\n",
    "print(labels_in_use)\n",
    "\n",
    "def convert_int_to_label(example):\n",
    "    example[\"label\"] = int_to_label_dict[example[\"label\"]]\n",
    "    return example\n",
    "\n",
    "full_trainset = [convert_int_to_label(example) for example in full_trainset]\n",
    "full_testset = [convert_int_to_label(example) for example in full_testset]\n",
    "\n",
    "print(full_trainset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_SIZE = 500\n",
    "PROMPT_OPT_TRAIN_SIZE = 150\n",
    "PROMPT_OPT_DEV_SIZE = 350\n",
    "\n",
    "shuffled_trainset = [d for d in full_trainset]\n",
    "rng.shuffle(shuffled_trainset)\n",
    "\n",
    "devset = shuffled_trainset[:DEV_SIZE]\n",
    "remaining_trainset = shuffled_trainset[DEV_SIZE:]\n",
    "\n",
    "# The devset shouldn't overlap\n",
    "ft_trainset = remaining_trainset\n",
    "ft_optimizer_trainset = remaining_trainset[:PROMPT_OPT_TRAIN_SIZE]\n",
    "ft_optimizer_devset = remaining_trainset[PROMPT_OPT_TRAIN_SIZE:PROMPT_OPT_TRAIN_SIZE+PROMPT_OPT_DEV_SIZE]\n",
    "\n",
    "po_trainset = remaining_trainset[:-PROMPT_OPT_DEV_SIZE]\n",
    "po_devset = remaining_trainset[-PROMPT_OPT_DEV_SIZE:]\n",
    "\n",
    "testset = full_testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set up the metric and evaluator. We will be using the answer exact match metric.\n",
    "\n",
    "The evaluator is what we will consider as our test set.\n",
    "\n",
    "We choose `num_threads=90` because we are bottlenecked by the retrieval server, and through testing this is the maximum number of concurrent threads that can be run without causing issues for other people using the retrieval server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the metric and evaluator\n",
    "from dspy.evaluate import answer_exact_match\n",
    "\n",
    "NUM_THREADS = 50\n",
    "\n",
    "def adjusted_exact_match(example, pred, trace=None, frac=1.0):\n",
    "    example.answer = example.label\n",
    "    pred.answer = pred.label\n",
    "    return answer_exact_match(example, pred, trace, frac)\n",
    "\n",
    "metric = adjusted_exact_match\n",
    "common_kwargs = dict(metric=metric, num_threads=NUM_THREADS, display_progress=True, max_errors=10000)\n",
    "\n",
    "evaluate_devset = Evaluate(devset=devset, **common_kwargs)\n",
    "evaluate_testset = Evaluate(devset=testset, **common_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return [ujson.loads(line) for line in f]\n",
    "\n",
    "def write_jsonl(filename, data):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for item in data:\n",
    "            f.write(ujson.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering baseline performance\n",
    "\n",
    "run evaluate on a base pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 1000\n",
    "MODEL_PARAMETERS = {\n",
    "  \"max_tokens\": MAX_TOKENS,\n",
    "  \"temperature\": 0,\n",
    "}\n",
    "\n",
    "LOCAL_API_PARAMETERS = {\n",
    "  \"api_base\": \"http://localhost:8000/v1\",\n",
    "  \"api_key\": \"fake-key-doesnt-matter\"\n",
    "}\n",
    "vanilla_program = IntentClassificationModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Run above this to do all setup without launching any models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a local VLLM instance to run the initial benchmarks and data collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering training data and running the 70B Model\n",
    "\n",
    "Now that we have a baseline for the 8B model, let's run the 70B model and compare its performance.\n",
    "\n",
    "## Preparation\n",
    "\n",
    "Before running the 70B model:\n",
    "1. Kill the 8B server (use `Ctrl+C`) to free up memory.\n",
    "2. Remember to set your HF_TOKEN and HF_HOME environment variables\n",
    "3. Use the following command to start the 70B server:\n",
    "\n",
    "   ```\n",
    "   vllm serve meta-llama/Meta-Llama-3.1-70B-Instruct --port 8000 --pipeline_parallel_size 2 --enable_prefix_caching --tensor_parallel_size 2\n",
    "   ```\n",
    "\n",
    "## Parallelism Configuration\n",
    "\n",
    "We've chosen pipeline parallelism and tensor parallelism of 2 for the 70B model based on our current setup. Here's the reasoning:\n",
    "\n",
    "1. Model size: The 70B model has 30 parts of ~5 GB each (based on [HuggingFace documentation](https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct/tree/main)).\n",
    "   - Total size: 30 * 5 GB = 150 GB\n",
    "\n",
    "2. Available VRAM:\n",
    "   - Our GPUs: 80 GB VRAM x 4 = 320 GB\n",
    "   - Tensor parallelism: floor(320/150) = 2\n",
    "   - Pipeline parallelism: floor(num_gpus/2) = 2\n",
    "   - To use all 4 GPUs efficiently:\n",
    "     - Pipeline parallel size: 2\n",
    "     - Tensor parallelism: 2\n",
    "\n",
    "3. Alternative setup (8x24GB GPUs):\n",
    "   - Pipeline parallel size: 1\n",
    "   - Tensor parallelism: ceil(150/24) = 7\n",
    "\n",
    "This configuration allows us to run the 70B model efficiently across our available GPU resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I needed to add the HF_HOME var to my serve config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command for easy copying: \n",
    "# `export HF_HOME=/mnt/local_storage/huggingface`\n",
    "# `vllm serve meta-llama/Meta-Llama-3.1-70B-Instruct --port 8000 --pipeline_parallel_size 2 --enable_prefix_caching --tensor_parallel_size 2`\n",
    "\n",
    "# input(\"Press Enter once you have the vllm server running...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_70b = dspy.LM(model=\"openai/meta-llama/Meta-Llama-3.1-70B-Instruct\", **MODEL_PARAMETERS, **LOCAL_API_PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "with dspy.context(lm=llama_70b):\n",
    "    test_predictor = IntentClassificationModule()\n",
    "    sample_input = testset[15]\n",
    "    print(sample_input)\n",
    "    print(test_predictor(**sample_input.inputs()).label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see how the vanilla program performs on our small labeled dataset\n",
    "# vanilla_program = IntentClassificationModule()\n",
    "# with dspy.context(lm=llama_70b):\n",
    "#     print(\"Evaluating the vanilla program on the devset using llama 70B...\")\n",
    "#     true_labeled_eval = evaluate_devset(vanilla_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the LLaMa 70B pipeline\n",
    "\n",
    "Now we are ready to optimize the pipeline. We want to optimize the 70B pipeline in order to get the best possible data to then train our 8B model.\n",
    "\n",
    "We will use Bootstrap Few Shot with Random Search (BFRS) to optimize the pipeline.\n",
    "\n",
    "The essence of BFRS is to try out different configurations of few shot demonstrations per step and see which one works best on the validation set.\n",
    "\n",
    "The cool part about BFRs is that it will automatically collect the \"good\" chains of thought for us and add them to the examples at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how well the base pipeline performs, let's run prompt optimization on the pipeline in order to juice up the performance.\n",
    "\n",
    "Let's go over what the hyperparameters mean:\n",
    "- MAX_BOOTSTRAPPED_DEMOS: DSPy will \"bootstrap\" the program by collecting examples at each step that are successful and reusing those in the pipeline. This means that it will automatically collect and add chains of thought to the pipeline.\n",
    "- MAX_LABELED_DEMOS: DSPy will also insert some labeled demonstrations from the training set. These would be unmodified examples from the training set that are just using the gold answer.\n",
    "- NUM_CANDIDATE_PROGRAMS: This is the number of candidate programs that the optimizer will generate. The actual number of programs that are created is this plus three, as DSPy will also try a program with no examples, a program with TODO (check)\n",
    "- OPTIMIZER_NUM_TRAIN and OPTIMIZER_NUM_VAL: These are the number of examples that the optimizer will use for training and validation. Note that we will be taking the \"validation\" set from the trainset so as the actual validation set is untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization hyperparameters\n",
    "from dspy.teleprompt.random_search import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# Define the hyperparameters for prompt optimization\n",
    "MAX_BOOTSTRAPPED_DEMOS = 3\n",
    "MAX_LABELED_DEMOS = 3\n",
    "NUM_CANDIDATE_PROGRAMS = 6\n",
    "OPTIMIZER_NUM_TRAIN = 100\n",
    "OPTIMIZER_NUM_VAL = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the optimizer\n",
    "bfrs_optimizer = BootstrapFewShotWithRandomSearch(\n",
    "    metric=metric,\n",
    "    max_bootstrapped_demos=MAX_BOOTSTRAPPED_DEMOS,\n",
    "    max_labeled_demos=MAX_LABELED_DEMOS,\n",
    "    num_candidate_programs=NUM_CANDIDATE_PROGRAMS,\n",
    "    num_threads=NUM_THREADS,\n",
    "    max_errors=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have added this flag to save you some compute and time while running the notebook\n",
    "# TODO: do prompt optimization on the 100 labeled examples\n",
    "# COMPILE_PROGRAM = False\n",
    "# EVAL_PROGRAM = True\n",
    "\n",
    "# # Compile the optimizer and evaluate\n",
    "# with dspy.context(lm=llama_70b):\n",
    "#     vanilla_program = IntentClassificationModule()\n",
    "#     if COMPILE_PROGRAM:\n",
    "#         bfrs_base_program = bfrs_optimizer.compile(vanilla_program, trainset=po_trainset, valset=po_devset)\n",
    "#         bfrs_base_program.save(f\"b25_70b_31_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}.json\")\n",
    "#     else:\n",
    "#         bfrs_base_program = IntentClassificationModule()\n",
    "#         bfrs_base_program.load(f\"b25_70b_31_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}.json\")\n",
    "#     if EVAL_PROGRAM:\n",
    "#         llama_70b_bfrs_eval = evaluate_devset(bfrs_base_program)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_metric = lambda x, y: 1\n",
    "def fake_metric(example, pred, trace=None, frac=1.0):\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do some data analysis and cleaning\n",
    "# First we will convert the data to a pandas dataframe\n",
    "import pandas as pd\n",
    "from dspy.teleprompt.finetune_teleprompter import bootstrap_data, convert_to_module_level_message_data\n",
    "\n",
    "# TODO: WORKING HERE\n",
    "\n",
    "# For realism of this scenario, we are going to delete all our labels except for our test set(which is cheating and we wouldn't have in production) and our 100 true labeled examples\n",
    "def delete_labels(dataset):\n",
    "    for example in dataset:\n",
    "        if \"label\" in example:\n",
    "            del example[\"label\"]\n",
    "    return dataset\n",
    "\n",
    "ft_trainset_to_label = delete_labels(ft_trainset)\n",
    "with dspy.context(lm=llama_70b):\n",
    "    collected_data = bootstrap_data(vanilla_program, ft_trainset_to_label, metric=fake_metric, num_threads=NUM_THREADS, max_errors=10000)\n",
    "    print(collected_data[0])\n",
    "    collected_data_filtered = [x for x in collected_data if x[\"prediction\"][\"label\"] in labels_in_use]\n",
    "\n",
    "    # Convert collected_data to a pandas DataFrame\n",
    "    dataset = convert_to_module_level_message_data(collected_data_filtered, program=vanilla_program, exclude_demos=True)\n",
    "print(dataset[0])\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data points removed:\", len(collected_data) - len(collected_data_filtered))\n",
    "# look at all the data that was removed to see if any can be cleaned\n",
    "filtered_data = [x for x in collected_data if x[\"prediction\"][\"label\"] not in labels_in_use]\n",
    "bad_labels = [x[\"prediction\"][\"label\"] for x in filtered_data]\n",
    "print(bad_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_formatted = [{\"messages\": x} for x in dataset]\n",
    "\n",
    "# Note: Maybe dont use devset here\n",
    "dataset_filenames = {f\"trainset_data_banking.jsonl\": dataset}\n",
    "\n",
    "for filename, data in dataset_filenames.items():\n",
    "    # we first need to convert the data to be only the messages and to be in proper messages format\n",
    "    messages_format = [{\"messages\": item} for item in data]\n",
    "    # print(messages_format[0])\n",
    "\n",
    "    write_jsonl(filename, messages_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dspy.teleprompt.finetune_teleprompter import bootstrap_data, convert_to_module_level_message_data, bootstrap_data_for_round\n",
    "# import ujson\n",
    "\n",
    "# # This should be moved inside the finetune_teleprompter class\n",
    "# def write_data(program, data, filename):\n",
    "#     print(\"Bootstrapping and writing data to\", filename)\n",
    "#     correct_data = bootstrap_data(program, data, metric=metric, num_threads=NUM_THREADS, max_errors=10000)\n",
    "#     correct_data_round = [x for x in correct_data if x[\"score\"]]\n",
    "\n",
    "#     # Convert the data to prompt completion format\n",
    "#     dataset = convert_to_module_level_message_data(correct_data_round, program=program, exclude_demos=True)\n",
    "    \n",
    "#     dataset_formatted = [{\"messages\": x} for x in dataset]\n",
    "#     # Format the data for finetuning using the LM\n",
    "#     print(\"Writing dataset with length\", len(dataset), \"to\", filename)\n",
    "#     write_jsonl(filename, dataset_formatted)\n",
    "\n",
    "# dataset_filenames = {f\"ft_trainset_data_{len(ft_trainset)}.jsonl\": ft_trainset, f\"ft_valset_data_{len(devset)}.jsonl\": devset}\n",
    "\n",
    "\n",
    "# WRITE_DATA = True\n",
    "# if WRITE_DATA:\n",
    "#     for filename, data in dataset_filenames.items():\n",
    "#         bootstrap_program = IntentClassificationModule()\n",
    "#         with dspy.context(lm=llama_70b):\n",
    "#             write_data(bootstrap_program, data, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at an example prompt completion pair!\n",
    "# with open(f\"trainset_data_banking_{TRAIN_SIZE}.json\", \"r\") as f:\n",
    "#     data_example = ujson.load(f)\n",
    "from pprint import pprint\n",
    "data_example = read_jsonl(f\"trainset_data_banking.jsonl\")[0]\n",
    "\n",
    "print(\"Example prompt:\")\n",
    "pprint(data_example[\"messages\"][:-1])\n",
    "print(\"<end prompt>\\n\"+\"-\"*50)\n",
    "print(\"Example completion:\")\n",
    "pprint(data_example[\"messages\"][-1])\n",
    "print(\"<end completion>\\n\"+\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning\n",
    "\n",
    "We will use LLM Forge to fine-tune the 8B model.\n",
    "\n",
    "In order to do this, we need to format our data into the correct format (Follows OpenAI messaging format placed in a jsonl file).\n",
    "\n",
    "We initially saved the data into a json file in prompt-completion format.\n",
    "\n",
    "In order to prepare for finetuning, we need to do three steps:\n",
    "1. Format the data into the correct format and verify that the data is valid\n",
    "2. Upload the data to GCP\n",
    "3. Generate the compute configuration file\n",
    "\n",
    "After the compute configuration file is generated, we can submit the job to LLM Forge, using either the command line or using the anyscale jobs sdk.\n",
    "TODO: Add the anyscale jobs sdk submit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.modules.lm import TrainingMethod\n",
    "\n",
    "train_path = f\"trainset_data_banking.jsonl\"\n",
    "# eval_path = f\"valset_data_banking.jsonl\"\n",
    "eval_path = None\n",
    "method = TrainingMethod.SFT\n",
    "\n",
    "kwargs = {\n",
    "    \"hyperparameters\": {\n",
    "        \"num_devices\": 4,\n",
    "        \"trainer_resources\": None,\n",
    "        \"worker_resources\": None,\n",
    "        \"generation_config\": {\n",
    "            \"prompt_format\": {\n",
    "                \"system\": \"<|start_header_id|>system<|end_header_id|>\\n\\n{instruction}<|eot_id|>\",\n",
    "                \"user\": \"<|start_header_id|>user<|end_header_id|>\\n{instruction}<|eot_id|>\",\n",
    "                \"assistant\": \"<|start_header_id|>assistant<|end_header_id|>\\n\\n{instruction}<|eot_id|>\",\n",
    "                \"trailing_assistant\": \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    "                \"bos\": \"<|begin_of_text|>\",\n",
    "                \"system_in_user\": False,\n",
    "                \"default_system_message\": \"\"\n",
    "            },\n",
    "        },\n",
    "        \"learning_rate\": 3e-5,\n",
    "        \"num_epochs\": 6,\n",
    "        \"train_batch_size_per_device\": 32\n",
    "    },\n",
    "    \"use_lora\": True,\n",
    "    # TODO: I think this needs to be set dynamically\n",
    "    # \"lora_dynamic_folder\": \"dspy/lora_weights/prodjob_qmulcjw4x8z599m8hkyja8tbmi/meta-llama/Llama-3.2-1B-Instruct\"\n",
    "}\n",
    "\n",
    "SKIP_FT = False\n",
    "if not SKIP_FT:\n",
    "    # TODO: Get job working with LLMForge\n",
    "    student_llama_1b = dspy.TrainableAnyscale(model=\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "    future = student_llama_1b.get_finetune(method, train_path, eval_path, **kwargs)\n",
    "    checkpoint_names = future.result()\n",
    "\n",
    "    model_names = checkpoint_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Throughout this section, anything using 8B model (or technically 70B too) should use the new evaluate with ray data batch offline(or technically online) inference.\n",
    "\n",
    "Probably worth testing offline with 8x8 threads vs just 64 threads to see if it makes a meaningful difference.\n",
    "\n",
    "## Performance comparisons\n",
    "\n",
    "- 70B\n",
    "- 70B BSFS\n",
    "- 8B\n",
    "- 8B BSFT\n",
    "- 8B BSFT + BSFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model to run is the 8B model in order to collect a baseline of performance.\n",
    "\n",
    "You can run the local VLLM instance with the following command:\n",
    "\n",
    "Make sure to set your HF_TOKEN and HF_HOME environment variables\n",
    "\n",
    "For Anyscale, putting models into /mnt/local_storage is a typical pattern.\n",
    "\n",
    "\n",
    "`vllm serve meta-llama/Meta-Llama-3.1-8B-Instruct --port 8000 --pipeline_parallel_size 4 --enable_prefix_caching`\n",
    "\n",
    "Lets break down what this command does:\n",
    "- `vllm serve` is the command to run the VLLM server\n",
    "- `meta-llama/Meta-Llama-3.1-8B-Instruct` is the model to run\n",
    "- `--port 8000` is the port to run the server on\n",
    "- `--pipeline_parallel_size 4` is the number of pipeline parallel size to run the server with. We are using 4 because we have 4 GPUs all of which can hold an instance of the model.\n",
    "- `--enable_prefix_caching` is the flag to enable the prefix caching. This will store and reuse the beginnings of prompts to avoid repeating the same computation. This is especially useful for DSPy since we are almost always using prompts with the same beginning parts in the form of few shot demonstrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I need to eval the model with all the possible configurations\n",
    "# 70B CoT: Have from above\n",
    "# 1B CoT:\n",
    "# 1B CoT + BSRS:        \n",
    "# 1B CoT + BSFT(need to find best epoch):        \n",
    "# 1B CoT + BSFT + BSRS: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO IMPORTANT IMPORTANT IMPORTANT\n",
    "# model_names # I need to get this somehow. Waiting for response from Omar\n",
    "import json\n",
    "if False:\n",
    "    with open(\"model_names.json\", \"w\") as f:\n",
    "        json.dump(model_names, f)\n",
    "else:\n",
    "    with open(\"model_names.json\", \"r\") as f:\n",
    "        model_names = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command for easy copying: \n",
    "\n",
    "llama_1b = dspy.LM(model=\"openai/meta-llama/Llama-3.2-1B-Instruct\", **LOCAL_API_PARAMETERS, **MODEL_PARAMETERS)\n",
    "finetuned_llamas_1b = {f: dspy.LM(model=\"openai/\" + f, **LOCAL_API_PARAMETERS, **MODEL_PARAMETERS) for f in model_names}\n",
    "all_llamas = {**finetuned_llamas_1b, \"base\": llama_1b}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving things above this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope to bring the 8B performance up to at least 70B level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dspy.teleprompt import MIPROv2\n",
    "\n",
    "# eval_kwargs = dict(display_progress=True, display_table=0, num_threads=NUM_THREADS)\n",
    "# teleprompter = MIPROv2(prompt_model=llama_70b, task_model=llama_70b, metric=metric, num_candidates=10, init_temperature=0.9, verbose=True)\n",
    "\n",
    "# COMPILE_PROGRAM = True\n",
    "# if COMPILE_PROGRAM:\n",
    "#     with dspy.context(lm=llama_70b):\n",
    "#         compiled_program = teleprompter.compile(vanilla_program, trainset=optimizer_trainset, valset=optimizer_valset, num_batches=30, max_bootstrapped_demos=MAX_BOOTSTRAPPED_DEMOS,max_labeled_demos=MAX_LABELED_DEMOS, eval_kwargs=eval_kwargs, requires_permission_to_run=False)\n",
    "#         compiled_program.save(f\"t2sql_70b_31_MIPROv2_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}.json\")\n",
    "# else:\n",
    "#     compiled_program = TextToSQLModule()\n",
    "#     compiled_program.load(f\"t2sql_70b_31_MIPROv2_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}.json\")\n",
    "\n",
    "# with dspy.context(lm=llama_70b):\n",
    "#     llama_70b_mipro_eval = evaluate_devset(compiled_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Data\n",
    "\n",
    "\n",
    "In this section, we bootstrap data for fine-tuning. In the code block below, we are deciding which program should be used to collect the bootstraps. We are setting this to the prompt optimized program, but one could also set this to the vanilla program, though doing so would lead to lower quality bootstraps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_program = bfrs_base_program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to checkout the fine-tuning documentation for the latest on how to use our [API](https://docs.anyscale.com/llms/finetuning/intro) and additional [capabilities](https://docs.anyscale.com/category/fine-tuning-beta/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll fine-tune our LLM by choosing a set of configurations. We have created recipes for different LLMs in the [`training configs`](configs/training/lora/llama-3-8b.yaml) folder which can be used as is or modified for experiments. These configurations provide flexibility over a broad range of parameters such as model, data paths, compute to use for training, number of training epochs, how often to save checkpoints, padding, loss, etc. We also include several [DeepSpeed](https://github.com/microsoft/DeepSpeed) [configurations](configs/deepspeed/zero_3_offload_optim+param.json) to choose from for further optimizations around data/model parallelism, mixed precision, checkpointing, etc.\n",
    "\n",
    "We also have recipes for [LoRA](https://arxiv.org/abs/2106.09685) (where we train a set of small low ranked matrices instead of the original attention and feed forward layers) or full parameter fine-tuning. We recommend starting with LoRA as it's less resource intensive and quicker to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to serve the base model and tell VLLM where to find the LoRA weights\n",
    "\n",
    "Run the following command:\n",
    "\n",
    "```\n",
    "vllm serve meta-llama/Meta-Llama-3.1-8B-Instruct --port 8000 --pipeline_parallel_size 4 --enable_prefix_caching --enable_lora --lora_modules mhqa-lora=/mnt/local_storage/dspy/mhqa-lora\n",
    "```\n",
    "\n",
    "# Explanation:\n",
    "This command starts a VLLM server to serve the Meta-Llama-3-8B-Instruct model with LoRA fine-tuning.\n",
    "Here's a breakdown of the command:\n",
    "- 'vllm serve': Starts the VLLM server\n",
    "- 'meta-llama/Meta-Llama-3.1-8B-Instruct': Specifies the base model to use\n",
    "- '--port 8000': Sets the server port to 8000\n",
    "- '--pipeline_parallel_size 4': Enables pipeline parallelism with 4 stages\n",
    "- '--enable_prefix_caching': Enables caching of prefixes for faster inference\n",
    "- '--enable_lora': Enables LoRA (Low-Rank Adaptation) for fine-tuning\n",
    "- '--lora_modules mhqa-lora=/mnt/local_storage/dspy/mhqa-lora': Specifies the name of the LoRA module and the path to the LoRA weights. We use the name instead of the base model name when trying to use the LoRA weights. If we just use the base model name, the server will ignore the LoRA weights.\n",
    "\n",
    "This setup allows us to serve a fine-tuned version of the 8B model, which we'll use for subsequent evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sanity check that the finetuned models are working\n",
    "llama1 = list(finetuned_llamas_1b.values())[1]\n",
    "with dspy.context(lm=llama1):\n",
    "    print(llama1.model)\n",
    "    test_predictor = IntentClassificationModule()\n",
    "    sample_input = ft_trainset[11]\n",
    "    print(sample_input)\n",
    "    print(test_predictor(**sample_input.inputs()).label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try optimizing the program with the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collected_data_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollected_data_to_example\u001b[39m(data):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dspy\u001b[38;5;241m.\u001b[39mExample(text\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mwith_inputs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m collected_data_examples \u001b[38;5;241m=\u001b[39m [collected_data_to_example(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcollected_data_filtered\u001b[49m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# collected_data_examples[0]\u001b[39;00m\n\u001b[1;32m      7\u001b[0m devset_synthetic \u001b[38;5;241m=\u001b[39m collected_data_examples[:DEV_SIZE]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collected_data_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "def collected_data_to_example(data):\n",
    "    return dspy.Example(text=data[\"example\"][\"text\"], label=data[\"prediction\"][\"label\"]).with_inputs(\"text\")\n",
    "\n",
    "collected_data_examples = [collected_data_to_example(x) for x in collected_data_filtered]\n",
    "# collected_data_examples[0]\n",
    "\n",
    "devset_synthetic = collected_data_examples[:DEV_SIZE]\n",
    "ft_optimizer_devset = collected_data_examples[DEV_SIZE:DEV_SIZE+OPTIMIZER_NUM_VAL]\n",
    "ft_optimizer_trainset = collected_data_examples[DEV_SIZE+OPTIMIZER_NUM_VAL:]\n",
    "\n",
    "evaluate_devset = Evaluate(devset=devset_synthetic, metric=metric, num_threads=NUM_THREADS, display_progress=True, max_errors=10000)\n",
    "\n",
    "print(len(devset_synthetic), len(ft_optimizer_trainset), len(ft_optimizer_devset))\n",
    "print(devset_synthetic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 135.0 / 320  (42.2):  91%|█████████ | 319/350 [00:21<00:00, 32.35it/s]=024-10-12T23:12:17.200926Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 147.0 / 350  (42.0): 100%|██████████| 350/350 [00:21<00:00, 16.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 42.0 for seed -1\n",
      "Scores so far: [16.29, 16.29, 42.0]\n",
      "Best score so far: 42.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 9/150 [00:04<01:08,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0):   0%|          | 1/350 [00:01<07:27,  1.28s/it]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 50  (46.0):  14%|█▍        | 50/350 [00:03<00:16, 18.54it/s]2024-10-12T23:12:25.582669Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 51  (45.1):  14%|█▍        | 50/350 [00:03<00:16, 18.54it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 52  (44.2):  15%|█▍        | 51/350 [00:03<00:16, 18.54it/s]2024-10-12T23:12:25.894267Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 190  (42.6):  54%|█████▍    | 189/350 [00:11<00:08, 18.08it/s]2024-10-12T23:12:33.660151Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 83.0 / 198  (41.9):  56%|█████▋    | 197/350 [00:11<00:08, 18.57it/s]2024-10-12T23:12:34.343646Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 113.0 / 260  (43.5):  74%|███████▍  | 259/350 [00:15<00:05, 15.47it/s]2024-10-12T23:12:38.022321Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 124.0 / 285  (43.5):  81%|████████▏ | 285/350 [00:17<00:05, 12.57it/s]]024-10-12T23:12:39.583471Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 155.0 / 350  (44.3): 100%|██████████| 350/350 [00:18<00:00, 18.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 44.29 for seed 0\n",
      "Scores so far: [16.29, 16.29, 42.0, 44.29]\n",
      "Best score so far: 44.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/150 [00:01<00:47,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:12:44.104856Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 49  (42.9):  14%|█▍        | 49/350 [00:03<00:21, 14.08it/s]2024-10-12T23:12:46.963789Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 51  (43.1):  14%|█▍        | 50/350 [00:03<00:21, 14.08it/s]2024-10-12T23:12:46.969504Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 52  (42.3):  15%|█▍        | 51/350 [00:03<00:21, 14.08it/s]2024-10-12T23:12:46.973739Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 137  (40.9):  39%|███▉      | 137/350 [00:09<00:12, 16.41it/s]2024-10-12T23:12:52.880295Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 111.0 / 255  (43.5):  73%|███████▎  | 255/350 [00:17<00:04, 23.48it/s]filename12T23:13:00.767702Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 124.0 / 287  (43.2):  82%|████████▏ | 287/350 [00:19<00:04, 14.52it/s]2024-10-12T23:13:02.788682Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 154.0 / 350  (44.0): 100%|██████████| 350/350 [00:21<00:00, 16.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [16.29, 16.29, 42.0, 44.29, 44.0]\n",
      "Best score so far: 44.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6/150 [00:02<00:49,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 20 / 49  (40.8):  14%|█▎        | 48/350 [00:03<00:10, 27.51it/s]2024-10-12T23:13:11.035718Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 113.0 / 286  (39.5):  81%|████████▏ | 285/350 [00:19<00:04, 14.31it/s]2024-10-12T23:13:26.855778Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 142.0 / 350  (40.6): 100%|██████████| 350/350 [00:21<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [16.29, 16.29, 42.0, 44.29, 44.0, 40.57]\n",
      "Best score so far: 44.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/150 [00:01<01:10,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:13:31.581849Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 51  (45.1):  14%|█▍        | 50/350 [00:03<00:17, 17.19it/s]2024-10-12T23:13:34.415728Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 52  (44.2):  15%|█▍        | 51/350 [00:03<00:17, 17.19it/s]2024-10-12T23:13:34.513111Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 100.0 / 248  (40.3):  71%|███████   | 247/350 [00:17<00:07, 13.28it/s]2024-10-12T23:13:48.190458Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 108.0 / 281  (38.4):  80%|████████  | 281/350 [00:19<00:04, 16.30it/s]2024-10-12T23:13:50.490210Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 136.0 / 350  (38.9): 100%|██████████| 350/350 [00:22<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [16.29, 16.29, 42.0, 44.29, 44.0, 40.57, 38.86]\n",
      "Best score so far: 44.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:01<00:53,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:13:55.978390Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<05:03,  1.15it/s]2024-10-12T23:13:56.123496Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 48  (25.0):  13%|█▎        | 47/350 [00:03<00:16, 17.99it/s]2024-10-12T23:13:58.408439Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 49  (24.5):  14%|█▎        | 48/350 [00:03<00:16, 17.99it/s]2024-10-12T23:13:58.649421Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 51  (23.5):  14%|█▍        | 50/350 [00:03<00:19, 15.63it/s]2024-10-12T23:13:58.795648Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 94  (33.0):  27%|██▋       | 94/350 [00:06<00:14, 17.27it/s]2024-10-12T23:14:01.309468Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 45.0 / 140  (32.1):  40%|███▉      | 139/350 [00:08<00:11, 19.14it/s]2024-10-12T23:14:03.810949Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 72.0 / 209  (34.4):  59%|█████▉    | 208/350 [00:13<00:09, 14.29it/s]198y.evaluate.evaluate7030Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=\n",
      "Average Metric: 81.0 / 238  (34.0):  68%|██████▊   | 237/350 [00:14<00:06, 17.47it/s]2024-10-12T23:14:09.687926Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 84.0 / 264  (31.8):  75%|███████▌  | 263/350 [00:16<00:06, 12.64it/s]2024-10-12T23:14:11.404280Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 269  (32.0):  77%|███████▋  | 269/350 [00:16<00:05, 15.44it/s]2024-10-12T23:14:11.751683Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 113.0 / 350  (32.3): 100%|██████████| 350/350 [00:18<00:00, 18.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [16.29, 16.29, 42.0, 44.29, 44.0, 40.57, 38.86, 32.29]\n",
      "Best score so far: 44.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 20/150 [00:08<00:52,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 21 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:14:23.644589Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:01<06:59,  1.20s/it]2024-10-12T23:14:23.673268Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/350 [00:01<06:59,  1.20s/it]2024-10-12T23:14:23.989140Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 6  (50.0):   1%|▏         | 5/350 [00:01<02:00,  2.86it/s]2024-10-12T23:14:24.246244Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 57  (49.1):  16%|█▌        | 56/350 [00:03<00:12, 23.52it/s]2024-10-12T23:14:26.351188Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 60  (46.7):  17%|█▋        | 60/350 [00:04<00:15, 18.14it/s]2024-10-12T23:14:26.733918Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 62  (45.2):  17%|█▋        | 61/350 [00:04<00:15, 18.14it/s]2024-10-12T23:14:26.780252Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 63  (44.4):  18%|█▊        | 63/350 [00:04<00:18, 15.69it/s]2024-10-12T23:14:26.890915Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 64  (43.8):  18%|█▊        | 63/350 [00:04<00:18, 15.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 114  (45.6):  32%|███▏      | 113/350 [00:07<00:13, 17.47it/s]2024-10-12T23:14:29.947139Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 117  (44.4):  33%|███▎      | 116/350 [00:07<00:18, 12.78it/s]2024-10-12T23:14:30.018755Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 120  (44.2):  34%|███▍      | 119/350 [00:07<00:16, 14.31it/s]2024-10-12T23:14:30.410709Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 76.0 / 167  (45.5):  47%|████▋     | 166/350 [00:10<00:14, 12.37it/s]lineno0-12T23:14:33.046956Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 81.0 / 178  (45.5):  51%|█████     | 177/350 [00:11<00:13, 12.42it/s]]024-10-12T23:14:33.836747Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 88.0 / 193  (45.6):  55%|█████▍    | 192/350 [00:12<00:10, 15.24it/s] [24-10-12T23:14:34.585631Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 93.0 / 202  (46.0):  57%|█████▋    | 201/350 [00:12<00:10, 14.70it/s]2024-10-12T23:14:35.260758Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 94.0 / 206  (45.6):  59%|█████▊    | 205/350 [00:12<00:07, 18.79it/s]2024-10-12T23:14:35.267537Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 97.0 / 216  (44.9):  61%|██████▏   | 215/350 [00:13<00:06, 19.43it/s]2024-10-12T23:14:35.865222Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 106.0 / 233  (45.5):  66%|██████▋   | 232/350 [00:14<00:09, 12.24it/s]2024-10-12T23:14:37.136325Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 114.0 / 249  (45.8):  71%|███████   | 249/350 [00:15<00:07, 14.18it/s]2024-10-12T23:14:38.407561Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 137.0 / 291  (47.1):  83%|████████▎ | 290/350 [00:18<00:04, 14.88it/s] ilenameluate.evaluate9953Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] =evaluate.pylineno=198\n",
      "Average Metric: 140.0 / 299  (46.8):  85%|████████▌ | 298/350 [00:18<00:03, 15.90it/s]2024-10-12T23:14:41.506922Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 154.0 / 329  (46.8):  94%|█████████▎| 328/350 [00:19<00:00, 42.89it/s]=024-10-12T23:14:42.006269Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 161.0 / 350  (46.0): 100%|██████████| 350/350 [00:19<00:00, 17.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 46.0 for seed 5\n",
      "Scores so far: [16.29, 16.29, 42.0, 44.29, 44.0, 40.57, 38.86, 32.29, 46.0]\n",
      "Best score so far: 46.0\n",
      "9 candidate programs found.\n",
      "[('intent_classifier', Predict(StringSignature(intent -> reasoning, label\n",
      "    instructions=\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\\nThe intent should exactly match one of the following:\\n['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\"\n",
      "    intent = Field(annotation=str required=True json_schema_extra={'desc': 'Intent of the query', '__dspy_field_type': 'input', 'prefix': 'Intent:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the output fields}. We ...', '__dspy_field_type': 'output'})\n",
      "    label = Field(annotation=str required=True json_schema_extra={'desc': 'Type of the intent; Should just be one of the 25 labels with no other text', '__dspy_field_type': 'output', 'prefix': 'Label:'})\n",
      ")))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]2024-10-12T23:14:43.776404Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/500 [00:01<09:02,  1.09s/it]2024-10-12T23:14:43.804919Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/500 [00:01<09:02,  1.09s/it]2024-10-12T23:14:44.105258Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 45  (44.4):   9%|▉         | 45/500 [00:03<00:15, 29.33it/s]2024-10-12T23:14:46.018472Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 53  (45.3):  11%|█         | 53/500 [00:03<00:24, 18.05it/s]2024-10-12T23:14:46.395877Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 56  (46.4):  11%|█         | 55/500 [00:03<00:24, 18.05it/s]dspy.evaluate.evaluate2810Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 143  (51.7):  28%|██▊       | 142/500 [00:09<00:29, 12.12it/s]evaluate.py23:14:51.902007Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 75.0 / 145  (51.7):  29%|██▉       | 144/500 [00:09<00:29, 12.12it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 78.0 / 151  (51.7):  30%|███       | 150/500 [00:09<00:26, 13.24it/s]2024-10-12T23:14:52.347820Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 154  (51.9):  31%|███       | 153/500 [00:09<00:20, 16.64it/s]2024-10-12T23:14:52.724785Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 165  (52.1):  33%|███▎      | 164/500 [00:10<00:18, 18.30it/s]2024-10-12T23:14:53.140633Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 92.0 / 178  (51.7):  36%|███▌      | 178/500 [00:11<00:19, 16.68it/s]]024-10-12T23:14:53.945507Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 97.0 / 192  (50.5):  38%|███▊      | 191/500 [00:11<00:19, 15.80it/s]2024-10-12T23:14:54.645441Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 98.0 / 195  (50.3):  39%|███▉      | 194/500 [00:12<00:14, 20.50it/s]2024-10-12T23:14:55.010939Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 107.0 / 216  (49.5):  43%|████▎     | 215/500 [00:13<00:17, 16.47it/s]evaluate.py23:14:56.224594Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 123.0 / 248  (49.6):  50%|████▉     | 248/500 [00:15<00:09, 25.33it/s]2024-10-12T23:14:57.905518Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 139.0 / 272  (51.1):  54%|█████▍    | 271/500 [00:16<00:15, 14.91it/s]2024-10-12T23:14:59.474351Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 146.0 / 291  (50.2):  58%|█████▊    | 290/500 [00:18<00:14, 14.48it/s]dspy.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 147.0 / 293  (50.2):  58%|█████▊    | 292/500 [00:18<00:14, 14.48it/s]2024-10-12T23:15:00.775036Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 147.0 / 296  (49.7):  59%|█████▉    | 295/500 [00:18<00:11, 18.13it/s] 024-10-12T23:15:00.841684Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 165.0 / 322  (51.2):  64%|██████▍   | 321/500 [00:19<00:12, 14.48it/s] 024-10-12T23:15:02.322134Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 167.0 / 329  (50.8):  66%|██████▌   | 328/500 [00:20<00:12, 13.27it/s]2024-10-12T23:15:02.932960Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 171.0 / 337  (50.7):  67%|██████▋   | 337/500 [00:21<00:12, 13.38it/s] 024-10-12T23:15:03.759906Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 195.0 / 378  (51.6):  76%|███████▌  | 378/500 [00:23<00:09, 12.36it/s]2024-10-12T23:15:06.408223Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 195.0 / 379  (51.5):  76%|███████▌  | 378/500 [00:23<00:09, 12.36it/s]2024-10-12T23:15:06.616594Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 195.0 / 380  (51.3):  76%|███████▌  | 380/500 [00:23<00:12,  9.79it/s]2024-10-12T23:15:06.666777Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 200.0 / 393  (50.9):  78%|███████▊  | 392/500 [00:24<00:05, 18.79it/s]2024-10-12T23:15:07.402138Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 206.0 / 402  (51.2):  80%|████████  | 401/500 [00:24<00:04, 20.56it/s]2024-10-12T23:15:07.595367Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 212.0 / 419  (50.6):  84%|████████▎ | 418/500 [00:25<00:04, 17.56it/s]2024-10-12T23:15:08.819693Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 212.0 / 421  (50.4):  84%|████████▍ | 421/500 [00:26<00:05, 15.44it/s]2024-10-12T23:15:08.851805Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 216.0 / 429  (50.3):  86%|████████▌ | 428/500 [00:26<00:04, 14.66it/s]2024-10-12T23:15:09.318058Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 219.0 / 438  (50.0):  88%|████████▊ | 438/500 [00:27<00:04, 13.71it/s]2024-10-12T23:15:10.031428Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 222.0 / 442  (50.2):  88%|████████▊ | 441/500 [00:27<00:04, 13.71it/s]2024-10-12T23:15:10.297868Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 250.0 / 500  (50.0): 100%|██████████| 500/500 [00:28<00:00, 17.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for meta-llama/Llama-3.2-1B-Instruct:epochs-5-total-trained-steps-174: 50.0, None, None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]2024-10-12T23:15:13.355727Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 39  (17.9):   8%|▊         | 38/500 [00:03<00:34, 13.49it/s]2024-10-12T23:15:15.368612Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 85  (23.5):  17%|█▋        | 85/500 [00:05<00:17, 23.93it/s]2024-10-12T23:15:17.671705Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 103  (22.3):  20%|██        | 102/500 [00:06<00:15, 25.08it/s]2024-10-12T23:15:18.487659Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 120  (21.7):  24%|██▍       | 119/500 [00:07<00:16, 22.90it/s]dspy.evaluate.evaluate2130Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 39.0 / 179  (21.8):  36%|███▌      | 178/500 [00:10<00:17, 18.22it/s]2024-10-12T23:15:22.276802Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 233  (22.3):  47%|████▋     | 233/500 [00:13<00:16, 16.20it/s]2024-10-12T23:15:25.054816Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 258  (22.1):  51%|█████▏    | 257/500 [00:14<00:15, 15.56it/s]2024-10-12T23:15:26.409442Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 78.0 / 359  (21.7):  72%|███████▏  | 358/500 [00:21<00:08, 15.79it/s]2024-10-12T23:15:32.929214Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 87.0 / 382  (22.8):  76%|███████▌  | 381/500 [00:22<00:07, 15.59it/s]2024-10-12T23:15:34.200268Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 92.0 / 434  (21.2):  87%|████████▋ | 433/500 [00:25<00:03, 18.26it/s]2024-10-12T23:15:37.108234Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 109.0 / 499  (21.8): 100%|█████████▉| 498/500 [00:27<00:00, 49.84it/s]2024-10-12T23:15:42.351073Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 109.0 / 500  (21.8): 100%|██████████| 500/500 [00:30<00:00, 16.39it/s]\n",
      "Average Metric: 20 / 102  (19.6):  29%|██▉       | 101/350 [00:05<00:15, 16.52it/s]2024-10-12T23:15:48.299675Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 58.0 / 317  (18.3):  90%|█████████ | 316/350 [00:17<00:01, 33.71it/s]2024-10-12T23:16:00.056442Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 322  (18.3):  92%|█████████▏| 321/350 [00:17<00:00, 33.71it/s]2024-10-12T23:16:00.102239Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 347  (18.7):  99%|█████████▉| 346/350 [00:18<00:00, 38.51it/s]2024-10-12T23:16:04.736591Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 348  (18.7):  99%|█████████▉| 347/350 [00:22<00:00, 38.51it/s]2024-10-12T23:16:05.224629Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 349  (18.6): 100%|█████████▉| 349/350 [00:22<00:00,  4.63it/s]2024-10-12T23:16:05.762949Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 350  (18.6): 100%|██████████| 350/350 [00:23<00:00, 15.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 18.57 for seed -3\n",
      "Scores so far: [18.57]\n",
      "Best score so far: 18.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-12T23:16:05.834339Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0 / 8  (0.0):   2%|▏         | 7/350 [00:00<00:00, 788.21it/s]=r example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 3 / 17  (17.6):   5%|▍         | 16/350 [00:00<00:00, 649.34it/s]=ilenameT23:16:05.879335Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]evaluate.py lineno=198\n",
      "Average Metric: 5 / 26  (19.2):   7%|▋         | 25/350 [00:00<00:00, 692.21it/s] [24-10-12T23:16:05.918697Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filenameevaluate.pylineno=198\n",
      "Average Metric: 7 / 33  (21.2):   9%|▉         | 32/350 [00:00<00:00, 635.09it/s]1984-10-12T23:16:05.940045Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno=\n",
      "Average Metric: 8 / 42  (19.0):  12%|█▏        | 41/350 [00:00<00:00, 646.17it/s]198enote.py23:16:05.942158Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename= =\n",
      "Average Metric: 65.0 / 350  (18.6): 100%|██████████| 350/350 [00:00<00:00, 1120.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [18.57, 18.57]\n",
      "Best score so far: 18.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 8/150 [00:03<01:04,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:16:10.903881Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<04:30,  1.29it/s]12T23:16:10.940103Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/350 [00:00<04:30,  1.29it/s]2024-10-12T23:16:10.986217Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 2/350 [00:00<04:29,  1.29it/s]2024-10-12T23:16:11.071504Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 4/350 [00:00<01:03,  5.47it/s]2024-10-12T23:16:11.097594Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   1%|          | 4/350 [00:00<01:03,  5.47it/s]2024-10-12T23:16:11.486434Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   2%|▏         | 6/350 [00:01<01:06,  5.16it/s]2024-10-12T23:16:11.668959Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   2%|▏         | 7/350 [00:01<01:05,  5.22it/s]2024-10-12T23:16:11.699205Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 9  (0.0):   2%|▏         | 8/350 [00:01<01:05,  5.22it/s]2024-10-12T23:16:11.960858Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 39  (23.1):  11%|█         | 38/350 [00:02<00:14, 22.23it/s]2024-10-12T23:16:13.255542Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 46  (28.3):  13%|█▎        | 45/350 [00:03<00:13, 22.29it/s]2024-10-12T23:16:13.699855Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 50  (28.0):  14%|█▍        | 49/350 [00:03<00:16, 17.99it/s]2024-10-12T23:16:13.802154Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 53  (26.4):  15%|█▌        | 53/350 [00:03<00:13, 22.34it/s] [24-10-12T23:16:13.808032Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 55  (27.3):  15%|█▌        | 54/350 [00:03<00:13, 22.34it/s]2024-10-12T23:16:13.875571Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 57  (28.1):  16%|█▌        | 56/350 [00:03<00:13, 22.34it/s]2024-10-12T23:16:13.924631Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 67  (23.9):  19%|█▉        | 66/350 [00:04<00:13, 20.54it/s]2024-10-12T23:16:14.368789Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 70  (24.3):  20%|█▉        | 69/350 [00:04<00:10, 26.44it/s]2024-10-12T23:16:14.452222Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 81  (27.2):  23%|██▎       | 80/350 [00:04<00:12, 22.49it/s]2024-10-12T23:16:15.352496Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 86  (27.9):  24%|██▍       | 85/350 [00:05<00:15, 16.80it/s]filename12T23:16:15.392306Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 97  (27.8):  27%|██▋       | 96/350 [00:05<00:15, 16.19it/s]2024-10-12T23:16:16.122179Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 99  (28.3):  28%|██▊       | 98/350 [00:05<00:15, 16.19it/s]2024-10-12T23:16:16.130849Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 108  (28.7):  31%|███       | 108/350 [00:06<00:10, 22.96it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 119  (29.4):  34%|███▎      | 118/350 [00:06<00:10, 22.16it/s] 024-10-12T23:16:16.917142Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 123  (29.3):  35%|███▍      | 122/350 [00:06<00:08, 26.61it/s]2024-10-12T23:16:17.297640Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 129  (29.5):  37%|███▋      | 129/350 [00:07<00:14, 15.57it/s]=024-10-12T23:16:17.685981Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filenameevaluate.py lineno=198\n",
      "Average Metric: 38.0 / 130  (29.2):  37%|███▋      | 129/350 [00:07<00:14, 15.57it/s]2024-10-12T23:16:17.735602Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 138  (27.5):  39%|███▉      | 137/350 [00:07<00:14, 14.34it/s]1984-10-12T23:16:18.170806Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 46.0 / 160  (28.8):  45%|████▌     | 159/350 [00:09<00:11, 16.75it/s]2024-10-12T23:16:19.476230Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 161  (28.6):  46%|████▌     | 161/350 [00:09<00:10, 17.71it/s]] 24-10-12T23:16:19.481994Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 48.0 / 170  (28.2):  48%|████▊     | 169/350 [00:10<00:13, 13.11it/s]2024-10-12T23:16:20.204781Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 49.0 / 174  (28.2):  50%|████▉     | 174/350 [00:10<00:09, 18.84it/s]2024-10-12T23:16:20.345147Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 181  (27.6):  51%|█████▏    | 180/350 [00:10<00:13, 12.48it/s]2024-10-12T23:16:21.008055Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 200  (28.5):  57%|█████▋    | 200/350 [00:11<00:09, 15.93it/s]2024-10-12T23:16:22.119078Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 58.0 / 203  (28.6):  58%|█████▊    | 202/350 [00:12<00:09, 15.93it/s]=rror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 58.0 / 204  (28.4):  58%|█████▊    | 203/350 [00:12<00:09, 15.93it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 213  (29.1):  61%|██████    | 212/350 [00:12<00:07, 18.17it/s]2024-10-12T23:16:22.908472Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 219  (28.3):  62%|██████▏   | 218/350 [00:13<00:11, 11.60it/s]2024-10-12T23:16:23.311741Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 248  (28.6):  71%|███████   | 248/350 [00:15<00:08, 12.25it/s]2024-10-12T23:16:25.287939Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 251  (28.3):  71%|███████▏  | 250/350 [00:15<00:08, 12.25it/s]filename   ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 257  (28.8):  73%|███████▎  | 256/350 [00:15<00:07, 12.22it/s]error    2T23:16:25.778195Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 77.0 / 271  (28.4):  77%|███████▋  | 270/350 [00:15<00:03, 26.63it/s]2024-10-12T23:16:26.186393Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 82.0 / 284  (28.9):  81%|████████  | 284/350 [00:16<00:03, 19.44it/s]2024-10-12T23:16:27.327475Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 84.0 / 295  (28.5):  84%|████████▍ | 294/350 [00:17<00:05, 10.93it/s]filename12T23:16:27.986706Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 90.0 / 307  (29.3):  87%|████████▋ | 306/350 [00:18<00:02, 16.09it/s]2024-10-12T23:16:28.468120Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 91.0 / 314  (29.0):  89%|████████▉ | 313/350 [00:18<00:01, 24.01it/s]2024-10-12T23:16:28.550527Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 102.0 / 350  (29.1): 100%|██████████| 350/350 [00:18<00:00, 18.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 29.14 for seed -1\n",
      "Scores so far: [18.57, 18.57, 29.14]\n",
      "Best score so far: 29.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 10/150 [00:03<00:48,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:16:33.683391Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<04:42,  1.24it/s]2024-10-12T23:16:33.713660Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/350 [00:00<04:42,  1.24it/s]2024-10-12T23:16:33.753274Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 2/350 [00:00<04:41,  1.24it/s]2024-10-12T23:16:33.759139Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 4/350 [00:00<01:02,  5.50it/s]2024-10-12T23:16:33.763697Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   1%|          | 4/350 [00:00<01:02,  5.50it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   1%|▏         | 5/350 [00:00<01:02,  5.50it/s]2024-10-12T23:16:33.790707Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   2%|▏         | 6/350 [00:00<01:02,  5.50it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   2%|▏         | 7/350 [00:01<01:02,  5.50it/s]2024-10-12T23:16:33.817758Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 9  (0.0):   3%|▎         | 9/350 [00:01<00:26, 12.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 10  (0.0):   3%|▎         | 9/350 [00:01<00:26, 12.86it/s]2024-10-12T23:16:33.848193Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 11  (0.0):   3%|▎         | 10/350 [00:01<00:26, 12.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 13  (0.0):   3%|▎         | 12/350 [00:01<00:26, 12.86it/s]2024-10-12T23:16:34.311929Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 14  (0.0):   4%|▎         | 13/350 [00:01<00:29, 11.37it/s]2024-10-12T23:16:34.318368Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 45  (15.6):  13%|█▎        | 44/350 [00:02<00:09, 30.65it/s]2024-10-12T23:16:35.544451Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 47  (14.9):  13%|█▎        | 46/350 [00:02<00:12, 24.41it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 49  (14.3):  14%|█▎        | 48/350 [00:02<00:12, 24.41it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 51  (13.7):  14%|█▍        | 50/350 [00:02<00:12, 24.41it/s]filename12T23:16:35.629132Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 53  (13.2):  15%|█▍        | 52/350 [00:03<00:10, 29.71it/s]2024-10-12T23:16:35.927579Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 57  (15.8):  16%|█▌        | 56/350 [00:03<00:09, 29.71it/s] [24-10-12T23:16:35.946399Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 59  (15.3):  17%|█▋        | 58/350 [00:03<00:12, 23.70it/s]2024-10-12T23:16:35.967915Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 62  (14.5):  17%|█▋        | 61/350 [00:03<00:12, 23.70it/s]=024-10-12T23:16:36.034484Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 10.0 / 69  (14.5):  19%|█▉        | 68/350 [00:03<00:11, 24.04it/s]024-10-12T23:16:36.426599Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 70  (14.3):  20%|█▉        | 69/350 [00:03<00:11, 24.04it/s]2024-10-12T23:16:36.451280Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 71  (14.1):  20%|██        | 70/350 [00:03<00:11, 24.04it/s]2024-10-12T23:16:36.474580Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 79  (17.7):  22%|██▏       | 78/350 [00:04<00:16, 16.26it/s]lineno0-12T23:16:37.129552Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 14.0 / 82  (17.1):  23%|██▎       | 81/350 [00:04<00:12, 20.70it/s]2024-10-12T23:16:37.139908Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 90  (16.7):  25%|██▌       | 89/350 [00:04<00:13, 18.97it/s]2024-10-12T23:16:37.589264Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 95  (16.8):  27%|██▋       | 95/350 [00:05<00:17, 14.20it/s] 024-10-12T23:16:38.176720Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 21.0 / 102  (20.6):  29%|██▉       | 101/350 [00:05<00:16, 15.28it/s]evaluate.py23:16:38.497684Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 24.0 / 114  (21.1):  32%|███▏      | 113/350 [00:06<00:12, 19.03it/s]2024-10-12T23:16:39.018396Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 118  (20.3):  33%|███▎      | 117/350 [00:06<00:10, 22.66it/s]2024-10-12T23:16:39.065994Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 125  (20.8):  35%|███▌      | 124/350 [00:06<00:07, 29.44it/s]2024-10-12T23:16:39.472270Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 127  (21.3):  36%|███▌      | 126/350 [00:06<00:07, 29.44it/s]filename   ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 131  (20.6):  37%|███▋      | 130/350 [00:06<00:09, 22.65it/s]]024-10-12T23:16:39.489895Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 135  (20.7):  39%|███▊      | 135/350 [00:06<00:07, 28.11it/s]2024-10-12T23:16:39.493555Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 137  (20.4):  39%|███▉      | 136/350 [00:07<00:07, 28.11it/s]2024-10-12T23:16:39.920400Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 29.0 / 141  (20.6):  40%|████      | 140/350 [00:07<00:09, 22.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.pylineno=198\n",
      "Average Metric: 30.0 / 144  (20.8):  41%|████      | 143/350 [00:07<00:09, 22.38it/s] 024-10-12T23:16:40.053763Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 30.0 / 146  (20.5):  41%|████▏     | 145/350 [00:07<00:09, 22.38it/s]2024-10-12T23:16:40.120359Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 30.0 / 147  (20.4):  42%|████▏     | 147/350 [00:07<00:07, 28.58it/s]2024-10-12T23:16:40.354531Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 151  (20.5):  43%|████▎     | 150/350 [00:07<00:06, 28.58it/s]] 24-10-12T23:16:40.376520Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 152  (20.4):  43%|████▎     | 152/350 [00:07<00:08, 23.68it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 154  (20.1):  44%|████▎     | 153/350 [00:07<00:08, 23.68it/s]2024-10-12T23:16:40.464773Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 159  (20.8):  45%|████▌     | 158/350 [00:07<00:09, 20.43it/s]=024-10-12T23:16:40.790083Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 34.0 / 162  (21.0):  46%|████▌     | 161/350 [00:07<00:09, 20.43it/s]2024-10-12T23:16:40.866706Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 165  (21.2):  47%|████▋     | 164/350 [00:08<00:07, 25.40it/s]2024-10-12T23:16:41.198421Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 171  (21.1):  49%|████▊     | 170/350 [00:08<00:08, 20.21it/s]evaluate.py23:16:41.361269Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 36.0 / 175  (20.6):  50%|████▉     | 174/350 [00:08<00:09, 18.13it/s]][24-10-12T23:16:41.614029Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 179  (20.1):  51%|█████     | 178/350 [00:08<00:07, 23.22it/s]error    2T23:16:41.659760Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 37.0 / 185  (20.0):  53%|█████▎    | 184/350 [00:09<00:08, 19.26it/s]2024-10-12T23:16:42.036227Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 189  (20.1):  54%|█████▎    | 188/350 [00:09<00:06, 24.26it/s]2024-10-12T23:16:42.041678Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 196  (20.4):  56%|█████▌    | 196/350 [00:09<00:06, 25.23it/s]evaluate.py23:16:42.436347Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 40.0 / 201  (19.9):  57%|█████▋    | 200/350 [00:09<00:07, 19.92it/s]2024-10-12T23:16:42.799977Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 204  (19.6):  58%|█████▊    | 203/350 [00:09<00:07, 19.92it/s]2024-10-12T23:16:42.809007Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 207  (19.3):  59%|█████▉    | 206/350 [00:10<00:05, 24.24it/s]2024-10-12T23:16:42.837939Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 208  (19.2):  59%|█████▉    | 207/350 [00:10<00:05, 24.24it/s]2024-10-12T23:16:42.908702Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 210  (19.0):  60%|██████    | 210/350 [00:10<00:06, 21.18it/s]2024-10-12T23:16:43.186353Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 213  (18.8):  61%|██████    | 212/350 [00:10<00:06, 21.18it/s]filename   ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 217  (18.4):  62%|██████▏   | 216/350 [00:10<00:05, 23.32it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 41.0 / 221  (18.6):  63%|██████▎   | 220/350 [00:10<00:06, 20.59it/s]2024-10-12T23:16:43.643376Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 41.0 / 224  (18.3):  64%|██████▎   | 223/350 [00:10<00:06, 20.59it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 226  (18.6):  64%|██████▍   | 225/350 [00:10<00:04, 25.89it/s]] ror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 228  (18.4):  65%|██████▍   | 227/350 [00:10<00:04, 25.89it/s]2024-10-12T23:16:43.819498Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 229  (18.3):  65%|██████▌   | 228/350 [00:10<00:04, 25.89it/s]2024-10-12T23:16:43.859275Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 43.0 / 232  (18.5):  66%|██████▌   | 231/350 [00:11<00:04, 29.19it/s]1984-10-12T23:16:44.160501Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 43.0 / 237  (18.1):  67%|██████▋   | 236/350 [00:11<00:05, 20.50it/s]1984-10-12T23:16:44.189931Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 46.0 / 245  (18.8):  70%|███████   | 245/350 [00:11<00:04, 22.11it/s]2024-10-12T23:16:44.625986Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 247  (18.6):  70%|███████   | 246/350 [00:11<00:04, 22.11it/s]2024-10-12T23:16:44.634135Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 248  (18.5):  71%|███████   | 247/350 [00:11<00:04, 22.11it/s]2024-10-12T23:16:44.673532Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 249  (18.5):  71%|███████   | 248/350 [00:11<00:04, 22.11it/s]2024-10-12T23:16:44.690066Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 252  (18.3):  72%|███████▏  | 251/350 [00:12<00:03, 27.76it/s]lineno0-12T23:16:45.006462Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 48.0 / 259  (18.5):  74%|███████▎  | 258/350 [00:12<00:04, 20.85it/s]]rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 48.0 / 261  (18.4):  74%|███████▍  | 260/350 [00:12<00:04, 20.85it/s]2024-10-12T23:16:45.019718Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 48.0 / 262  (18.3):  75%|███████▍  | 262/350 [00:12<00:03, 27.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 48.0 / 263  (18.3):  75%|███████▍  | 262/350 [00:12<00:03, 27.60it/s]2024-10-12T23:16:45.210483Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 272  (18.4):  77%|███████▋  | 271/350 [00:13<00:04, 18.08it/s]filename12T23:16:45.853954Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 277  (18.1):  79%|███████▉  | 276/350 [00:13<00:03, 21.82it/s]1984-10-12T23:16:45.889698Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=\n",
      "Average Metric: 50.0 / 278  (18.0):  79%|███████▉  | 277/350 [00:13<00:03, 21.82it/s]2024-10-12T23:16:46.009061Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 51.0 / 285  (17.9):  81%|████████  | 284/350 [00:13<00:03, 21.92it/s] 024-10-12T23:16:46.310520Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 53.0 / 290  (18.3):  83%|████████▎ | 289/350 [00:13<00:02, 21.18it/s]2024-10-12T23:16:46.637563Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 291  (18.2):  83%|████████▎ | 290/350 [00:13<00:02, 21.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 293  (18.1):  84%|████████▎ | 293/350 [00:13<00:02, 24.74it/s]2024-10-12T23:16:46.653329Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 295  (18.0):  84%|████████▍ | 294/350 [00:13<00:02, 24.74it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 298  (18.1):  85%|████████▍ | 297/350 [00:13<00:02, 24.74it/s]2024-10-12T23:16:46.750701Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 306  (18.6):  87%|████████▋ | 305/350 [00:14<00:01, 23.31it/s]2024-10-12T23:16:47.130825Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 313  (18.8):  89%|████████▉ | 312/350 [00:14<00:01, 33.95it/s]2024-10-12T23:16:47.219973Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 316  (18.7):  90%|█████████ | 315/350 [00:14<00:01, 33.95it/s]198ename12T23:16:47.236111Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=\n",
      "Average Metric: 59.0 / 319  (18.5):  91%|█████████ | 318/350 [00:14<00:00, 33.95it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 61.0 / 324  (18.8):  92%|█████████▏| 323/350 [00:14<00:00, 47.84it/s]2024-10-12T23:16:47.302737Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 63.0 / 336  (18.8):  96%|█████████▌| 335/350 [00:14<00:00, 60.17it/s]2024-10-12T23:16:47.415138Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 63.0 / 350  (18.0): 100%|██████████| 350/350 [00:15<00:00, 22.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [18.57, 18.57, 29.14, 18.0]\n",
      "Best score so far: 29.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:01<00:48,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0):   0%|          | 1/350 [00:00<02:11,  2.66it/s]2024-10-12T23:16:50.843946Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 2  (50.0):   1%|          | 2/350 [00:01<03:07,  1.85it/s]2024-10-12T23:16:50.850644Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 5  (40.0):   1%|          | 4/350 [00:01<03:06,  1.85it/s]2024-10-12T23:16:50.859886Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 7  (42.9):   2%|▏         | 6/350 [00:01<03:05,  1.85it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 9  (44.4):   2%|▏         | 8/350 [00:01<00:35,  9.50it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 41  (29.3):  11%|█▏        | 40/350 [00:02<00:09, 32.58it/s] 024-10-12T23:16:52.391116Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 15.0 / 53  (28.3):  15%|█▍        | 52/350 [00:02<00:12, 23.62it/s]2024-10-12T23:16:52.827261Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 58  (27.6):  16%|█▋        | 57/350 [00:03<00:11, 25.66it/s]]024-10-12T23:16:53.194815Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 61  (27.9):  17%|█▋        | 60/350 [00:03<00:13, 21.06it/s]error    2T23:16:53.201884Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 64  (28.1):  18%|█▊        | 63/350 [00:03<00:14, 19.31it/s]2024-10-12T23:16:53.482778Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 72  (29.2):  20%|██        | 71/350 [00:03<00:13, 20.61it/s]2024-10-12T23:16:53.828719Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 30.0 / 96  (31.2):  27%|██▋       | 95/350 [00:04<00:11, 22.02it/s]2024-10-12T23:16:54.735421Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 115  (33.0):  33%|███▎      | 114/350 [00:05<00:10, 22.61it/s]2024-10-12T23:16:55.772914Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 123  (32.5):  35%|███▍      | 122/350 [00:06<00:13, 16.50it/s]2024-10-12T23:16:56.173914Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 173  (30.1):  49%|████▉     | 172/350 [00:08<00:06, 25.67it/s]2024-10-12T23:16:57.949051Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 174  (29.9):  49%|████▉     | 173/350 [00:08<00:06, 25.67it/s]2024-10-12T23:16:58.031133Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 181  (28.7):  51%|█████▏    | 180/350 [00:08<00:08, 20.58it/s]2024-10-12T23:16:58.355507Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 187  (28.9):  53%|█████▎    | 187/350 [00:09<00:08, 18.54it/s]2024-10-12T23:16:58.929590Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 199  (29.6):  57%|█████▋    | 198/350 [00:09<00:08, 17.27it/s]2024-10-12T23:16:59.569557Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 202  (29.2):  57%|█████▋    | 201/350 [00:09<00:08, 17.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 221  (29.0):  63%|██████▎   | 220/350 [00:10<00:06, 21.15it/s]dspy.evaluate.evaluate7433Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 230  (28.3):  65%|██████▌   | 229/350 [00:10<00:06, 19.07it/s]2024-10-12T23:17:00.836282Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 267  (30.3):  76%|███████▌  | 266/350 [00:12<00:04, 19.22it/s]2024-10-12T23:17:02.754203Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 82.0 / 269  (30.5):  77%|███████▋  | 268/350 [00:12<00:04, 19.22it/s] [24-10-12T23:17:02.806031Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 85.0 / 284  (29.9):  81%|████████  | 283/350 [00:13<00:02, 28.20it/s]2024-10-12T23:17:03.313109Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 286  (30.1):  82%|████████▏ | 286/350 [00:13<00:02, 23.38it/s]2024-10-12T23:17:03.558027Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 88.0 / 293  (30.0):  83%|████████▎ | 292/350 [00:14<00:02, 24.22it/s]2024-10-12T23:17:03.941573Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 105.0 / 344  (30.5):  98%|█████████▊| 343/350 [00:15<00:00, 49.10it/s]2024-10-12T23:17:04.936746Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 107.0 / 350  (30.6): 100%|██████████| 350/350 [00:15<00:00, 23.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 30.57 for seed 1\n",
      "Scores so far: [18.57, 18.57, 29.14, 18.0, 30.57]\n",
      "Best score so far: 30.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/150 [00:00<00:30,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 4  (50.0):   1%|          | 3/350 [00:00<05:23,  1.07it/s] 2024-10-12T23:17:07.041144Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 5  (40.0):   1%|▏         | 5/350 [00:01<01:00,  5.75it/s]2024-10-12T23:17:07.048364Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 31  (25.8):   9%|▊         | 30/350 [00:02<00:19, 16.28it/s]2024-10-12T23:17:08.090556Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 48  (25.0):  14%|█▎        | 48/350 [00:03<00:16, 18.60it/s]2024-10-12T23:17:08.986534Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 297  (25.3):  85%|████████▍ | 297/350 [00:14<00:02, 18.86it/s] 024-10-12T23:17:20.355681Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno=198\n",
      "Average Metric: 88.0 / 342  (25.7):  97%|█████████▋| 341/350 [00:15<00:00, 67.23it/s]2024-10-12T23:17:21.017471Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 88.0 / 348  (25.3):  99%|█████████▉| 348/350 [00:15<00:00, 58.07it/s]2024-10-12T23:17:21.911284Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 88.0 / 349  (25.2):  99%|█████████▉| 348/350 [00:15<00:00, 58.07it/s]2024-10-12T23:17:25.496423Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 88.0 / 350  (25.1): 100%|██████████| 350/350 [00:19<00:00, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [18.57, 18.57, 29.14, 18.0, 30.57, 25.14]\n",
      "Best score so far: 30.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:00<01:01,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:17:27.467099Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<04:48,  1.21it/s]2024-10-12T23:17:27.646488Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|          | 2/350 [00:01<02:36,  2.22it/s] [24-10-12T23:17:27.653699Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 2/350 [00:01<02:36,  2.22it/s]2024-10-12T23:17:27.678566Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 3/350 [00:01<02:36,  2.22it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   1%|          | 4/350 [00:01<02:35,  2.22it/s]2024-10-12T23:17:28.146686Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   2%|▏         | 6/350 [00:01<01:08,  5.04it/s]2024-10-12T23:17:28.427809Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   2%|▏         | 7/350 [00:01<01:14,  4.61it/s]2024-10-12T23:17:28.465722Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 9  (0.0):   2%|▏         | 8/350 [00:01<01:14,  4.61it/s]2024-10-12T23:17:28.489143Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 13  (7.7):   3%|▎         | 12/350 [00:02<00:45,  7.41it/s]2024-10-12T23:17:28.760608Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 20  (10.0):   5%|▌         | 19/350 [00:02<00:27, 12.17it/s]2024-10-12T23:17:29.158001Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 34  (14.7):   9%|▉         | 33/350 [00:02<00:14, 21.26it/s]2024-10-12T23:17:29.611604Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 40  (15.0):  11%|█         | 39/350 [00:03<00:15, 20.26it/s]2024-10-12T23:17:29.950762Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 45  (17.8):  13%|█▎        | 44/350 [00:03<00:18, 16.55it/s]2024-10-12T23:17:30.314973Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 52  (17.3):  15%|█▍        | 51/350 [00:04<00:12, 24.14it/s]2024-10-12T23:17:30.803765Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 53  (17.0):  15%|█▍        | 52/350 [00:04<00:12, 24.14it/s]2024-10-12T23:17:30.827483Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 54  (16.7):  15%|█▌        | 54/350 [00:04<00:17, 16.75it/s]2024-10-12T23:17:30.929062Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 56  (16.1):  16%|█▌        | 55/350 [00:04<00:17, 16.75it/s]2024-10-12T23:17:31.195845Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 57  (15.8):  16%|█▋        | 57/350 [00:04<00:21, 13.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 58  (15.5):  16%|█▋        | 57/350 [00:04<00:21, 13.62it/s]2024-10-12T23:17:31.295711Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 59  (15.3):  17%|█▋        | 58/350 [00:04<00:21, 13.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 64  (18.8):  18%|█▊        | 63/350 [00:05<00:28, 10.21it/s]2024-10-12T23:17:32.042534Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 69  (17.4):  19%|█▉        | 68/350 [00:05<00:27, 10.19it/s]2024-10-12T23:17:32.339933Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 78  (16.7):  22%|██▏       | 77/350 [00:06<00:22, 11.91it/s]2024-10-12T23:17:32.956219Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 81  (16.0):  23%|██▎       | 80/350 [00:06<00:18, 14.73it/s]2024-10-12T23:17:33.020250Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 83  (16.9):  24%|██▎       | 83/350 [00:06<00:15, 17.22it/s]2024-10-12T23:17:33.330472Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 90  (17.8):  25%|██▌       | 89/350 [00:07<00:20, 12.77it/s]evaluate.py23:17:33.659967Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename= lineno=198\n",
      "Average Metric: 20.0 / 102  (19.6):  29%|██▉       | 101/350 [00:07<00:21, 11.55it/s]2024-10-12T23:17:34.640536Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 104  (19.2):  30%|██▉       | 104/350 [00:08<00:17, 14.35it/s]2024-10-12T23:17:34.747158Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 109  (19.3):  31%|███       | 108/350 [00:08<00:20, 11.57it/s]2024-10-12T23:17:35.113656Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 110  (19.1):  31%|███       | 109/350 [00:08<00:20, 11.57it/s]2024-10-12T23:17:35.338513Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 113  (18.6):  32%|███▏      | 112/350 [00:08<00:17, 13.33it/s]2024-10-12T23:17:35.642909Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 114  (18.4):  33%|███▎      | 114/350 [00:09<00:19, 12.21it/s]2024-10-12T23:17:35.699942Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 116  (18.1):  33%|███▎      | 116/350 [00:09<00:19, 12.31it/s]2024-10-12T23:17:35.820962Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 121  (19.0):  35%|███▍      | 121/350 [00:09<00:17, 13.24it/s]2024-10-12T23:17:36.431817Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 123  (18.7):  35%|███▌      | 123/350 [00:09<00:20, 10.86it/s]=[error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 23.0 / 124  (18.5):  35%|███▌      | 123/350 [00:09<00:20, 10.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 126  (18.3):  36%|███▌      | 126/350 [00:09<00:17, 13.02it/s]2024-10-12T23:17:36.605041Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 134  (17.2):  38%|███▊      | 133/350 [00:10<00:19, 11.10it/s]evaluate.pyxample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 25.0 / 142  (17.6):  40%|████      | 141/350 [00:10<00:13, 15.41it/s]2024-10-12T23:17:38.155138Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 143  (17.5):  41%|████      | 143/350 [00:11<00:21,  9.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 147  (17.7):  42%|████▏     | 146/350 [00:11<00:18, 11.13it/s]2024-10-12T23:17:38.570113Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 149  (18.1):  42%|████▏     | 148/350 [00:11<00:19, 10.19it/s]2024-10-12T23:17:38.612189Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 151  (17.9):  43%|████▎     | 151/350 [00:12<00:16, 12.07it/s]2024-10-12T23:17:38.971575Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 154  (18.2):  44%|████▎     | 153/350 [00:12<00:19,  9.88it/s]dspy.evaluate.evaluate1052Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 30.0 / 163  (18.4):  46%|████▋     | 162/350 [00:12<00:15, 12.42it/s]1984-10-12T23:17:39.601616Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 30.0 / 165  (18.2):  47%|████▋     | 165/350 [00:13<00:12, 15.10it/s]2024-10-12T23:17:39.755552Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 30.0 / 166  (18.1):  47%|████▋     | 165/350 [00:13<00:12, 15.10it/s]2024-10-12T23:17:39.992505Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 30.0 / 172  (17.4):  49%|████▉     | 172/350 [00:13<00:14, 12.06it/s]filenamer example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 30.0 / 176  (17.0):  50%|█████     | 176/350 [00:13<00:11, 15.39it/s]2024-10-12T23:17:40.569885Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 30.0 / 177  (16.9):  50%|█████     | 176/350 [00:13<00:11, 15.39it/s]2024-10-12T23:17:40.573243Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 182  (18.1):  52%|█████▏    | 181/350 [00:14<00:11, 14.49it/s]2024-10-12T23:17:40.837142Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 185  (18.4):  53%|█████▎    | 184/350 [00:14<00:09, 18.42it/s] 024-10-12T23:17:40.945807Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.pylineno=198\n",
      "Average Metric: 34.0 / 188  (18.1):  53%|█████▎    | 187/350 [00:14<00:09, 16.84it/s]2024-10-12T23:17:41.391342Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 191  (17.8):  55%|█████▍    | 191/350 [00:15<00:13, 11.68it/s]2024-10-12T23:17:41.664590Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 193  (17.6):  55%|█████▍    | 192/350 [00:15<00:13, 11.68it/s]error    2T23:17:41.691221Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 194  (17.5):  55%|█████▌    | 193/350 [00:15<00:13, 11.68it/s]2024-10-12T23:17:41.936221Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 199  (18.1):  57%|█████▋    | 198/350 [00:15<00:11, 12.81it/s]2024-10-12T23:17:42.099394Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 37.0 / 204  (18.1):  58%|█████▊    | 204/350 [00:15<00:10, 14.50it/s]2024-10-12T23:17:42.693220Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 207  (18.4):  59%|█████▉    | 206/350 [00:16<00:11, 12.23it/s]2024-10-12T23:17:42.851881Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 39.0 / 214  (18.2):  61%|██████    | 213/350 [00:16<00:12, 11.02it/s]2024-10-12T23:17:43.258413Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 220  (19.1):  63%|██████▎   | 219/350 [00:16<00:10, 12.95it/s]2024-10-12T23:17:43.795150Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 224  (18.8):  64%|██████▎   | 223/350 [00:17<00:09, 13.14it/s]2024-10-12T23:17:43.988716Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 227  (18.5):  65%|██████▍   | 227/350 [00:17<00:09, 13.40it/s]2024-10-12T23:17:44.277706Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 229  (18.3):  65%|██████▌   | 228/350 [00:17<00:09, 13.40it/s]2024-10-12T23:17:44.313937Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 230  (18.3):  65%|██████▌   | 229/350 [00:17<00:09, 13.40it/s]2024-10-12T23:17:44.541079Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 233  (18.0):  66%|██████▋   | 232/350 [00:17<00:08, 13.59it/s]2024-10-12T23:17:44.620944Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 238  (17.6):  68%|██████▊   | 237/350 [00:18<00:09, 11.81it/s]filename12T23:17:44.998024Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 241  (17.4):  69%|██████▊   | 240/350 [00:18<00:09, 11.81it/s]2024-10-12T23:17:45.084360Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 242  (17.4):  69%|██████▉   | 242/350 [00:18<00:05, 18.66it/s]2024-10-12T23:17:45.348254Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 243  (17.3):  69%|██████▉   | 242/350 [00:18<00:05, 18.66it/s]2024-10-12T23:17:45.354983Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 246  (17.1):  70%|███████   | 245/350 [00:18<00:08, 12.89it/s]2024-10-12T23:17:45.612157Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 253  (17.4):  72%|███████▏  | 252/350 [00:19<00:06, 14.28it/s]2024-10-12T23:17:46.297866Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 254  (17.3):  73%|███████▎  | 254/350 [00:19<00:08, 11.46it/s]2024-10-12T23:17:46.352650Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 261  (16.9):  74%|███████▍  | 260/350 [00:20<00:08, 10.93it/s]2024-10-12T23:17:46.962050Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 266  (16.5):  76%|███████▌  | 265/350 [00:20<00:07, 11.98it/s]2024-10-12T23:17:47.060507Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 48.0 / 274  (17.5):  78%|███████▊  | 274/350 [00:20<00:04, 16.92it/s]2024-10-12T23:17:47.796952Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 49.0 / 276  (17.8):  79%|███████▉  | 276/350 [00:21<00:05, 13.33it/s]2024-10-12T23:17:47.838206Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 49.0 / 279  (17.6):  79%|███████▉  | 278/350 [00:21<00:05, 13.33it/s] [24-10-12T23:17:47.867603Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 283  (17.7):  81%|████████  | 282/350 [00:21<00:04, 14.57it/s]dspy.evaluate.evaluate8849Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 51.0 / 285  (17.9):  81%|████████  | 284/350 [00:21<00:04, 14.57it/s]2024-10-12T23:17:48.270295Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 51.0 / 286  (17.8):  82%|████████▏ | 286/350 [00:21<00:03, 18.23it/s]2024-10-12T23:17:48.499918Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 289  (18.0):  82%|████████▏ | 288/350 [00:21<00:03, 18.23it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 291  (18.2):  83%|████████▎ | 290/350 [00:21<00:03, 15.32it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 293  (18.4):  84%|████████▎ | 293/350 [00:22<00:03, 15.70it/s]2024-10-12T23:17:49.082037Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 295  (18.3):  84%|████████▍ | 295/350 [00:22<00:04, 12.52it/s]2024-10-12T23:17:49.111476Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 55.0 / 298  (18.5):  85%|████████▍ | 297/350 [00:22<00:04, 13.15it/s]2024-10-12T23:17:49.501858Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 300  (18.7):  85%|████████▌ | 299/350 [00:23<00:04, 11.16it/s]2024-10-12T23:17:49.738364Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 63.0 / 320  (19.7):  91%|█████████ | 319/350 [00:23<00:01, 29.53it/s]2024-10-12T23:17:50.202322Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 324  (20.1):  92%|█████████▏| 323/350 [00:23<00:00, 29.53it/s]2024-10-12T23:17:50.274120Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 67.0 / 336  (19.9):  96%|█████████▌| 335/350 [00:23<00:00, 38.21it/s]2024-10-12T23:17:50.419287Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 67.0 / 337  (19.9):  96%|█████████▋| 337/350 [00:23<00:00, 52.58it/s]2024-10-12T23:17:50.430962Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 69.0 / 350  (19.7): 100%|██████████| 350/350 [00:24<00:00, 14.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [18.57, 18.57, 29.14, 18.0, 30.57, 25.14, 19.71]\n",
      "Best score so far: 30.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/150 [00:00<00:47,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 1  (100.0):   0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:17:53.106334Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 2  (50.0):   1%|          | 2/350 [00:00<02:16,  2.56it/s]error    2T23:17:53.116640Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 4  (25.0):   1%|          | 3/350 [00:00<02:15,  2.56it/s]=024-10-12T23:17:53.123504Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 3.0 / 11  (27.3):   3%|▎         | 11/350 [00:01<00:29, 11.39it/s]=4-10-12T23:17:53.600111Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 7.0 / 37  (18.9):  10%|█         | 36/350 [00:01<00:11, 27.96it/s]2024-10-12T23:17:54.221709Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 10.0 / 47  (21.3):  13%|█▎        | 46/350 [00:02<00:10, 28.46it/s]filename2T23:17:54.593004Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 54  (20.4):  15%|█▌        | 53/350 [00:02<00:08, 34.34it/s]filename12T23:17:54.937888Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 55  (20.0):  15%|█▌        | 54/350 [00:02<00:08, 34.34it/s]2024-10-12T23:17:54.945878Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 56  (19.6):  16%|█▌        | 55/350 [00:02<00:08, 34.34it/s]2024-10-12T23:17:54.965234Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 57  (19.3):  16%|█▋        | 57/350 [00:02<00:11, 26.24it/s]2024-10-12T23:17:54.983543Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 60  (20.0):  17%|█▋        | 59/350 [00:02<00:11, 26.24it/s]2024-10-12T23:17:55.254714Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 62  (19.4):  17%|█▋        | 61/350 [00:02<00:13, 21.70it/s]2024-10-12T23:17:55.261951Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 63  (19.0):  18%|█▊        | 62/350 [00:02<00:13, 21.70it/s]2024-10-12T23:17:55.290329Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 91  (23.1):  26%|██▌       | 90/350 [00:04<00:12, 20.63it/s]2024-10-12T23:17:56.489028Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 107  (24.3):  31%|███       | 107/350 [00:04<00:07, 30.79it/s]=[24-10-12T23:17:56.996590Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 33.0 / 127  (26.0):  36%|███▋      | 127/350 [00:05<00:08, 26.30it/s]=024-10-12T23:17:57.847085Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 34.0 / 129  (26.4):  37%|███▋      | 128/350 [00:05<00:08, 26.30it/s]2024-10-12T23:17:57.851760Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 131  (26.0):  37%|███▋      | 130/350 [00:05<00:08, 26.30it/s]dspy.evaluate.evaluate example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 137  (24.8):  39%|███▉      | 136/350 [00:06<00:09, 22.95it/s]2024-10-12T23:17:58.466292Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 144  (24.3):  41%|████      | 143/350 [00:06<00:10, 19.24it/s]=024-10-12T23:17:58.778574Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 43.0 / 168  (25.6):  48%|████▊     | 167/350 [00:07<00:08, 22.53it/s]dspy.evaluate.evaluate7646Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 175  (26.3):  50%|████▉     | 174/350 [00:07<00:05, 29.79it/s]2024-10-12T23:18:00.032067Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 48.0 / 180  (26.7):  51%|█████▏    | 180/350 [00:07<00:08, 20.44it/s]2024-10-12T23:18:00.305033Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 196  (26.5):  56%|█████▌    | 195/350 [00:08<00:09, 16.22it/s]2024-10-12T23:18:01.100359Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 199  (26.1):  57%|█████▋    | 198/350 [00:08<00:07, 20.86it/s]evaluate.py] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] = lineno=198\n",
      "Average Metric: 55.0 / 212  (25.9):  60%|██████    | 211/350 [00:09<00:05, 23.30it/s] [24-10-12T23:18:01.618330Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 217  (25.8):  62%|██████▏   | 216/350 [00:09<00:05, 24.91it/s]2024-10-12T23:18:02.008419Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 231  (26.0):  66%|██████▌   | 230/350 [00:10<00:04, 28.74it/s]2024-10-12T23:18:02.437609Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 237  (25.3):  67%|██████▋   | 236/350 [00:10<00:05, 21.37it/s]2024-10-12T23:18:02.761552Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 245  (25.3):  70%|██████▉   | 244/350 [00:11<00:05, 20.31it/s]2024-10-12T23:18:03.372051Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 66.0 / 256  (25.8):  73%|███████▎  | 255/350 [00:11<00:03, 27.17it/s]2024-10-12T23:18:03.570950Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 68.0 / 271  (25.1):  77%|███████▋  | 270/350 [00:11<00:02, 32.08it/s]=024-10-12T23:18:04.227637Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 69.0 / 274  (25.2):  78%|███████▊  | 273/350 [00:11<00:03, 23.80it/s]filename   ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 70.0 / 279  (25.1):  79%|███████▉  | 278/350 [00:12<00:03, 23.80it/s]=024-10-12T23:18:04.316690Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 70.0 / 282  (24.8):  80%|████████  | 281/350 [00:12<00:02, 29.72it/s] [24-10-12T23:18:04.335230Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 70.0 / 285  (24.6):  81%|████████▏ | 285/350 [00:12<00:02, 23.16it/s]lineno0-12T23:18:04.762869Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 70.0 / 288  (24.3):  82%|████████▏ | 287/350 [00:12<00:02, 23.16it/s]2024-10-12T23:18:04.786651Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 319  (25.4):  91%|█████████ | 318/350 [00:13<00:01, 21.43it/s]2024-10-12T23:18:06.002688Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 89.0 / 349  (25.5):  99%|█████████▉| 348/350 [00:14<00:00, 62.24it/s]2024-10-12T23:18:10.653247Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 89.0 / 350  (25.4): 100%|██████████| 350/350 [00:18<00:00, 19.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [18.57, 18.57, 29.14, 18.0, 30.57, 25.14, 19.71, 25.43]\n",
      "Best score so far: 30.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 23/150 [00:06<00:35,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 24 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:18:18.459278Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<05:00,  1.16it/s] ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/350 [00:00<05:00,  1.16it/s]2024-10-12T23:18:18.488386Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 2/350 [00:00<04:59,  1.16it/s]2024-10-12T23:18:18.508052Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 3/350 [00:00<04:59,  1.16it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   1%|▏         | 5/350 [00:00<00:52,  6.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   1%|▏         | 5/350 [00:00<00:52,  6.62it/s]2024-10-12T23:18:18.544530Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   2%|▏         | 6/350 [00:01<00:51,  6.62it/s]2024-10-12T23:18:18.569776Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   2%|▏         | 7/350 [00:01<00:51,  6.62it/s]2024-10-12T23:18:18.909808Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 9  (0.0):   3%|▎         | 9/350 [00:01<00:38,  8.89it/s]2024-10-12T23:18:18.961331Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 10  (0.0):   3%|▎         | 9/350 [00:01<00:38,  8.89it/s]2024-10-12T23:18:19.062752Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 53  (30.2):  15%|█▍        | 52/350 [00:03<00:17, 17.33it/s]] 24-10-12T23:18:20.948528Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 56  (28.6):  16%|█▌        | 55/350 [00:03<00:14, 20.38it/s]2024-10-12T23:18:21.045907Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 58  (27.6):  16%|█▋        | 57/350 [00:03<00:14, 20.38it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 59  (27.1):  17%|█▋        | 59/350 [00:03<00:11, 25.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 61  (26.2):  17%|█▋        | 60/350 [00:03<00:11, 25.03it/s]2024-10-12T23:18:21.144316Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 62  (25.8):  17%|█▋        | 61/350 [00:03<00:11, 25.03it/s]2024-10-12T23:18:21.148946Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 63  (25.4):  18%|█▊        | 62/350 [00:03<00:11, 25.03it/s]2024-10-12T23:18:21.267497Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 69  (23.2):  19%|█▉        | 68/350 [00:04<00:17, 15.82it/s]2024-10-12T23:18:21.845427Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 80  (28.8):  23%|██▎       | 80/350 [00:04<00:12, 20.91it/s] [24-10-12T23:18:22.330538Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 86  (29.1):  24%|██▍       | 85/350 [00:05<00:15, 17.29it/s]1984-10-12T23:18:22.683493Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=\n",
      "Average Metric: 26.0 / 90  (28.9):  26%|██▌       | 90/350 [00:05<00:11, 22.39it/s]error    2T23:18:22.687539Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 96  (29.2):  27%|██▋       | 96/350 [00:05<00:11, 21.59it/s]2024-10-12T23:18:23.121698Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 106  (32.1):  30%|███       | 105/350 [00:05<00:12, 19.33it/s]2024-10-12T23:18:23.546777Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 109  (32.1):  31%|███       | 108/350 [00:05<00:12, 19.33it/s]2024-10-12T23:18:23.625965Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 116  (31.0):  33%|███▎      | 115/350 [00:06<00:11, 20.20it/s] 024-10-12T23:18:23.947454Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 38.0 / 124  (30.6):  35%|███▌      | 124/350 [00:06<00:10, 21.57it/s]2024-10-12T23:18:24.367761Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 127  (29.9):  36%|███▌      | 126/350 [00:06<00:10, 21.57it/s]dspy.evaluate.evaluate3018Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 130  (29.2):  37%|███▋      | 129/350 [00:06<00:09, 24.25it/s] 024-10-12T23:18:24.472203Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 132  (28.8):  37%|███▋      | 131/350 [00:06<00:09, 24.25it/s]=[error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 42.0 / 151  (27.8):  43%|████▎     | 151/350 [00:07<00:07, 26.82it/s]2024-10-12T23:18:25.389659Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 152  (27.6):  43%|████▎     | 151/350 [00:07<00:07, 26.82it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 45.0 / 162  (27.8):  46%|████▌     | 161/350 [00:08<00:07, 24.68it/s]2024-10-12T23:18:26.156513Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 48.0 / 179  (26.8):  51%|█████     | 178/350 [00:09<00:07, 22.05it/s]1984-10-12T23:18:26.673947Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 48.0 / 181  (26.5):  51%|█████▏    | 180/350 [00:09<00:06, 24.89it/s]2024-10-12T23:18:26.748624Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 49.0 / 185  (26.5):  53%|█████▎    | 184/350 [00:09<00:05, 29.05it/s]2024-10-12T23:18:27.059037Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 188  (26.6):  53%|█████▎    | 187/350 [00:09<00:05, 29.05it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 51.0 / 192  (26.6):  55%|█████▍    | 192/350 [00:09<00:06, 24.18it/s]2024-10-12T23:18:27.258575Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 205  (27.3):  58%|█████▊    | 204/350 [00:10<00:08, 16.92it/s]2024-10-12T23:18:27.997143Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 208  (26.9):  59%|█████▉    | 208/350 [00:10<00:06, 23.65it/s]2024-10-12T23:18:28.094641Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 219  (26.0):  62%|██████▏   | 218/350 [00:11<00:05, 25.13it/s]1984-10-12T23:18:28.783956Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 58.0 / 225  (25.8):  64%|██████▍   | 224/350 [00:11<00:06, 18.05it/s]198or    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=\n",
      "Average Metric: 59.0 / 232  (25.4):  66%|██████▌   | 231/350 [00:11<00:04, 25.31it/s]2024-10-12T23:18:29.111796Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 66.0 / 244  (27.0):  69%|██████▉   | 243/350 [00:12<00:06, 17.55it/s]filename12T23:18:29.835809Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 69.0 / 257  (26.8):  73%|███████▎  | 256/350 [00:13<00:04, 20.46it/s]1984-10-12T23:18:30.613633Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 72.0 / 267  (27.0):  76%|███████▌  | 266/350 [00:13<00:03, 22.78it/s]2024-10-12T23:18:30.861697Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 73.0 / 274  (26.6):  78%|███████▊  | 273/350 [00:13<00:03, 19.52it/s]=ineno0-12T23:18:31.198020Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py 198\n",
      "Average Metric: 76.0 / 284  (26.8):  81%|████████  | 284/350 [00:14<00:03, 21.62it/s]2024-10-12T23:18:31.637514Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 76.0 / 285  (26.7):  81%|████████  | 284/350 [00:14<00:03, 21.62it/s]2024-10-12T23:18:31.682623Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 292  (27.1):  83%|████████▎ | 291/350 [00:14<00:03, 19.32it/s]]024-10-12T23:18:31.977997Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 294  (27.2):  84%|████████▎ | 293/350 [00:14<00:02, 22.25it/s]2024-10-12T23:18:32.071599Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 87.0 / 318  (27.4):  91%|█████████ | 318/350 [00:15<00:00, 38.09it/s]=024-10-12T23:18:32.782274Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 99.0 / 350  (28.3): 100%|██████████| 350/350 [00:15<00:00, 22.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [18.57, 18.57, 29.14, 18.0, 30.57, 25.14, 19.71, 25.43, 28.29]\n",
      "Best score so far: 30.57\n",
      "9 candidate programs found.\n",
      "[('intent_classifier', Predict(StringSignature(intent -> reasoning, label\n",
      "    instructions=\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\\nThe intent should exactly match one of the following:\\n['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\"\n",
      "    intent = Field(annotation=str required=True json_schema_extra={'desc': 'Intent of the query', '__dspy_field_type': 'input', 'prefix': 'Intent:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the output fields}. We ...', '__dspy_field_type': 'output'})\n",
      "    label = Field(annotation=str required=True json_schema_extra={'desc': 'Type of the intent; Should just be one of the 25 labels with no other text', '__dspy_field_type': 'output', 'prefix': 'Label:'})\n",
      ")))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]2024-10-12T23:18:34.300930Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/500 [00:00<08:13,  1.01it/s]   ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/500 [00:01<08:13,  1.01it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   0%|          | 2/500 [00:01<08:12,  1.01it/s]2024-10-12T23:18:34.332228Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 3/500 [00:01<08:11,  1.01it/s]2024-10-12T23:18:34.360737Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 50  (18.0):  10%|▉         | 49/500 [00:02<00:13, 33.03it/s]2024-10-12T23:18:36.178125Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 52  (17.3):  10%|█         | 51/500 [00:02<00:13, 33.03it/s]2024-10-12T23:18:36.187234Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 144  (32.6):  29%|██▊       | 143/500 [00:06<00:14, 24.44it/s]2024-10-12T23:18:40.190085Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 49.0 / 151  (32.5):  30%|███       | 150/500 [00:07<00:15, 22.19it/s]=024-10-12T23:18:40.514993Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 50.0 / 160  (31.2):  32%|███▏      | 159/500 [00:07<00:16, 21.20it/s]2024-10-12T23:18:40.906785Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 167  (29.9):  33%|███▎      | 166/500 [00:07<00:11, 28.21it/s]dspy.evaluate.evaluate1046Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 173  (28.9):  34%|███▍      | 172/500 [00:08<00:13, 23.61it/s] 024-10-12T23:18:41.365701Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 50.0 / 179  (27.9):  36%|███▌      | 178/500 [00:08<00:15, 21.43it/s]=024-10-12T23:18:41.707709Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 51.0 / 183  (27.9):  36%|███▋      | 182/500 [00:08<00:14, 21.43it/s]1984-10-12T23:18:41.725612Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 64.0 / 224  (28.6):  45%|████▍     | 223/500 [00:10<00:14, 19.77it/s]2024-10-12T23:18:43.991817Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 70.0 / 238  (29.4):  47%|████▋     | 237/500 [00:11<00:20, 13.07it/s] [24-10-12T23:18:44.721271Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 72.0 / 244  (29.5):  49%|████▊     | 243/500 [00:11<00:14, 17.81it/s]=rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 79.0 / 263  (30.0):  53%|█████▎    | 263/500 [00:12<00:11, 19.90it/s]1984-10-12T23:18:45.863309Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 82.0 / 271  (30.3):  54%|█████▍    | 270/500 [00:12<00:13, 17.23it/s]=024-10-12T23:18:46.247874Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 82.0 / 274  (29.9):  55%|█████▍    | 273/500 [00:13<00:12, 18.02it/s] ilename12T23:18:46.495608Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.pylineno=198\n",
      "Average Metric: 85.0 / 283  (30.0):  57%|█████▋    | 283/500 [00:13<00:11, 19.02it/s]2024-10-12T23:18:46.921007Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 90.0 / 302  (29.8):  60%|██████    | 301/500 [00:14<00:08, 22.34it/s]2024-10-12T23:18:47.581380Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 96.0 / 323  (29.7):  64%|██████▍   | 322/500 [00:15<00:07, 25.17it/s]2024-10-12T23:18:48.745943Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 120.0 / 387  (31.0):  77%|███████▋  | 386/500 [00:18<00:03, 28.55it/s]2024-10-12T23:18:51.624195Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 125.0 / 417  (30.0):  83%|████████▎ | 417/500 [00:19<00:04, 18.40it/s]]024-10-12T23:18:53.145431Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 130.0 / 427  (30.4):  85%|████████▌ | 426/500 [00:20<00:04, 15.69it/s]=024-10-12T23:18:53.707362Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 138.0 / 450  (30.7):  90%|████████▉ | 449/500 [00:21<00:02, 22.16it/s]2024-10-12T23:18:54.557485Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 139.0 / 461  (30.2):  92%|█████████▏| 460/500 [00:21<00:01, 24.96it/s]2024-10-12T23:18:54.859626Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 152.0 / 500  (30.4): 100%|██████████| 500/500 [00:21<00:00, 22.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for meta-llama/Llama-3.2-1B-Instruct:epochs-0-total-trained-steps-29: 30.4, None, None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3 / 63  (4.8):  12%|█▏        | 62/500 [00:07<00:39, 10.95it/s]] 24-10-12T23:19:02.793908Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 69.0 / 500  (13.8): 100%|██████████| 500/500 [00:32<00:00, 15.34it/s]\n",
      "Average Metric: 44 / 278  (15.8):  79%|███████▉  | 277/350 [00:19<00:05, 12.66it/s]2024-10-12T23:19:47.683723Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 350  (16.3): 100%|██████████| 350/350 [00:21<00:00, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 16.29 for seed -3\n",
      "Scores so far: [16.29]\n",
      "Best score so far: 16.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 7  (14.3):   2%|▏         | 6/350 [00:00<00:00, 576.77it/s]198.evaluate.evaluate\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filenameevaluate.py lineno=\n",
      "Average Metric: 57.0 / 350  (16.3): 100%|██████████| 350/350 [00:00<00:00, 1158.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [16.29, 16.29]\n",
      "Best score so far: 16.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 10/150 [00:04<01:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:19:56.423622Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:01<06:03,  1.04s/it]2024-10-12T23:19:56.628159Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|          | 2/350 [00:01<03:11,  1.81it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 50  (42.0):  14%|█▍        | 49/350 [00:03<00:15, 19.05it/s]2024-10-12T23:19:59.136655Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 54  (38.9):  15%|█▌        | 53/350 [00:04<00:17, 16.51it/s]2024-10-12T23:19:59.752024Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 56  (37.5):  16%|█▌        | 55/350 [00:04<00:20, 14.08it/s]2024-10-12T23:19:59.805622Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 60  (36.7):  17%|█▋        | 59/350 [00:04<00:21, 13.43it/s]]024-10-12T23:20:00.037923Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 37.0 / 105  (35.2):  30%|███       | 105/350 [00:07<00:20, 12.18it/s]2024-10-12T23:20:03.069102Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 140  (35.7):  40%|███▉      | 139/350 [00:09<00:09, 22.72it/s]2024-10-12T23:20:04.724643Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 195  (36.4):  55%|█████▌    | 194/350 [00:12<00:07, 22.21it/s]2024-10-12T23:20:07.988643Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 76.0 / 204  (37.3):  58%|█████▊    | 203/350 [00:12<00:04, 32.09it/s]2024-10-12T23:20:08.246219Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 76.0 / 210  (36.2):  60%|█████▉    | 209/350 [00:13<00:05, 23.74it/s]2024-10-12T23:20:08.895353Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 217  (36.4):  62%|██████▏   | 216/350 [00:13<00:06, 19.18it/s] 024-10-12T23:20:09.304587Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 84.0 / 226  (37.2):  64%|██████▍   | 225/350 [00:14<00:05, 21.99it/s]2024-10-12T23:20:09.742448Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 231  (37.2):  66%|██████▌   | 231/350 [00:14<00:07, 15.27it/s]2024-10-12T23:20:10.330747Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 103.0 / 274  (37.6):  78%|███████▊  | 273/350 [00:17<00:03, 23.04it/s]2024-10-12T23:20:12.509534Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 107.0 / 283  (37.8):  81%|████████  | 282/350 [00:17<00:04, 15.60it/s]2024-10-12T23:20:13.240731Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 128.0 / 329  (38.9):  94%|█████████▎| 328/350 [00:19<00:00, 38.37it/s]2024-10-12T23:20:15.151734Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 136.0 / 350  (38.9): 100%|██████████| 350/350 [00:20<00:00, 17.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 38.86 for seed -1\n",
      "Scores so far: [16.29, 16.29, 38.86]\n",
      "Best score so far: 38.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 8/150 [00:03<01:07,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:20:20.664812Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:01<06:39,  1.14s/it]2024-10-12T23:20:20.885909Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 42  (50.0):  12%|█▏        | 41/350 [00:03<00:16, 18.44it/s]=024-10-12T23:20:22.825515Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 24.0 / 53  (45.3):  15%|█▍        | 52/350 [00:03<00:10, 29.67it/s]2024-10-12T23:20:23.366873Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 58  (44.8):  16%|█▋        | 57/350 [00:04<00:19, 14.73it/s]2024-10-12T23:20:23.833476Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 72.0 / 191  (37.7):  54%|█████▍    | 190/350 [00:12<00:10, 15.17it/s]2024-10-12T23:20:31.931448Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 73.0 / 194  (37.6):  55%|█████▌    | 193/350 [00:12<00:12, 12.83it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 102.0 / 256  (39.8):  73%|███████▎  | 255/350 [00:16<00:06, 13.59it/s]2024-10-12T23:20:35.984386Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 109.0 / 285  (38.2):  81%|████████  | 284/350 [00:18<00:03, 17.36it/s]2024-10-12T23:20:37.652448Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 136.0 / 350  (38.9): 100%|██████████| 350/350 [00:20<00:00, 17.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [16.29, 16.29, 38.86, 38.86]\n",
      "Best score so far: 38.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/150 [00:01<00:48,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 2  (0.0):   1%|          | 2/350 [00:01<02:58,  1.95it/s]2024-10-12T23:20:43.278162Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 3/350 [00:01<02:22,  2.43it/s]2024-10-12T23:20:43.321979Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 53  (37.7):  15%|█▍        | 52/350 [00:03<00:16, 18.18it/s]2024-10-12T23:20:45.967071Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 55  (36.4):  15%|█▌        | 54/350 [00:04<00:16, 18.18it/s]2024-10-12T23:20:46.259754Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 56  (35.7):  16%|█▌        | 56/350 [00:04<00:20, 14.29it/s] [24-10-12T23:20:46.267007Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 45.0 / 121  (37.2):  34%|███▍      | 120/350 [00:08<00:17, 12.93it/s]dspy.evaluate.evaluate9309Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 104.0 / 256  (40.6):  73%|███████▎  | 255/350 [00:17<00:08, 10.96it/s]2024-10-12T23:20:59.358202Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 118.0 / 285  (41.4):  81%|████████  | 284/350 [00:19<00:05, 13.00it/s]2024-10-12T23:21:01.480599Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 133.0 / 324  (41.0):  92%|█████████▏| 323/350 [00:20<00:00, 38.33it/s]=024-10-12T23:21:02.259365Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 143.0 / 349  (41.0):  99%|█████████▉| 348/350 [00:20<00:00, 56.73it/s]2024-10-12T23:21:02.742870Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 143.0 / 350  (40.9): 100%|██████████| 350/350 [00:20<00:00, 16.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 40.86 for seed 1\n",
      "Scores so far: [16.29, 16.29, 38.86, 38.86, 40.86]\n",
      "Best score so far: 40.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6/150 [00:02<00:49,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 17 / 50  (34.0):  14%|█▍        | 49/350 [00:03<00:11, 25.49it/s]2024-10-12T23:21:08.888456Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 96.0 / 252  (38.1):  72%|███████▏  | 251/350 [00:16<00:07, 12.78it/s]2024-10-12T23:21:21.256605Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 109.0 / 287  (38.0):  82%|████████▏ | 287/350 [00:18<00:03, 16.42it/s]2024-10-12T23:21:23.673222Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 136.0 / 350  (38.9): 100%|██████████| 350/350 [00:20<00:00, 17.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [16.29, 16.29, 38.86, 38.86, 40.86, 38.86]\n",
      "Best score so far: 40.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:00<01:04,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:21:27.865564Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 52  (34.6):  15%|█▍        | 52/350 [00:04<00:24, 12.40it/s]2024-10-12T23:21:30.937270Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 121.0 / 301  (40.2):  86%|████████▌ | 300/350 [00:17<00:02, 23.44it/s]2024-10-12T23:21:44.312267Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 136.0 / 350  (38.9): 100%|██████████| 350/350 [00:18<00:00, 18.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [16.29, 16.29, 38.86, 38.86, 40.86, 38.86, 38.86]\n",
      "Best score so far: 40.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:01<00:52,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:21:47.801716Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<05:06,  1.14it/s]]  Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 46  (23.9):  13%|█▎        | 45/350 [00:02<00:10, 28.17it/s]2024-10-12T23:21:49.871264Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 48  (22.9):  13%|█▎        | 47/350 [00:02<00:10, 28.17it/s]error    2T23:21:49.876215Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 50  (24.0):  14%|█▍        | 49/350 [00:03<00:14, 20.78it/s]2024-10-12T23:21:50.244398Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 93  (33.3):  26%|██▋       | 92/350 [00:05<00:11, 23.34it/s]2024-10-12T23:21:52.384640Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 149  (33.6):  42%|████▏     | 148/350 [00:08<00:07, 27.58it/s]2024-10-12T23:21:55.752623Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 68.0 / 199  (34.2):  57%|█████▋    | 199/350 [00:11<00:08, 18.71it/s]2024-10-12T23:21:58.738923Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 69.0 / 207  (33.3):  59%|█████▉    | 206/350 [00:12<00:13, 11.00it/s] 024-10-12T23:21:59.792455Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 252  (32.1):  72%|███████▏  | 251/350 [00:14<00:04, 22.05it/s]2024-10-12T23:22:01.357302Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 255  (31.8):  73%|███████▎  | 255/350 [00:14<00:04, 19.36it/s]2024-10-12T23:22:01.823969Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 102.0 / 309  (33.0):  88%|████████▊ | 308/350 [00:17<00:02, 17.72it/s]2024-10-12T23:22:04.155536Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 104.0 / 315  (33.0):  90%|████████▉ | 314/350 [00:17<00:02, 17.72it/s]2024-10-12T23:22:04.253111Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 110.0 / 350  (31.4): 100%|██████████| 350/350 [00:17<00:00, 19.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [16.29, 16.29, 38.86, 38.86, 40.86, 38.86, 38.86, 31.43]\n",
      "Best score so far: 40.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:00<01:03,  2.33it/s]2024-10-12T23:22:05.840114Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_card_payment', 'text': \"Why hasn't payment gone through yet?\", 'answer': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 13%|█▎        | 20/150 [00:07<00:51,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 21 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:22:13.950695Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<05:39,  1.03it/s]2024-10-12T23:22:14.118542Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|          | 2/350 [00:01<02:53,  2.01it/s]2024-10-12T23:22:14.334499Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 3/350 [00:01<02:07,  2.71it/s]2024-10-12T23:22:14.545902Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 8  (37.5):   2%|▏         | 7/350 [00:01<01:45,  3.26it/s]2024-10-12T23:22:14.662251Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 32  (37.5):   9%|▉         | 31/350 [00:02<00:11, 28.99it/s]2024-10-12T23:22:15.393174Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 50  (34.0):  14%|█▍        | 49/350 [00:03<00:12, 23.51it/s]2024-10-12T23:22:16.264097Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 51  (33.3):  14%|█▍        | 50/350 [00:03<00:12, 23.51it/s]2024-10-12T23:22:16.504900Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 52  (32.7):  15%|█▍        | 51/350 [00:03<00:12, 23.51it/s]2024-10-12T23:22:16.533524Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 53  (32.1):  15%|█▌        | 53/350 [00:03<00:15, 19.22it/s]2024-10-12T23:22:16.562321Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 56  (32.1):  16%|█▌        | 56/350 [00:03<00:18, 15.57it/s]lineno0-12T23:22:16.863222Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 18.0 / 57  (31.6):  16%|█▌        | 56/350 [00:03<00:18, 15.57it/s]2024-10-12T23:22:16.890656Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 58  (31.0):  16%|█▋        | 57/350 [00:03<00:18, 15.57it/s]2024-10-12T23:22:16.902236Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 99  (36.4):  28%|██▊       | 99/350 [00:06<00:13, 19.12it/s]2024-10-12T23:22:19.058928Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 100  (36.0):  28%|██▊       | 99/350 [00:06<00:13, 19.12it/s]2024-10-12T23:22:19.311638Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 103  (35.0):  29%|██▉       | 102/350 [00:06<00:15, 15.98it/s]2024-10-12T23:22:19.462470Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 117  (35.9):  33%|███▎      | 116/350 [00:07<00:16, 14.20it/s]2024-10-12T23:22:20.363284Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 45.0 / 132  (34.1):  37%|███▋      | 131/350 [00:08<00:12, 17.11it/s]2024-10-12T23:22:21.151195Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 148  (35.1):  42%|████▏     | 147/350 [00:08<00:09, 22.25it/s]2024-10-12T23:22:21.662749Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 55.0 / 155  (35.5):  44%|████▍     | 154/350 [00:09<00:12, 15.24it/s]2024-10-12T23:22:22.330085Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 161  (34.8):  46%|████▌     | 161/350 [00:09<00:14, 13.19it/s]2024-10-12T23:22:22.979633Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 67.0 / 185  (36.2):  53%|█████▎    | 184/350 [00:11<00:08, 20.46it/s]2024-10-12T23:22:24.406272Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 70.0 / 193  (36.3):  55%|█████▍    | 192/350 [00:11<00:10, 15.05it/s]2024-10-12T23:22:24.809384Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 72.0 / 203  (35.5):  58%|█████▊    | 202/350 [00:12<00:06, 24.43it/s]2024-10-12T23:22:25.325134Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 208  (35.6):  59%|█████▉    | 208/350 [00:12<00:07, 19.70it/s]2024-10-12T23:22:25.522861Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 211  (35.1):  60%|██████    | 211/350 [00:12<00:08, 17.35it/s]2024-10-12T23:22:25.770338Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 215  (34.9):  61%|██████    | 214/350 [00:13<00:09, 15.03it/s]evaluate.py23:22:26.019368Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 75.0 / 217  (34.6):  62%|██████▏   | 217/350 [00:13<00:07, 16.76it/s]2024-10-12T23:22:26.171934Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 240  (33.8):  68%|██████▊   | 239/350 [00:14<00:05, 19.82it/s]2024-10-12T23:22:27.571606Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 82.0 / 244  (33.6):  69%|██████▉   | 243/350 [00:14<00:06, 16.66it/s]2024-10-12T23:22:27.603598Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 252  (34.1):  72%|███████▏  | 251/350 [00:15<00:05, 16.84it/s]2024-10-12T23:22:28.072657Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 87.0 / 254  (34.3):  72%|███████▏  | 253/350 [00:15<00:05, 16.84it/s]2024-10-12T23:22:28.157014Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 90.0 / 260  (34.6):  74%|███████▍  | 260/350 [00:15<00:04, 19.17it/s] [24-10-12T23:22:28.472012Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 93.0 / 272  (34.2):  77%|███████▋  | 271/350 [00:15<00:03, 20.19it/s]2024-10-12T23:22:29.158730Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 97.0 / 278  (34.9):  79%|███████▉  | 277/350 [00:16<00:05, 12.33it/s]=[24-10-12T23:22:29.659421Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 97.0 / 279  (34.8):  79%|███████▉  | 278/350 [00:16<00:05, 12.33it/s]2024-10-12T23:22:29.664989Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 110.0 / 311  (35.4):  89%|████████▊ | 310/350 [00:18<00:01, 24.62it/s]=024-10-12T23:22:31.364583Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 120.0 / 335  (35.8):  95%|█████████▌| 334/350 [00:18<00:00, 45.23it/s]2024-10-12T23:22:31.661310Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 124.0 / 350  (35.4): 100%|██████████| 350/350 [00:18<00:00, 18.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [16.29, 16.29, 38.86, 38.86, 40.86, 38.86, 38.86, 31.43, 35.43]\n",
      "Best score so far: 40.86\n",
      "9 candidate programs found.\n",
      "[('intent_classifier', Predict(StringSignature(intent -> reasoning, label\n",
      "    instructions=\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\\nThe intent should exactly match one of the following:\\n['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\"\n",
      "    intent = Field(annotation=str required=True json_schema_extra={'desc': 'Intent of the query', '__dspy_field_type': 'input', 'prefix': 'Intent:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the output fields}. We ...', '__dspy_field_type': 'output'})\n",
      "    label = Field(annotation=str required=True json_schema_extra={'desc': 'Type of the intent; Should just be one of the 25 labels with no other text', '__dspy_field_type': 'output', 'prefix': 'Label:'})\n",
      ")))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]2024-10-12T23:22:33.032335Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 147  (40.8):  29%|██▉       | 146/500 [00:09<00:17, 19.81it/s]2024-10-12T23:22:41.655128Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 157  (39.5):  31%|███▏      | 157/500 [00:10<00:25, 13.28it/s]2024-10-12T23:22:42.507900Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 193  (38.9):  38%|███▊      | 192/500 [00:12<00:19, 15.84it/s]2024-10-12T23:22:44.456094Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 100.0 / 263  (38.0):  52%|█████▏    | 262/500 [00:17<00:20, 11.88it/s]2024-10-12T23:22:49.443660Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 164.0 / 437  (37.5):  87%|████████▋ | 437/500 [00:28<00:03, 17.05it/s]2024-10-12T23:23:00.995662Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 191.0 / 500  (38.2): 100%|██████████| 500/500 [00:30<00:00, 16.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for meta-llama/Llama-3.2-1B-Instruct:epochs-3-total-trained-steps-116: 38.2, None, None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 70 / 500  (14.0): 100%|██████████| 500/500 [00:33<00:00, 15.05it/s]\n",
      "Average Metric: 56 / 349  (16.0):  99%|█████████▉| 348/350 [00:20<00:00, 60.60it/s]2024-10-12T23:24:01.769929Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 350  (16.0): 100%|██████████| 350/350 [00:24<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 16.0 for seed -3\n",
      "Scores so far: [16.0]\n",
      "Best score so far: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 4  (25.0):   1%|          | 3/350 [00:00<00:00, 685.53it/s]ed ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 56.0 / 350  (16.0): 100%|██████████| 350/350 [00:00<00:00, 1177.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [16.0, 16.0]\n",
      "Best score so far: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 10/150 [00:04<00:59,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:24:08.094341Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:01<07:29,  1.29s/it]   ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/350 [00:01<07:29,  1.29s/it]2024-10-12T23:24:08.243825Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 50  (40.0):  14%|█▍        | 50/350 [00:03<00:16, 18.39it/s]2024-10-12T23:24:10.720237Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 53  (37.7):  15%|█▌        | 53/350 [00:04<00:21, 13.74it/s]2024-10-12T23:24:11.335059Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 55  (38.2):  15%|█▌        | 54/350 [00:04<00:21, 13.74it/s]2024-10-12T23:24:11.364733Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 126  (41.3):  36%|███▌      | 125/350 [00:08<00:11, 19.11it/s]2024-10-12T23:24:15.123999Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 140  (40.0):  40%|███▉      | 139/350 [00:09<00:12, 17.32it/s]2024-10-12T23:24:16.142314Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 77.0 / 186  (41.4):  53%|█████▎    | 185/350 [00:11<00:07, 22.62it/s]]024-10-12T23:24:18.699048Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 82.0 / 201  (40.8):  57%|█████▋    | 200/350 [00:12<00:09, 15.39it/s]2024-10-12T23:24:20.022005Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 82.0 / 203  (40.4):  58%|█████▊    | 202/350 [00:13<00:11, 13.27it/s]2024-10-12T23:24:20.039686Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 83.0 / 212  (39.2):  60%|██████    | 211/350 [00:13<00:08, 15.86it/s]2024-10-12T23:24:20.454675Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 83.0 / 213  (39.0):  61%|██████    | 212/350 [00:13<00:08, 15.86it/s]2024-10-12T23:24:20.522574Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 105.0 / 252  (41.7):  72%|███████▏  | 251/350 [00:16<00:08, 11.24it/s]2024-10-12T23:24:22.983824Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 120.0 / 286  (42.0):  81%|████████▏ | 285/350 [00:18<00:03, 17.95it/s]2024-10-12T23:24:25.223234Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 140.0 / 327  (42.8):  93%|█████████▎| 327/350 [00:19<00:00, 45.66it/s]2024-10-12T23:24:26.486509Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 149.0 / 350  (42.6): 100%|██████████| 350/350 [00:19<00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 42.57 for seed -1\n",
      "Scores so far: [16.0, 16.0, 42.57]\n",
      "Best score so far: 42.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 9/150 [00:04<01:07,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:24:32.536312Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 49  (46.9):  14%|█▎        | 48/350 [00:03<00:12, 24.45it/s]2024-10-12T23:24:35.040559Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 51  (45.1):  14%|█▍        | 50/350 [00:03<00:19, 15.52it/s]2024-10-12T23:24:35.098439Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 52  (44.2):  15%|█▍        | 51/350 [00:03<00:19, 15.52it/s]2024-10-12T23:24:35.100758Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 83.0 / 198  (41.9):  56%|█████▋    | 197/350 [00:11<00:08, 18.67it/s] [24-10-12T23:24:42.763360Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 90.0 / 212  (42.5):  60%|██████    | 211/350 [00:11<00:07, 18.53it/s]2024-10-12T23:24:43.644184Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 111.0 / 261  (42.5):  75%|███████▍  | 261/350 [00:14<00:04, 21.16it/s]1984-10-12T23:24:46.253123Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 126.0 / 299  (42.1):  85%|████████▌ | 298/350 [00:16<00:03, 15.92it/s]filenameluate.evaluate2105Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] =evaluate.py lineno=198\n",
      "Average Metric: 149.0 / 350  (42.6): 100%|██████████| 350/350 [00:17<00:00, 19.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [16.0, 16.0, 42.57, 42.57]\n",
      "Best score so far: 42.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 5/150 [00:01<00:46,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:24:52.108117Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 53  (43.4):  15%|█▍        | 52/350 [00:03<00:06, 48.91it/s]2024-10-12T23:24:54.879115Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 56  (41.1):  16%|█▌        | 55/350 [00:03<00:17, 16.58it/s]2024-10-12T23:24:54.883277Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 48.0 / 119  (40.3):  34%|███▎      | 118/350 [00:07<00:22, 10.40it/s] [24-10-12T23:24:58.811106Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 117.0 / 269  (43.5):  77%|███████▋  | 268/350 [00:16<00:05, 15.02it/s]1984-10-12T23:25:07.608727Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 123.0 / 282  (43.6):  80%|████████  | 281/350 [00:17<00:03, 20.08it/s]2024-10-12T23:25:08.550820Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 154.0 / 350  (44.0): 100%|██████████| 350/350 [00:19<00:00, 17.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 44.0 for seed 1\n",
      "Scores so far: [16.0, 16.0, 42.57, 42.57, 44.0]\n",
      "Best score so far: 44.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6/150 [00:02<00:48,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 19 / 50  (38.0):  14%|█▍        | 49/350 [00:03<00:12, 24.53it/s]2024-10-12T23:25:16.829478Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 112.0 / 277  (40.4):  79%|███████▉  | 276/350 [00:18<00:04, 17.61it/s]2024-10-12T23:25:32.028115Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 141.0 / 350  (40.3): 100%|██████████| 350/350 [00:21<00:00, 16.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [16.0, 16.0, 42.57, 42.57, 44.0, 40.29]\n",
      "Best score so far: 44.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/150 [00:01<01:08,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:25:36.868863Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 49  (49.0):  14%|█▎        | 48/350 [00:03<00:13, 21.87it/s]2024-10-12T23:25:39.546765Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 52  (48.1):  15%|█▍        | 51/350 [00:03<00:18, 16.50it/s]2024-10-12T23:25:39.812356Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 102.0 / 256  (39.8):  73%|███████▎  | 255/350 [00:17<00:10,  9.37it/s]2024-10-12T23:25:53.512593Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 112.0 / 286  (39.2):  81%|████████▏ | 285/350 [00:18<00:04, 15.43it/s]=024-10-12T23:25:54.933943Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 137.0 / 350  (39.1): 100%|██████████| 350/350 [00:20<00:00, 16.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [16.0, 16.0, 42.57, 42.57, 44.0, 40.29, 39.14]\n",
      "Best score so far: 44.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:01<00:56,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:25:59.513085Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<04:36,  1.26it/s]2024-10-12T23:25:59.652739Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 48  (25.0):  13%|█▎        | 47/350 [00:02<00:11, 25.67it/s]2024-10-12T23:26:01.666688Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 49  (24.5):  14%|█▎        | 48/350 [00:02<00:11, 25.67it/s]2024-10-12T23:26:01.690894Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 50  (24.0):  14%|█▍        | 50/350 [00:02<00:14, 21.16it/s]2024-10-12T23:26:01.961239Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 94  (33.0):  27%|██▋       | 93/350 [00:05<00:12, 20.08it/s]2024-10-12T23:26:04.214227Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 138  (31.9):  39%|███▉      | 137/350 [00:07<00:12, 16.81it/s]2024-10-12T23:26:06.547342Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 245  (32.7):  70%|██████▉   | 244/350 [00:13<00:06, 15.81it/s]2024-10-12T23:26:12.594975Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 82.0 / 253  (32.4):  72%|███████▏  | 252/350 [00:14<00:07, 13.73it/s]2024-10-12T23:26:13.162543Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 92.0 / 283  (32.5):  81%|████████  | 282/350 [00:15<00:03, 19.81it/s]2024-10-12T23:26:14.544810Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 115.0 / 350  (32.9): 100%|██████████| 350/350 [00:17<00:00, 19.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [16.0, 16.0, 42.57, 42.57, 44.0, 40.29, 39.14, 32.86]\n",
      "Best score so far: 44.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/150 [00:00<01:00,  2.46it/s]2024-10-12T23:26:17.686893Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_card_payment', 'text': \"Why hasn't payment gone through yet?\", 'answer': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 13%|█▎        | 20/150 [00:07<00:51,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 21 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:26:25.837499Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:01<07:04,  1.22s/it]2024-10-12T23:26:26.035545Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|          | 2/350 [00:01<03:34,  1.62it/s]2024-10-12T23:26:26.078557Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 5  (40.0):   1%|          | 4/350 [00:01<01:54,  3.02it/s]2024-10-12T23:26:26.388903Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 44  (50.0):  12%|█▏        | 43/350 [00:03<00:15, 20.02it/s]2024-10-12T23:26:28.278951Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 51  (47.1):  15%|█▍        | 51/350 [00:03<00:14, 21.03it/s]2024-10-12T23:26:28.665747Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 52  (46.2):  15%|█▍        | 51/350 [00:04<00:14, 21.03it/s]2024-10-12T23:26:28.694957Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 53  (45.3):  15%|█▍        | 52/350 [00:04<00:14, 21.03it/s]2024-10-12T23:26:28.701031Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 54  (44.4):  15%|█▌        | 54/350 [00:04<00:17, 17.05it/s] [24-10-12T23:26:28.732513Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 55  (43.6):  15%|█▌        | 54/350 [00:04<00:17, 17.05it/s]2024-10-12T23:26:29.030350Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28.0 / 63  (44.4):  18%|█▊        | 62/350 [00:04<00:24, 11.63it/s] rror    2T23:26:29.394022Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 48.0 / 106  (45.3):  30%|███       | 105/350 [00:06<00:13, 18.68it/s]2024-10-12T23:26:31.827679Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 51.0 / 113  (45.1):  32%|███▏      | 112/350 [00:07<00:18, 12.84it/s]2024-10-12T23:26:32.300555Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 122  (45.9):  35%|███▍      | 121/350 [00:08<00:13, 17.48it/s]2024-10-12T23:26:32.934334Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 67.0 / 149  (45.0):  42%|████▏     | 148/350 [00:09<00:08, 23.49it/s]2024-10-12T23:26:34.244429Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 69.0 / 153  (45.1):  43%|████▎     | 152/350 [00:09<00:10, 18.63it/s]2024-10-12T23:26:34.399562Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 76.0 / 165  (46.1):  47%|████▋     | 165/350 [00:10<00:11, 15.77it/s]2024-10-12T23:26:35.158674Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 77.0 / 173  (44.5):  49%|████▉     | 173/350 [00:11<00:10, 17.21it/s]2024-10-12T23:26:35.687722Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 89.0 / 193  (46.1):  55%|█████▍    | 192/350 [00:12<00:09, 15.81it/s]2024-10-12T23:26:36.841956Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 92.0 / 201  (45.8):  57%|█████▋    | 200/350 [00:12<00:08, 17.40it/s]=024-10-12T23:26:37.196854Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 92.0 / 204  (45.1):  58%|█████▊    | 203/350 [00:12<00:06, 22.13it/s]2024-10-12T23:26:37.557563Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 93.0 / 210  (44.3):  60%|█████▉    | 209/350 [00:13<00:09, 14.20it/s]2024-10-12T23:26:37.955670Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 94.0 / 213  (44.1):  61%|██████    | 212/350 [00:13<00:09, 14.20it/s]2024-10-12T23:26:38.035917Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 95.0 / 216  (44.0):  61%|██████▏   | 215/350 [00:13<00:07, 18.52it/s]2024-10-12T23:26:38.311856Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 96.0 / 221  (43.4):  63%|██████▎   | 220/350 [00:14<00:11, 10.84it/s]2024-10-12T23:26:38.882286Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 102.0 / 235  (43.4):  67%|██████▋   | 234/350 [00:15<00:10, 10.94it/s]2024-10-12T23:26:39.733736Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 105.0 / 240  (43.8):  68%|██████▊   | 239/350 [00:15<00:07, 14.58it/s]2024-10-12T23:26:40.047576Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 115.0 / 255  (45.1):  73%|███████▎  | 255/350 [00:16<00:05, 17.33it/s]dspy.evaluate.evaluate4788Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 134.0 / 284  (47.2):  81%|████████  | 283/350 [00:18<00:03, 17.00it/s]2024-10-12T23:26:42.622242Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 135.0 / 290  (46.6):  83%|████████▎ | 289/350 [00:18<00:03, 17.59it/s]2024-10-12T23:26:42.995135Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 140.0 / 308  (45.5):  88%|████████▊ | 307/350 [00:19<00:02, 19.31it/s]2024-10-12T23:26:43.802815Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 145.0 / 320  (45.3):  91%|█████████ | 319/350 [00:19<00:00, 32.20it/s]2024-10-12T23:26:43.963974Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 161.0 / 350  (46.0): 100%|██████████| 350/350 [00:19<00:00, 17.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 46.0 for seed 5\n",
      "Scores so far: [16.0, 16.0, 42.57, 42.57, 44.0, 40.29, 39.14, 32.86, 46.0]\n",
      "Best score so far: 46.0\n",
      "9 candidate programs found.\n",
      "[('intent_classifier', Predict(StringSignature(intent -> reasoning, label\n",
      "    instructions=\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\\nThe intent should exactly match one of the following:\\n['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\"\n",
      "    intent = Field(annotation=str required=True json_schema_extra={'desc': 'Intent of the query', '__dspy_field_type': 'input', 'prefix': 'Intent:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the output fields}. We ...', '__dspy_field_type': 'output'})\n",
      "    label = Field(annotation=str required=True json_schema_extra={'desc': 'Type of the intent; Should just be one of the 25 labels with no other text', '__dspy_field_type': 'output', 'prefix': 'Label:'})\n",
      ")))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]2024-10-12T23:26:45.936221Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/500 [00:01<09:23,  1.13s/it]2024-10-12T23:26:46.138258Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 2/500 [00:01<04:50,  1.71it/s]2024-10-12T23:26:46.165799Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   0%|          | 2/500 [00:01<04:50,  1.71it/s]2024-10-12T23:26:46.195782Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 39  (41.0):   8%|▊         | 38/500 [00:03<00:19, 23.87it/s]2024-10-12T23:26:47.964674Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 51  (41.2):  10%|█         | 50/500 [00:03<00:28, 15.86it/s]2024-10-12T23:26:48.655319Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 52  (40.4):  10%|█         | 51/500 [00:03<00:28, 15.86it/s]2024-10-12T23:26:48.662503Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 54  (40.7):  11%|█         | 54/500 [00:04<00:29, 14.91it/s]2024-10-12T23:26:48.937204Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 55  (40.0):  11%|█         | 54/500 [00:04<00:29, 14.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 157  (51.0):  31%|███▏      | 157/500 [00:09<00:15, 21.89it/s]2024-10-12T23:26:54.357594Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 158  (50.6):  31%|███▏      | 157/500 [00:09<00:15, 21.89it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 160  (50.0):  32%|███▏      | 159/500 [00:09<00:15, 21.89it/s]2024-10-12T23:26:54.643987Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 161  (49.7):  32%|███▏      | 161/500 [00:09<00:20, 16.78it/s]2024-10-12T23:26:54.733062Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 163  (49.7):  32%|███▏      | 162/500 [00:10<00:20, 16.78it/s]2024-10-12T23:26:54.990293Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 83.0 / 167  (49.7):  33%|███▎      | 166/500 [00:10<00:26, 12.77it/s]=024-10-12T23:26:55.253817Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 83.0 / 168  (49.4):  33%|███▎      | 167/500 [00:10<00:26, 12.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 83.0 / 169  (49.1):  34%|███▎      | 168/500 [00:10<00:26, 12.77it/s]2024-10-12T23:26:55.369095Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 90.0 / 185  (48.6):  37%|███▋      | 184/500 [00:11<00:23, 13.17it/s]2024-10-12T23:26:56.412043Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 94.0 / 193  (48.7):  38%|███▊      | 192/500 [00:11<00:15, 19.55it/s]2024-10-12T23:26:56.567801Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 102.0 / 214  (47.7):  43%|████▎     | 214/500 [00:13<00:20, 14.25it/s]2024-10-12T23:26:58.293840Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 118.0 / 246  (48.0):  49%|████▉     | 245/500 [00:15<00:11, 21.96it/s]2024-10-12T23:27:00.261721Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 123.0 / 255  (48.2):  51%|█████     | 254/500 [00:16<00:14, 16.41it/s]2024-10-12T23:27:00.937189Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 125.0 / 260  (48.1):  52%|█████▏    | 260/500 [00:16<00:18, 12.66it/s]2024-10-12T23:27:01.292430Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 133.0 / 269  (49.4):  54%|█████▎    | 268/500 [00:16<00:17, 13.37it/s]2024-10-12T23:27:01.695402Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 134.0 / 273  (49.1):  55%|█████▍    | 273/500 [00:17<00:14, 15.29it/s]2024-10-12T23:27:02.023887Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 135.0 / 275  (49.1):  55%|█████▍    | 274/500 [00:17<00:14, 15.29it/s]error    2T23:27:02.081458Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 135.0 / 277  (48.7):  55%|█████▌    | 277/500 [00:17<00:11, 19.06it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 137.0 / 285  (48.1):  57%|█████▋    | 284/500 [00:17<00:14, 14.83it/s]2024-10-12T23:27:02.852732Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 139.0 / 289  (48.1):  58%|█████▊    | 288/500 [00:18<00:16, 12.91it/s]lineno0-12T23:27:03.057244Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 143.0 / 302  (47.4):  60%|██████    | 301/500 [00:18<00:11, 16.89it/s]2024-10-12T23:27:03.515097Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 151.0 / 317  (47.6):  63%|██████▎   | 316/500 [00:20<00:11, 15.64it/s]2024-10-12T23:27:04.829092Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 153.0 / 321  (47.7):  64%|██████▍   | 320/500 [00:20<00:13, 13.79it/s]lineno0-12T23:27:05.142264Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 157.0 / 328  (47.9):  65%|██████▌   | 327/500 [00:20<00:12, 14.37it/s]2024-10-12T23:27:05.593737Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 157.0 / 330  (47.6):  66%|██████▌   | 330/500 [00:20<00:09, 17.66it/s]2024-10-12T23:27:05.903964Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 165.0 / 343  (48.1):  68%|██████▊   | 342/500 [00:21<00:11, 13.55it/s]2024-10-12T23:27:06.428096Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 188.0 / 386  (48.7):  77%|███████▋  | 385/500 [00:24<00:09, 12.28it/s]2024-10-12T23:27:09.370149Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 188.0 / 388  (48.5):  77%|███████▋  | 387/500 [00:24<00:09, 12.28it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 191.0 / 396  (48.2):  79%|███████▉  | 395/500 [00:25<00:07, 14.91it/s]dspy.evaluate.evaluate4699Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 193.0 / 399  (48.4):  80%|███████▉  | 398/500 [00:25<00:05, 19.92it/s]2024-10-12T23:27:09.903370Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 194.0 / 402  (48.3):  80%|████████  | 402/500 [00:25<00:04, 24.30it/s]2024-10-12T23:27:10.159330Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 197.0 / 412  (47.8):  82%|████████▏ | 411/500 [00:25<00:06, 14.06it/s]2024-10-12T23:27:10.812693Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 197.0 / 416  (47.4):  83%|████████▎ | 415/500 [00:26<00:04, 17.88it/s]1984-10-12T23:27:11.124587Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 199.0 / 424  (46.9):  85%|████████▍ | 424/500 [00:26<00:04, 16.80it/s]2024-10-12T23:27:11.576527Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 216.0 / 450  (48.0):  90%|████████▉ | 449/500 [00:28<00:03, 15.96it/s]2024-10-12T23:27:13.034958Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 216.0 / 452  (47.8):  90%|█████████ | 451/500 [00:28<00:03, 15.96it/s]2024-10-12T23:27:13.039794Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 218.0 / 459  (47.5):  92%|█████████▏| 458/500 [00:28<00:01, 21.58it/s]dspy.evaluate.evaluate1875Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 222.0 / 465  (47.7):  93%|█████████▎| 464/500 [00:28<00:01, 21.58it/s]2024-10-12T23:27:13.480554Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 242.0 / 500  (48.4): 100%|██████████| 500/500 [00:29<00:00, 17.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for meta-llama/Llama-3.2-1B-Instruct:epochs-4-total-trained-steps-145: 48.4, None, None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 59 / 367  (16.1):  73%|███████▎  | 366/500 [00:29<00:13, 10.00it/s]2024-10-12T23:27:43.675068Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 375  (16.5):  75%|███████▍  | 374/500 [00:30<00:09, 13.54it/s]2024-10-12T23:27:44.313707Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 486  (16.3):  97%|█████████▋| 486/500 [00:37<00:00, 32.66it/s]2024-10-12T23:27:53.776296Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 487  (16.2):  97%|█████████▋| 486/500 [00:39<00:00, 32.66it/s]2024-10-12T23:27:53.956014Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 488  (16.2):  97%|█████████▋| 487/500 [00:39<00:00, 32.66it/s]2024-10-12T23:27:53.961727Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 489  (16.2):  98%|█████████▊| 488/500 [00:39<00:00, 32.66it/s]2024-10-12T23:27:54.523434Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 490  (16.1):  98%|█████████▊| 490/500 [00:40<00:02,  4.59it/s]dspy.evaluate.evaluate6316Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 491  (16.1):  98%|█████████▊| 490/500 [00:40<00:02,  4.59it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 492  (16.1):  98%|█████████▊| 491/500 [00:40<00:01,  4.59it/s]2024-10-12T23:27:54.564416Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 493  (16.0):  98%|█████████▊| 492/500 [00:40<00:01,  4.59it/s]2024-10-12T23:27:54.977003Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 494  (16.0):  99%|█████████▉| 494/500 [00:40<00:01,  5.29it/s]2024-10-12T23:27:55.261907Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 495  (16.0):  99%|█████████▉| 494/500 [00:41<00:01,  5.29it/s]2024-10-12T23:27:55.440214Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 496  (15.9):  99%|█████████▉| 495/500 [00:41<00:00,  5.29it/s]2024-10-12T23:27:55.723277Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 497  (15.9):  99%|█████████▉| 497/500 [00:41<00:00,  4.94it/s]2024-10-12T23:27:55.887296Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 498  (15.9):  99%|█████████▉| 497/500 [00:41<00:00,  4.94it/s]2024-10-12T23:27:56.947627Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 499  (15.8): 100%|█████████▉| 499/500 [00:42<00:00,  3.65it/s]2024-10-12T23:27:57.094277Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 500  (15.8): 100%|██████████| 500/500 [00:42<00:00, 11.65it/s]\n",
      "Average Metric: 38 / 229  (16.6):  65%|██████▌   | 228/350 [00:15<00:11, 10.36it/s]2024-10-12T23:28:12.767795Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 342  (18.1):  97%|█████████▋| 341/350 [00:21<00:00, 53.14it/s]2024-10-12T23:28:22.715557Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 343  (18.1):  98%|█████████▊| 343/350 [00:25<00:01,  5.49it/s]2024-10-12T23:28:22.723356Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 344  (18.0):  98%|█████████▊| 343/350 [00:25<00:01,  5.49it/s]2024-10-12T23:28:22.732405Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 345  (18.0):  98%|█████████▊| 344/350 [00:25<00:01,  5.49it/s]2024-10-12T23:28:23.065900Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 346  (17.9):  99%|█████████▊| 345/350 [00:25<00:00,  5.49it/s]2024-10-12T23:28:23.136171Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 347  (17.9):  99%|█████████▉| 346/350 [00:25<00:00,  5.49it/s]2024-10-12T23:28:23.328064Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 348  (17.8):  99%|█████████▉| 348/350 [00:25<00:00,  5.96it/s]2024-10-12T23:28:23.629980Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 349  (17.8):  99%|█████████▉| 348/350 [00:26<00:00,  5.96it/s]2024-10-12T23:28:24.376291Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 350  (17.7): 100%|██████████| 350/350 [00:26<00:00, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 17.71 for seed -3\n",
      "Scores so far: [17.71]\n",
      "Best score so far: 17.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-12T23:28:24.426033Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0 / 4  (0.0):   1%|          | 3/350 [00:00<00:00, 485.64it/s]ted ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 3 / 12  (25.0):   3%|▎         | 11/350 [00:00<00:00, 580.33it/s]198   2T23:28:24.445434Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filenameevaluate.pylineno=\n",
      "Average Metric: 6 / 20  (30.0):   5%|▌         | 19/350 [00:00<00:00, 537.28it/s]198ename 2T23:28:24.463768Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate =evaluate.pylineno=\n",
      "Average Metric: 8 / 29  (27.6):   8%|▊         | 28/350 [00:00<00:00, 582.68it/s]lineno0-12T23:28:24.465340Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 12 / 39  (30.8):  11%|█         | 38/350 [00:00<00:00, 586.27it/s]024-10-12T23:28:24.472648Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13 / 50  (26.0):  14%|█▍        | 49/350 [00:00<00:00, 606.74it/s]][24-10-12T23:28:24.491154Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 13 / 58  (22.4):  16%|█▋        | 57/350 [00:00<00:00, 586.16it/s]198enovaluate.evaluate8068Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py =\n",
      "Average Metric: 16 / 68  (23.5):  19%|█▉        | 67/350 [00:00<00:00, 588.55it/s]198enamer example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=\n",
      "Average Metric: 62.0 / 350  (17.7): 100%|██████████| 350/350 [00:00<00:00, 979.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [17.71, 17.71]\n",
      "Best score so far: 17.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 10/150 [00:04<00:58,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:28:30.410607Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:01<05:49,  1.00s/it]2024-10-12T23:28:30.439611Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/350 [00:01<05:49,  1.00s/it]2024-10-12T23:28:30.488991Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 2/350 [00:01<05:48,  1.00s/it]2024-10-12T23:28:30.886053Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 5  (20.0):   1%|          | 4/350 [00:01<01:49,  3.15it/s]2024-10-12T23:28:30.945944Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 26  (42.3):   7%|▋         | 25/350 [00:02<00:28, 11.59it/s]2024-10-12T23:28:32.198195Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 32  (40.6):   9%|▉         | 31/350 [00:03<00:21, 14.88it/s]2024-10-12T23:28:32.644279Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 35  (40.0):  10%|▉         | 34/350 [00:03<00:21, 14.88it/s]2024-10-12T23:28:32.708888Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 45  (37.8):  13%|█▎        | 44/350 [00:03<00:15, 19.53it/s]2024-10-12T23:28:33.177150Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 46  (37.0):  13%|█▎        | 45/350 [00:03<00:15, 19.53it/s]2024-10-12T23:28:33.181541Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 57  (36.8):  16%|█▌        | 56/350 [00:04<00:13, 22.55it/s]]024-10-12T23:28:33.911324Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 59  (35.6):  17%|█▋        | 58/350 [00:04<00:15, 18.44it/s]2024-10-12T23:28:33.976341Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 64  (34.4):  18%|█▊        | 64/350 [00:05<00:20, 14.24it/s] 024-10-12T23:28:34.425744Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 22.0 / 65  (33.8):  18%|█▊        | 64/350 [00:05<00:20, 14.24it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 68  (32.4):  19%|█▉        | 67/350 [00:05<00:22, 12.70it/s]2024-10-12T23:28:34.745663Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 30.0 / 93  (32.3):  26%|██▋       | 92/350 [00:06<00:16, 15.95it/s]2024-10-12T23:28:36.036744Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 30.0 / 96  (31.2):  27%|██▋       | 95/350 [00:06<00:13, 18.93it/s]2024-10-12T23:28:36.321048Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 102  (30.4):  29%|██▉       | 102/350 [00:07<00:12, 19.33it/s]]024-10-12T23:28:36.486097Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 103  (30.1):  29%|██▉       | 102/350 [00:07<00:12, 19.33it/s]2024-10-12T23:28:36.718310Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 106  (31.1):  30%|███       | 105/350 [00:07<00:14, 16.70it/s]2024-10-12T23:28:36.775649Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 108  (30.6):  31%|███       | 107/350 [00:07<00:14, 16.70it/s]] 24-10-12T23:28:36.788867Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 117  (29.1):  33%|███▎      | 117/350 [00:08<00:14, 16.47it/s]2024-10-12T23:28:37.440610Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 125  (30.4):  35%|███▌      | 124/350 [00:08<00:14, 15.45it/s]2024-10-12T23:28:37.867427Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 132  (30.3):  37%|███▋      | 131/350 [00:08<00:13, 16.11it/s]2024-10-12T23:28:38.213781Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 133  (30.1):  38%|███▊      | 132/350 [00:08<00:13, 16.11it/s]2024-10-12T23:28:38.463428Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 145  (30.3):  41%|████      | 144/350 [00:09<00:12, 16.76it/s]]024-10-12T23:28:39.030605Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 153  (28.8):  43%|████▎     | 152/350 [00:10<00:11, 17.34it/s]2024-10-12T23:28:39.448135Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 154  (28.6):  44%|████▎     | 153/350 [00:10<00:11, 17.34it/s]2024-10-12T23:28:39.672904Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 159  (29.6):  45%|████▌     | 158/350 [00:10<00:12, 15.29it/s]2024-10-12T23:28:39.776446Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 48.0 / 162  (29.6):  46%|████▌     | 161/350 [00:10<00:08, 21.11it/s]2024-10-12T23:28:40.095988Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 181  (28.7):  51%|█████▏    | 180/350 [00:11<00:13, 12.97it/s]2024-10-12T23:28:41.338388Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 186  (28.5):  53%|█████▎    | 186/350 [00:12<00:11, 14.76it/s]]spy.evaluate.evaluate4326Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [ filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 197  (28.4):  56%|█████▌    | 196/350 [00:12<00:07, 20.81it/s]]024-10-12T23:28:42.125530Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 58.0 / 202  (28.7):  57%|█████▋    | 201/350 [00:13<00:08, 17.64it/s]evaluate.py23:28:42.387113Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename= lineno=198\n",
      "Average Metric: 60.0 / 207  (29.0):  59%|█████▉    | 206/350 [00:13<00:05, 24.11it/s]]024-10-12T23:28:42.778665Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 213  (28.2):  61%|██████    | 212/350 [00:13<00:07, 18.79it/s]2024-10-12T23:28:42.947656Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 219  (28.3):  62%|██████▏   | 218/350 [00:13<00:06, 19.39it/s]2024-10-12T23:28:43.267874Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 67.0 / 228  (29.4):  65%|██████▍   | 227/350 [00:14<00:08, 14.03it/s]2024-10-12T23:28:44.019639Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 70.0 / 239  (29.3):  68%|██████▊   | 238/350 [00:15<00:05, 20.27it/s]filename12T23:28:44.668302Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 70.0 / 242  (28.9):  69%|██████▉   | 241/350 [00:15<00:06, 15.98it/s]2024-10-12T23:28:44.672133Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 70.0 / 243  (28.8):  69%|██████▉   | 242/350 [00:15<00:06, 15.98it/s]2024-10-12T23:28:44.782320Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 73.0 / 251  (29.1):  71%|███████▏  | 250/350 [00:15<00:06, 16.51it/s]2024-10-12T23:28:45.203225Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 78.0 / 265  (29.4):  75%|███████▌  | 264/350 [00:16<00:05, 17.04it/s]filename12T23:28:45.915859Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 273  (29.7):  78%|███████▊  | 272/350 [00:16<00:04, 16.84it/s]2024-10-12T23:28:46.394223Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 85.0 / 282  (30.1):  80%|████████  | 281/350 [00:17<00:04, 14.50it/s]2024-10-12T23:28:47.087064Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 292  (29.5):  83%|████████▎ | 291/350 [00:18<00:04, 13.59it/s] 024-10-12T23:28:47.818611Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 100.0 / 328  (30.5):  93%|█████████▎| 327/350 [00:18<00:00, 41.78it/s]2024-10-12T23:28:48.431301Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 109.0 / 350  (31.1): 100%|██████████| 350/350 [00:19<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 31.14 for seed -1\n",
      "Scores so far: [17.71, 17.71, 31.14]\n",
      "Best score so far: 31.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 11/150 [00:04<00:53,  2.60it/s]2024-10-12T23:28:58.446194Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_fee_charged', 'text': 'Why did I get charged a fee on my card?', 'answer': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 11%|█         | 16/150 [00:11<01:32,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:29:01.328376Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<05:37,  1.04it/s]2024-10-12T23:29:01.508386Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|          | 2/350 [00:01<02:55,  1.98it/s]2024-10-12T23:29:01.535248Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 37  (29.7):  10%|█         | 36/350 [00:02<00:13, 23.76it/s]2024-10-12T23:29:03.263601Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 50  (32.0):  14%|█▍        | 49/350 [00:03<00:21, 14.02it/s]2024-10-12T23:29:04.384570Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 51  (31.4):  14%|█▍        | 50/350 [00:04<00:21, 14.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 58  (29.3):  17%|█▋        | 58/350 [00:04<00:26, 11.19it/s]2024-10-12T23:29:05.201587Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 65  (27.7):  18%|█▊        | 64/350 [00:05<00:23, 12.25it/s]2024-10-12T23:29:05.566401Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 97  (32.0):  28%|██▊       | 97/350 [00:06<00:13, 18.69it/s]2024-10-12T23:29:07.442742Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 113  (29.2):  32%|███▏      | 112/350 [00:08<00:15, 15.56it/s]2024-10-12T23:29:08.664822Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 152  (27.6):  43%|████▎     | 151/350 [00:10<00:12, 15.85it/s]2024-10-12T23:29:11.053914Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 160  (28.8):  46%|████▌     | 160/350 [00:11<00:10, 17.38it/s]1984-10-12T23:29:11.375550Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 51.0 / 182  (28.0):  52%|█████▏    | 181/350 [00:12<00:10, 15.90it/s]2024-10-12T23:29:12.825853Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 55.0 / 200  (27.5):  57%|█████▋    | 199/350 [00:13<00:07, 20.96it/s]2024-10-12T23:29:13.752713Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 213  (27.7):  61%|██████    | 212/350 [00:14<00:09, 14.78it/s]2024-10-12T23:29:14.801483Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 216  (27.8):  61%|██████▏   | 215/350 [00:14<00:09, 13.78it/s]2024-10-12T23:29:15.044300Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 264  (30.3):  75%|███████▌  | 263/350 [00:17<00:06, 13.73it/s]2024-10-12T23:29:18.005046Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 88.0 / 291  (30.2):  83%|████████▎ | 290/350 [00:19<00:04, 14.56it/s]2024-10-12T23:29:19.674735Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 93.0 / 301  (30.9):  86%|████████▌ | 300/350 [00:20<00:04, 12.06it/s]2024-10-12T23:29:20.523672Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 105.0 / 350  (30.0): 100%|██████████| 350/350 [00:21<00:00, 16.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [17.71, 17.71, 31.14, 30.0]\n",
      "Best score so far: 31.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:01<00:59,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:29:24.427596Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<05:36,  1.04it/s]2024-10-12T23:29:24.621392Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|          | 2/350 [00:01<02:58,  1.95it/s]2024-10-12T23:29:24.788320Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 3/350 [00:01<02:02,  2.83it/s]2024-10-12T23:29:24.843564Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 3/350 [00:01<02:02,  2.83it/s]2024-10-12T23:29:24.935553Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   1%|▏         | 5/350 [00:01<01:07,  5.11it/s]2024-10-12T23:29:25.162594Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   2%|▏         | 6/350 [00:01<01:10,  4.87it/s]2024-10-12T23:29:25.187976Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 50  (26.0):  14%|█▍        | 50/350 [00:03<00:12, 23.74it/s]2024-10-12T23:29:27.128508Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 53  (28.3):  15%|█▍        | 52/350 [00:03<00:12, 23.74it/s]2024-10-12T23:29:27.393632Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 55  (27.3):  15%|█▌        | 54/350 [00:04<00:18, 16.13it/s]2024-10-12T23:29:27.697160Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 61  (24.6):  17%|█▋        | 60/350 [00:04<00:21, 13.37it/s] [24-10-12T23:29:27.987608Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 70  (27.1):  20%|█▉        | 69/350 [00:04<00:19, 14.66it/s]2024-10-12T23:29:28.401235Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 77  (27.3):  22%|██▏       | 76/350 [00:05<00:12, 21.24it/s] 024-10-12T23:29:28.536677Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 26.0 / 98  (26.5):  28%|██▊       | 98/350 [00:05<00:10, 24.82it/s]2024-10-12T23:29:29.479004Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 101  (25.7):  29%|██▊       | 100/350 [00:06<00:10, 24.82it/s]24-10-12T23:29:29.943556Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 104  (25.0):  29%|██▉       | 103/350 [00:06<00:16, 15.19it/s]2024-10-12T23:29:30.214293Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 107  (24.3):  30%|███       | 106/350 [00:06<00:17, 14.08it/s]2024-10-12T23:29:30.366903Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 37.0 / 148  (25.0):  42%|████▏     | 147/350 [00:09<00:09, 20.47it/s]2024-10-12T23:29:32.756853Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 39.0 / 155  (25.2):  44%|████▍     | 155/350 [00:09<00:13, 14.10it/s]2024-10-12T23:29:33.480307Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 43.0 / 165  (26.1):  47%|████▋     | 164/350 [00:10<00:15, 12.13it/s] [24-10-12T23:29:33.831792Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 171  (25.7):  49%|████▊     | 170/350 [00:10<00:10, 16.93it/s]2024-10-12T23:29:34.131362Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 45.0 / 177  (25.4):  50%|█████     | 176/350 [00:11<00:10, 16.61it/s]evaluate.pyte.evaluate4853Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename= lineno=198\n",
      "Average Metric: 50.0 / 193  (25.9):  55%|█████▌    | 193/350 [00:11<00:08, 19.10it/s]2024-10-12T23:29:35.357938Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 51.0 / 199  (25.6):  57%|█████▋    | 198/350 [00:12<00:09, 16.88it/s]evaluate.py23:29:35.632098Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 51.0 / 200  (25.5):  57%|█████▋    | 199/350 [00:12<00:08, 16.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 213  (24.4):  61%|██████    | 212/350 [00:12<00:08, 16.71it/s]2024-10-12T23:29:36.403519Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 222  (24.3):  63%|██████▎   | 221/350 [00:13<00:08, 16.03it/s]2024-10-12T23:29:36.905808Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 226  (25.2):  64%|██████▍   | 225/350 [00:13<00:05, 21.59it/s]2024-10-12T23:29:37.232409Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 234  (25.2):  67%|██████▋   | 234/350 [00:13<00:04, 24.44it/s]2024-10-12T23:29:37.608628Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 61.0 / 241  (25.3):  69%|██████▉   | 241/350 [00:14<00:06, 18.05it/s]2024-10-12T23:29:37.938201Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 246  (25.2):  70%|███████   | 245/350 [00:14<00:05, 18.51it/s]2024-10-12T23:29:38.280698Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 67.0 / 253  (26.5):  72%|███████▏  | 252/350 [00:15<00:05, 17.13it/s]2024-10-12T23:29:38.587128Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 280  (26.4):  80%|███████▉  | 279/350 [00:16<00:03, 18.06it/s]2024-10-12T23:29:40.015219Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 298  (26.5):  85%|████████▍ | 297/350 [00:17<00:03, 16.43it/s]2024-10-12T23:29:41.102744Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 299  (26.4):  85%|████████▌ | 298/350 [00:17<00:03, 16.43it/s]2024-10-12T23:29:41.175965Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 313  (27.5):  89%|████████▉ | 312/350 [00:18<00:02, 15.73it/s]2024-10-12T23:29:41.579958Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 92.0 / 328  (28.0):  93%|█████████▎| 327/350 [00:18<00:00, 33.12it/s]2024-10-12T23:29:41.774545Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 94.0 / 337  (27.9):  96%|█████████▌| 336/350 [00:18<00:00, 48.85it/s]1984-10-12T23:29:41.840428Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 96.0 / 350  (27.4): 100%|██████████| 350/350 [00:18<00:00, 18.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [17.71, 17.71, 31.14, 30.0, 27.43]\n",
      "Best score so far: 31.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]2024-10-12T23:29:41.995033Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_fee_charged', 'text': 'Why did I get charged a fee on my card?', 'answer': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  8%|▊         | 12/150 [00:03<00:41,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:29:46.967115Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 17  (23.5):   5%|▍         | 16/350 [00:02<00:29, 11.21it/s]filename12T23:29:47.884748Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 48  (22.9):  14%|█▎        | 48/350 [00:03<00:13, 22.61it/s]2024-10-12T23:29:49.437209Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 61.0 / 250  (24.4):  71%|███████   | 249/350 [00:16<00:03, 28.79it/s]2024-10-12T23:30:02.807902Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 67.0 / 271  (24.7):  77%|███████▋  | 270/350 [00:17<00:03, 23.92it/s]2024-10-12T23:30:04.028519Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 67.0 / 275  (24.4):  78%|███████▊  | 274/350 [00:18<00:04, 17.03it/s]2024-10-12T23:30:04.357079Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 90.0 / 349  (25.8):  99%|█████████▉| 348/350 [00:21<00:00, 51.39it/s]2024-10-12T23:30:07.003773Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 90.0 / 350  (25.7): 100%|██████████| 350/350 [00:21<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [17.71, 17.71, 31.14, 30.0, 27.43, 25.71]\n",
      "Best score so far: 31.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/150 [00:00<00:52,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:30:08.600044Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<05:28,  1.06it/s]2024-10-12T23:30:08.740045Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 2/350 [00:01<02:43,  2.13it/s]2024-10-12T23:30:09.020061Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 48  (27.1):  13%|█▎        | 47/350 [00:02<00:08, 36.80it/s]2024-10-12T23:30:10.574358Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 49  (26.5):  14%|█▎        | 48/350 [00:02<00:08, 36.80it/s]2024-10-12T23:30:10.838487Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 50  (26.0):  14%|█▍        | 49/350 [00:03<00:08, 36.80it/s]2024-10-12T23:30:10.844459Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 29.0 / 92  (31.5):  26%|██▌       | 91/350 [00:04<00:08, 28.97it/s]2024-10-12T23:30:12.497515Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 29.0 / 99  (29.3):  28%|██▊       | 99/350 [00:04<00:06, 38.64it/s]2024-10-12T23:30:12.900978Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 115  (27.0):  33%|███▎      | 115/350 [00:06<00:11, 20.42it/s]2024-10-12T23:30:13.731461Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 117  (27.4):  33%|███▎      | 116/350 [00:06<00:11, 20.42it/s]2024-10-12T23:30:13.807300Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 118  (27.1):  33%|███▎      | 117/350 [00:06<00:11, 20.42it/s]2024-10-12T23:30:14.058959Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 120  (26.7):  34%|███▍      | 119/350 [00:06<00:13, 17.21it/s]2024-10-12T23:30:14.330889Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 43.0 / 152  (28.3):  43%|████▎     | 151/350 [00:07<00:07, 25.67it/s]2024-10-12T23:30:15.533775Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 43.0 / 156  (27.6):  44%|████▍     | 155/350 [00:08<00:07, 25.53it/s]2024-10-12T23:30:15.755278Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 165  (27.9):  47%|████▋     | 164/350 [00:08<00:10, 18.59it/s]2024-10-12T23:30:16.465125Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 168  (28.0):  48%|████▊     | 167/350 [00:08<00:11, 15.37it/s] [24-10-12T23:30:16.489532Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 170  (27.6):  48%|████▊     | 169/350 [00:08<00:11, 15.37it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 174  (27.0):  49%|████▉     | 173/350 [00:09<00:10, 16.82it/s]2024-10-12T23:30:16.863453Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 210  (26.7):  60%|█████▉    | 209/350 [00:10<00:05, 25.99it/s]2024-10-12T23:30:18.581373Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 213  (26.8):  61%|██████    | 212/350 [00:10<00:06, 21.38it/s]2024-10-12T23:30:18.729710Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 58.0 / 216  (26.9):  61%|██████▏   | 215/350 [00:11<00:06, 20.91it/s]2024-10-12T23:30:18.939697Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 223  (26.5):  63%|██████▎   | 222/350 [00:11<00:06, 18.46it/s]2024-10-12T23:30:19.276905Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 235  (26.4):  67%|██████▋   | 234/350 [00:12<00:07, 16.39it/s]2024-10-12T23:30:19.929093Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 236  (26.3):  67%|██████▋   | 235/350 [00:12<00:07, 16.39it/s]2024-10-12T23:30:20.044496Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 67.0 / 249  (26.9):  71%|███████   | 248/350 [00:12<00:06, 16.18it/s]2024-10-12T23:30:20.635317Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 67.0 / 251  (26.7):  71%|███████▏  | 250/350 [00:13<00:04, 22.91it/s]2024-10-12T23:30:20.706335Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 73.0 / 265  (27.5):  75%|███████▌  | 264/350 [00:13<00:06, 14.19it/s]2024-10-12T23:30:21.639364Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 73.0 / 268  (27.2):  76%|███████▋  | 267/350 [00:14<00:04, 20.18it/s]dspy.evaluate.evaluate dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 73.0 / 273  (26.7):  78%|███████▊  | 272/350 [00:14<00:03, 20.18it/s]2024-10-12T23:30:21.649698Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 78.0 / 286  (27.3):  82%|████████▏ | 286/350 [00:15<00:04, 14.91it/s]2024-10-12T23:30:22.886780Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 296  (27.4):  84%|████████▍ | 295/350 [00:15<00:03, 16.38it/s]=[24-10-12T23:30:23.291684Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 85.0 / 308  (27.6):  88%|████████▊ | 307/350 [00:15<00:01, 22.86it/s]2024-10-12T23:30:23.688127Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 85.0 / 309  (27.5):  88%|████████▊ | 308/350 [00:16<00:01, 22.86it/s]2024-10-12T23:30:23.714475Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 94.0 / 336  (28.0):  96%|█████████▌| 335/350 [00:16<00:00, 55.75it/s]1984-10-12T23:30:23.991437Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 97.0 / 350  (27.7): 100%|██████████| 350/350 [00:16<00:00, 21.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [17.71, 17.71, 31.14, 30.0, 27.43, 25.71, 27.71]\n",
      "Best score so far: 31.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 8/150 [00:03<00:58,  2.42it/s]2024-10-12T23:30:32.659483Z [error    ] Failed to run or to evaluate example Example({'label': 'transfer_fee_charged', 'text': 'When I was transferring money I was charged extra why?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 21%|██▏       | 32/150 [00:20<01:14,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 33 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:30:45.502523Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<05:46,  1.01it/s]2024-10-12T23:30:45.552281Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/350 [00:01<05:46,  1.01it/s]2024-10-12T23:30:45.643557Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 3/350 [00:01<01:46,  3.26it/s]2024-10-12T23:30:45.871979Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 4/350 [00:01<01:36,  3.57it/s]2024-10-12T23:30:46.043300Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 47  (23.4):  13%|█▎        | 47/350 [00:03<00:16, 18.59it/s]2024-10-12T23:30:47.872686Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 49  (22.4):  14%|█▎        | 48/350 [00:03<00:16, 18.59it/s]2024-10-12T23:30:47.913409Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 50  (22.0):  14%|█▍        | 49/350 [00:03<00:16, 18.59it/s]2024-10-12T23:30:48.173654Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 53  (20.8):  15%|█▍        | 52/350 [00:03<00:18, 16.41it/s]2024-10-12T23:30:48.347866Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 63  (22.2):  18%|█▊        | 63/350 [00:04<00:22, 12.49it/s]2024-10-12T23:30:49.150466Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 66  (22.7):  19%|█▊        | 65/350 [00:04<00:22, 12.49it/s]2024-10-12T23:30:49.165802Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 100  (23.0):  29%|██▊       | 100/350 [00:07<00:31,  8.05it/s]24-10-12T23:30:51.758996Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 105  (23.8):  30%|██▉       | 104/350 [00:07<00:23, 10.49it/s]=024-10-12T23:30:51.826071Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 37.0 / 146  (25.3):  41%|████▏     | 145/350 [00:08<00:06, 29.90it/s]2024-10-12T23:30:53.331375Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 149  (25.5):  43%|████▎     | 149/350 [00:08<00:10, 18.53it/s]lineno0-12T23:30:53.357504Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 38.0 / 150  (25.3):  43%|████▎     | 149/350 [00:08<00:10, 18.53it/s]2024-10-12T23:30:53.594106Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 151  (25.2):  43%|████▎     | 150/350 [00:09<00:10, 18.53it/s]2024-10-12T23:30:53.616730Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 152  (25.0):  43%|████▎     | 151/350 [00:09<00:10, 18.53it/s]2024-10-12T23:30:53.642819Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 158  (25.3):  45%|████▍     | 157/350 [00:09<00:15, 12.38it/s]]024-10-12T23:30:54.199686Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 41.0 / 162  (25.3):  46%|████▋     | 162/350 [00:09<00:10, 17.28it/s] rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno=198\n",
      "Average Metric: 50.0 / 196  (25.5):  56%|█████▌    | 195/350 [00:10<00:05, 28.50it/s]2024-10-12T23:30:55.693779Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 200  (25.0):  57%|█████▋    | 199/350 [00:11<00:06, 22.19it/s]2024-10-12T23:30:56.057744Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 210  (25.2):  60%|██████    | 210/350 [00:12<00:11, 12.11it/s]2024-10-12T23:30:56.939256Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 213  (25.4):  61%|██████    | 212/350 [00:12<00:11, 12.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 224  (25.4):  64%|██████▎   | 223/350 [00:12<00:07, 17.04it/s]2024-10-12T23:30:57.379726Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 58.0 / 227  (25.6):  65%|██████▍   | 226/350 [00:12<00:05, 23.40it/s]2024-10-12T23:30:57.446630Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 234  (25.2):  67%|██████▋   | 233/350 [00:13<00:05, 20.77it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 253  (25.7):  72%|███████▏  | 252/350 [00:14<00:05, 16.37it/s]2024-10-12T23:30:58.818777Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 257  (25.3):  73%|███████▎  | 257/350 [00:14<00:05, 16.94it/s]2024-10-12T23:30:59.204340Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 66.0 / 259  (25.5):  74%|███████▍  | 259/350 [00:14<00:06, 14.46it/s]2024-10-12T23:30:59.444634Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 72.0 / 277  (26.0):  79%|███████▉  | 276/350 [00:15<00:03, 19.28it/s]2024-10-12T23:31:00.276075Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 295  (26.8):  84%|████████▍ | 294/350 [00:16<00:02, 23.02it/s]2024-10-12T23:31:01.250065Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 299  (26.4):  85%|████████▌ | 299/350 [00:16<00:02, 19.27it/s]2024-10-12T23:31:01.386202Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 83.0 / 319  (26.0):  91%|█████████ | 318/350 [00:17<00:01, 30.18it/s]2024-10-12T23:31:01.978223Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 87.0 / 333  (26.1):  95%|█████████▌| 333/350 [00:17<00:00, 49.75it/s]=024-10-12T23:31:02.085016Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno198\n",
      "Average Metric: 92.0 / 350  (26.3): 100%|██████████| 350/350 [00:17<00:00, 19.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [17.71, 17.71, 31.14, 30.0, 27.43, 25.71, 27.71, 26.29]\n",
      "Best score so far: 31.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 21/150 [00:05<00:32,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 22 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:31:08.753799Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<04:35,  1.27it/s] ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/350 [00:00<04:35,  1.27it/s]2024-10-12T23:31:08.787754Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 2/350 [00:00<04:34,  1.27it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 3/350 [00:00<04:34,  1.27it/s]2024-10-12T23:31:08.824988Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   1%|▏         | 5/350 [00:00<00:48,  7.14it/s]2024-10-12T23:31:09.138106Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   1%|▏         | 5/350 [00:01<00:48,  7.14it/s]2024-10-12T23:31:09.180933Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   2%|▏         | 6/350 [00:01<00:48,  7.14it/s]2024-10-12T23:31:09.656789Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   2%|▏         | 8/350 [00:01<01:08,  5.02it/s]2024-10-12T23:31:09.826245Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 46  (30.4):  13%|█▎        | 45/350 [00:03<00:10, 28.69it/s]2024-10-12T23:31:11.497384Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 47  (29.8):  13%|█▎        | 46/350 [00:03<00:10, 28.69it/s]2024-10-12T23:31:11.524578Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 55  (25.5):  15%|█▌        | 54/350 [00:03<00:15, 19.65it/s]linenovaluate.evaluate7621Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py =198\n",
      "Average Metric: 14.0 / 56  (25.0):  16%|█▌        | 55/350 [00:03<00:15, 19.65it/s]2024-10-12T23:31:11.900041Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 57  (24.6):  16%|█▋        | 57/350 [00:03<00:12, 24.03it/s]2024-10-12T23:31:11.904077Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 58  (24.1):  16%|█▋        | 57/350 [00:03<00:12, 24.03it/s]2024-10-12T23:31:11.935487Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 14.0 / 59  (23.7):  17%|█▋        | 58/350 [00:03<00:12, 24.03it/s]2024-10-12T23:31:11.945239Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 62  (24.2):  17%|█▋        | 61/350 [00:04<00:14, 20.42it/s]2024-10-12T23:31:12.221092Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 64  (23.4):  18%|█▊        | 63/350 [00:04<00:14, 20.42it/s]2024-10-12T23:31:12.526027Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 68  (22.1):  19%|█▉        | 67/350 [00:04<00:16, 16.68it/s]2024-10-12T23:31:12.577533Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 82  (25.6):  23%|██▎       | 81/350 [00:05<00:17, 15.49it/s] [24-10-12T23:31:13.334385Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 103  (30.1):  29%|██▉       | 102/350 [00:06<00:15, 16.49it/s]24-10-12T23:31:14.478533Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 107  (29.0):  30%|███       | 106/350 [00:06<00:11, 21.79it/s]2024-10-12T23:31:14.640153Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 108  (28.7):  31%|███       | 107/350 [00:06<00:11, 21.79it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 109  (28.4):  31%|███       | 108/350 [00:06<00:11, 21.79it/s]2024-10-12T23:31:14.675529Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 117  (29.1):  33%|███▎      | 116/350 [00:07<00:11, 20.81it/s]2024-10-12T23:31:15.307818Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 120  (29.2):  34%|███▍      | 119/350 [00:07<00:12, 17.91it/s] 024-10-12T23:31:15.582372Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 41.0 / 133  (30.8):  38%|███▊      | 132/350 [00:08<00:15, 14.32it/s]dspy.evaluate.evaluate0047Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 145  (30.3):  41%|████▏     | 145/350 [00:08<00:09, 20.57it/s]2024-10-12T23:31:16.831220Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 151  (29.1):  43%|████▎     | 150/350 [00:09<00:11, 17.79it/s]2024-10-12T23:31:17.150764Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 157  (29.3):  45%|████▍     | 157/350 [00:09<00:09, 19.56it/s]filename12T23:31:17.516028Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 49.0 / 163  (30.1):  46%|████▋     | 162/350 [00:09<00:09, 19.56it/s]2024-10-12T23:31:17.641325Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 49.0 / 167  (29.3):  48%|████▊     | 167/350 [00:09<00:08, 21.24it/s]2024-10-12T23:31:17.967800Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 178  (29.2):  51%|█████     | 177/350 [00:10<00:09, 18.80it/s]2024-10-12T23:31:18.377050Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 187  (28.3):  53%|█████▎    | 186/350 [00:11<00:10, 15.74it/s]2024-10-12T23:31:19.053167Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 192  (28.1):  55%|█████▍    | 191/350 [00:11<00:09, 17.49it/s]2024-10-12T23:31:19.430953Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 61.0 / 209  (29.2):  59%|█████▉    | 208/350 [00:12<00:10, 13.88it/s]2024-10-12T23:31:20.307872Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 215  (28.8):  61%|██████    | 214/350 [00:12<00:08, 16.04it/s]2024-10-12T23:31:20.672658Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 218  (28.4):  62%|██████▏   | 217/350 [00:12<00:08, 16.04it/s]2024-10-12T23:31:20.750095Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 63.0 / 220  (28.6):  63%|██████▎   | 219/350 [00:12<00:06, 21.79it/s]filename   Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 63.0 / 224  (28.1):  64%|██████▍   | 224/350 [00:12<00:04, 26.35it/s]=024-10-12T23:31:20.791412Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 64.0 / 227  (28.2):  65%|██████▍   | 226/350 [00:13<00:04, 26.35it/s]2024-10-12T23:31:21.167232Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 231  (27.7):  66%|██████▌   | 230/350 [00:13<00:06, 19.44it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 233  (27.5):  67%|██████▋   | 233/350 [00:13<00:06, 17.44it/s]2024-10-12T23:31:21.591118Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 237  (27.0):  67%|██████▋   | 236/350 [00:13<00:06, 17.44it/s]2024-10-12T23:31:21.642103Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 66.0 / 240  (27.5):  68%|██████▊   | 239/350 [00:13<00:05, 21.69it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 69.0 / 251  (27.5):  71%|███████▏  | 250/350 [00:14<00:06, 16.11it/s]2024-10-12T23:31:22.542529Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 256  (27.7):  73%|███████▎  | 255/350 [00:14<00:05, 16.00it/s]2024-10-12T23:31:22.909978Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 72.0 / 261  (27.6):  74%|███████▍  | 260/350 [00:15<00:06, 13.44it/s]2024-10-12T23:31:23.220078Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 265  (27.9):  76%|███████▌  | 265/350 [00:15<00:06, 13.50it/s]2024-10-12T23:31:23.577720Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 77.0 / 283  (27.2):  81%|████████  | 282/350 [00:16<00:04, 16.06it/s]2024-10-12T23:31:24.396078Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 78.0 / 285  (27.4):  81%|████████▏ | 285/350 [00:16<00:03, 21.11it/s] 024-10-12T23:31:24.457113Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 80.0 / 297  (26.9):  85%|████████▍ | 296/350 [00:17<00:02, 18.53it/s]2024-10-12T23:31:25.095545Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 314  (27.4):  89%|████████▉ | 313/350 [00:17<00:01, 24.67it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 87.0 / 316  (27.5):  90%|█████████ | 315/350 [00:17<00:01, 24.67it/s] 024-10-12T23:31:25.654400Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 93.0 / 337  (27.6):  96%|█████████▌| 336/350 [00:17<00:00, 44.89it/s]=024-10-12T23:31:25.870924Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 98.0 / 350  (28.0): 100%|██████████| 350/350 [00:17<00:00, 19.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [17.71, 17.71, 31.14, 30.0, 27.43, 25.71, 27.71, 26.29, 28.0]\n",
      "Best score so far: 31.14\n",
      "9 candidate programs found.\n",
      "[('intent_classifier', Predict(StringSignature(intent -> reasoning, label\n",
      "    instructions=\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\\nThe intent should exactly match one of the following:\\n['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\"\n",
      "    intent = Field(annotation=str required=True json_schema_extra={'desc': 'Intent of the query', '__dspy_field_type': 'input', 'prefix': 'Intent:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the output fields}. We ...', '__dspy_field_type': 'output'})\n",
      "    label = Field(annotation=str required=True json_schema_extra={'desc': 'Type of the intent; Should just be one of the 25 labels with no other text', '__dspy_field_type': 'output', 'prefix': 'Label:'})\n",
      ")))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]2024-10-12T23:31:27.350315Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/500 [00:01<08:20,  1.00s/it]12T23:31:27.356365Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/500 [00:01<08:20,  1.00s/it]2024-10-12T23:31:27.627044Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 3/500 [00:01<02:58,  2.79it/s]2024-10-12T23:31:27.658025Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 3/500 [00:01<02:58,  2.79it/s]2024-10-12T23:31:27.689459Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   1%|          | 4/500 [00:01<02:57,  2.79it/s]2024-10-12T23:31:27.919005Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   1%|          | 6/500 [00:01<01:38,  5.04it/s]2024-10-12T23:31:27.924532Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 8  (12.5):   1%|▏         | 7/500 [00:01<01:37,  5.04it/s]2024-10-12T23:31:28.072993Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 15  (20.0):   3%|▎         | 14/500 [00:02<01:17,  6.30it/s] 024-10-12T23:31:28.815575Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 13.0 / 45  (28.9):   9%|▉         | 44/500 [00:03<00:13, 34.23it/s]2024-10-12T23:31:29.493412Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 56  (28.6):  11%|█         | 55/500 [00:03<00:11, 40.44it/s]2024-10-12T23:31:30.094394Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 59  (27.1):  12%|█▏        | 58/500 [00:03<00:19, 22.55it/s]2024-10-12T23:31:30.402902Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 16.0 / 63  (25.4):  12%|█▏        | 62/500 [00:04<00:25, 17.14it/s]2024-10-12T23:31:30.882945Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 69  (29.0):  14%|█▍        | 69/500 [00:05<00:38, 11.25it/s]2024-10-12T23:31:31.431987Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 110  (32.7):  22%|██▏       | 109/500 [00:06<00:16, 24.19it/s]2024-10-12T23:31:33.264497Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 51.0 / 151  (33.8):  30%|███       | 150/500 [00:09<00:16, 20.67it/s]2024-10-12T23:31:35.730209Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 157  (33.1):  31%|███       | 156/500 [00:09<00:19, 17.94it/s]2024-10-12T23:31:36.388789Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 163  (32.5):  32%|███▏      | 162/500 [00:10<00:28, 11.81it/s]=024-10-12T23:31:36.696016Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 53.0 / 164  (32.3):  33%|███▎      | 163/500 [00:10<00:28, 11.81it/s]2024-10-12T23:31:36.914793Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 165  (32.1):  33%|███▎      | 165/500 [00:10<00:24, 13.50it/s] [24-10-12T23:31:36.929621Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 168  (31.5):  33%|███▎      | 167/500 [00:10<00:24, 13.50it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 169  (31.4):  34%|███▍      | 169/500 [00:10<00:19, 17.12it/s]2024-10-12T23:31:36.964685Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 170  (31.2):  34%|███▍      | 169/500 [00:10<00:19, 17.12it/s]2024-10-12T23:31:36.968650Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 172  (30.8):  34%|███▍      | 171/500 [00:10<00:19, 17.12it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 174  (31.0):  35%|███▍      | 174/500 [00:10<00:14, 21.95it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 55.0 / 177  (31.1):  35%|███▌      | 177/500 [00:11<00:18, 17.16it/s]2024-10-12T23:31:37.473003Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 55.0 / 178  (30.9):  35%|███▌      | 177/500 [00:11<00:18, 17.16it/s]2024-10-12T23:31:37.686391Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 55.0 / 179  (30.7):  36%|███▌      | 178/500 [00:11<00:18, 17.16it/s]2024-10-12T23:31:37.716163Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 192  (29.7):  38%|███▊      | 191/500 [00:12<00:38,  8.10it/s]2024-10-12T23:31:39.018380Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 208  (29.8):  41%|████▏     | 207/500 [00:13<00:17, 16.97it/s]198luate.py23:31:39.391223Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=\n",
      "Average Metric: 69.0 / 222  (31.1):  44%|████▍     | 222/500 [00:13<00:08, 34.31it/s]2024-10-12T23:31:39.662979Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 73.0 / 231  (31.6):  46%|████▌     | 230/500 [00:13<00:06, 39.21it/s]198or for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 75.0 / 241  (31.1):  48%|████▊     | 240/500 [00:13<00:06, 40.86it/s]2024-10-12T23:31:40.619102Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 242  (31.0):  48%|████▊     | 241/500 [00:14<00:06, 40.86it/s]2024-10-12T23:31:40.661600Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 243  (30.9):  48%|████▊     | 242/500 [00:14<00:06, 40.86it/s]2024-10-12T23:31:40.896612Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 244  (30.7):  49%|████▉     | 244/500 [00:14<00:16, 15.16it/s]2024-10-12T23:31:40.902183Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 245  (30.6):  49%|████▉     | 244/500 [00:14<00:16, 15.16it/s]2024-10-12T23:31:40.934980Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 76.0 / 247  (30.8):  49%|████▉     | 246/500 [00:14<00:16, 15.16it/s]2024-10-12T23:31:41.056240Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 77.0 / 251  (30.7):  50%|█████     | 250/500 [00:14<00:15, 16.59it/s]2024-10-12T23:31:41.309656Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 77.0 / 252  (30.6):  50%|█████     | 252/500 [00:14<00:15, 16.41it/s]2024-10-12T23:31:41.420058Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 264  (30.3):  53%|█████▎    | 263/500 [00:16<00:20, 11.44it/s]2024-10-12T23:31:42.406701Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 266  (30.1):  53%|█████▎    | 265/500 [00:16<00:20, 11.44it/s]2024-10-12T23:31:42.493525Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 268  (30.2):  53%|█████▎    | 267/500 [00:16<00:13, 16.66it/s]2024-10-12T23:31:42.537917Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 83.0 / 280  (29.6):  56%|█████▌    | 279/500 [00:16<00:09, 22.50it/s]2024-10-12T23:31:43.242353Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 84.0 / 288  (29.2):  57%|█████▋    | 287/500 [00:17<00:12, 17.27it/s]1984-10-12T23:31:43.390626Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 85.0 / 294  (28.9):  59%|█████▊    | 293/500 [00:17<00:09, 22.91it/s]2024-10-12T23:31:43.776770Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 88.0 / 310  (28.4):  62%|██████▏   | 309/500 [00:18<00:11, 16.66it/s]2024-10-12T23:31:44.722295Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 91.0 / 317  (28.7):  63%|██████▎   | 316/500 [00:18<00:12, 15.18it/s]2024-10-12T23:31:45.216141Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 92.0 / 324  (28.4):  65%|██████▍   | 323/500 [00:19<00:11, 15.21it/s]2024-10-12T23:31:45.548502Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 92.0 / 325  (28.3):  65%|██████▌   | 325/500 [00:19<00:08, 20.94it/s]2024-10-12T23:31:45.575003Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 100.0 / 348  (28.7):  69%|██████▉   | 347/500 [00:20<00:08, 17.44it/s]024-10-12T23:31:46.718929Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 102.0 / 354  (28.8):  71%|███████   | 353/500 [00:20<00:08, 16.54it/s]filenamer example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 103.0 / 360  (28.6):  72%|███████▏  | 360/500 [00:21<00:08, 16.59it/s]2024-10-12T23:31:47.537351Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 106.0 / 369  (28.7):  74%|███████▎  | 368/500 [00:21<00:10, 12.18it/s]2024-10-12T23:31:48.270888Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 113.0 / 394  (28.7):  79%|███████▉  | 394/500 [00:23<00:06, 16.60it/s]2024-10-12T23:31:49.613953Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 114.0 / 402  (28.4):  80%|████████  | 401/500 [00:23<00:06, 16.41it/s]dspy.evaluate.evaluate1697Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 115.0 / 405  (28.4):  81%|████████  | 404/500 [00:23<00:04, 20.53it/s]2024-10-12T23:31:50.036956Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 116.0 / 407  (28.5):  81%|████████  | 406/500 [00:23<00:04, 20.53it/s]2024-10-12T23:31:50.110252Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 116.0 / 411  (28.2):  82%|████████▏ | 410/500 [00:24<00:04, 19.97it/s]2024-10-12T23:31:50.399716Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 119.0 / 423  (28.1):  84%|████████▍ | 422/500 [00:24<00:04, 16.24it/s]filename12T23:31:50.967896Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 127.0 / 437  (29.1):  87%|████████▋ | 436/500 [00:25<00:03, 17.21it/s]2024-10-12T23:31:51.893920Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 128.0 / 440  (29.1):  88%|████████▊ | 439/500 [00:25<00:03, 18.04it/s]2024-10-12T23:31:52.135295Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 129.0 / 444  (29.1):  89%|████████▉ | 444/500 [00:25<00:03, 17.16it/s]2024-10-12T23:31:52.523166Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 146.0 / 489  (29.9):  98%|█████████▊| 488/500 [00:27<00:00, 46.20it/s]2024-10-12T23:31:53.538716Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 149.0 / 500  (29.8): 100%|██████████| 500/500 [00:27<00:00, 18.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for meta-llama/Llama-3.2-1B-Instruct:epochs-1-total-trained-steps-58: 29.8, None, None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 115 / 498  (23.1):  99%|█████████▉| 497/500 [00:33<00:00, 54.18it/s]2024-10-12T23:32:29.841150Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 115.0 / 499  (23.0): 100%|█████████▉| 498/500 [00:35<00:00, 54.18it/s]2024-10-12T23:32:30.498959Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 115.0 / 500  (23.0): 100%|██████████| 500/500 [00:36<00:00, 13.72it/s]\n",
      "Average Metric: 48 / 196  (24.5):  56%|█████▌    | 195/350 [00:13<00:11, 13.04it/s]2024-10-12T23:32:44.680604Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 78.0 / 350  (22.3): 100%|██████████| 350/350 [00:22<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 22.29 for seed -3\n",
      "Scores so far: [22.29]\n",
      "Best score so far: 22.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 4  (25.0):   1%|          | 3/350 [00:00<00:00, 713.88it/s]198enoeasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py =\n",
      "Average Metric: 78.0 / 350  (22.3): 100%|██████████| 350/350 [00:00<00:00, 1215.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [22.29, 22.29]\n",
      "Best score so far: 22.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 7/150 [00:02<01:01,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:32:58.296965Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:01<06:41,  1.15s/it]2024-10-12T23:32:58.349028Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 4  (25.0):   1%|          | 3/350 [00:01<02:49,  2.05it/s]2024-10-12T23:32:58.845640Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 48  (35.4):  13%|█▎        | 47/350 [00:03<00:08, 35.50it/s]2024-10-12T23:33:01.031277Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 53  (34.0):  15%|█▍        | 52/350 [00:03<00:20, 14.39it/s]2024-10-12T23:33:01.104882Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 54  (33.3):  15%|█▌        | 53/350 [00:03<00:20, 14.39it/s]2024-10-12T23:33:01.426797Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 55  (32.7):  16%|█▌        | 55/350 [00:04<00:20, 14.11it/s]2024-10-12T23:33:01.454883Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 57  (33.3):  16%|█▌        | 56/350 [00:04<00:20, 14.11it/s]2024-10-12T23:33:01.501276Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 114  (33.3):  33%|███▎      | 114/350 [00:07<00:19, 12.33it/s]2024-10-12T23:33:05.117515Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 123  (34.1):  35%|███▍      | 122/350 [00:08<00:16, 13.71it/s]2024-10-12T23:33:05.629241Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 161  (35.4):  46%|████▌     | 160/350 [00:10<00:17, 11.12it/s]=024-10-12T23:33:07.939619Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno198\n",
      "Average Metric: 68.0 / 189  (36.0):  54%|█████▎    | 188/350 [00:12<00:10, 15.73it/s]2024-10-12T23:33:09.612107Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 201  (35.3):  57%|█████▋    | 200/350 [00:13<00:11, 13.36it/s]2024-10-12T23:33:10.317309Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 73.0 / 208  (35.1):  59%|█████▉    | 207/350 [00:13<00:09, 15.07it/s]2024-10-12T23:33:11.082980Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 73.0 / 210  (34.8):  60%|█████▉    | 209/350 [00:13<00:12, 11.41it/s]2024-10-12T23:33:11.140127Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 99.0 / 267  (37.1):  76%|███████▌  | 266/350 [00:16<00:03, 22.60it/s]2024-10-12T23:33:13.725104Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 103.0 / 279  (36.9):  79%|███████▉  | 278/350 [00:17<00:03, 18.01it/s]2024-10-12T23:33:14.735238Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 122.0 / 330  (37.0):  94%|█████████▍| 329/350 [00:19<00:00, 42.95it/s]2024-10-12T23:33:16.204247Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 129.0 / 350  (36.9): 100%|██████████| 350/350 [00:19<00:00, 18.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 36.86 for seed -1\n",
      "Scores so far: [22.29, 22.29, 36.86]\n",
      "Best score so far: 36.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 8/150 [00:03<01:01,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:33:21.214541Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<05:07,  1.13it/s]2024-10-12T23:33:21.241769Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/350 [00:00<05:07,  1.13it/s]2024-10-12T23:33:21.358774Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 3/350 [00:01<01:38,  3.53it/s]2024-10-12T23:33:21.559219Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 23.0 / 51  (45.1):  14%|█▍        | 50/350 [00:03<00:09, 31.85it/s]2024-10-12T23:33:23.977190Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 55  (43.6):  15%|█▌        | 54/350 [00:03<00:14, 19.87it/s]2024-10-12T23:33:24.284499Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 56  (42.9):  16%|█▌        | 56/350 [00:03<00:16, 17.71it/s]2024-10-12T23:33:24.557072Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 57  (42.1):  16%|█▌        | 56/350 [00:04<00:16, 17.71it/s]2024-10-12T23:33:24.605657Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 41.0 / 110  (37.3):  31%|███▏      | 110/350 [00:08<00:28,  8.42it/s]2024-10-12T23:33:28.450627Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 156  (38.5):  44%|████▍     | 155/350 [00:10<00:13, 14.41it/s]2024-10-12T23:33:31.536752Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 194  (38.7):  55%|█████▌    | 193/350 [00:13<00:09, 16.15it/s]2024-10-12T23:33:33.876996Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 76.0 / 199  (38.2):  57%|█████▋    | 199/350 [00:13<00:09, 16.44it/s]]rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 100.0 / 258  (38.8):  74%|███████▎  | 258/350 [00:17<00:06, 14.59it/s]2024-10-12T23:33:38.504513Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 107.0 / 283  (37.8):  81%|████████  | 282/350 [00:19<00:04, 13.86it/s]2024-10-12T23:33:40.110940Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 113.0 / 299  (37.8):  85%|████████▌ | 299/350 [00:20<00:03, 15.00it/s]2024-10-12T23:33:41.058353Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 120.0 / 320  (37.5):  91%|█████████ | 319/350 [00:21<00:01, 24.65it/s]2024-10-12T23:33:41.615543Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 133.0 / 350  (38.0): 100%|██████████| 350/350 [00:21<00:00, 16.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 38.0 for seed 0\n",
      "Scores so far: [22.29, 22.29, 36.86, 38.0]\n",
      "Best score so far: 38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:01<00:59,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:33:44.716376Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 48  (14.6):  14%|█▎        | 48/350 [00:02<00:13, 22.78it/s]2024-10-12T23:33:46.854084Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 50  (14.0):  14%|█▍        | 49/350 [00:02<00:13, 22.78it/s]2024-10-12T23:33:47.157899Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 26.0 / 205  (12.7):  58%|█████▊    | 204/350 [00:10<00:10, 13.70it/s]filenameluate.evaluate7608Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] =evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 252  (10.7):  72%|███████▏  | 251/350 [00:13<00:07, 12.91it/s]dspy.evaluate.evaluate0426Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 31.0 / 286  (10.8):  81%|████████▏ | 285/350 [00:14<00:02, 29.28it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 350  (13.4): 100%|██████████| 350/350 [00:16<00:00, 21.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [22.29, 22.29, 36.86, 38.0, 13.43]\n",
      "Best score so far: 38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 17/150 [00:07<00:56,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 18 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:34:09.362396Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 50  (30.0):  14%|█▍        | 50/350 [00:05<00:25, 11.74it/s]2024-10-12T23:34:14.212250Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 85.0 / 271  (31.4):  77%|███████▋  | 270/350 [00:30<00:09,  8.87it/s]2024-10-12T23:34:38.812794Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 117.0 / 350  (33.4): 100%|██████████| 350/350 [00:40<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [22.29, 22.29, 36.86, 38.0, 13.43, 33.43]\n",
      "Best score so far: 38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/150 [00:01<01:01,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:34:51.039072Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<05:03,  1.15it/s]2024-10-12T23:34:51.242991Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 51  (29.4):  15%|█▍        | 51/350 [00:03<00:13, 21.56it/s]2024-10-12T23:34:54.071123Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 189  (31.7):  54%|█████▎    | 188/350 [00:11<00:07, 20.97it/s]2024-10-12T23:35:02.059994Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 242  (33.5):  69%|██████▉   | 241/350 [00:15<00:06, 17.87it/s]2024-10-12T23:35:06.075204Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 82.0 / 251  (32.7):  71%|███████▏  | 250/350 [00:16<00:07, 14.25it/s]2024-10-12T23:35:06.905564Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 92.0 / 279  (33.0):  79%|███████▉  | 278/350 [00:18<00:05, 13.39it/s]2024-10-12T23:35:08.623562Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 118.0 / 349  (33.8):  99%|█████████▉| 348/350 [00:20<00:00, 68.25it/s]2024-10-12T23:35:10.846744Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 118.0 / 350  (33.7): 100%|██████████| 350/350 [00:20<00:00, 16.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [22.29, 22.29, 36.86, 38.0, 13.43, 33.43, 33.71]\n",
      "Best score so far: 38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/150 [00:01<00:56,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0 / 7  (0.0):   2%|▏         | 6/350 [00:00<00:14, 23.41it/s]2024-10-12T23:35:13.784439Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   2%|▏         | 7/350 [00:00<00:14, 23.41it/s]2024-10-12T23:35:13.805703Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 9  (0.0):   2%|▏         | 8/350 [00:00<00:14, 23.41it/s]2024-10-12T23:35:13.827005Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 14  (0.0):   4%|▎         | 13/350 [00:00<00:09, 37.37it/s]2024-10-12T23:35:13.938433Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 54  (27.8):  15%|█▌        | 54/350 [00:02<00:08, 34.05it/s]2024-10-12T23:35:16.246583Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 65  (29.2):  18%|█▊        | 64/350 [00:02<00:10, 26.45it/s]2024-10-12T23:35:16.440246Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 67  (28.4):  19%|█▉        | 66/350 [00:02<00:09, 31.49it/s]2024-10-12T23:35:16.445857Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 70  (27.1):  20%|█▉        | 69/350 [00:03<00:08, 31.49it/s]2024-10-12T23:35:16.812239Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 33.0 / 116  (28.4):  33%|███▎      | 115/350 [00:05<00:08, 26.79it/s]2024-10-12T23:35:19.074854Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 120  (28.3):  34%|███▍      | 119/350 [00:05<00:09, 24.80it/s]2024-10-12T23:35:19.346624Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 121  (28.1):  35%|███▍      | 121/350 [00:05<00:10, 21.52it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 130  (26.9):  37%|███▋      | 129/350 [00:06<00:16, 13.28it/s]2024-10-12T23:35:20.308706Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 55.0 / 200  (27.5):  57%|█████▋    | 199/350 [00:10<00:08, 17.53it/s]2024-10-12T23:35:23.963488Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 216  (25.9):  61%|██████▏   | 215/350 [00:11<00:05, 25.57it/s]2024-10-12T23:35:24.714193Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 58.0 / 222  (26.1):  63%|██████▎   | 221/350 [00:11<00:08, 16.06it/s]2024-10-12T23:35:25.112320Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 229  (26.2):  65%|██████▌   | 228/350 [00:11<00:07, 16.30it/s]2024-10-12T23:35:25.498296Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 246  (25.2):  70%|███████   | 245/350 [00:13<00:05, 18.24it/s]2024-10-12T23:35:26.592126Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 265  (24.5):  75%|███████▌  | 264/350 [00:13<00:03, 21.99it/s]2024-10-12T23:35:27.242221Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 266  (24.4):  76%|███████▌  | 265/350 [00:13<00:03, 21.99it/s]2024-10-12T23:35:27.439349Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 66.0 / 269  (24.5):  77%|███████▋  | 268/350 [00:14<00:04, 20.04it/s]2024-10-12T23:35:27.775047Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 70.0 / 286  (24.5):  81%|████████▏ | 285/350 [00:15<00:05, 12.42it/s]2024-10-12T23:35:29.123310Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 84.0 / 338  (24.9):  96%|█████████▋| 337/350 [00:17<00:00, 48.93it/s]2024-10-12T23:35:30.658258Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 85.0 / 350  (24.3): 100%|██████████| 350/350 [00:17<00:00, 19.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [22.29, 22.29, 36.86, 38.0, 13.43, 33.43, 33.71, 24.29]\n",
      "Best score so far: 38.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 14/150 [00:05<00:50,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 15 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:35:38.053574Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:01<07:00,  1.21s/it]2024-10-12T23:35:38.085754Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/350 [00:01<07:00,  1.21s/it]2024-10-12T23:35:38.094122Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 2/350 [00:01<06:59,  1.21s/it]2024-10-12T23:35:38.337764Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 4/350 [00:01<01:45,  3.29it/s]2024-10-12T23:35:38.368887Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   1%|          | 4/350 [00:01<01:45,  3.29it/s]2024-10-12T23:35:38.677539Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 51  (43.1):  14%|█▍        | 50/350 [00:04<00:15, 18.91it/s]2024-10-12T23:35:40.972900Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 52  (42.3):  15%|█▍        | 52/350 [00:04<00:18, 16.00it/s]2024-10-12T23:35:41.002999Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 53  (41.5):  15%|█▍        | 52/350 [00:04<00:18, 16.00it/s]2024-10-12T23:35:41.268408Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 54  (40.7):  15%|█▌        | 53/350 [00:04<00:18, 16.00it/s]2024-10-12T23:35:41.309873Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 55  (40.0):  16%|█▌        | 55/350 [00:04<00:21, 13.47it/s]2024-10-12T23:35:41.536906Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 63  (39.7):  18%|█▊        | 62/350 [00:05<00:25, 11.29it/s]2024-10-12T23:35:41.938670Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 101  (39.6):  29%|██▊       | 100/350 [00:07<00:15, 16.40it/s]valuate.py3:35:44.170145Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 41.0 / 107  (38.3):  30%|███       | 106/350 [00:07<00:19, 12.38it/s]2024-10-12T23:35:44.870871Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 43.0 / 113  (38.1):  32%|███▏      | 112/350 [00:08<00:19, 11.99it/s]2024-10-12T23:35:45.204518Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 116  (37.9):  33%|███▎      | 115/350 [00:08<00:14, 16.72it/s]2024-10-12T23:35:45.496037Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 134  (38.8):  38%|███▊      | 133/350 [00:09<00:15, 14.37it/s]2024-10-12T23:35:46.605125Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 137  (38.7):  39%|███▉      | 137/350 [00:09<00:10, 19.55it/s]2024-10-12T23:35:46.689919Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 159  (37.7):  45%|████▌     | 158/350 [00:11<00:13, 14.12it/s]2024-10-12T23:35:48.161822Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 170  (36.5):  49%|████▊     | 170/350 [00:12<00:11, 15.74it/s]2024-10-12T23:35:49.106030Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 181  (35.9):  51%|█████▏    | 180/350 [00:12<00:13, 12.27it/s]=024-10-12T23:35:49.599894Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 70.0 / 195  (35.9):  55%|█████▌    | 194/350 [00:13<00:12, 12.29it/s]2024-10-12T23:35:50.606748Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 72.0 / 198  (36.4):  56%|█████▋    | 197/350 [00:13<00:09, 15.99it/s] [24-10-12T23:35:50.611180Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 208  (35.6):  59%|█████▉    | 207/350 [00:14<00:07, 19.11it/s]2024-10-12T23:35:51.059983Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 211  (35.1):  60%|██████    | 211/350 [00:14<00:05, 23.77it/s]2024-10-12T23:35:51.159670Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 212  (34.9):  60%|██████    | 211/350 [00:14<00:05, 23.77it/s]2024-10-12T23:35:51.185648Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 213  (34.7):  61%|██████    | 212/350 [00:14<00:05, 23.77it/s]2024-10-12T23:35:51.389854Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 82.0 / 234  (35.0):  67%|██████▋   | 233/350 [00:15<00:07, 15.96it/s]2024-10-12T23:35:52.737759Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 84.0 / 239  (35.1):  68%|██████▊   | 238/350 [00:16<00:09, 12.23it/s]2024-10-12T23:35:53.208809Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 89.0 / 251  (35.5):  71%|███████▏  | 250/350 [00:17<00:07, 14.02it/s]2024-10-12T23:35:53.897333Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 99.0 / 280  (35.4):  80%|███████▉  | 279/350 [00:18<00:04, 16.34it/s]2024-10-12T23:35:55.577052Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 101.0 / 284  (35.6):  81%|████████  | 284/350 [00:19<00:04, 15.85it/s]2024-10-12T23:35:55.949599Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 104.0 / 294  (35.4):  84%|████████▎ | 293/350 [00:19<00:04, 13.16it/s]2024-10-12T23:35:56.820169Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 120.0 / 331  (36.3):  94%|█████████▍| 330/350 [00:20<00:00, 42.65it/s]2024-10-12T23:35:57.724732Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 125.0 / 350  (35.7): 100%|██████████| 350/350 [00:21<00:00, 16.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [22.29, 22.29, 36.86, 38.0, 13.43, 33.43, 33.71, 24.29, 35.71]\n",
      "Best score so far: 38.0\n",
      "9 candidate programs found.\n",
      "[('intent_classifier', Predict(StringSignature(intent -> reasoning, label\n",
      "    instructions=\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\\nThe intent should exactly match one of the following:\\n['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\"\n",
      "    intent = Field(annotation=str required=True json_schema_extra={'desc': 'Intent of the query', '__dspy_field_type': 'input', 'prefix': 'Intent:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the output fields}. We ...', '__dspy_field_type': 'output'})\n",
      "    label = Field(annotation=str required=True json_schema_extra={'desc': 'Type of the intent; Should just be one of the 25 labels with no other text', '__dspy_field_type': 'output', 'prefix': 'Label:'})\n",
      ")))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]2024-10-12T23:36:00.070967Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/500 [00:00<08:05,  1.03it/s]2024-10-12T23:36:00.126444Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/500 [00:01<08:05,  1.03it/s]2024-10-12T23:36:00.133199Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 46  (37.0):   9%|▉         | 45/500 [00:03<00:13, 34.24it/s] 024-10-12T23:36:02.275143Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 151  (42.4):  30%|███       | 150/500 [00:09<00:19, 17.89it/s]2024-10-12T23:36:09.044061Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 153  (41.8):  31%|███       | 153/500 [00:10<00:20, 17.01it/s]2024-10-12T23:36:09.314816Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 155  (41.3):  31%|███       | 154/500 [00:10<00:20, 17.01it/s]2024-10-12T23:36:09.450309Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 156  (41.0):  31%|███       | 156/500 [00:10<00:19, 17.34it/s]2024-10-12T23:36:09.633794Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 159  (40.3):  32%|███▏      | 158/500 [00:10<00:26, 12.80it/s]2024-10-12T23:36:09.954773Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 70.0 / 184  (38.0):  37%|███▋      | 183/500 [00:11<00:14, 22.35it/s]2024-10-12T23:36:11.120550Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 207  (38.6):  41%|████      | 206/500 [00:13<00:22, 13.06it/s]2024-10-12T23:36:12.857909Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 118.0 / 309  (38.2):  62%|██████▏   | 308/500 [00:20<00:16, 11.32it/s]2024-10-12T23:36:20.119943Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 138.0 / 365  (37.8):  73%|███████▎  | 364/500 [00:24<00:10, 12.89it/s]lineno0-12T23:36:23.688471Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 150.0 / 397  (37.8):  79%|███████▉  | 396/500 [00:26<00:07, 14.33it/s]2024-10-12T23:36:25.834059Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 154.0 / 412  (37.4):  82%|████████▏ | 411/500 [00:27<00:08, 11.05it/s]2024-10-12T23:36:27.023868Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 154.0 / 414  (37.2):  83%|████████▎ | 414/500 [00:28<00:05, 15.54it/s]filename   ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 163.0 / 443  (36.8):  89%|████████▊ | 443/500 [00:30<00:04, 13.29it/s]2024-10-12T23:36:29.123167Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 185.0 / 500  (37.0): 100%|██████████| 500/500 [00:31<00:00, 15.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for meta-llama/Llama-3.2-1B-Instruct:epochs-2-total-trained-steps-87: 37.0, None, None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]2024-10-12T23:36:31.322812Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/500 [00:00<04:28,  1.86it/s]]  Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/500 [00:00<04:28,  1.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   0%|          | 2/500 [00:00<04:28,  1.86it/s]2024-10-12T23:36:31.362201Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 3/500 [00:00<04:27,  1.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   1%|          | 4/500 [00:00<04:27,  1.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   1%|          | 6/500 [00:00<00:41, 11.78it/s]2024-10-12T23:36:31.391786Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   1%|          | 6/500 [00:00<00:41, 11.78it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   1%|▏         | 7/500 [00:00<00:41, 11.78it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 9  (0.0):   2%|▏         | 8/500 [00:00<00:41, 11.78it/s]2024-10-12T23:36:31.442866Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 10  (0.0):   2%|▏         | 9/500 [00:00<00:41, 11.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 11  (0.0):   2%|▏         | 10/500 [00:00<00:41, 11.78it/s]2024-10-12T23:36:31.640925Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 12  (0.0):   2%|▏         | 12/500 [00:00<00:25, 18.90it/s]2024-10-12T23:36:31.668977Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 13  (0.0):   2%|▏         | 12/500 [00:00<00:25, 18.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 14  (0.0):   3%|▎         | 13/500 [00:00<00:25, 18.90it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 15  (0.0):   3%|▎         | 15/500 [00:00<00:23, 21.08it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 16  (0.0):   3%|▎         | 15/500 [00:00<00:23, 21.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 17  (0.0):   3%|▎         | 16/500 [00:00<00:22, 21.08it/s]2024-10-12T23:36:31.761678Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 18  (0.0):   3%|▎         | 17/500 [00:01<00:22, 21.08it/s]2024-10-12T23:36:31.764969Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 19  (0.0):   4%|▎         | 18/500 [00:01<00:22, 21.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 20  (0.0):   4%|▍         | 20/500 [00:01<00:17, 26.67it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 21  (0.0):   4%|▍         | 20/500 [00:01<00:17, 26.67it/s]2024-10-12T23:36:31.798592Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 22  (0.0):   4%|▍         | 21/500 [00:01<00:17, 26.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 23  (0.0):   4%|▍         | 22/500 [00:01<00:17, 26.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 24  (0.0):   5%|▍         | 23/500 [00:01<00:17, 26.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 25  (0.0):   5%|▍         | 24/500 [00:01<00:17, 26.67it/s]2024-10-12T23:36:31.847116Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 26  (0.0):   5%|▌         | 26/500 [00:01<00:13, 34.25it/s]2024-10-12T23:36:31.864900Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 27  (0.0):   5%|▌         | 26/500 [00:01<00:13, 34.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 28  (0.0):   5%|▌         | 27/500 [00:01<00:13, 34.25it/s]2024-10-12T23:36:32.306653Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 29  (0.0):   6%|▌         | 28/500 [00:01<00:13, 34.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 31  (0.0):   6%|▌         | 31/500 [00:01<00:24, 19.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 33  (3.0):   6%|▋         | 32/500 [00:01<00:24, 19.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 34  (2.9):   7%|▋         | 33/500 [00:01<00:24, 19.11it/s]2024-10-12T23:36:32.396232Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 36  (2.8):   7%|▋         | 36/500 [00:01<00:20, 23.16it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 1.0 / 38  (2.6):   7%|▋         | 37/500 [00:01<00:19, 23.16it/s]linenor    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 1.0 / 40  (2.5):   8%|▊         | 39/500 [00:01<00:19, 23.16it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 41  (2.4):   8%|▊         | 40/500 [00:01<00:19, 23.16it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 43  (2.3):   8%|▊         | 42/500 [00:01<00:15, 29.54it/s] [ror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 44  (2.3):   9%|▊         | 43/500 [00:01<00:15, 29.54it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 45  (2.2):   9%|▉         | 44/500 [00:01<00:15, 29.54it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 47  (2.1):   9%|▉         | 46/500 [00:01<00:15, 29.54it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 48  (2.1):  10%|▉         | 48/500 [00:01<00:12, 34.84it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 50  (2.0):  10%|▉         | 49/500 [00:02<00:12, 34.84it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 51  (2.0):  10%|█         | 50/500 [00:02<00:12, 34.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 52  (1.9):  10%|█         | 51/500 [00:02<00:12, 34.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 53  (1.9):  10%|█         | 52/500 [00:02<00:12, 34.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 54  (1.9):  11%|█         | 54/500 [00:02<00:11, 38.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 55  (1.8):  11%|█         | 54/500 [00:02<00:11, 38.09it/s]2024-10-12T23:36:32.666690Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 56  (1.8):  11%|█         | 55/500 [00:02<00:11, 38.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 57  (1.8):  11%|█         | 56/500 [00:02<00:11, 38.09it/s]2024-10-12T23:36:32.721260Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 58  (1.7):  11%|█▏        | 57/500 [00:02<00:11, 38.09it/s]2024-10-12T23:36:32.738595Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 59  (1.7):  12%|█▏        | 58/500 [00:02<00:11, 38.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 60  (1.7):  12%|█▏        | 60/500 [00:02<00:10, 41.67it/s]] 24-10-12T23:36:32.762108Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 61  (1.6):  12%|█▏        | 60/500 [00:02<00:10, 41.67it/s]2024-10-12T23:36:32.768210Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 62  (1.6):  12%|█▏        | 61/500 [00:02<00:10, 41.67it/s]2024-10-12T23:36:32.795666Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 63  (1.6):  12%|█▏        | 62/500 [00:02<00:10, 41.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 64  (1.6):  13%|█▎        | 63/500 [00:02<00:10, 41.67it/s]2024-10-12T23:36:32.818045Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 65  (1.5):  13%|█▎        | 64/500 [00:02<00:10, 41.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 66  (1.5):  13%|█▎        | 66/500 [00:02<00:09, 44.88it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 67  (1.5):  13%|█▎        | 66/500 [00:02<00:09, 44.88it/s]2024-10-12T23:36:32.857681Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 68  (1.5):  13%|█▎        | 67/500 [00:02<00:09, 44.88it/s]2024-10-12T23:36:32.886350Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 69  (1.4):  14%|█▎        | 68/500 [00:02<00:09, 44.88it/s]2024-10-12T23:36:32.891685Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 70  (1.4):  14%|█▍        | 69/500 [00:02<00:09, 44.88it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 71  (1.4):  14%|█▍        | 70/500 [00:02<00:09, 44.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 72  (1.4):  14%|█▍        | 72/500 [00:02<00:09, 47.33it/s]error    2T23:36:32.985381Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 73  (1.4):  14%|█▍        | 72/500 [00:02<00:09, 47.33it/s]2024-10-12T23:36:33.018881Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 74  (1.4):  15%|█▍        | 73/500 [00:02<00:09, 47.33it/s]2024-10-12T23:36:33.080198Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 75  (1.3):  15%|█▍        | 74/500 [00:02<00:09, 47.33it/s]2024-10-12T23:36:33.480243Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 76  (1.3):  15%|█▌        | 75/500 [00:02<00:08, 47.33it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 77  (1.3):  15%|█▌        | 76/500 [00:02<00:08, 47.33it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 78  (1.3):  16%|█▌        | 78/500 [00:02<00:12, 34.78it/s]2024-10-12T23:36:33.502675Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 79  (1.3):  16%|█▌        | 78/500 [00:02<00:12, 34.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 81  (1.2):  16%|█▌        | 80/500 [00:02<00:12, 34.78it/s]2024-10-12T23:36:33.604175Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 82  (1.2):  16%|█▌        | 81/500 [00:02<00:12, 34.78it/s]2024-10-12T23:36:33.702923Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 83  (1.2):  17%|█▋        | 83/500 [00:02<00:12, 32.16it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 84  (1.2):  17%|█▋        | 83/500 [00:02<00:12, 32.16it/s]2024-10-12T23:36:33.724514Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 85  (1.2):  17%|█▋        | 84/500 [00:03<00:12, 32.16it/s]2024-10-12T23:36:33.751272Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 86  (1.2):  17%|█▋        | 85/500 [00:03<00:12, 32.16it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 87  (1.1):  17%|█▋        | 87/500 [00:03<00:13, 30.96it/s]2024-10-12T23:36:33.766083Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 88  (1.1):  17%|█▋        | 87/500 [00:03<00:13, 30.96it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 89  (1.1):  18%|█▊        | 88/500 [00:03<00:13, 30.96it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 90  (1.1):  18%|█▊        | 89/500 [00:03<00:13, 30.96it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 91  (1.1):  18%|█▊        | 90/500 [00:03<00:13, 30.96it/s]2024-10-12T23:36:33.826033Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 92  (1.1):  18%|█▊        | 92/500 [00:03<00:12, 33.64it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 93  (1.1):  18%|█▊        | 92/500 [00:03<00:12, 33.64it/s]2024-10-12T23:36:33.845603Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 94  (1.1):  19%|█▊        | 93/500 [00:03<00:12, 33.64it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 95  (1.1):  19%|█▉        | 94/500 [00:03<00:12, 33.64it/s]2024-10-12T23:36:33.862792Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 96  (1.0):  19%|█▉        | 95/500 [00:03<00:12, 33.64it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 97  (1.0):  19%|█▉        | 96/500 [00:03<00:12, 33.64it/s]2024-10-12T23:36:33.872734Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 98  (1.0):  20%|█▉        | 98/500 [00:03<00:10, 39.14it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 99  (1.0):  20%|█▉        | 98/500 [00:03<00:10, 39.14it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 100  (1.0):  20%|█▉        | 99/500 [00:03<00:10, 39.14it/s]2024-10-12T23:36:33.897593Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 101  (1.0):  20%|██        | 100/500 [00:03<00:10, 39.14it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 102  (1.0):  20%|██        | 101/500 [00:03<00:10, 39.14it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 103  (1.0):  20%|██        | 102/500 [00:03<00:10, 39.14it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 104  (1.0):  21%|██        | 104/500 [00:03<00:09, 43.81it/s]2024-10-12T23:36:33.927085Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 105  (1.0):  21%|██        | 104/500 [00:03<00:09, 43.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 106  (0.9):  21%|██        | 105/500 [00:03<00:09, 43.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 107  (0.9):  21%|██        | 106/500 [00:03<00:08, 43.81it/s]2024-10-12T23:36:33.971179Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 108  (0.9):  21%|██▏       | 107/500 [00:03<00:08, 43.81it/s]2024-10-12T23:36:34.378889Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 109  (0.9):  22%|██▏       | 109/500 [00:03<00:10, 36.09it/s] [24-10-12T23:36:34.382956Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 110  (0.9):  22%|██▏       | 109/500 [00:03<00:10, 36.09it/s]2024-10-12T23:36:34.388640Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 111  (0.9):  22%|██▏       | 110/500 [00:03<00:10, 36.09it/s]2024-10-12T23:36:34.422642Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 112  (0.9):  22%|██▏       | 111/500 [00:03<00:10, 36.09it/s]2024-10-12T23:36:34.426796Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 113  (0.9):  22%|██▏       | 112/500 [00:03<00:10, 36.09it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 114  (0.9):  23%|██▎       | 114/500 [00:03<00:10, 36.99it/s]error    2T23:36:34.451287Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 115  (0.9):  23%|██▎       | 114/500 [00:03<00:10, 36.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 116  (0.9):  23%|██▎       | 115/500 [00:03<00:10, 36.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 117  (0.9):  23%|██▎       | 116/500 [00:03<00:10, 36.99it/s]2024-10-12T23:36:34.497715Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 118  (0.8):  23%|██▎       | 117/500 [00:03<00:10, 36.99it/s]2024-10-12T23:36:34.500744Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 119  (0.8):  24%|██▎       | 118/500 [00:03<00:10, 36.99it/s]2024-10-12T23:36:34.537013Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 121  (1.7):  24%|██▍       | 120/500 [00:03<00:09, 41.68it/s]2024-10-12T23:36:34.735213Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 122  (1.6):  24%|██▍       | 121/500 [00:03<00:09, 41.68it/s]2024-10-12T23:36:34.766210Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 123  (1.6):  24%|██▍       | 122/500 [00:03<00:09, 41.68it/s]2024-10-12T23:36:34.771061Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 124  (1.6):  25%|██▍       | 123/500 [00:03<00:09, 41.68it/s]2024-10-12T23:36:34.806784Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 126  (1.6):  25%|██▌       | 125/500 [00:04<00:10, 36.58it/s]2024-10-12T23:36:34.935893Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 127  (1.6):  25%|██▌       | 126/500 [00:04<00:10, 36.58it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 128  (1.6):  25%|██▌       | 127/500 [00:04<00:10, 36.58it/s]2024-10-12T23:36:34.966387Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 129  (1.6):  26%|██▌       | 128/500 [00:04<00:10, 36.58it/s]2024-10-12T23:36:34.975404Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 130  (1.5):  26%|██▌       | 130/500 [00:04<00:12, 29.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 131  (1.5):  26%|██▌       | 130/500 [00:04<00:12, 29.88it/s]2024-10-12T23:36:34.996987Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 132  (1.5):  26%|██▌       | 131/500 [00:04<00:12, 29.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 133  (1.5):  26%|██▋       | 132/500 [00:04<00:12, 29.88it/s]2024-10-12T23:36:35.026455Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 134  (1.5):  27%|██▋       | 134/500 [00:04<00:11, 31.60it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 135  (1.5):  27%|██▋       | 134/500 [00:04<00:11, 31.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 136  (1.5):  27%|██▋       | 135/500 [00:04<00:11, 31.60it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 137  (1.5):  27%|██▋       | 136/500 [00:04<00:11, 31.60it/s]2024-10-12T23:36:35.052746Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 138  (1.4):  27%|██▋       | 137/500 [00:04<00:11, 31.60it/s]2024-10-12T23:36:35.073087Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 139  (1.4):  28%|██▊       | 138/500 [00:04<00:11, 31.60it/s]2024-10-12T23:36:35.100513Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 140  (1.4):  28%|██▊       | 140/500 [00:04<00:09, 37.07it/s]2024-10-12T23:36:35.106132Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 141  (1.4):  28%|██▊       | 140/500 [00:04<00:09, 37.07it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 142  (1.4):  28%|██▊       | 141/500 [00:04<00:09, 37.07it/s]2024-10-12T23:36:35.132641Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 143  (1.4):  28%|██▊       | 142/500 [00:04<00:09, 37.07it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 144  (1.4):  29%|██▊       | 143/500 [00:04<00:09, 37.07it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 145  (1.4):  29%|██▉       | 144/500 [00:04<00:09, 37.07it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 146  (1.4):  29%|██▉       | 145/500 [00:04<00:09, 37.07it/s]2024-10-12T23:36:35.173270Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 147  (1.4):  29%|██▉       | 147/500 [00:04<00:08, 43.33it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 149  (1.3):  30%|██▉       | 148/500 [00:04<00:08, 43.33it/s]2024-10-12T23:36:35.524789Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label', 'reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 150  (1.3):  30%|██▉       | 149/500 [00:04<00:08, 43.33it/s]2024-10-12T23:36:35.558602Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 151  (1.3):  30%|███       | 150/500 [00:04<00:08, 43.33it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 153  (2.0):  30%|███       | 152/500 [00:04<00:09, 35.42it/s]2024-10-12T23:36:35.566851Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 154  (1.9):  31%|███       | 153/500 [00:04<00:09, 35.42it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 155  (1.9):  31%|███       | 154/500 [00:04<00:09, 35.42it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 156  (1.9):  31%|███       | 155/500 [00:04<00:09, 35.42it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 157  (1.9):  31%|███       | 156/500 [00:04<00:09, 35.42it/s]2024-10-12T23:36:35.623200Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 159  (1.9):  32%|███▏      | 158/500 [00:05<00:08, 40.06it/s]2024-10-12T23:36:35.804689Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 160  (1.9):  32%|███▏      | 159/500 [00:05<00:08, 40.06it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 161  (1.9):  32%|███▏      | 160/500 [00:05<00:08, 40.06it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 162  (1.9):  32%|███▏      | 161/500 [00:05<00:08, 40.06it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 164  (2.4):  33%|███▎      | 163/500 [00:05<00:09, 34.38it/s]error    2T23:36:35.853578Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 165  (2.4):  33%|███▎      | 164/500 [00:05<00:09, 34.38it/s]2024-10-12T23:36:35.875721Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 166  (2.4):  33%|███▎      | 165/500 [00:05<00:09, 34.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 167  (2.4):  33%|███▎      | 166/500 [00:05<00:09, 34.38it/s]2024-10-12T23:36:35.934797Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 169  (2.4):  34%|███▍      | 169/500 [00:05<00:09, 33.27it/s]2024-10-12T23:36:36.112590Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 170  (2.4):  34%|███▍      | 169/500 [00:05<00:09, 33.27it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 171  (2.3):  34%|███▍      | 170/500 [00:05<00:09, 33.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 172  (2.3):  34%|███▍      | 171/500 [00:05<00:09, 33.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 173  (2.3):  35%|███▍      | 173/500 [00:05<00:09, 33.31it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 174  (2.3):  35%|███▍      | 173/500 [00:05<00:09, 33.31it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 175  (2.3):  35%|███▍      | 174/500 [00:05<00:09, 33.31it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 176  (2.3):  35%|███▌      | 175/500 [00:05<00:09, 33.31it/s]2024-10-12T23:36:36.184415Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 177  (2.3):  35%|███▌      | 176/500 [00:05<00:09, 33.31it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 178  (2.2):  36%|███▌      | 178/500 [00:05<00:08, 36.77it/s]2024-10-12T23:36:36.207157Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 179  (2.2):  36%|███▌      | 178/500 [00:05<00:08, 36.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 180  (2.2):  36%|███▌      | 179/500 [00:05<00:08, 36.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 181  (2.2):  36%|███▌      | 180/500 [00:05<00:08, 36.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 182  (2.2):  36%|███▌      | 181/500 [00:05<00:08, 36.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 184  (2.2):  37%|███▋      | 184/500 [00:05<00:09, 33.98it/s]2024-10-12T23:36:36.536676Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 185  (2.2):  37%|███▋      | 184/500 [00:05<00:09, 33.98it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 187  (2.1):  37%|███▋      | 186/500 [00:05<00:09, 33.98it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 188  (2.1):  38%|███▊      | 188/500 [00:05<00:09, 34.13it/s]2024-10-12T23:36:36.579096Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 189  (2.1):  38%|███▊      | 188/500 [00:05<00:09, 34.13it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 190  (2.1):  38%|███▊      | 189/500 [00:05<00:09, 34.13it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 191  (2.1):  38%|███▊      | 190/500 [00:05<00:09, 34.13it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 192  (2.1):  38%|███▊      | 191/500 [00:05<00:09, 34.13it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 193  (2.1):  38%|███▊      | 192/500 [00:05<00:09, 34.13it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 194  (2.1):  39%|███▉      | 194/500 [00:05<00:07, 38.77it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 195  (2.1):  39%|███▉      | 194/500 [00:05<00:07, 38.77it/s]2024-10-12T23:36:36.671343Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 196  (2.0):  39%|███▉      | 195/500 [00:05<00:07, 38.77it/s]2024-10-12T23:36:36.875165Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 197  (2.0):  39%|███▉      | 196/500 [00:06<00:07, 38.77it/s]2024-10-12T23:36:36.898486Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 198  (2.0):  39%|███▉      | 197/500 [00:06<00:07, 38.77it/s]2024-10-12T23:36:36.903285Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 199  (2.0):  40%|███▉      | 199/500 [00:06<00:08, 33.70it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 200  (2.0):  40%|███▉      | 199/500 [00:06<00:08, 33.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 201  (2.0):  40%|████      | 200/500 [00:06<00:08, 33.70it/s]2024-10-12T23:36:36.941326Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 202  (2.0):  40%|████      | 201/500 [00:06<00:08, 33.70it/s]2024-10-12T23:36:37.094994Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 203  (2.0):  41%|████      | 203/500 [00:06<00:09, 31.27it/s]2024-10-12T23:36:37.118952Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 204  (2.0):  41%|████      | 203/500 [00:06<00:09, 31.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 206  (1.9):  41%|████      | 205/500 [00:06<00:09, 31.27it/s]2024-10-12T23:36:37.134294Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 208  (1.9):  41%|████▏     | 207/500 [00:06<00:09, 32.18it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 210  (1.9):  42%|████▏     | 209/500 [00:06<00:09, 32.18it/s]2024-10-12T23:36:37.172874Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 211  (1.9):  42%|████▏     | 210/500 [00:06<00:09, 32.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 212  (1.9):  42%|████▏     | 211/500 [00:06<00:08, 32.18it/s]2024-10-12T23:36:37.210352Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 213  (1.9):  43%|████▎     | 213/500 [00:06<00:07, 38.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 214  (1.9):  43%|████▎     | 213/500 [00:06<00:07, 38.23it/s]2024-10-12T23:36:37.239542Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 215  (1.9):  43%|████▎     | 214/500 [00:06<00:07, 38.23it/s]2024-10-12T23:36:37.292785Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 216  (1.9):  43%|████▎     | 215/500 [00:06<00:07, 38.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 217  (1.8):  43%|████▎     | 216/500 [00:06<00:07, 38.23it/s]2024-10-12T23:36:37.488654Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 218  (1.8):  44%|████▎     | 218/500 [00:06<00:08, 34.64it/s]2024-10-12T23:36:37.526154Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 219  (1.8):  44%|████▎     | 218/500 [00:06<00:08, 34.64it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 220  (1.8):  44%|████▍     | 219/500 [00:06<00:08, 34.64it/s]2024-10-12T23:36:37.535225Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 221  (1.8):  44%|████▍     | 220/500 [00:06<00:08, 34.64it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 223  (1.8):  44%|████▍     | 222/500 [00:06<00:08, 33.87it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 224  (1.8):  45%|████▍     | 223/500 [00:06<00:08, 33.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 225  (1.8):  45%|████▍     | 224/500 [00:06<00:08, 33.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 226  (1.8):  45%|████▌     | 225/500 [00:06<00:08, 33.87it/s]2024-10-12T23:36:37.595557Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 227  (1.8):  45%|████▌     | 226/500 [00:06<00:08, 33.87it/s]2024-10-12T23:36:37.600378Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 228  (1.8):  45%|████▌     | 227/500 [00:06<00:08, 33.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 229  (1.7):  46%|████▌     | 229/500 [00:06<00:06, 41.26it/s]2024-10-12T23:36:37.826316Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 230  (1.7):  46%|████▌     | 229/500 [00:07<00:06, 41.26it/s]2024-10-12T23:36:37.847794Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 232  (1.7):  46%|████▌     | 231/500 [00:07<00:06, 41.26it/s]2024-10-12T23:36:37.868714Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 233  (1.7):  46%|████▋     | 232/500 [00:07<00:06, 41.26it/s]2024-10-12T23:36:37.914015Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 235  (1.7):  47%|████▋     | 234/500 [00:07<00:07, 35.56it/s]2024-10-12T23:36:38.030788Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 236  (1.7):  47%|████▋     | 235/500 [00:07<00:07, 35.56it/s]2024-10-12T23:36:38.061594Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 237  (1.7):  47%|████▋     | 236/500 [00:07<00:07, 35.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 239  (1.7):  48%|████▊     | 238/500 [00:07<00:08, 30.81it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 240  (1.7):  48%|████▊     | 239/500 [00:07<00:08, 30.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 241  (1.7):  48%|████▊     | 240/500 [00:07<00:08, 30.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 242  (1.7):  48%|████▊     | 241/500 [00:07<00:08, 30.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 246  (1.6):  49%|████▉     | 245/500 [00:07<00:11, 22.68it/s] [24-10-12T23:36:38.532277Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 4.0 / 247  (1.6):  49%|████▉     | 247/500 [00:07<00:10, 23.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 249  (1.6):  50%|████▉     | 248/500 [00:07<00:10, 23.30it/s]dspy.evaluate.evaluate example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 250  (1.6):  50%|████▉     | 249/500 [00:07<00:10, 23.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 251  (1.6):  50%|█████     | 250/500 [00:07<00:10, 23.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 252  (1.6):  50%|█████     | 252/500 [00:07<00:09, 27.22it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 255  (1.6):  51%|█████     | 254/500 [00:07<00:09, 27.22it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 257  (1.6):  51%|█████     | 256/500 [00:08<00:08, 27.22it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 258  (1.6):  51%|█████▏    | 257/500 [00:08<00:08, 27.22it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 259  (1.5):  52%|█████▏    | 259/500 [00:08<00:06, 35.21it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 260  (1.5):  52%|█████▏    | 259/500 [00:08<00:06, 35.21it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 261  (1.5):  52%|█████▏    | 260/500 [00:08<00:06, 35.21it/s]2024-10-12T23:36:38.707909Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 262  (1.5):  52%|█████▏    | 261/500 [00:08<00:06, 35.21it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 263  (1.5):  52%|█████▏    | 262/500 [00:08<00:06, 35.21it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 264  (1.5):  53%|█████▎    | 264/500 [00:08<00:06, 37.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 265  (1.5):  53%|█████▎    | 264/500 [00:08<00:06, 37.81it/s]2024-10-12T23:36:38.752700Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 266  (1.5):  53%|█████▎    | 265/500 [00:08<00:06, 37.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 267  (1.5):  53%|█████▎    | 266/500 [00:08<00:06, 37.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 268  (1.5):  53%|█████▎    | 267/500 [00:08<00:06, 37.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 269  (1.5):  54%|█████▎    | 268/500 [00:08<00:06, 37.81it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 270  (1.5):  54%|█████▍    | 270/500 [00:08<00:05, 41.84it/s]] 24-10-12T23:36:38.867205Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 271  (1.5):  54%|█████▍    | 270/500 [00:08<00:05, 41.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 272  (1.5):  54%|█████▍    | 271/500 [00:08<00:05, 41.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 273  (1.5):  54%|█████▍    | 272/500 [00:08<00:05, 41.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 274  (1.5):  55%|█████▍    | 273/500 [00:08<00:05, 41.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 275  (1.5):  55%|█████▍    | 274/500 [00:08<00:05, 41.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 276  (1.4):  55%|█████▌    | 276/500 [00:08<00:04, 45.90it/s]2024-10-12T23:36:39.224923Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 277  (1.4):  55%|█████▌    | 276/500 [00:08<00:04, 45.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 279  (1.4):  56%|█████▌    | 278/500 [00:08<00:04, 45.90it/s]2024-10-12T23:36:39.322314Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 281  (1.4):  56%|█████▌    | 281/500 [00:08<00:05, 38.56it/s]2024-10-12T23:36:39.457125Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 282  (1.4):  56%|█████▌    | 281/500 [00:08<00:05, 38.56it/s]2024-10-12T23:36:39.483667Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 285  (1.8):  57%|█████▋    | 284/500 [00:08<00:05, 38.56it/s] spy.evaluate.evaluate example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.pylineno=198\n",
      "Average Metric: 5.0 / 286  (1.7):  57%|█████▋    | 286/500 [00:08<00:06, 34.35it/s]2024-10-12T23:36:39.493150Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 287  (1.7):  57%|█████▋    | 286/500 [00:08<00:06, 34.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 288  (1.7):  57%|█████▋    | 287/500 [00:08<00:06, 34.35it/s]2024-10-12T23:36:39.688812Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 289  (1.7):  58%|█████▊    | 288/500 [00:08<00:06, 34.35it/s]2024-10-12T23:36:39.710710Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 290  (1.7):  58%|█████▊    | 290/500 [00:08<00:06, 30.29it/s]2024-10-12T23:36:39.741413Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 291  (1.7):  58%|█████▊    | 290/500 [00:08<00:06, 30.29it/s]2024-10-12T23:36:39.750419Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 292  (1.7):  58%|█████▊    | 291/500 [00:08<00:06, 30.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 293  (1.7):  58%|█████▊    | 292/500 [00:09<00:06, 30.29it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 294  (1.7):  59%|█████▉    | 294/500 [00:09<00:06, 30.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 295  (1.7):  59%|█████▉    | 294/500 [00:09<00:06, 30.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 296  (1.7):  59%|█████▉    | 295/500 [00:09<00:06, 30.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 297  (1.7):  59%|█████▉    | 296/500 [00:09<00:06, 30.66it/s]2024-10-12T23:36:39.814022Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 298  (1.7):  59%|█████▉    | 297/500 [00:09<00:06, 30.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 299  (1.7):  60%|█████▉    | 298/500 [00:09<00:06, 30.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 300  (1.7):  60%|██████    | 300/500 [00:09<00:05, 36.78it/s]2024-10-12T23:36:39.860780Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 301  (1.7):  60%|██████    | 300/500 [00:09<00:05, 36.78it/s]2024-10-12T23:36:40.064705Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 303  (1.7):  60%|██████    | 302/500 [00:09<00:05, 36.78it/s]dspy.evaluate.evaluate8203Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 304  (1.6):  61%|██████    | 303/500 [00:09<00:05, 36.78it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 306  (1.6):  61%|██████    | 305/500 [00:09<00:06, 32.46it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 307  (1.6):  61%|██████    | 306/500 [00:09<00:05, 32.46it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 308  (1.6):  61%|██████▏   | 307/500 [00:09<00:05, 32.46it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 309  (1.6):  62%|██████▏   | 308/500 [00:09<00:05, 32.46it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 310  (1.6):  62%|██████▏   | 309/500 [00:09<00:05, 32.46it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 311  (1.6):  62%|██████▏   | 311/500 [00:09<00:05, 37.50it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 312  (1.6):  62%|██████▏   | 311/500 [00:09<00:05, 37.50it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 314  (1.6):  63%|██████▎   | 313/500 [00:09<00:04, 37.50it/s]2024-10-12T23:36:40.395945Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 316  (1.6):  63%|██████▎   | 316/500 [00:09<00:05, 31.79it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 317  (1.6):  63%|██████▎   | 316/500 [00:09<00:05, 31.79it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 318  (1.6):  63%|██████▎   | 317/500 [00:09<00:05, 31.79it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 319  (1.6):  64%|██████▎   | 318/500 [00:09<00:05, 31.79it/s]2024-10-12T23:36:40.440047Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 320  (1.6):  64%|██████▍   | 319/500 [00:09<00:05, 31.79it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 321  (1.6):  64%|██████▍   | 320/500 [00:09<00:05, 31.79it/s]2024-10-12T23:36:40.485369Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 322  (1.6):  64%|██████▍   | 322/500 [00:09<00:04, 36.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 323  (1.5):  64%|██████▍   | 322/500 [00:09<00:04, 36.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 324  (1.5):  65%|██████▍   | 323/500 [00:09<00:04, 36.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 325  (1.5):  65%|██████▍   | 324/500 [00:09<00:04, 36.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 326  (1.5):  65%|██████▌   | 325/500 [00:09<00:04, 36.90it/s]2024-10-12T23:36:40.597540Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 327  (1.5):  65%|██████▌   | 326/500 [00:09<00:04, 36.90it/s]2024-10-12T23:36:40.773944Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 328  (1.5):  66%|██████▌   | 328/500 [00:09<00:05, 33.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 329  (1.5):  66%|██████▌   | 328/500 [00:09<00:05, 33.90it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 330  (1.5):  66%|██████▌   | 329/500 [00:10<00:05, 33.90it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 331  (1.5):  66%|██████▌   | 330/500 [00:10<00:05, 33.90it/s]2024-10-12T23:36:40.861886Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 332  (1.5):  66%|██████▌   | 331/500 [00:10<00:04, 33.90it/s]2024-10-12T23:36:40.962411Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 333  (1.5):  67%|██████▋   | 333/500 [00:10<00:05, 31.91it/s]2024-10-12T23:36:40.988677Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 335  (1.5):  67%|██████▋   | 334/500 [00:10<00:05, 31.91it/s]2024-10-12T23:36:40.992424Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 336  (1.5):  67%|██████▋   | 335/500 [00:10<00:05, 31.91it/s]2024-10-12T23:36:41.037066Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 337  (1.5):  67%|██████▋   | 336/500 [00:10<00:05, 31.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 338  (1.5):  68%|██████▊   | 338/500 [00:10<00:04, 35.23it/s]2024-10-12T23:36:41.056148Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 339  (1.5):  68%|██████▊   | 338/500 [00:10<00:04, 35.23it/s]2024-10-12T23:36:41.198342Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 341  (1.5):  68%|██████▊   | 340/500 [00:10<00:04, 35.23it/s]2024-10-12T23:36:41.211156Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 342  (1.5):  68%|██████▊   | 342/500 [00:10<00:05, 30.31it/s]2024-10-12T23:36:41.220922Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 344  (1.5):  69%|██████▊   | 343/500 [00:10<00:05, 30.31it/s]2024-10-12T23:36:41.223561Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 345  (1.4):  69%|██████▉   | 344/500 [00:10<00:05, 30.31it/s]2024-10-12T23:36:41.255691Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 346  (1.4):  69%|██████▉   | 346/500 [00:10<00:04, 32.07it/s] [24-10-12T23:36:41.261691Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 347  (1.4):  69%|██████▉   | 346/500 [00:10<00:04, 32.07it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 348  (1.4):  69%|██████▉   | 347/500 [00:10<00:04, 32.07it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 349  (1.4):  70%|██████▉   | 348/500 [00:10<00:04, 32.07it/s]2024-10-12T23:36:41.309558Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 350  (1.4):  70%|██████▉   | 349/500 [00:10<00:04, 32.07it/s]2024-10-12T23:36:41.325064Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 351  (1.4):  70%|███████   | 350/500 [00:10<00:04, 32.07it/s]2024-10-12T23:36:41.340122Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 352  (1.4):  70%|███████   | 352/500 [00:10<00:03, 37.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 353  (1.4):  70%|███████   | 352/500 [00:10<00:03, 37.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 354  (1.4):  71%|███████   | 353/500 [00:10<00:03, 37.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 355  (1.4):  71%|███████   | 354/500 [00:10<00:03, 37.56it/s]2024-10-12T23:36:41.407494Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 356  (1.4):  71%|███████   | 355/500 [00:10<00:03, 37.56it/s]2024-10-12T23:36:41.660402Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 357  (1.4):  71%|███████▏  | 357/500 [00:10<00:04, 32.48it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 359  (1.4):  72%|███████▏  | 358/500 [00:10<00:04, 32.48it/s]2024-10-12T23:36:41.673074Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 5.0 / 360  (1.4):  72%|███████▏  | 359/500 [00:10<00:04, 32.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 362  (1.7):  72%|███████▏  | 361/500 [00:10<00:04, 32.98it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 363  (1.7):  72%|███████▏  | 362/500 [00:11<00:04, 32.98it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 364  (1.6):  73%|███████▎  | 363/500 [00:11<00:04, 32.98it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 365  (1.6):  73%|███████▎  | 364/500 [00:11<00:04, 32.98it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 366  (1.6):  73%|███████▎  | 365/500 [00:11<00:04, 32.98it/s]2024-10-12T23:36:41.785634Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 367  (1.6):  73%|███████▎  | 367/500 [00:11<00:03, 38.44it/s]error    2T23:36:41.789075Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 368  (1.6):  73%|███████▎  | 367/500 [00:11<00:03, 38.44it/s]2024-10-12T23:36:41.793562Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 369  (1.6):  74%|███████▎  | 368/500 [00:11<00:03, 38.44it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 370  (1.6):  74%|███████▍  | 369/500 [00:11<00:03, 38.44it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 371  (1.6):  74%|███████▍  | 370/500 [00:11<00:03, 38.44it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 372  (1.6):  74%|███████▍  | 371/500 [00:11<00:03, 38.44it/s]2024-10-12T23:36:41.849373Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 373  (1.6):  75%|███████▍  | 373/500 [00:11<00:02, 43.45it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 374  (1.6):  75%|███████▍  | 373/500 [00:11<00:02, 43.45it/s]2024-10-12T23:36:42.134737Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 375  (1.6):  75%|███████▍  | 374/500 [00:11<00:02, 43.45it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 376  (1.6):  75%|███████▌  | 375/500 [00:11<00:02, 43.45it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 377  (1.6):  75%|███████▌  | 376/500 [00:11<00:02, 43.45it/s]2024-10-12T23:36:42.157536Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 378  (1.6):  76%|███████▌  | 378/500 [00:11<00:03, 31.44it/s]2024-10-12T23:36:42.177329Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 379  (1.6):  76%|███████▌  | 378/500 [00:11<00:03, 31.44it/s]2024-10-12T23:36:42.310649Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['label']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 380  (1.6):  76%|███████▌  | 379/500 [00:11<00:03, 31.44it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 381  (1.6):  76%|███████▌  | 380/500 [00:11<00:03, 31.44it/s]2024-10-12T23:36:42.346048Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 382  (1.6):  76%|███████▌  | 381/500 [00:11<00:03, 31.44it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 383  (1.6):  77%|███████▋  | 383/500 [00:11<00:03, 34.18it/s]] 24-10-12T23:36:42.368422Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 384  (1.6):  77%|███████▋  | 383/500 [00:11<00:03, 34.18it/s]2024-10-12T23:36:42.522709Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 385  (1.6):  77%|███████▋  | 384/500 [00:11<00:03, 34.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 386  (1.6):  77%|███████▋  | 385/500 [00:11<00:03, 34.18it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 387  (1.6):  77%|███████▋  | 387/500 [00:11<00:04, 27.99it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 388  (1.5):  77%|███████▋  | 387/500 [00:11<00:04, 27.99it/s]2024-10-12T23:36:42.568773Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 389  (1.5):  78%|███████▊  | 388/500 [00:11<00:04, 27.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 390  (1.5):  78%|███████▊  | 389/500 [00:11<00:03, 27.99it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 391  (1.5):  78%|███████▊  | 390/500 [00:11<00:03, 27.99it/s]2024-10-12T23:36:42.588590Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 392  (1.5):  78%|███████▊  | 391/500 [00:11<00:03, 27.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 393  (1.5):  79%|███████▊  | 393/500 [00:11<00:03, 33.50it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 394  (1.5):  79%|███████▊  | 393/500 [00:11<00:03, 33.50it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 395  (1.5):  79%|███████▉  | 394/500 [00:11<00:03, 33.50it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 396  (1.5):  79%|███████▉  | 395/500 [00:11<00:03, 33.50it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 397  (1.5):  79%|███████▉  | 396/500 [00:11<00:03, 33.50it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 398  (1.5):  79%|███████▉  | 397/500 [00:11<00:03, 33.50it/s]2024-10-12T23:36:42.911267Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 399  (1.5):  80%|███████▉  | 399/500 [00:12<00:03, 32.14it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 400  (1.5):  80%|███████▉  | 399/500 [00:12<00:03, 32.14it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 402  (1.5):  80%|████████  | 401/500 [00:12<00:03, 32.14it/s]2024-10-12T23:36:42.963123Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 403  (1.5):  80%|████████  | 402/500 [00:12<00:03, 32.14it/s]2024-10-12T23:36:43.008429Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 404  (1.5):  81%|████████  | 404/500 [00:12<00:02, 35.71it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 405  (1.5):  81%|████████  | 404/500 [00:12<00:02, 35.71it/s]2024-10-12T23:36:43.030408Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 406  (1.5):  81%|████████  | 405/500 [00:12<00:02, 35.71it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 407  (1.5):  81%|████████  | 406/500 [00:12<00:02, 35.71it/s]2024-10-12T23:36:43.184803Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 408  (1.5):  81%|████████▏ | 407/500 [00:12<00:02, 35.71it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 409  (1.5):  82%|████████▏ | 409/500 [00:12<00:02, 30.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 411  (1.5):  82%|████████▏ | 410/500 [00:12<00:02, 30.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 413  (1.5):  82%|████████▏ | 412/500 [00:12<00:02, 30.82it/s]filename12T23:36:43.236160Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 414  (1.4):  83%|████████▎ | 414/500 [00:12<00:02, 34.23it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 415  (1.4):  83%|████████▎ | 414/500 [00:12<00:02, 34.23it/s]2024-10-12T23:36:43.266065Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 416  (1.4):  83%|████████▎ | 415/500 [00:12<00:02, 34.23it/s]2024-10-12T23:36:43.272783Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 417  (1.4):  83%|████████▎ | 416/500 [00:12<00:02, 34.23it/s]2024-10-12T23:36:43.276225Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 418  (1.4):  83%|████████▎ | 417/500 [00:12<00:02, 34.23it/s]2024-10-12T23:36:43.279525Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 419  (1.4):  84%|████████▎ | 418/500 [00:12<00:02, 34.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 420  (1.4):  84%|████████▍ | 420/500 [00:12<00:02, 39.57it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 421  (1.4):  84%|████████▍ | 420/500 [00:12<00:02, 39.57it/s]2024-10-12T23:36:43.318057Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 422  (1.4):  84%|████████▍ | 421/500 [00:12<00:01, 39.57it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 423  (1.4):  84%|████████▍ | 422/500 [00:12<00:01, 39.57it/s]2024-10-12T23:36:43.361332Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 424  (1.4):  85%|████████▍ | 423/500 [00:12<00:01, 39.57it/s]2024-10-12T23:36:43.633985Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 426  (1.4):  85%|████████▌ | 425/500 [00:12<00:02, 33.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 427  (1.4):  85%|████████▌ | 426/500 [00:12<00:02, 33.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 429  (1.4):  86%|████████▌ | 428/500 [00:12<00:02, 33.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 430  (1.4):  86%|████████▌ | 429/500 [00:12<00:02, 33.08it/s]2024-10-12T23:36:43.677346Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 431  (1.4):  86%|████████▌ | 431/500 [00:12<00:01, 38.01it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 432  (1.4):  86%|████████▌ | 431/500 [00:12<00:01, 38.01it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 433  (1.4):  86%|████████▋ | 432/500 [00:12<00:01, 38.01it/s]2024-10-12T23:36:43.723812Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 434  (1.4):  87%|████████▋ | 433/500 [00:13<00:01, 38.01it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 435  (1.4):  87%|████████▋ | 434/500 [00:13<00:01, 38.01it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 436  (1.4):  87%|████████▋ | 435/500 [00:13<00:01, 38.01it/s]2024-10-12T23:36:43.794210Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 437  (1.4):  87%|████████▋ | 437/500 [00:13<00:01, 42.54it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 439  (1.4):  88%|████████▊ | 438/500 [00:13<00:01, 42.54it/s]2024-10-12T23:36:44.058813Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 440  (1.4):  88%|████████▊ | 439/500 [00:13<00:01, 42.54it/s]2024-10-12T23:36:44.080421Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 441  (1.4):  88%|████████▊ | 440/500 [00:13<00:01, 42.54it/s]2024-10-12T23:36:44.091216Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 442  (1.4):  88%|████████▊ | 442/500 [00:13<00:01, 33.79it/s]2024-10-12T23:36:44.126487Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 443  (1.4):  88%|████████▊ | 442/500 [00:13<00:01, 33.79it/s]2024-10-12T23:36:44.262446Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 444  (1.4):  89%|████████▊ | 443/500 [00:13<00:01, 33.79it/s]2024-10-12T23:36:44.267987Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 445  (1.3):  89%|████████▉ | 444/500 [00:13<00:01, 33.79it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 446  (1.3):  89%|████████▉ | 446/500 [00:13<00:01, 27.27it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 448  (1.3):  89%|████████▉ | 447/500 [00:13<00:01, 27.27it/s]error    2T23:36:44.307050Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 449  (1.3):  90%|████████▉ | 448/500 [00:13<00:01, 27.27it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 450  (1.3):  90%|████████▉ | 449/500 [00:13<00:01, 27.27it/s]2024-10-12T23:36:44.315614Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 451  (1.3):  90%|█████████ | 450/500 [00:13<00:01, 27.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 452  (1.3):  90%|█████████ | 451/500 [00:13<00:01, 27.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 453  (1.3):  90%|█████████ | 452/500 [00:13<00:01, 27.27it/s]2024-10-12T23:36:44.363068Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 454  (1.3):  91%|█████████ | 454/500 [00:13<00:01, 36.61it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 455  (1.3):  91%|█████████ | 454/500 [00:13<00:01, 36.61it/s]2024-10-12T23:36:44.395368Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 456  (1.3):  91%|█████████ | 455/500 [00:13<00:01, 36.61it/s]2024-10-12T23:36:44.429417Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 457  (1.3):  91%|█████████ | 456/500 [00:13<00:01, 36.61it/s]2024-10-12T23:36:44.727377Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 458  (1.3):  91%|█████████▏| 457/500 [00:13<00:01, 36.61it/s]2024-10-12T23:36:44.747796Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 461  (1.3):  92%|█████████▏| 460/500 [00:14<00:01, 26.10it/s]2024-10-12T23:36:44.763335Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 463  (1.3):  92%|█████████▏| 462/500 [00:14<00:01, 26.10it/s]2024-10-12T23:36:44.780736Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 464  (1.3):  93%|█████████▎| 463/500 [00:14<00:01, 26.10it/s]2024-10-12T23:36:44.784209Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 466  (1.3):  93%|█████████▎| 465/500 [00:14<00:01, 26.10it/s]2024-10-12T23:36:44.792321Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 469  (1.3):  94%|█████████▎| 468/500 [00:14<00:01, 26.10it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 470  (1.3):  94%|█████████▍| 470/500 [00:14<00:00, 39.70it/s]2024-10-12T23:36:44.799738Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 471  (1.3):  94%|█████████▍| 470/500 [00:14<00:00, 39.70it/s]2024-10-12T23:36:44.806324Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 472  (1.3):  94%|█████████▍| 471/500 [00:14<00:00, 39.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 473  (1.3):  94%|█████████▍| 472/500 [00:14<00:00, 39.70it/s]2024-10-12T23:36:44.832504Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 474  (1.3):  95%|█████████▍| 473/500 [00:14<00:00, 39.70it/s]2024-10-12T23:36:44.843610Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 475  (1.3):  95%|█████████▍| 474/500 [00:14<00:00, 39.70it/s]2024-10-12T23:36:44.849959Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 476  (1.3):  95%|█████████▌| 475/500 [00:14<00:00, 39.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 477  (1.3):  95%|█████████▌| 476/500 [00:14<00:00, 39.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 478  (1.3):  95%|█████████▌| 477/500 [00:14<00:00, 39.70it/s]2024-10-12T23:36:44.862752Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 479  (1.3):  96%|█████████▌| 479/500 [00:14<00:00, 48.42it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 480  (1.2):  96%|█████████▌| 479/500 [00:14<00:00, 48.42it/s]2024-10-12T23:36:44.882631Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 482  (1.2):  96%|█████████▌| 481/500 [00:14<00:00, 48.42it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 483  (1.2):  96%|█████████▋| 482/500 [00:14<00:00, 48.42it/s]2024-10-12T23:36:44.944562Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 484  (1.2):  97%|█████████▋| 483/500 [00:14<00:00, 48.42it/s]2024-10-12T23:36:44.951389Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 485  (1.2):  97%|█████████▋| 484/500 [00:14<00:00, 48.42it/s]2024-10-12T23:36:44.957884Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 486  (1.2):  97%|█████████▋| 485/500 [00:14<00:00, 48.42it/s]2024-10-12T23:36:44.968318Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 487  (1.2):  97%|█████████▋| 486/500 [00:14<00:00, 48.42it/s]2024-10-12T23:36:44.979667Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 492  (1.2):  98%|█████████▊| 491/500 [00:14<00:00, 48.82it/s]2024-10-12T23:36:45.700841Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 493  (1.2):  98%|█████████▊| 492/500 [00:14<00:00, 48.82it/s]2024-10-12T23:36:46.007936Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 494  (1.2):  99%|█████████▊| 493/500 [00:15<00:00, 48.82it/s]2024-10-12T23:36:47.599259Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 496  (1.2):  99%|█████████▉| 495/500 [00:18<00:00,  9.23it/s]2024-10-12T23:36:49.322888Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 497  (1.2):  99%|█████████▉| 496/500 [00:18<00:00,  9.23it/s]2024-10-12T23:36:49.801472Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 500  (1.4): 100%|██████████| 500/500 [00:19<00:00, 25.69it/s]\n",
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:36:50.920440Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<02:26,  2.39it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/350 [00:00<02:26,  2.39it/s]2024-10-12T23:36:51.203984Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 3/350 [00:00<01:15,  4.58it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 3/350 [00:00<01:15,  4.58it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 5  (0.0):   1%|          | 4/350 [00:00<01:15,  4.58it/s]2024-10-12T23:36:51.254276Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   2%|▏         | 6/350 [00:00<00:36,  9.37it/s]] 24-10-12T23:36:51.271645Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   2%|▏         | 6/350 [00:00<00:36,  9.37it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   2%|▏         | 7/350 [00:00<00:36,  9.37it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 9  (0.0):   2%|▏         | 8/350 [00:00<00:36,  9.37it/s]2024-10-12T23:36:51.324540Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 10  (0.0):   3%|▎         | 9/350 [00:00<00:36,  9.37it/s]2024-10-12T23:36:51.329707Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 11  (0.0):   3%|▎         | 11/350 [00:00<00:19, 17.59it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 12  (0.0):   3%|▎         | 11/350 [00:00<00:19, 17.59it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 13  (0.0):   3%|▎         | 12/350 [00:00<00:19, 17.59it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 14  (0.0):   4%|▎         | 13/350 [00:00<00:19, 17.59it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 15  (0.0):   4%|▍         | 14/350 [00:01<00:19, 17.59it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 16  (0.0):   4%|▍         | 15/350 [00:01<00:19, 17.59it/s]2024-10-12T23:36:51.397637Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 17  (0.0):   5%|▍         | 17/350 [00:01<00:12, 26.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 18  (0.0):   5%|▍         | 17/350 [00:01<00:12, 26.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 19  (0.0):   5%|▌         | 18/350 [00:01<00:12, 26.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 20  (0.0):   5%|▌         | 19/350 [00:01<00:12, 26.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 21  (0.0):   6%|▌         | 20/350 [00:01<00:12, 26.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 22  (0.0):   6%|▌         | 21/350 [00:01<00:12, 26.75it/s]2024-10-12T23:36:51.485900Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 23  (0.0):   7%|▋         | 23/350 [00:01<00:09, 34.49it/s]error    2T23:36:51.522609Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 24  (0.0):   7%|▋         | 23/350 [00:01<00:09, 34.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 25  (0.0):   7%|▋         | 24/350 [00:01<00:09, 34.49it/s]2024-10-12T23:36:51.801151Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 26  (0.0):   7%|▋         | 25/350 [00:01<00:09, 34.49it/s]2024-10-12T23:36:51.827409Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 27  (0.0):   7%|▋         | 26/350 [00:01<00:09, 34.49it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 28  (0.0):   8%|▊         | 28/350 [00:01<00:11, 28.86it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 29  (0.0):   8%|▊         | 28/350 [00:01<00:11, 28.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 30  (0.0):   8%|▊         | 29/350 [00:01<00:11, 28.86it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 31  (0.0):   9%|▊         | 30/350 [00:01<00:11, 28.86it/s]2024-10-12T23:36:51.919666Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 32  (0.0):   9%|▉         | 32/350 [00:01<00:10, 30.89it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 33  (0.0):   9%|▉         | 32/350 [00:01<00:10, 30.89it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 34  (0.0):   9%|▉         | 33/350 [00:01<00:10, 30.89it/s]2024-10-12T23:36:51.949872Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 35  (0.0):  10%|▉         | 34/350 [00:01<00:10, 30.89it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 36  (0.0):  10%|█         | 35/350 [00:01<00:10, 30.89it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 37  (0.0):  10%|█         | 36/350 [00:01<00:10, 30.89it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 38  (0.0):  11%|█         | 38/350 [00:01<00:08, 36.23it/s]2024-10-12T23:36:51.994736Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 39  (0.0):  11%|█         | 38/350 [00:01<00:08, 36.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 40  (0.0):  11%|█         | 39/350 [00:01<00:08, 36.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 41  (0.0):  11%|█▏        | 40/350 [00:01<00:08, 36.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 42  (0.0):  12%|█▏        | 41/350 [00:01<00:08, 36.23it/s]2024-10-12T23:36:52.077884Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 43  (0.0):  12%|█▏        | 42/350 [00:01<00:08, 36.23it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 44  (0.0):  13%|█▎        | 44/350 [00:01<00:07, 41.35it/s]2024-10-12T23:36:52.201655Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 45  (0.0):  13%|█▎        | 44/350 [00:01<00:07, 41.35it/s]2024-10-12T23:36:52.329123Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 46  (0.0):  13%|█▎        | 45/350 [00:01<00:07, 41.35it/s]2024-10-12T23:36:52.351560Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 47  (0.0):  13%|█▎        | 46/350 [00:01<00:07, 41.35it/s]2024-10-12T23:36:52.377384Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 48  (0.0):  13%|█▎        | 47/350 [00:01<00:07, 41.35it/s]2024-10-12T23:36:52.399205Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 49  (0.0):  14%|█▍        | 49/350 [00:01<00:08, 35.59it/s]2024-10-12T23:36:52.424356Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 50  (0.0):  14%|█▍        | 49/350 [00:01<00:08, 35.59it/s]2024-10-12T23:36:52.529852Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 51  (0.0):  14%|█▍        | 50/350 [00:02<00:08, 35.59it/s]2024-10-12T23:36:52.556003Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 52  (0.0):  15%|█▍        | 51/350 [00:02<00:08, 35.59it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 53  (0.0):  15%|█▍        | 52/350 [00:02<00:08, 35.59it/s]2024-10-12T23:36:52.586735Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 54  (0.0):  15%|█▌        | 54/350 [00:02<00:10, 28.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 55  (0.0):  15%|█▌        | 54/350 [00:02<00:10, 28.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 56  (0.0):  16%|█▌        | 55/350 [00:02<00:10, 28.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 57  (0.0):  16%|█▌        | 56/350 [00:02<00:10, 28.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 58  (0.0):  16%|█▋        | 57/350 [00:02<00:10, 28.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 59  (0.0):  17%|█▋        | 58/350 [00:02<00:10, 28.99it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 60  (0.0):  17%|█▋        | 60/350 [00:02<00:08, 34.36it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 61  (0.0):  17%|█▋        | 60/350 [00:02<00:08, 34.36it/s]2024-10-12T23:36:52.654611Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 62  (0.0):  17%|█▋        | 61/350 [00:02<00:08, 34.36it/s]2024-10-12T23:36:52.661415Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 63  (0.0):  18%|█▊        | 62/350 [00:02<00:08, 34.36it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 64  (0.0):  18%|█▊        | 63/350 [00:02<00:08, 34.36it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 65  (0.0):  18%|█▊        | 64/350 [00:02<00:08, 34.36it/s]2024-10-12T23:36:52.685322Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 66  (0.0):  19%|█▉        | 66/350 [00:02<00:07, 39.53it/s]2024-10-12T23:36:52.734540Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 68  (0.0):  19%|█▉        | 67/350 [00:02<00:07, 39.53it/s]2024-10-12T23:36:53.033187Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 69  (0.0):  19%|█▉        | 68/350 [00:02<00:07, 39.53it/s]2024-10-12T23:36:53.036990Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 70  (0.0):  20%|█▉        | 69/350 [00:02<00:07, 39.53it/s]2024-10-12T23:36:53.042909Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 71  (0.0):  20%|██        | 71/350 [00:02<00:09, 30.69it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 72  (0.0):  20%|██        | 71/350 [00:02<00:09, 30.69it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 73  (0.0):  21%|██        | 72/350 [00:02<00:09, 30.69it/s]2024-10-12T23:36:53.090250Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 74  (0.0):  21%|██        | 73/350 [00:02<00:09, 30.69it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 75  (0.0):  21%|██        | 74/350 [00:02<00:08, 30.69it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 76  (0.0):  22%|██▏       | 76/350 [00:02<00:08, 33.68it/s]error    2T23:36:53.119283Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 77  (0.0):  22%|██▏       | 76/350 [00:02<00:08, 33.68it/s]2024-10-12T23:36:53.122822Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 78  (0.0):  22%|██▏       | 77/350 [00:02<00:08, 33.68it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 79  (0.0):  22%|██▏       | 78/350 [00:02<00:08, 33.68it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 80  (0.0):  23%|██▎       | 79/350 [00:02<00:08, 33.68it/s]2024-10-12T23:36:53.146587Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 81  (0.0):  23%|██▎       | 80/350 [00:02<00:08, 33.68it/s]2024-10-12T23:36:53.166389Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 82  (0.0):  23%|██▎       | 82/350 [00:02<00:06, 39.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 83  (0.0):  23%|██▎       | 82/350 [00:02<00:06, 39.09it/s]2024-10-12T23:36:53.175819Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 84  (0.0):  24%|██▎       | 83/350 [00:02<00:06, 39.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 85  (0.0):  24%|██▍       | 84/350 [00:02<00:06, 39.09it/s]2024-10-12T23:36:53.201018Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 86  (0.0):  24%|██▍       | 85/350 [00:02<00:06, 39.09it/s]2024-10-12T23:36:53.205342Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 87  (0.0):  25%|██▍       | 86/350 [00:02<00:06, 39.09it/s]2024-10-12T23:36:53.240911Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 88  (0.0):  25%|██▌       | 88/350 [00:02<00:05, 43.85it/s]2024-10-12T23:36:53.756785Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 90  (0.0):  25%|██▌       | 89/350 [00:03<00:05, 43.85it/s]2024-10-12T23:36:53.777123Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 91  (0.0):  26%|██▌       | 90/350 [00:03<00:05, 43.85it/s]2024-10-12T23:36:53.809413Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 92  (0.0):  26%|██▌       | 91/350 [00:03<00:05, 43.85it/s]2024-10-12T23:36:53.843589Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 93  (0.0):  27%|██▋       | 93/350 [00:03<00:10, 25.68it/s]2024-10-12T23:36:53.971126Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 94  (0.0):  27%|██▋       | 93/350 [00:03<00:10, 25.68it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 95  (0.0):  27%|██▋       | 94/350 [00:03<00:09, 25.68it/s]2024-10-12T23:36:53.978639Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 96  (0.0):  27%|██▋       | 95/350 [00:03<00:09, 25.68it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 97  (0.0):  28%|██▊       | 97/350 [00:03<00:11, 22.76it/s] [24-10-12T23:36:54.005202Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 98  (0.0):  28%|██▊       | 97/350 [00:03<00:11, 22.76it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 99  (0.0):  28%|██▊       | 98/350 [00:03<00:11, 22.76it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 100  (0.0):  28%|██▊       | 99/350 [00:03<00:11, 22.76it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 101  (0.0):  29%|██▊       | 100/350 [00:03<00:10, 22.76it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 102  (0.0):  29%|██▉       | 101/350 [00:03<00:10, 22.76it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 103  (0.0):  29%|██▉       | 103/350 [00:03<00:08, 28.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 104  (0.0):  29%|██▉       | 103/350 [00:03<00:08, 28.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 105  (0.0):  30%|██▉       | 104/350 [00:03<00:08, 28.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 106  (0.0):  30%|███       | 105/350 [00:03<00:08, 28.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 107  (0.0):  30%|███       | 106/350 [00:03<00:08, 28.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 108  (0.0):  31%|███       | 107/350 [00:03<00:08, 28.03it/s]2024-10-12T23:36:54.133274Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 109  (0.0):  31%|███       | 108/350 [00:03<00:08, 28.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 110  (0.0):  31%|███▏      | 110/350 [00:03<00:06, 34.83it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 111  (0.0):  31%|███▏      | 110/350 [00:03<00:06, 34.83it/s]2024-10-12T23:36:54.210662Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 112  (0.0):  32%|███▏      | 111/350 [00:03<00:06, 34.83it/s]2024-10-12T23:36:54.466309Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 114  (0.0):  32%|███▏      | 113/350 [00:03<00:06, 34.83it/s]2024-10-12T23:36:54.479121Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 116  (0.0):  33%|███▎      | 115/350 [00:04<00:07, 31.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 117  (0.0):  33%|███▎      | 116/350 [00:04<00:07, 31.67it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 118  (0.0):  33%|███▎      | 117/350 [00:04<00:07, 31.67it/s]2024-10-12T23:36:54.557453Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 119  (0.0):  34%|███▍      | 119/350 [00:04<00:06, 33.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 120  (0.0):  34%|███▍      | 119/350 [00:04<00:06, 33.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 121  (0.0):  34%|███▍      | 120/350 [00:04<00:06, 33.29it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 122  (0.0):  35%|███▍      | 121/350 [00:04<00:06, 33.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 123  (0.0):  35%|███▍      | 122/350 [00:04<00:06, 33.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 124  (0.0):  35%|███▌      | 123/350 [00:04<00:06, 33.29it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 125  (0.0):  36%|███▌      | 125/350 [00:04<00:05, 38.52it/s]2024-10-12T23:36:54.620383Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 126  (0.0):  36%|███▌      | 125/350 [00:04<00:05, 38.52it/s]2024-10-12T23:36:54.638511Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 127  (0.0):  36%|███▌      | 126/350 [00:04<00:05, 38.52it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 128  (0.0):  36%|███▋      | 127/350 [00:04<00:05, 38.52it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 129  (0.0):  37%|███▋      | 128/350 [00:04<00:05, 38.52it/s]2024-10-12T23:36:55.040263Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 130  (0.0):  37%|███▋      | 130/350 [00:04<00:08, 25.17it/s]2024-10-12T23:36:55.053601Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 132  (0.0):  37%|███▋      | 131/350 [00:04<00:08, 25.17it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 133  (0.0):  38%|███▊      | 132/350 [00:04<00:08, 25.17it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 135  (0.0):  38%|███▊      | 134/350 [00:04<00:08, 26.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 137  (0.0):  39%|███▉      | 136/350 [00:04<00:08, 26.43it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 140  (0.0):  40%|███▉      | 139/350 [00:04<00:07, 26.43it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 142  (0.0):  40%|████      | 141/350 [00:04<00:06, 32.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 144  (0.0):  41%|████      | 143/350 [00:04<00:06, 32.91it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 145  (0.0):  41%|████      | 144/350 [00:04<00:06, 32.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 147  (0.7):  42%|████▏     | 147/350 [00:04<00:05, 38.10it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 148  (0.7):  42%|████▏     | 147/350 [00:04<00:05, 38.10it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 149  (0.7):  42%|████▏     | 148/350 [00:04<00:05, 38.10it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 150  (0.7):  43%|████▎     | 149/350 [00:04<00:05, 38.10it/s]2024-10-12T23:36:55.226714Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 151  (0.7):  43%|████▎     | 150/350 [00:05<00:05, 38.10it/s]2024-10-12T23:36:55.241352Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 152  (0.7):  43%|████▎     | 151/350 [00:05<00:05, 38.10it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 153  (0.7):  44%|████▎     | 153/350 [00:05<00:04, 42.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 154  (0.6):  44%|████▎     | 153/350 [00:05<00:04, 42.11it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 155  (0.6):  44%|████▍     | 154/350 [00:05<00:04, 42.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 156  (0.6):  44%|████▍     | 155/350 [00:05<00:04, 42.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 157  (0.6):  45%|████▍     | 156/350 [00:05<00:04, 42.11it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 158  (0.6):  45%|████▍     | 157/350 [00:05<00:04, 42.11it/s]2024-10-12T23:36:55.388542Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 159  (0.6):  45%|████▌     | 159/350 [00:05<00:04, 45.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 160  (0.6):  45%|████▌     | 159/350 [00:05<00:04, 45.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 161  (0.6):  46%|████▌     | 160/350 [00:05<00:04, 45.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 162  (0.6):  46%|████▌     | 161/350 [00:05<00:04, 45.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 163  (0.6):  46%|████▋     | 162/350 [00:05<00:04, 45.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 164  (0.6):  47%|████▋     | 163/350 [00:05<00:04, 45.75it/s]2024-10-12T23:36:55.476681Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 165  (0.6):  47%|████▋     | 165/350 [00:05<00:03, 48.23it/s]2024-10-12T23:36:55.514441Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 166  (0.6):  47%|████▋     | 165/350 [00:05<00:03, 48.23it/s]2024-10-12T23:36:55.547254Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 167  (0.6):  47%|████▋     | 166/350 [00:05<00:03, 48.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 168  (0.6):  48%|████▊     | 167/350 [00:05<00:03, 48.23it/s]2024-10-12T23:36:55.967179Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 169  (0.6):  48%|████▊     | 168/350 [00:05<00:03, 48.23it/s]2024-10-12T23:36:55.990800Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 170  (0.6):  48%|████▊     | 169/350 [00:05<00:03, 48.23it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 171  (0.6):  49%|████▉     | 171/350 [00:05<00:04, 36.48it/s]dspy.evaluate.evaluate1706Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 172  (0.6):  49%|████▉     | 171/350 [00:05<00:04, 36.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 173  (0.6):  49%|████▉     | 172/350 [00:05<00:04, 36.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 174  (0.6):  49%|████▉     | 173/350 [00:05<00:04, 36.48it/s]2024-10-12T23:36:56.062259Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 175  (0.6):  50%|████▉     | 174/350 [00:05<00:04, 36.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 176  (0.6):  50%|█████     | 175/350 [00:05<00:04, 36.48it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 177  (0.6):  51%|█████     | 177/350 [00:05<00:04, 40.55it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 178  (0.6):  51%|█████     | 177/350 [00:05<00:04, 40.55it/s]2024-10-12T23:36:56.264357Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 179  (0.6):  51%|█████     | 178/350 [00:05<00:04, 40.55it/s]2024-10-12T23:36:56.290023Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 180  (0.6):  51%|█████     | 179/350 [00:05<00:04, 40.55it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 181  (0.6):  51%|█████▏    | 180/350 [00:05<00:04, 40.55it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 182  (0.5):  52%|█████▏    | 182/350 [00:05<00:04, 35.31it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 183  (0.5):  52%|█████▏    | 182/350 [00:05<00:04, 35.31it/s]2024-10-12T23:36:56.472758Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 185  (0.5):  53%|█████▎    | 184/350 [00:05<00:04, 35.31it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 186  (0.5):  53%|█████▎    | 185/350 [00:06<00:04, 35.31it/s]2024-10-12T23:36:56.489532Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 187  (0.5):  53%|█████▎    | 187/350 [00:06<00:05, 30.45it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 188  (0.5):  53%|█████▎    | 187/350 [00:06<00:05, 30.45it/s]2024-10-12T23:36:56.547376Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 189  (0.5):  54%|█████▎    | 188/350 [00:06<00:05, 30.45it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 190  (0.5):  54%|█████▍    | 189/350 [00:06<00:05, 30.45it/s]2024-10-12T23:36:56.561883Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 191  (0.5):  54%|█████▍    | 190/350 [00:06<00:05, 30.45it/s]2024-10-12T23:36:56.567575Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 192  (0.5):  55%|█████▍    | 192/350 [00:06<00:04, 33.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 193  (0.5):  55%|█████▍    | 192/350 [00:06<00:04, 33.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 194  (0.5):  55%|█████▌    | 193/350 [00:06<00:04, 33.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 195  (0.5):  55%|█████▌    | 194/350 [00:06<00:04, 33.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 196  (0.5):  56%|█████▌    | 195/350 [00:06<00:04, 33.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 197  (0.5):  56%|█████▌    | 196/350 [00:06<00:04, 33.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 198  (0.5):  57%|█████▋    | 198/350 [00:06<00:03, 39.44it/s]2024-10-12T23:36:56.868873Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 200  (0.5):  57%|█████▋    | 199/350 [00:06<00:03, 39.44it/s]2024-10-12T23:36:56.892752Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 201  (0.5):  57%|█████▋    | 200/350 [00:06<00:03, 39.44it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 203  (0.5):  58%|█████▊    | 203/350 [00:06<00:04, 34.43it/s]dspy.evaluate.evaluate example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 204  (0.5):  58%|█████▊    | 203/350 [00:06<00:04, 34.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 205  (0.5):  58%|█████▊    | 204/350 [00:06<00:04, 34.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 206  (0.5):  59%|█████▊    | 205/350 [00:06<00:04, 34.43it/s]2024-10-12T23:36:56.954447Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 207  (0.5):  59%|█████▉    | 206/350 [00:06<00:04, 34.43it/s]2024-10-12T23:36:56.958952Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 208  (0.5):  59%|█████▉    | 207/350 [00:06<00:04, 34.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 209  (0.5):  60%|█████▉    | 209/350 [00:06<00:03, 39.87it/s]2024-10-12T23:36:57.181949Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 211  (0.5):  60%|██████    | 210/350 [00:06<00:03, 39.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 213  (0.5):  61%|██████    | 212/350 [00:06<00:03, 39.87it/s] 024-10-12T23:36:57.196875Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 1.0 / 214  (0.5):  61%|██████    | 214/350 [00:06<00:04, 33.64it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 215  (0.5):  61%|██████    | 214/350 [00:06<00:04, 33.64it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 216  (0.5):  61%|██████▏   | 215/350 [00:06<00:04, 33.64it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 217  (0.5):  62%|██████▏   | 216/350 [00:06<00:03, 33.64it/s]2024-10-12T23:36:57.286021Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 218  (0.5):  62%|██████▏   | 217/350 [00:06<00:03, 33.64it/s]2024-10-12T23:36:57.297759Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 219  (0.5):  62%|██████▏   | 218/350 [00:06<00:03, 33.64it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 220  (0.5):  63%|██████▎   | 220/350 [00:06<00:03, 38.15it/s]2024-10-12T23:36:57.336146Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 221  (0.5):  63%|██████▎   | 220/350 [00:06<00:03, 38.15it/s]2024-10-12T23:36:57.508768Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 223  (0.4):  63%|██████▎   | 222/350 [00:07<00:03, 38.15it/s]2024-10-12T23:36:57.543463Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 224  (0.4):  64%|██████▎   | 223/350 [00:07<00:03, 38.15it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 225  (0.4):  64%|██████▍   | 225/350 [00:07<00:03, 33.24it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 226  (0.4):  64%|██████▍   | 225/350 [00:07<00:03, 33.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 227  (0.4):  65%|██████▍   | 226/350 [00:07<00:03, 33.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 228  (0.4):  65%|██████▍   | 227/350 [00:07<00:03, 33.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 229  (0.4):  65%|██████▌   | 228/350 [00:07<00:03, 33.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 230  (0.4):  65%|██████▌   | 229/350 [00:07<00:03, 33.24it/s]2024-10-12T23:36:57.796620Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 231  (0.4):  66%|██████▌   | 231/350 [00:07<00:03, 30.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 232  (0.4):  66%|██████▌   | 231/350 [00:07<00:03, 30.43it/s]2024-10-12T23:36:57.811526Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 233  (0.4):  66%|██████▋   | 232/350 [00:07<00:03, 30.43it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 235  (0.4):  67%|██████▋   | 235/350 [00:07<00:03, 30.93it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 236  (0.4):  67%|██████▋   | 235/350 [00:07<00:03, 30.93it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 237  (0.4):  67%|██████▋   | 236/350 [00:07<00:03, 30.93it/s]2024-10-12T23:36:57.861751Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 238  (0.4):  68%|██████▊   | 237/350 [00:07<00:03, 30.93it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 239  (0.4):  68%|██████▊   | 238/350 [00:07<00:03, 30.93it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 240  (0.4):  68%|██████▊   | 239/350 [00:07<00:03, 30.93it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 241  (0.4):  69%|██████▉   | 241/350 [00:07<00:03, 35.82it/s]2024-10-12T23:36:57.897378Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 242  (0.4):  69%|██████▉   | 241/350 [00:07<00:03, 35.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 243  (0.4):  69%|██████▉   | 242/350 [00:07<00:03, 35.82it/s]2024-10-12T23:36:57.915868Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 244  (0.4):  69%|██████▉   | 243/350 [00:07<00:02, 35.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 245  (0.4):  70%|██████▉   | 244/350 [00:07<00:02, 35.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 246  (0.4):  70%|███████   | 245/350 [00:07<00:02, 35.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 247  (0.4):  71%|███████   | 247/350 [00:07<00:02, 40.97it/s] [24-10-12T23:36:57.944422Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 248  (0.4):  71%|███████   | 247/350 [00:07<00:02, 40.97it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 249  (0.4):  71%|███████   | 248/350 [00:07<00:02, 40.97it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 250  (0.4):  71%|███████   | 249/350 [00:07<00:02, 40.97it/s]2024-10-12T23:36:58.317796Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 251  (0.4):  71%|███████▏  | 250/350 [00:07<00:02, 40.97it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 252  (0.4):  72%|███████▏  | 252/350 [00:07<00:02, 34.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 253  (0.4):  72%|███████▏  | 252/350 [00:07<00:02, 34.34it/s]2024-10-12T23:36:58.339178Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 254  (0.4):  72%|███████▏  | 253/350 [00:07<00:02, 34.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 255  (0.4):  73%|███████▎  | 254/350 [00:07<00:02, 34.34it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 256  (0.4):  73%|███████▎  | 256/350 [00:07<00:02, 35.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 257  (0.4):  73%|███████▎  | 256/350 [00:07<00:02, 35.30it/s]2024-10-12T23:36:58.406766Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 258  (0.4):  73%|███████▎  | 257/350 [00:07<00:02, 35.30it/s]2024-10-12T23:36:58.420384Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 259  (0.4):  74%|███████▎  | 258/350 [00:08<00:02, 35.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 260  (0.4):  74%|███████▍  | 259/350 [00:08<00:02, 35.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 261  (0.4):  74%|███████▍  | 260/350 [00:08<00:02, 35.30it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 262  (0.4):  75%|███████▍  | 262/350 [00:08<00:02, 40.05it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 265  (0.4):  75%|███████▌  | 264/350 [00:08<00:02, 40.05it/s]2024-10-12T23:36:58.739032Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 266  (0.4):  76%|███████▌  | 265/350 [00:08<00:02, 40.05it/s]2024-10-12T23:36:58.744844Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 267  (0.4):  76%|███████▋  | 267/350 [00:08<00:02, 33.35it/s]2024-10-12T23:36:58.759894Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 268  (0.4):  76%|███████▋  | 267/350 [00:08<00:02, 33.35it/s]2024-10-12T23:36:58.776693Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 269  (0.4):  77%|███████▋  | 268/350 [00:08<00:02, 33.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 270  (0.4):  77%|███████▋  | 269/350 [00:08<00:02, 33.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 271  (0.4):  77%|███████▋  | 270/350 [00:08<00:02, 33.35it/s]2024-10-12T23:36:58.961044Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 272  (0.4):  78%|███████▊  | 272/350 [00:08<00:02, 31.52it/s]error    2T23:36:58.969357Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 274  (0.4):  78%|███████▊  | 273/350 [00:08<00:02, 31.52it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 275  (0.4):  78%|███████▊  | 274/350 [00:08<00:02, 31.52it/s]2024-10-12T23:36:59.010240Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 276  (0.4):  79%|███████▊  | 275/350 [00:08<00:02, 31.52it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 277  (0.4):  79%|███████▉  | 277/350 [00:08<00:02, 33.83it/s]2024-10-12T23:36:59.049358Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 278  (0.4):  79%|███████▉  | 277/350 [00:08<00:02, 33.83it/s]2024-10-12T23:36:59.069116Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 279  (0.4):  79%|███████▉  | 278/350 [00:08<00:02, 33.83it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 280  (0.4):  80%|███████▉  | 279/350 [00:08<00:02, 33.83it/s]2024-10-12T23:36:59.086430Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 281  (0.4):  80%|████████  | 280/350 [00:08<00:02, 33.83it/s]2024-10-12T23:36:59.292870Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 283  (0.4):  81%|████████  | 282/350 [00:08<00:02, 29.36it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 284  (0.4):  81%|████████  | 283/350 [00:08<00:02, 29.36it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 285  (0.4):  81%|████████  | 284/350 [00:08<00:02, 29.36it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 286  (0.3):  81%|████████▏ | 285/350 [00:08<00:02, 29.36it/s]2024-10-12T23:36:59.357752Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 287  (0.3):  82%|████████▏ | 287/350 [00:08<00:01, 32.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 288  (0.3):  82%|████████▏ | 287/350 [00:08<00:01, 32.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 289  (0.3):  82%|████████▏ | 288/350 [00:08<00:01, 32.56it/s]2024-10-12T23:36:59.386134Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 290  (0.3):  83%|████████▎ | 289/350 [00:08<00:01, 32.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 291  (0.3):  83%|████████▎ | 290/350 [00:08<00:01, 32.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 292  (0.3):  83%|████████▎ | 291/350 [00:08<00:01, 32.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 293  (0.3):  83%|████████▎ | 292/350 [00:09<00:01, 32.56it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 294  (0.3):  84%|████████▍ | 294/350 [00:09<00:01, 39.35it/s]2024-10-12T23:36:59.661560Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 295  (0.3):  84%|████████▍ | 294/350 [00:09<00:01, 39.35it/s]2024-10-12T23:36:59.669466Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 296  (0.3):  84%|████████▍ | 295/350 [00:09<00:01, 39.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 297  (0.3):  85%|████████▍ | 296/350 [00:09<00:01, 39.35it/s]2024-10-12T23:36:59.682939Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 298  (0.3):  85%|████████▍ | 297/350 [00:09<00:01, 39.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 299  (0.3):  85%|████████▌ | 299/350 [00:09<00:01, 32.08it/s]2024-10-12T23:36:59.715254Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 300  (0.3):  85%|████████▌ | 299/350 [00:09<00:01, 32.08it/s]2024-10-12T23:36:59.721333Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 301  (0.3):  86%|████████▌ | 300/350 [00:09<00:01, 32.08it/s]2024-10-12T23:36:59.733392Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 302  (0.3):  86%|████████▌ | 301/350 [00:09<00:01, 32.08it/s]2024-10-12T23:36:59.737669Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 303  (0.3):  86%|████████▋ | 302/350 [00:09<00:01, 32.08it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 304  (0.3):  87%|████████▋ | 303/350 [00:09<00:01, 32.08it/s]2024-10-12T23:36:59.757754Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 305  (0.3):  87%|████████▋ | 304/350 [00:09<00:01, 32.08it/s]2024-10-12T23:36:59.895911Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 307  (0.3):  87%|████████▋ | 306/350 [00:09<00:01, 38.51it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 308  (0.3):  88%|████████▊ | 307/350 [00:09<00:01, 38.51it/s]2024-10-12T23:36:59.932383Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 310  (0.3):  88%|████████▊ | 309/350 [00:09<00:01, 38.51it/s]2024-10-12T23:36:59.946180Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 311  (0.3):  89%|████████▊ | 310/350 [00:09<00:01, 38.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 312  (0.3):  89%|████████▉ | 312/350 [00:09<00:00, 42.66it/s]2024-10-12T23:36:59.961746Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 313  (0.3):  89%|████████▉ | 312/350 [00:09<00:00, 42.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 315  (0.6):  90%|████████▉ | 314/350 [00:09<00:00, 42.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 317  (0.6):  90%|█████████ | 316/350 [00:09<00:00, 42.66it/s]2024-10-12T23:36:59.999911Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 318  (0.6):  91%|█████████ | 317/350 [00:09<00:00, 42.66it/s]2024-10-12T23:37:00.011452Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 319  (0.6):  91%|█████████ | 319/350 [00:09<00:00, 45.22it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 321  (0.6):  91%|█████████▏| 320/350 [00:09<00:00, 45.22it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 323  (0.6):  92%|█████████▏| 322/350 [00:09<00:00, 45.22it/s]2024-10-12T23:37:00.055966Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 324  (0.6):  92%|█████████▏| 323/350 [00:09<00:00, 45.22it/s]2024-10-12T23:37:00.059529Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 325  (0.6):  93%|█████████▎| 324/350 [00:09<00:00, 45.22it/s]2024-10-12T23:37:00.079784Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 327  (0.6):  93%|█████████▎| 327/350 [00:09<00:00, 52.76it/s]2024-10-12T23:37:00.087198Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 329  (0.6):  94%|█████████▎| 328/350 [00:09<00:00, 52.76it/s] 024-10-12T23:37:00.109985Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 2.0 / 330  (0.6):  94%|█████████▍| 329/350 [00:09<00:00, 52.76it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 331  (0.6):  94%|█████████▍| 330/350 [00:09<00:00, 52.76it/s]2024-10-12T23:37:00.123327Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 332  (0.6):  95%|█████████▍| 331/350 [00:09<00:00, 52.76it/s]2024-10-12T23:37:00.144905Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 333  (0.6):  95%|█████████▍| 332/350 [00:09<00:00, 52.76it/s]2024-10-12T23:37:00.154181Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 334  (0.6):  95%|█████████▌| 333/350 [00:09<00:00, 52.76it/s]2024-10-12T23:37:00.160943Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 335  (0.6):  95%|█████████▌| 334/350 [00:09<00:00, 52.76it/s]2024-10-12T23:37:00.164971Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 336  (0.6):  96%|█████████▌| 335/350 [00:09<00:00, 52.76it/s]2024-10-12T23:37:00.184544Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 337  (0.6):  96%|█████████▌| 336/350 [00:09<00:00, 52.76it/s]2024-10-12T23:37:00.194506Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 338  (0.6):  97%|█████████▋| 338/350 [00:09<00:00, 66.68it/s]2024-10-12T23:37:00.201768Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 339  (0.6):  97%|█████████▋| 338/350 [00:09<00:00, 66.68it/s]2024-10-12T23:37:00.211230Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 340  (0.6):  97%|█████████▋| 339/350 [00:09<00:00, 66.68it/s]2024-10-12T23:37:00.224144Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 341  (0.6):  97%|█████████▋| 340/350 [00:09<00:00, 66.68it/s]2024-10-12T23:37:00.228331Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 345  (0.6):  98%|█████████▊| 344/350 [00:10<00:00, 66.68it/s]2024-10-12T23:37:01.983847Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 346  (0.6):  99%|█████████▉| 346/350 [00:11<00:00, 13.96it/s]2024-10-12T23:37:02.496649Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 347  (0.6):  99%|█████████▉| 346/350 [00:11<00:00, 13.96it/s]2024-10-12T23:37:04.714742Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 350  (0.6): 100%|██████████| 350/350 [00:14<00:00, 24.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.57 for seed -3\n",
      "Scores so far: [0.57]\n",
      "Best score so far: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-12T23:37:05.128787Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-12T23:37:05.129753Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "  0%|          | 0/350 [00:00<?, ?it/s] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   1%|▏         | 5/350 [00:00<00:00, 506.96it/s] spy.evaluate.evaluate set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.pylineno=198\n",
      "Average Metric: 0.0 / 7  (0.0):   2%|▏         | 6/350 [00:00<00:00, 424.90it/s]2024-10-12T23:37:05.134549Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 8  (0.0):   2%|▏         | 7/350 [00:00<00:01, 280.52it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 9  (0.0):   2%|▏         | 8/350 [00:00<00:01, 238.15it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 11  (0.0):   3%|▎         | 10/350 [00:00<00:01, 221.10it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 12  (0.0):   3%|▎         | 11/350 [00:00<00:01, 201.18it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 13  (0.0):   3%|▎         | 12/350 [00:00<00:01, 186.66it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 14  (0.0):   4%|▎         | 13/350 [00:00<00:01, 176.71it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 15  (0.0):   4%|▍         | 14/350 [00:00<00:02, 165.38it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 16  (0.0):   4%|▍         | 15/350 [00:00<00:02, 157.75it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 17  (0.0):   5%|▍         | 17/350 [00:00<00:02, 159.82it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 18  (0.0):   5%|▍         | 17/350 [00:00<00:02, 159.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 19  (0.0):   5%|▌         | 18/350 [00:00<00:02, 159.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 20  (0.0):   5%|▌         | 19/350 [00:00<00:02, 159.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 21  (0.0):   6%|▌         | 20/350 [00:00<00:02, 159.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 22  (0.0):   6%|▌         | 21/350 [00:00<00:02, 159.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 23  (0.0):   6%|▋         | 22/350 [00:00<00:02, 159.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 24  (0.0):   7%|▋         | 23/350 [00:00<00:02, 159.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 25  (0.0):   7%|▋         | 24/350 [00:00<00:02, 159.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 26  (0.0):   7%|▋         | 25/350 [00:00<00:02, 159.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 27  (0.0):   7%|▋         | 26/350 [00:00<00:02, 159.82it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 28  (0.0):   8%|▊         | 27/350 [00:00<00:02, 159.82it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 29  (0.0):   8%|▊         | 28/350 [00:00<00:02, 159.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 30  (0.0):   8%|▊         | 29/350 [00:00<00:02, 159.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 32  (0.0):   9%|▉         | 31/350 [00:00<00:01, 159.82it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 33  (0.0):   9%|▉         | 33/350 [00:00<00:02, 124.51it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 34  (0.0):   9%|▉         | 33/350 [00:00<00:02, 124.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 35  (0.0):  10%|▉         | 34/350 [00:00<00:02, 124.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 36  (0.0):  10%|█         | 35/350 [00:00<00:02, 124.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 37  (0.0):  10%|█         | 36/350 [00:00<00:02, 124.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 38  (0.0):  11%|█         | 37/350 [00:00<00:02, 124.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 39  (0.0):  11%|█         | 38/350 [00:00<00:02, 124.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 40  (0.0):  11%|█         | 39/350 [00:00<00:02, 124.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 41  (0.0):  11%|█▏        | 40/350 [00:00<00:02, 124.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 42  (0.0):  12%|█▏        | 41/350 [00:00<00:02, 124.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 44  (0.0):  12%|█▏        | 43/350 [00:00<00:02, 124.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 45  (0.0):  13%|█▎        | 44/350 [00:00<00:02, 124.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 46  (0.0):  13%|█▎        | 46/350 [00:00<00:02, 117.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 47  (0.0):  13%|█▎        | 46/350 [00:00<00:02, 117.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 48  (0.0):  13%|█▎        | 47/350 [00:00<00:02, 117.25it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 49  (0.0):  14%|█▎        | 48/350 [00:00<00:02, 117.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 50  (0.0):  14%|█▍        | 49/350 [00:00<00:02, 117.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 51  (0.0):  14%|█▍        | 50/350 [00:00<00:02, 117.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 52  (0.0):  15%|█▍        | 51/350 [00:00<00:02, 117.25it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 53  (0.0):  15%|█▍        | 52/350 [00:00<00:02, 117.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 54  (0.0):  15%|█▌        | 53/350 [00:00<00:02, 117.25it/s]2024-10-12T23:37:05.194712Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 55  (0.0):  15%|█▌        | 54/350 [00:00<00:02, 117.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 56  (0.0):  16%|█▌        | 55/350 [00:00<00:02, 117.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 57  (0.0):  16%|█▌        | 56/350 [00:00<00:02, 117.25it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 58  (0.0):  17%|█▋        | 58/350 [00:00<00:02, 109.12it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 59  (0.0):  17%|█▋        | 58/350 [00:00<00:02, 109.12it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 60  (0.0):  17%|█▋        | 59/350 [00:00<00:02, 109.12it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 61  (0.0):  17%|█▋        | 60/350 [00:00<00:02, 109.12it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 62  (0.0):  17%|█▋        | 61/350 [00:00<00:02, 109.12it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 63  (0.0):  18%|█▊        | 62/350 [00:00<00:02, 109.12it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 65  (0.0):  18%|█▊        | 64/350 [00:00<00:02, 109.12it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 66  (0.0):  19%|█▊        | 65/350 [00:00<00:02, 109.12it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 67  (0.0):  19%|█▉        | 66/350 [00:00<00:02, 109.12it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 68  (0.0):  19%|█▉        | 67/350 [00:00<00:02, 109.12it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 69  (0.0):  19%|█▉        | 68/350 [00:00<00:02, 109.12it/s]2024-10-12T23:37:05.312621Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 70  (0.0):  20%|██        | 70/350 [00:00<00:02, 110.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 71  (0.0):  20%|██        | 70/350 [00:00<00:02, 110.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 72  (0.0):  20%|██        | 71/350 [00:00<00:02, 110.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 73  (0.0):  21%|██        | 72/350 [00:00<00:02, 110.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 74  (0.0):  21%|██        | 73/350 [00:00<00:02, 110.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 75  (0.0):  21%|██        | 74/350 [00:00<00:02, 110.02it/s]2024-10-12T23:37:05.371681Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 76  (0.0):  21%|██▏       | 75/350 [00:00<00:02, 110.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 79  (0.0):  22%|██▏       | 78/350 [00:00<00:02, 110.02it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 81  (0.0):  23%|██▎       | 80/350 [00:00<00:02, 110.02it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 82  (0.0):  23%|██▎       | 82/350 [00:00<00:02, 112.94it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 83  (0.0):  23%|██▎       | 82/350 [00:00<00:02, 112.94it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 86  (0.0):  24%|██▍       | 85/350 [00:00<00:02, 112.94it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 87  (0.0):  25%|██▍       | 86/350 [00:00<00:02, 112.94it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 88  (0.0):  25%|██▍       | 87/350 [00:00<00:02, 112.94it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 89  (0.0):  25%|██▌       | 88/350 [00:00<00:02, 112.94it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 90  (0.0):  25%|██▌       | 89/350 [00:00<00:02, 112.94it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 91  (0.0):  26%|██▌       | 90/350 [00:00<00:02, 112.94it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 92  (0.0):  26%|██▌       | 91/350 [00:00<00:02, 112.94it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 93  (0.0):  26%|██▋       | 92/350 [00:00<00:02, 112.94it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 94  (0.0):  27%|██▋       | 94/350 [00:00<00:02, 105.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 95  (0.0):  27%|██▋       | 94/350 [00:00<00:02, 105.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 97  (1.0):  27%|██▋       | 96/350 [00:00<00:02, 105.27it/s]2024-10-12T23:37:05.533791Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 98  (1.0):  28%|██▊       | 97/350 [00:00<00:02, 105.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 99  (1.0):  28%|██▊       | 98/350 [00:00<00:02, 105.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 100  (1.0):  28%|██▊       | 99/350 [00:00<00:02, 105.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 101  (1.0):  29%|██▊       | 100/350 [00:00<00:02, 105.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 103  (1.0):  29%|██▉       | 102/350 [00:00<00:02, 105.27it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 104  (1.0):  29%|██▉       | 103/350 [00:00<00:02, 105.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 105  (1.0):  30%|██▉       | 104/350 [00:00<00:02, 105.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 106  (0.9):  30%|███       | 105/350 [00:00<00:02, 105.27it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 107  (0.9):  31%|███       | 107/350 [00:00<00:02, 110.03it/s]] ror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 108  (0.9):  31%|███       | 107/350 [00:00<00:02, 110.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 109  (0.9):  31%|███       | 108/350 [00:00<00:02, 110.03it/s]2024-10-12T23:37:05.646437Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 110  (0.9):  31%|███       | 109/350 [00:00<00:02, 110.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 111  (0.9):  31%|███▏      | 110/350 [00:00<00:02, 110.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 112  (0.9):  32%|███▏      | 111/350 [00:00<00:02, 110.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 113  (0.9):  32%|███▏      | 112/350 [00:01<00:02, 110.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 114  (0.9):  32%|███▏      | 113/350 [00:01<00:02, 110.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 115  (0.9):  33%|███▎      | 114/350 [00:01<00:02, 110.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 116  (0.9):  33%|███▎      | 115/350 [00:01<00:02, 110.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 117  (0.9):  33%|███▎      | 116/350 [00:01<00:02, 110.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 118  (0.8):  33%|███▎      | 117/350 [00:01<00:02, 110.03it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 119  (0.8):  34%|███▍      | 119/350 [00:01<00:02, 108.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 120  (0.8):  34%|███▍      | 119/350 [00:01<00:02, 108.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 121  (0.8):  34%|███▍      | 120/350 [00:01<00:02, 108.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 123  (0.8):  35%|███▍      | 122/350 [00:01<00:02, 108.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 125  (0.8):  35%|███▌      | 124/350 [00:01<00:02, 108.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 126  (0.8):  36%|███▌      | 125/350 [00:01<00:02, 108.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 127  (0.8):  36%|███▌      | 126/350 [00:01<00:02, 108.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 129  (0.8):  37%|███▋      | 128/350 [00:01<00:02, 108.87it/s]2024-10-12T23:37:05.815411Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 130  (0.8):  37%|███▋      | 129/350 [00:01<00:02, 108.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 131  (0.8):  37%|███▋      | 130/350 [00:01<00:02, 108.87it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 132  (0.8):  38%|███▊      | 132/350 [00:01<00:01, 114.15it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 133  (0.8):  38%|███▊      | 132/350 [00:01<00:01, 114.15it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 134  (0.7):  38%|███▊      | 133/350 [00:01<00:01, 114.15it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 135  (0.7):  38%|███▊      | 134/350 [00:01<00:01, 114.15it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 136  (0.7):  39%|███▊      | 135/350 [00:01<00:01, 114.15it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 140  (0.7):  40%|███▉      | 139/350 [00:01<00:01, 114.15it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 141  (0.7):  40%|████      | 140/350 [00:01<00:01, 114.15it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 142  (0.7):  40%|████      | 141/350 [00:01<00:01, 114.15it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 143  (0.7):  41%|████      | 142/350 [00:01<00:01, 114.15it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 144  (0.7):  41%|████      | 143/350 [00:01<00:01, 114.15it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 145  (0.7):  41%|████▏     | 145/350 [00:01<00:01, 118.09it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 146  (0.7):  41%|████▏     | 145/350 [00:01<00:01, 118.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 147  (0.7):  42%|████▏     | 146/350 [00:01<00:01, 118.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 149  (0.7):  42%|████▏     | 148/350 [00:01<00:01, 118.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 150  (0.7):  43%|████▎     | 149/350 [00:01<00:01, 118.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 151  (0.7):  43%|████▎     | 150/350 [00:01<00:01, 118.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 153  (0.7):  43%|████▎     | 152/350 [00:01<00:01, 118.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 154  (0.6):  44%|████▎     | 153/350 [00:01<00:01, 118.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 155  (0.6):  44%|████▍     | 154/350 [00:01<00:01, 118.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 157  (0.6):  45%|████▍     | 156/350 [00:01<00:01, 118.09it/s] [24-10-12T23:37:06.076603Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 158  (0.6):  45%|████▌     | 158/350 [00:01<00:01, 120.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 159  (0.6):  45%|████▌     | 158/350 [00:01<00:01, 120.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 160  (0.6):  45%|████▌     | 159/350 [00:01<00:01, 120.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 161  (0.6):  46%|████▌     | 160/350 [00:01<00:01, 120.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 162  (0.6):  46%|████▌     | 161/350 [00:01<00:01, 120.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 163  (0.6):  46%|████▋     | 162/350 [00:01<00:01, 120.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 165  (0.6):  47%|████▋     | 164/350 [00:01<00:01, 120.88it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 166  (0.6):  47%|████▋     | 165/350 [00:01<00:01, 120.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 167  (0.6):  47%|████▋     | 166/350 [00:01<00:01, 120.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 168  (0.6):  48%|████▊     | 167/350 [00:01<00:01, 120.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 169  (0.6):  48%|████▊     | 168/350 [00:01<00:01, 120.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 170  (0.6):  48%|████▊     | 169/350 [00:01<00:01, 120.88it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 171  (0.6):  49%|████▉     | 171/350 [00:01<00:01, 117.77it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 172  (0.6):  49%|████▉     | 171/350 [00:01<00:01, 117.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 173  (0.6):  49%|████▉     | 172/350 [00:01<00:01, 117.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 174  (0.6):  49%|████▉     | 173/350 [00:01<00:01, 117.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 176  (1.1):  50%|█████     | 175/350 [00:01<00:01, 117.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 177  (1.1):  50%|█████     | 176/350 [00:01<00:01, 117.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 178  (1.1):  51%|█████     | 177/350 [00:01<00:01, 117.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 179  (1.1):  51%|█████     | 178/350 [00:01<00:01, 117.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 180  (1.1):  51%|█████     | 179/350 [00:01<00:01, 117.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 181  (1.1):  51%|█████▏    | 180/350 [00:01<00:01, 117.77it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 182  (1.1):  52%|█████▏    | 181/350 [00:01<00:01, 117.77it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 183  (1.1):  52%|█████▏    | 183/350 [00:01<00:01, 114.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 184  (1.1):  52%|█████▏    | 183/350 [00:01<00:01, 114.91it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 185  (1.1):  53%|█████▎    | 184/350 [00:01<00:01, 114.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 186  (1.1):  53%|█████▎    | 185/350 [00:01<00:01, 114.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 187  (1.1):  53%|█████▎    | 186/350 [00:01<00:01, 114.91it/s]] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 188  (1.1):  53%|█████▎    | 187/350 [00:01<00:01, 114.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 189  (1.1):  54%|█████▎    | 188/350 [00:01<00:01, 114.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 190  (1.1):  54%|█████▍    | 189/350 [00:01<00:01, 114.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 191  (1.0):  54%|█████▍    | 190/350 [00:01<00:01, 114.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 193  (1.0):  55%|█████▍    | 192/350 [00:01<00:01, 114.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 194  (1.0):  55%|█████▌    | 193/350 [00:01<00:01, 114.91it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 195  (1.0):  56%|█████▌    | 195/350 [00:01<00:01, 112.47it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 196  (1.0):  56%|█████▌    | 195/350 [00:01<00:01, 112.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 197  (1.0):  56%|█████▌    | 196/350 [00:01<00:01, 112.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 198  (1.0):  56%|█████▋    | 197/350 [00:01<00:01, 112.47it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 199  (1.0):  57%|█████▋    | 198/350 [00:01<00:01, 112.47it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 200  (1.0):  57%|█████▋    | 199/350 [00:01<00:01, 112.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 201  (1.0):  57%|█████▋    | 200/350 [00:01<00:01, 112.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 202  (1.0):  57%|█████▋    | 201/350 [00:01<00:01, 112.47it/s]2024-10-12T23:37:06.490634Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 203  (1.0):  58%|█████▊    | 202/350 [00:01<00:01, 112.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 204  (1.0):  58%|█████▊    | 203/350 [00:01<00:01, 112.47it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 205  (1.0):  58%|█████▊    | 204/350 [00:01<00:01, 112.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 206  (1.0):  59%|█████▊    | 205/350 [00:01<00:01, 112.47it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 207  (1.0):  59%|█████▉    | 207/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 208  (1.0):  59%|█████▉    | 207/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 209  (1.0):  59%|█████▉    | 208/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 210  (1.0):  60%|█████▉    | 209/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 211  (0.9):  60%|██████    | 210/350 [00:01<00:01, 107.62it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 212  (0.9):  60%|██████    | 211/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 213  (0.9):  61%|██████    | 212/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 215  (0.9):  61%|██████    | 214/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 216  (0.9):  61%|██████▏   | 215/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 217  (0.9):  62%|██████▏   | 216/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 218  (0.9):  62%|██████▏   | 218/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 219  (0.9):  62%|██████▏   | 218/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 220  (0.9):  63%|██████▎   | 219/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 221  (0.9):  63%|██████▎   | 220/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 222  (0.9):  63%|██████▎   | 221/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 223  (0.9):  63%|██████▎   | 222/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 224  (0.9):  64%|██████▎   | 223/350 [00:01<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 226  (0.9):  64%|██████▍   | 225/350 [00:02<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 227  (0.9):  65%|██████▍   | 226/350 [00:02<00:01, 107.62it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 229  (0.9):  65%|██████▌   | 228/350 [00:02<00:01, 107.62it/s]2024-10-12T23:37:06.729336Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 230  (0.9):  66%|██████▌   | 230/350 [00:02<00:01, 107.72it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 231  (0.9):  66%|██████▌   | 230/350 [00:02<00:01, 107.72it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 234  (0.9):  67%|██████▋   | 233/350 [00:02<00:01, 107.72it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 235  (0.9):  67%|██████▋   | 234/350 [00:02<00:01, 107.72it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 236  (0.8):  67%|██████▋   | 235/350 [00:02<00:01, 107.72it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 238  (0.8):  68%|██████▊   | 237/350 [00:02<00:01, 107.72it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 239  (0.8):  68%|██████▊   | 238/350 [00:02<00:01, 107.72it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 240  (0.8):  68%|██████▊   | 239/350 [00:02<00:01, 107.72it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 241  (0.8):  69%|██████▊   | 240/350 [00:02<00:01, 107.72it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 242  (0.8):  69%|██████▉   | 241/350 [00:02<00:01, 107.72it/s]2024-10-12T23:37:06.830211Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 243  (0.8):  69%|██████▉   | 243/350 [00:02<00:00, 112.80it/s]] error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 244  (0.8):  69%|██████▉   | 243/350 [00:02<00:00, 112.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 245  (0.8):  70%|██████▉   | 244/350 [00:02<00:00, 112.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 246  (0.8):  70%|███████   | 245/350 [00:02<00:00, 112.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 247  (0.8):  70%|███████   | 246/350 [00:02<00:00, 112.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 248  (0.8):  71%|███████   | 247/350 [00:02<00:00, 112.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 249  (0.8):  71%|███████   | 248/350 [00:02<00:00, 112.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 250  (0.8):  71%|███████   | 249/350 [00:02<00:00, 112.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 251  (0.8):  71%|███████▏  | 250/350 [00:02<00:00, 112.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 252  (0.8):  72%|███████▏  | 251/350 [00:02<00:00, 112.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 253  (0.8):  72%|███████▏  | 252/350 [00:02<00:00, 112.80it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 254  (0.8):  72%|███████▏  | 253/350 [00:02<00:00, 112.80it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 255  (0.8):  73%|███████▎  | 255/350 [00:02<00:00, 108.24it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 256  (0.8):  73%|███████▎  | 255/350 [00:02<00:00, 108.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 257  (0.8):  73%|███████▎  | 256/350 [00:02<00:00, 108.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 258  (0.8):  73%|███████▎  | 257/350 [00:02<00:00, 108.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 259  (0.8):  74%|███████▎  | 258/350 [00:02<00:00, 108.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 260  (0.8):  74%|███████▍  | 259/350 [00:02<00:00, 108.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 261  (0.8):  74%|███████▍  | 260/350 [00:02<00:00, 108.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 262  (0.8):  75%|███████▍  | 261/350 [00:02<00:00, 108.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 263  (0.8):  75%|███████▍  | 262/350 [00:02<00:00, 108.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 264  (0.8):  75%|███████▌  | 263/350 [00:02<00:00, 108.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 265  (0.8):  75%|███████▌  | 264/350 [00:02<00:00, 108.24it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 266  (0.8):  76%|███████▌  | 266/350 [00:02<00:00, 104.85it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 267  (0.7):  76%|███████▌  | 266/350 [00:02<00:00, 104.85it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 268  (0.7):  76%|███████▋  | 267/350 [00:02<00:00, 104.85it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 269  (0.7):  77%|███████▋  | 268/350 [00:02<00:00, 104.85it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 271  (0.7):  77%|███████▋  | 270/350 [00:02<00:00, 104.85it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 272  (0.7):  77%|███████▋  | 271/350 [00:02<00:00, 104.85it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 273  (0.7):  78%|███████▊  | 272/350 [00:02<00:00, 104.85it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 274  (0.7):  78%|███████▊  | 273/350 [00:02<00:00, 104.85it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 275  (0.7):  78%|███████▊  | 274/350 [00:02<00:00, 104.85it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 276  (0.7):  79%|███████▊  | 275/350 [00:02<00:00, 104.85it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 277  (0.7):  79%|███████▉  | 277/350 [00:02<00:00, 104.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 278  (0.7):  79%|███████▉  | 277/350 [00:02<00:00, 104.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 279  (0.7):  79%|███████▉  | 278/350 [00:02<00:00, 104.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 280  (0.7):  80%|███████▉  | 279/350 [00:02<00:00, 104.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 281  (0.7):  80%|████████  | 280/350 [00:02<00:00, 104.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 282  (0.7):  80%|████████  | 281/350 [00:02<00:00, 104.84it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 283  (0.7):  81%|████████  | 282/350 [00:02<00:00, 104.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 284  (0.7):  81%|████████  | 283/350 [00:02<00:00, 104.84it/s]2024-10-12T23:37:07.258566Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 285  (0.7):  81%|████████  | 284/350 [00:02<00:00, 104.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 286  (0.7):  81%|████████▏ | 285/350 [00:02<00:00, 104.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 287  (0.7):  82%|████████▏ | 286/350 [00:02<00:00, 104.84it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 288  (0.7):  82%|████████▏ | 288/350 [00:02<00:00, 94.28it/s]  [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 290  (0.7):  83%|████████▎ | 289/350 [00:02<00:00, 94.28it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 291  (0.7):  83%|████████▎ | 290/350 [00:02<00:00, 94.28it/s]2024-10-12T23:37:07.321279Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 293  (0.7):  83%|████████▎ | 292/350 [00:02<00:00, 94.28it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 294  (0.7):  84%|████████▎ | 293/350 [00:02<00:00, 94.28it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 295  (0.7):  84%|████████▍ | 294/350 [00:02<00:00, 94.28it/s]2024-10-12T23:37:07.351481Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 296  (0.7):  84%|████████▍ | 295/350 [00:02<00:00, 94.28it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 298  (0.7):  85%|████████▍ | 297/350 [00:02<00:00, 94.28it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 299  (0.7):  85%|████████▌ | 299/350 [00:02<00:00, 98.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 300  (0.7):  85%|████████▌ | 299/350 [00:02<00:00, 98.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 301  (0.7):  86%|████████▌ | 300/350 [00:02<00:00, 98.35it/s]2024-10-12T23:37:07.403160Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 302  (0.7):  86%|████████▌ | 301/350 [00:02<00:00, 98.35it/s]2024-10-12T23:37:07.413118Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 303  (0.7):  86%|████████▋ | 302/350 [00:02<00:00, 98.35it/s]2024-10-12T23:37:07.423102Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 304  (0.7):  87%|████████▋ | 303/350 [00:02<00:00, 98.35it/s]2024-10-12T23:37:07.432956Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 305  (0.7):  87%|████████▋ | 304/350 [00:02<00:00, 98.35it/s]2024-10-12T23:37:07.442893Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 306  (0.7):  87%|████████▋ | 305/350 [00:02<00:00, 98.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 307  (0.7):  87%|████████▋ | 306/350 [00:02<00:00, 98.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 308  (0.6):  88%|████████▊ | 307/350 [00:02<00:00, 98.35it/s]2024-10-12T23:37:07.473638Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 309  (0.6):  88%|████████▊ | 308/350 [00:02<00:00, 98.35it/s]2024-10-12T23:37:07.483927Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 310  (0.6):  89%|████████▊ | 310/350 [00:02<00:00, 99.53it/s]2024-10-12T23:37:07.493751Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 311  (0.6):  89%|████████▊ | 310/350 [00:02<00:00, 99.53it/s]2024-10-12T23:37:07.502184Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 312  (0.6):  89%|████████▉ | 311/350 [00:02<00:00, 99.53it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 313  (0.6):  89%|████████▉ | 312/350 [00:02<00:00, 99.53it/s]2024-10-12T23:37:07.523354Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 314  (0.6):  89%|████████▉ | 313/350 [00:02<00:00, 99.53it/s]2024-10-12T23:37:07.533438Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 315  (0.6):  90%|████████▉ | 314/350 [00:02<00:00, 99.53it/s]2024-10-12T23:37:07.543258Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 316  (0.6):  90%|█████████ | 315/350 [00:02<00:00, 99.53it/s]2024-10-12T23:37:07.555292Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 317  (0.6):  90%|█████████ | 316/350 [00:02<00:00, 99.53it/s]2024-10-12T23:37:07.565229Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 318  (0.6):  91%|█████████ | 317/350 [00:02<00:00, 99.53it/s]2024-10-12T23:37:07.576854Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 319  (0.6):  91%|█████████ | 318/350 [00:02<00:00, 99.53it/s]2024-10-12T23:37:07.586965Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 320  (0.6):  91%|█████████ | 319/350 [00:02<00:00, 99.53it/s]2024-10-12T23:37:07.599376Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 321  (0.6):  92%|█████████▏| 321/350 [00:02<00:00, 101.51it/s]024-10-12T23:37:07.610125Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 322  (0.6):  92%|█████████▏| 321/350 [00:02<00:00, 101.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 323  (0.6):  92%|█████████▏| 322/350 [00:02<00:00, 101.51it/s]2024-10-12T23:37:07.630822Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 324  (0.6):  92%|█████████▏| 323/350 [00:02<00:00, 101.51it/s]2024-10-12T23:37:07.641084Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 325  (0.6):  93%|█████████▎| 324/350 [00:02<00:00, 101.51it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 326  (0.6):  93%|█████████▎| 325/350 [00:02<00:00, 101.51it/s]2024-10-12T23:37:07.661509Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 327  (0.6):  93%|█████████▎| 326/350 [00:02<00:00, 101.51it/s]2024-10-12T23:37:07.670540Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 328  (0.6):  93%|█████████▎| 327/350 [00:03<00:00, 101.51it/s]2024-10-12T23:37:07.681274Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 329  (0.6):  94%|█████████▎| 328/350 [00:03<00:00, 101.51it/s]2024-10-12T23:37:07.691774Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 330  (0.6):  94%|█████████▍| 329/350 [00:03<00:00, 101.51it/s]2024-10-12T23:37:07.703320Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 331  (0.6):  94%|█████████▍| 330/350 [00:03<00:00, 101.51it/s]2024-10-12T23:37:07.716658Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 332  (0.6):  95%|█████████▍| 332/350 [00:03<00:00, 102.81it/s]2024-10-12T23:37:07.730077Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 333  (0.6):  95%|█████████▍| 332/350 [00:03<00:00, 102.81it/s]2024-10-12T23:37:07.743199Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 334  (0.6):  95%|█████████▌| 333/350 [00:03<00:00, 102.81it/s]2024-10-12T23:37:07.756527Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 335  (0.6):  95%|█████████▌| 334/350 [00:03<00:00, 102.81it/s]2024-10-12T23:37:07.769620Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 336  (0.6):  96%|█████████▌| 335/350 [00:03<00:00, 102.81it/s]2024-10-12T23:37:07.782765Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 337  (0.6):  96%|█████████▌| 336/350 [00:03<00:00, 102.81it/s]2024-10-12T23:37:07.796389Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 338  (0.6):  96%|█████████▋| 337/350 [00:03<00:00, 102.81it/s]2024-10-12T23:37:07.809922Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 339  (0.6):  97%|█████████▋| 338/350 [00:03<00:00, 102.81it/s]2024-10-12T23:37:07.823850Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 340  (0.6):  97%|█████████▋| 339/350 [00:03<00:00, 102.81it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 341  (0.6):  97%|█████████▋| 340/350 [00:03<00:00, 102.81it/s]2024-10-12T23:37:07.851412Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 342  (0.6):  97%|█████████▋| 341/350 [00:03<00:00, 102.81it/s]2024-10-12T23:37:07.864765Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 343  (0.6):  98%|█████████▊| 343/350 [00:03<00:00, 102.89it/s]2024-10-12T23:37:07.880869Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 344  (0.6):  98%|█████████▊| 343/350 [00:03<00:00, 102.89it/s]2024-10-12T23:37:07.895721Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 345  (0.6):  98%|█████████▊| 344/350 [00:03<00:00, 102.89it/s]2024-10-12T23:37:07.905781Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 346  (0.6):  99%|█████████▊| 345/350 [00:03<00:00, 102.89it/s]2024-10-12T23:37:07.917038Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 347  (0.6):  99%|█████████▉| 346/350 [00:03<00:00, 102.89it/s]2024-10-12T23:37:07.927154Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 348  (0.6):  99%|█████████▉| 347/350 [00:03<00:00, 102.89it/s]2024-10-12T23:37:07.937521Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 349  (0.6):  99%|█████████▉| 348/350 [00:03<00:00, 102.89it/s]2024-10-12T23:37:07.947554Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 350  (0.6): 100%|██████████| 350/350 [00:03<00:00, 108.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [0.57, 0.57]\n",
      "Best score so far: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/150 [00:00<00:43,  3.42it/s]2024-10-12T23:37:08.883185Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_amount_of_cash_received', 'text': 'I did not receive the right amount of cash I requested', 'answer': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 2/150 [00:00<00:31,  4.68it/s]2024-10-12T23:37:09.078346Z [error    ] Failed to run or to evaluate example Example({'label': 'extra_charge_on_statement', 'text': 'I just looked at my app and it seems I was charged extra, why is that?', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  2%|▏         | 3/150 [00:00<00:30,  4.88it/s]2024-10-12T23:37:09.300055Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_top_up', 'text': \"How long will it take for my top up to work? It's still pending\", 'answer': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 4/150 [00:00<00:30,  4.72it/s]2024-10-12T23:37:09.520214Z [error    ] Failed to run or to evaluate example Example({'label': 'transfer_not_received_by_recipient', 'text': \"Two days ago I did a transfer to another account within the country.  It doesn't appear the transfer went through.  I have verified the account number several times.  Could you please check on this for me?\", 'answer': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 5/150 [00:01<00:31,  4.67it/s]2024-10-12T23:37:09.707903Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_wrong_exchange_rate', 'text': 'I noticed an extra charge on the purchase that I made last Saturday on my account. Can you see if I received the correct exchange rate?', 'answer': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 6/150 [00:01<00:29,  4.86it/s]2024-10-12T23:37:09.877863Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_bank_transfer', 'text': 'Hi, I made a transfer from France two days ago and thought it would be here by now. Can you give me an update please?', 'answer': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▍         | 7/150 [00:01<00:27,  5.15it/s]2024-10-12T23:37:10.040925Z [error    ] Failed to run or to evaluate example Example({'label': 'extra_charge_on_statement', 'text': 'Why do I see an extra fee on my statement?', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▌         | 8/150 [00:01<00:26,  5.43it/s]2024-10-12T23:37:10.227564Z [error    ] Failed to run or to evaluate example Example({'label': 'extra_charge_on_statement', 'text': 'I was made to pay an additional pound!', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 9/150 [00:01<00:26,  5.42it/s]2024-10-12T23:37:10.393212Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_bank_transfer', 'text': \"I made a bank transfer earlier from my UK account.  I don't see it yet, can you check the status?\", 'answer': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 10/150 [00:01<00:25,  5.58it/s]2024-10-12T23:37:10.618429Z [error    ] Failed to run or to evaluate example Example({'label': 'transaction_charged_twice', 'text': 'Why was I double charged?', 'answer': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 11/150 [00:02<00:26,  5.18it/s]2024-10-12T23:37:10.803555Z [error    ] Failed to run or to evaluate example Example({'label': 'card_arrival', 'text': 'How much longer until I get my new card?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  8%|▊         | 12/150 [00:02<00:26,  5.24it/s]2024-10-12T23:37:10.957432Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_amount_of_cash_received', 'text': 'What do I do if I got the wrong amount at the ATM?', 'answer': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  9%|▊         | 13/150 [00:02<00:24,  5.58it/s]2024-10-12T23:37:11.140850Z [error    ] Failed to run or to evaluate example Example({'label': 'transfer_fee_charged', 'text': \"I don't think I was supposed to be charged so much.\", 'answer': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  9%|▉         | 14/150 [00:02<00:24,  5.54it/s]2024-10-12T23:37:11.250445Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_not_recognised', 'text': \"There's a payment with my card that I definitely didn't do myself, never seen that name before.\", 'answer': 'card_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 10%|█         | 15/150 [00:02<00:21,  6.28it/s]2024-10-12T23:37:11.402508Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_not_recognised', 'text': \"My app shows cash I didn't get.\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 11%|█         | 16/150 [00:02<00:21,  6.36it/s]2024-10-12T23:37:11.569374Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_not_recognised', 'text': \"There is a payment made with my card that I don't recognize at all.\", 'answer': 'card_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 11%|█▏        | 17/150 [00:03<00:21,  6.25it/s]2024-10-12T23:37:11.735905Z [error    ] Failed to run or to evaluate example Example({'label': 'direct_debit_payment_not_recognised', 'text': 'I see a charge for a direct debit that was not me.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 12%|█▏        | 18/150 [00:03<00:21,  6.17it/s]2024-10-12T23:37:11.907034Z [error    ] Failed to run or to evaluate example Example({'label': 'extra_charge_on_statement', 'text': 'There is a charge for an additional pound.', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 13%|█▎        | 19/150 [00:03<00:21,  6.07it/s]2024-10-12T23:37:12.080318Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_card_payment', 'text': 'My card payment is showing pending however this transaction was a couple of days ago. Is there a reason why it it still pending?', 'answer': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 13%|█▎        | 20/150 [00:03<00:21,  5.98it/s]2024-10-12T23:37:12.237850Z [error    ] Failed to run or to evaluate example Example({'label': 'transaction_charged_twice', 'text': 'I think there is a mistake.  I am being charged twice.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 14%|█▍        | 21/150 [00:03<00:21,  6.08it/s]2024-10-12T23:37:12.400438Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_cheque_or_cash_deposit', 'text': 'I checked the app and my balance has not been updated for the cash or cheque deposit.', 'answer': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 15%|█▍        | 22/150 [00:03<00:20,  6.10it/s]2024-10-12T23:37:12.580770Z [error    ] Failed to run or to evaluate example Example({'label': 'request_refund', 'text': \"I'm cancelling this charge. I still have not received what I bought from these people a while ago.\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 15%|█▌        | 23/150 [00:04<00:21,  5.93it/s]2024-10-12T23:37:12.688418Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_amount_of_cash_received', 'text': 'I requested $100 but only got $20', 'answer': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 17%|█▋        | 25/150 [00:04<00:21,  5.70it/s]2024-10-12T23:37:13.124811Z [error    ] Failed to run or to evaluate example Example({'label': 'activate_my_card', 'text': 'How long does it take to activate the card, as it does not look like its working?', 'answer': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 17%|█▋        | 26/150 [00:04<00:22,  5.45it/s]2024-10-12T23:37:13.412648Z [error    ] Failed to run or to evaluate example Example({'label': 'direct_debit_payment_not_recognised', 'text': \"Recently, a few weeks ago there was a transaction made on my account by some seller that I don't recognize. I am very certain that didn't happen  and will like for you to trace back to make sure.\", 'answer': 'direct_debit_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 18%|█▊        | 27/150 [00:04<00:26,  4.65it/s]2024-10-12T23:37:13.613008Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_charge', 'text': 'Why am I being charged for ATM fees?', 'answer': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 19%|█▊        | 28/150 [00:05<00:25,  4.75it/s]2024-10-12T23:37:13.722182Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_exchange_rate_for_cash_withdrawal', 'text': \"I'm upset because I got charged a ridiculous fee when making an ATM withdrawal over a holiday weekend.  It didn't notify me beforehand either or I wouldn't have ever done it.\", 'answer': 'wrong_exchange_rate_for_cash_withdrawal'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 19%|█▉        | 29/150 [00:05<00:21,  5.56it/s]2024-10-12T23:37:13.901072Z [error    ] Failed to run or to evaluate example Example({'label': 'activate_my_card', 'text': 'I just got my new card.  How can I activate it?', 'answer': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 20%|██        | 30/150 [00:05<00:21,  5.57it/s]2024-10-12T23:37:14.182098Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_top_up', 'text': 'My account is  new  why can I  not top up', 'answer': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 21%|██        | 31/150 [00:05<00:24,  4.76it/s]2024-10-12T23:37:14.292462Z [error    ] Failed to run or to evaluate example Example({'label': 'transfer_fee_charged', 'text': 'I use my card internationally to manage payments and I just noticed that you are adding additional fees.  Why?  I am a good customer and this has me thinking about leaving.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 21%|██▏       | 32/150 [00:05<00:21,  5.55it/s]2024-10-12T23:37:14.510398Z [error    ] Failed to run or to evaluate example Example({'label': 'declined_card_payment', 'text': \"My card payment didn't work\", 'answer': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 22%|██▏       | 33/150 [00:06<00:22,  5.22it/s]2024-10-12T23:37:14.669750Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_card_payment', 'text': \"I have a payment that hasn't went through yet.\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 23%|██▎       | 34/150 [00:06<00:21,  5.49it/s]2024-10-12T23:37:14.834055Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_charge', 'text': \"I used my card to get cash then I was charged a fee that I shouldn't have been charged.\", 'answer': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 24%|██▍       | 36/150 [00:06<00:23,  4.90it/s]2024-10-12T23:37:15.339345Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_not_recognised', 'text': 'Somebody is taking money out of my account without my approval in another town separate from me. Please place a freeze on my account until I can make it to the bank.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 25%|██▍       | 37/150 [00:06<00:24,  4.67it/s]2024-10-12T23:37:15.504731Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_cheque_or_cash_deposit', 'text': \"I have made a recent check and cash deposit that isn't reflected in my balance.\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 25%|██▌       | 38/150 [00:07<00:22,  5.02it/s]2024-10-12T23:37:15.655002Z [error    ] Failed to run or to evaluate example Example({'label': 'transfer_fee_charged', 'text': 'I noticed a fee, while banking abroad, that seems different than any I have been charged before. What does this fee mean?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 27%|██▋       | 40/150 [00:07<00:25,  4.25it/s]2024-10-12T23:37:16.185515Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_not_recognised', 'text': \"I don't understand where this charge came from.\", 'answer': 'card_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 27%|██▋       | 41/150 [00:07<00:23,  4.59it/s]2024-10-12T23:37:16.366178Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_card_payment', 'text': 'Why is the payment showing as pending from things I bought this morning?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 28%|██▊       | 42/150 [00:07<00:22,  4.84it/s]2024-10-12T23:37:16.571065Z [error    ] Failed to run or to evaluate example Example({'label': 'direct_debit_payment_not_recognised', 'text': \"How do I dispute a debit that I didn't make?\", 'answer': 'direct_debit_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 29%|██▊       | 43/150 [00:08<00:22,  4.85it/s]2024-10-12T23:37:16.770430Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_not_recognised', 'text': 'I did not make this payment that I see in the App.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 30%|███       | 45/150 [00:08<00:23,  4.43it/s]2024-10-12T23:37:17.292697Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_fee_charged', 'text': 'What is this extra fee?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 31%|███▏      | 47/150 [00:09<00:23,  4.30it/s]2024-10-12T23:37:17.689015Z [error    ] Failed to run or to evaluate example Example({'label': 'card_arrival', 'text': 'why hasnt my card come in yet?', 'answer': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 32%|███▏      | 48/150 [00:09<00:21,  4.74it/s]2024-10-12T23:37:17.852259Z [error    ] Failed to run or to evaluate example Example({'label': 'reverted_card_payment', 'text': 'I used my card to make a payment and wondered why the payment was reverted?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 33%|███▎      | 49/150 [00:09<00:19,  5.08it/s]2024-10-12T23:37:18.051738Z [error    ] Failed to run or to evaluate example Example({'label': 'request_refund', 'text': 'I would like to cancel a purchase.', 'answer': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 33%|███▎      | 50/150 [00:09<00:19,  5.06it/s]2024-10-12T23:37:18.250766Z [error    ] Failed to run or to evaluate example Example({'label': 'reverted_card_payment', 'text': 'My card payment has been cancelled', 'answer': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 34%|███▍      | 51/150 [00:09<00:19,  5.05it/s]2024-10-12T23:37:18.454323Z [error    ] Failed to run or to evaluate example Example({'label': 'activate_my_card', 'text': 'Could you please tell me how to activate my new card?', 'answer': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 35%|███▌      | 53/150 [00:11<00:54,  1.78it/s]2024-10-12T23:37:20.041436Z [error    ] Failed to run or to evaluate example Example({'label': 'extra_charge_on_statement', 'text': 'Why have I been charged an extra £1?', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 36%|███▌      | 54/150 [00:11<00:42,  2.24it/s]2024-10-12T23:37:20.242213Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_bank_transfer', 'text': \"I made a bank transfer but it doesn't seem to have gone through?\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 37%|███▋      | 55/150 [00:11<00:35,  2.68it/s]2024-10-12T23:37:20.402694Z [error    ] Failed to run or to evaluate example Example({'label': 'transaction_charged_twice', 'text': 'There are duplicate transactions on my account', 'answer': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 39%|███▉      | 59/150 [00:12<00:24,  3.64it/s]2024-10-12T23:37:21.311393Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_card_payment', 'text': \"I made a payment that's pending. Will it go through?\", 'answer': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 40%|████      | 60/150 [00:12<00:21,  4.12it/s]2024-10-12T23:37:21.479444Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_exchange_rate_for_cash_withdrawal', 'text': 'When I received my cash; they had my exchange rate incorrect.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 41%|████      | 61/150 [00:13<00:19,  4.54it/s]2024-10-12T23:37:21.642134Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_wrong_exchange_rate', 'text': 'A foreign purchase I made has the incorrect rate applied to it.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 41%|████▏     | 62/150 [00:13<00:17,  4.93it/s]2024-10-12T23:37:21.755954Z [error    ] Failed to run or to evaluate example Example({'label': 'declined_cash_withdrawal', 'text': \"Why can't I take money from my account?\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 42%|████▏     | 63/150 [00:13<00:15,  5.68it/s]2024-10-12T23:37:21.948391Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_cheque_or_cash_deposit', 'text': \"Why hasn't my balance been updated? I've deposited a few cheques some days ago!\", 'answer': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 43%|████▎     | 64/150 [00:13<00:15,  5.53it/s]2024-10-12T23:37:22.109531Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_not_recognised', 'text': \"There's a cash withdrawal I am certain I did not make\", 'answer': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 43%|████▎     | 65/150 [00:13<00:14,  5.71it/s]2024-10-12T23:37:22.218291Z [error    ] Failed to run or to evaluate example Example({'label': 'refund_not_showing_up', 'text': \"I can't find my refund. Please help.\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 44%|████▍     | 66/150 [00:13<00:13,  6.45it/s]2024-10-12T23:37:22.382446Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_exchange_rate_for_cash_withdrawal', 'text': 'I think the exchange rate for the cash I withdrew was wrong.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 45%|████▌     | 68/150 [00:14<00:15,  5.44it/s]2024-10-12T23:37:22.826153Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_not_recognised', 'text': \"My identity has been stolen. I still have my physical card but there are charges I didn't make on my account. How do I cancel this card or dispute the charges?\", 'answer': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 46%|████▌     | 69/150 [00:14<00:15,  5.29it/s]2024-10-12T23:37:22.991972Z [error    ] Failed to run or to evaluate example Example({'label': 'transfer_not_received_by_recipient', 'text': \"My transfer didn't arrive to the recipient\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 47%|████▋     | 70/150 [00:14<00:14,  5.50it/s]2024-10-12T23:37:23.158030Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_fee_charged', 'text': 'I was charged a fee for using my card. Can I check that in any way? It seems like there are occasions that I am charge for fees. Can you elaborate this?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 47%|████▋     | 71/150 [00:14<00:13,  5.65it/s]2024-10-12T23:37:23.370115Z [error    ] Failed to run or to evaluate example Example({'label': 'refund_not_showing_up', 'text': \"My refund isn't going fast enough.\", 'answer': 'refund_not_showing_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 48%|████▊     | 72/150 [00:14<00:14,  5.34it/s]2024-10-12T23:37:23.478527Z [error    ] Failed to run or to evaluate example Example({'label': 'request_refund', 'text': \"I'm interested in learning more about product refunds.\", 'answer': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 49%|████▊     | 73/150 [00:15<00:12,  6.10it/s]2024-10-12T23:37:23.769907Z [error    ] Failed to run or to evaluate example Example({'label': 'extra_charge_on_statement', 'text': 'Why would there be an extra charge on my app?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 49%|████▉     | 74/150 [00:15<00:15,  4.95it/s]2024-10-12T23:37:23.934790Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_wrong_exchange_rate', 'text': 'Why is the exchange rate different on my recent purchase?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 51%|█████     | 76/150 [00:16<00:29,  2.50it/s]2024-10-12T23:37:24.985846Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_wrong_exchange_rate', 'text': 'The wrong exchange rate was used when I purchased an item.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 52%|█████▏    | 78/150 [00:16<00:15,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 79 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 2  (50.0):   0%|          | 1/350 [00:00<02:12,  2.64it/s] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 6  (50.0):   1%|▏         | 5/350 [00:00<02:10,  2.64it/s]2024-10-12T23:37:26.632869Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 3.0 / 7  (42.9):   2%|▏         | 7/350 [00:01<00:46,  7.35it/s]2024-10-12T23:37:26.662035Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 25  (28.0):   7%|▋         | 24/350 [00:01<00:14, 23.14it/s]2024-10-12T23:37:27.129015Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 55  (23.6):  15%|█▌        | 54/350 [00:02<00:08, 34.52it/s]filename12T23:37:28.031077Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 57  (22.8):  16%|█▌        | 56/350 [00:02<00:08, 34.52it/s]dspy.evaluate.evaluate example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 58  (22.4):  17%|█▋        | 58/350 [00:02<00:10, 28.47it/s]2024-10-12T23:37:28.070678Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 61  (21.3):  17%|█▋        | 60/350 [00:02<00:10, 28.47it/s]2024-10-12T23:37:28.258822Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 74  (24.3):  21%|██        | 73/350 [00:03<00:09, 28.86it/s] 024-10-12T23:37:28.610654Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 24.0 / 103  (23.3):  29%|██▉       | 102/350 [00:04<00:13, 19.01it/s] 4-10-12T23:37:30.020991Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 36.0 / 140  (25.7):  40%|███▉      | 139/350 [00:05<00:04, 47.95it/s]2024-10-12T23:37:30.939107Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 141  (25.5):  40%|████      | 140/350 [00:05<00:04, 47.95it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 142  (25.4):  40%|████      | 141/350 [00:05<00:04, 47.95it/s]2024-10-12T23:37:31.003633Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 192  (24.5):  55%|█████▍    | 192/350 [00:06<00:04, 37.01it/s]2024-10-12T23:37:32.530943Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 193  (24.4):  55%|█████▍    | 192/350 [00:06<00:04, 37.01it/s]2024-10-12T23:37:32.560873Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 194  (24.2):  55%|█████▌    | 193/350 [00:06<00:04, 37.01it/s]2024-10-12T23:37:32.566939Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 195  (24.1):  55%|█████▌    | 194/350 [00:06<00:04, 37.01it/s]2024-10-12T23:37:32.574425Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 199  (23.6):  57%|█████▋    | 198/350 [00:07<00:05, 26.67it/s]2024-10-12T23:37:32.823459Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 242  (23.6):  69%|██████▉   | 241/350 [00:08<00:02, 39.52it/s]2024-10-12T23:37:34.016624Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 259  (23.2):  74%|███████▎  | 258/350 [00:09<00:03, 24.34it/s]dspy.evaluate.evaluate5178Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 68.0 / 293  (23.2):  83%|████████▎ | 292/350 [00:09<00:01, 34.99it/s]2024-10-12T23:37:35.550626Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 72.0 / 314  (22.9):  89%|████████▉ | 313/350 [00:10<00:00, 43.07it/s]=024-10-12T23:37:36.034740Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 73.0 / 319  (22.9):  91%|█████████ | 318/350 [00:10<00:00, 46.68it/s]1984-10-12T23:37:36.107132Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno=\n",
      "Average Metric: 79.0 / 345  (22.9):  98%|█████████▊| 344/350 [00:10<00:00, 84.17it/s] [24-10-12T23:37:36.278554Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 80.0 / 350  (22.9): 100%|██████████| 350/350 [00:10<00:00, 32.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 22.86 for seed -1\n",
      "Scores so far: [0.57, 0.57, 22.86]\n",
      "Best score so far: 22.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]2024-10-12T23:37:36.419647Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_charge', 'text': 'Why am I being charged for ATM fees?', 'answer': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:36.428650Z [error    ] Failed to run or to evaluate example Example({'label': 'reverted_card_payment', 'text': 'My card payment has been cancelled', 'answer': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:36.437969Z [error    ] Failed to run or to evaluate example Example({'label': 'extra_charge_on_statement', 'text': 'Why have I been charged an extra £1?', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:36.705417Z [error    ] Failed to run or to evaluate example Example({'label': 'request_refund', 'text': 'I want a refund on this.', 'answer': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 4/150 [00:00<00:10, 13.38it/s]2024-10-12T23:37:36.877599Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_amount_of_cash_received', 'text': 'i asked for 100 only got 80', 'answer': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:36.889721Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_not_recognised', 'text': \"There's a payment with my card that I definitely didn't do myself, never seen that name before.\", 'answer': 'card_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 6/150 [00:00<00:11, 12.19it/s]2024-10-12T23:37:36.904194Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_not_recognised', 'text': \"My identity has been stolen. I still have my physical card but there are charges I didn't make on my account. How do I cancel this card or dispute the charges?\", 'answer': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:37.079273Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_charge', 'text': 'How come my cash withdrawal came with an unnecessary fee?!', 'answer': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▌         | 8/150 [00:00<00:12, 11.52it/s]2024-10-12T23:37:37.253143Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_cheque_or_cash_deposit', 'text': \"I've deposited a check in my account but the cash isn't showing as available.\", 'answer': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:37.262713Z [error    ] Failed to run or to evaluate example Example({'label': 'activate_my_card', 'text': 'I just got my new card.  How can I activate it?', 'answer': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 10/150 [00:00<00:12, 11.40it/s]2024-10-12T23:37:37.272404Z [error    ] Failed to run or to evaluate example Example({'label': 'card_arrival', 'text': 'why hasnt my card come in yet?', 'answer': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  8%|▊         | 12/150 [00:01<00:22,  6.20it/s]2024-10-12T23:37:37.891264Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_cheque_or_cash_deposit', 'text': 'I checked the app and my balance has not been updated for the cash or cheque deposit.', 'answer': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:38.015511Z [error    ] Failed to run or to evaluate example Example({'label': 'card_arrival', 'text': 'My card never arrived.', 'answer': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  9%|▉         | 14/150 [00:01<00:17,  7.59it/s]2024-10-12T23:37:38.029654Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_amount_of_cash_received', 'text': 'I requested $100 but only got $20', 'answer': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:38.147980Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_amount_of_cash_received', 'text': 'Why is my withdrawal wrong? I took out $100 but only received $20.', 'answer': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 11%|█         | 16/150 [00:01<00:14,  9.04it/s]2024-10-12T23:37:38.395015Z [error    ] Failed to run or to evaluate example Example({'label': 'transaction_charged_twice', 'text': 'Hi, I was looking over my card receipts for the past week and I realize I had a charge put through two times for the same single restaurant visit. Can one of the charges be removed so that I can get the money back that was mistakenly taken from my account?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:38.404692Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_card_payment', 'text': \"I made a payment that's pending. Will it go through?\", 'answer': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 12%|█▏        | 18/150 [00:01<00:15,  8.63it/s]2024-10-12T23:37:38.414154Z [error    ] Failed to run or to evaluate example Example({'label': 'declined_card_payment', 'text': \"My card payment didn't work\", 'answer': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:38.629396Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_cheque_or_cash_deposit', 'text': \"Why hasn't my balance been updated from the check deposit I made?\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 13%|█▎        | 20/150 [00:02<00:14,  8.70it/s]2024-10-12T23:37:38.890282Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_card_payment', 'text': 'Card payment is still pending, why is that the case?', 'answer': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:39.433959Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_bank_transfer', 'text': \"How long does it typically take to make a transfer from a UK bank? I just made one and it hasn't shown up in my account yet.\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 15%|█▍        | 22/150 [00:03<00:25,  4.94it/s]2024-10-12T23:37:39.547994Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_fee_charged', 'text': 'Why did I have to pay an additional amount when using my card to pay?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 15%|█▌        | 23/150 [00:03<00:23,  5.34it/s]2024-10-12T23:37:39.561913Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_bank_transfer', 'text': 'Hi, I made a transfer from France two days ago and thought it would be here by now. Can you give me an update please?', 'answer': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:39.574005Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_bank_transfer', 'text': \"I made a bank transfer but it doesn't seem to have gone through?\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:39.586073Z [error    ] Failed to run or to evaluate example Example({'label': 'transaction_charged_twice', 'text': 'I think there is a mistake.  I am being charged twice.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:39.760280Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_bank_transfer', 'text': 'when will the balance on my account change form a transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 18%|█▊        | 27/150 [00:03<00:14,  8.37it/s]2024-10-12T23:37:39.880915Z [error    ] Failed to run or to evaluate example Example({'label': 'transfer_not_received_by_recipient', 'text': \"I've checked multiple times to make sure the account number listed is the right one after attempting to make a transfer within the country the day before yesterday. The transfer is still not available so can you please find out what is going on?\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:39.890940Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_top_up', 'text': \"How long will it take for my top up to work? It's still pending\", 'answer': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 19%|█▉        | 29/150 [00:03<00:12,  9.56it/s]2024-10-12T23:37:39.900932Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_card_payment', 'text': 'My card payment is showing pending however this transaction was a couple of days ago. Is there a reason why it it still pending?', 'answer': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:40.007051Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_charge', 'text': \"Since when do you charge to make a withdrawal? I've always done it for free. So how much is it now?\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 21%|██▏       | 32/150 [00:03<00:13,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 33 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:37:40.977279Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<03:22,  1.73it/s]2024-10-12T23:37:41.008180Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/350 [00:00<03:22,  1.73it/s]2024-10-12T23:37:41.022534Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 34  (23.5):   9%|▉         | 33/350 [00:01<00:08, 35.90it/s]2024-10-12T23:37:41.871426Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 48  (22.9):  13%|█▎        | 47/350 [00:01<00:10, 30.18it/s]2024-10-12T23:37:42.337344Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 75  (24.0):  21%|██        | 74/350 [00:02<00:06, 39.59it/s]2024-10-12T23:37:43.036648Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 20.0 / 86  (23.3):  24%|██▍       | 85/350 [00:02<00:07, 36.91it/s]evaluate.py23:37:43.328693Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 22.0 / 91  (24.2):  26%|██▌       | 91/350 [00:03<00:06, 40.82it/s]2024-10-12T23:37:43.578207Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 140  (25.7):  40%|███▉      | 139/350 [00:04<00:05, 37.64it/s] [24-10-12T23:37:44.868148Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 142  (25.4):  41%|████      | 142/350 [00:04<00:05, 37.29it/s]2024-10-12T23:37:45.041022Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 148  (25.7):  42%|████▏     | 147/350 [00:04<00:06, 32.28it/s]2024-10-12T23:37:45.121737Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 49.0 / 199  (24.6):  57%|█████▋    | 199/350 [00:06<00:05, 29.92it/s]2024-10-12T23:37:46.675256Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 217  (24.0):  62%|██████▏   | 216/350 [00:06<00:03, 42.73it/s]2024-10-12T23:37:47.003061Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 220  (24.1):  63%|██████▎   | 219/350 [00:06<00:03, 43.17it/s]=024-10-12T23:37:47.026656Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 53.0 / 224  (23.7):  64%|██████▎   | 223/350 [00:06<00:02, 43.17it/s]2024-10-12T23:37:47.139531Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 225  (23.6):  64%|██████▍   | 225/350 [00:06<00:02, 45.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 55.0 / 237  (23.2):  67%|██████▋   | 236/350 [00:07<00:03, 36.13it/s]2024-10-12T23:37:47.681965Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 66.0 / 276  (23.9):  79%|███████▉  | 276/350 [00:08<00:01, 47.24it/s]=spy.evaluate.evaluate5128Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename=evaluate.py lineno198\n",
      "Average Metric: 69.0 / 287  (24.0):  82%|████████▏ | 286/350 [00:08<00:01, 46.87it/s]2024-10-12T23:37:48.930316Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 69.0 / 288  (24.0):  82%|████████▏ | 288/350 [00:08<00:01, 40.71it/s]2024-10-12T23:37:49.054684Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 75.0 / 312  (24.0):  89%|████████▉ | 311/350 [00:09<00:01, 38.65it/s]=spy.evaluate.evaluate0556Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filenameevaluate.py lineno=198\n",
      "Average Metric: 83.0 / 337  (24.6):  96%|█████████▌| 336/350 [00:09<00:00, 52.04it/s]]024-10-12T23:37:49.751469Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 84.0 / 345  (24.3):  98%|█████████▊| 344/350 [00:09<00:00, 81.13it/s]2024-10-12T23:37:49.821584Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 350  (24.6): 100%|██████████| 350/350 [00:09<00:00, 37.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 24.57 for seed 0\n",
      "Scores so far: [0.57, 0.57, 22.86, 24.57]\n",
      "Best score so far: 24.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]2024-10-12T23:37:49.907674Z [error    ] Failed to run or to evaluate example Example({'label': 'request_refund', 'text': 'I would like to cancel a purchase.', 'answer': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:49.915479Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_not_recognised', 'text': \"I don't understand where this charge came from.\", 'answer': 'card_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:50.100876Z [error    ] Failed to run or to evaluate example Example({'label': 'refund_not_showing_up', 'text': 'A refund is taking too long.', 'answer': 'refund_not_showing_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 4/150 [00:00<00:07, 19.66it/s]2024-10-12T23:37:50.112055Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_bank_transfer', 'text': \"I made a bank transfer earlier from my UK account.  I don't see it yet, can you check the status?\", 'answer': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:50.121082Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_wrong_exchange_rate', 'text': 'The wrong exchange rate was used when I purchased an item.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:50.311652Z [error    ] Failed to run or to evaluate example Example({'label': 'reverted_card_payment', 'text': \"I received a message from a seller stating they hadn't received my money even though it definitely came out of my account. The money has now been deposited back into my account. Please get this resolved as soon as possible.\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▍         | 7/150 [00:00<00:08, 16.45it/s]2024-10-12T23:37:50.497141Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_wrong_exchange_rate', 'text': 'I bought an item and the exchange rate was wrong.', 'answer': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:50.506584Z [error    ] Failed to run or to evaluate example Example({'label': 'extra_charge_on_statement', 'text': 'I was made to pay an additional pound!', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  6%|▌         | 9/150 [00:00<00:10, 13.75it/s]2024-10-12T23:37:50.688840Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_not_recognised', 'text': \"A payment that I didn't make appears in my app.\", 'answer': 'card_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:50.698572Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_not_recognised', 'text': 'I did not make this payment that I see in the App.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 11/150 [00:00<00:11, 12.46it/s]2024-10-12T23:37:50.959412Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_fee_charged', 'text': 'What is the fee charged for using my card?', 'answer': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:51.073297Z [error    ] Failed to run or to evaluate example Example({'label': 'transfer_fee_charged', 'text': \"I don't appreciate the extra fees being siphoned from my account. I was helping some friends move to Japan and we were buying home decorations at the local stores. The  receipts differed greatly from what showed up in my bank account and my statement. When can I expect the extra fees to be back in my account?\", 'answer': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  9%|▊         | 13/150 [00:01<00:15,  8.76it/s]2024-10-12T23:37:51.084993Z [error    ] Failed to run or to evaluate example Example({'label': 'extra_charge_on_statement', 'text': 'There is a charge for an additional pound.', 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:51.250784Z [error    ] Failed to run or to evaluate example Example({'label': 'declined_card_payment', 'text': 'What is the reason my payment was not accepted?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 10%|█         | 15/150 [00:01<00:14,  9.42it/s]2024-10-12T23:37:51.477562Z [error    ] Failed to run or to evaluate example Example({'label': 'request_refund', 'text': \"I don't want to buy this car anymore, can I cancel the transaction and get a quick refund back?\", 'answer': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:51.486671Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_cheque_or_cash_deposit', 'text': 'I checked the app and my balance has not been updated for the cash or cheque deposit.', 'answer': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 11%|█▏        | 17/150 [00:01<00:14,  9.13it/s]2024-10-12T23:37:51.650403Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_charge', 'text': 'The bank charged me fees for withdrawing cash!', 'answer': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 12%|█▏        | 18/150 [00:01<00:15,  8.36it/s]2024-10-12T23:37:51.816530Z [error    ] Failed to run or to evaluate example Example({'label': 'reverted_card_payment', 'text': 'I believe my card payment has reverted', 'answer': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 13%|█▎        | 19/150 [00:01<00:16,  7.76it/s]2024-10-12T23:37:51.826824Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_card_payment', 'text': \"I made a payment that's pending. Will it go through?\", 'answer': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:51.835411Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_exchange_rate_for_cash_withdrawal', 'text': 'I think the exchange rate for the cash I withdrew was wrong.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:51.844444Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_bank_transfer', 'text': 'Hi, I made a transfer from France two days ago and thought it would be here by now. Can you give me an update please?', 'answer': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:51.851574Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_card_payment', 'text': \"I have a payment that hasn't went through yet.\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:37:52.010213Z [error    ] Failed to run or to evaluate example Example({'label': 'request_refund', 'text': 'I did not receive my purchase, how do I cancel it?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 17%|█▋        | 25/150 [00:02<00:10, 11.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 26 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:37:52.852546Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<03:06,  1.87it/s] [T23:37:52.860121Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/350 [00:00<03:06,  1.87it/s]2024-10-12T23:37:52.936229Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 3  (0.0):   1%|          | 2/350 [00:00<03:05,  1.87it/s]2024-10-12T23:37:52.985120Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 5  (20.0):   1%|          | 4/350 [00:00<00:46,  7.38it/s]2024-10-12T23:37:53.044980Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 7  (14.3):   2%|▏         | 7/350 [00:00<00:33, 10.21it/s]lineno0-12T23:37:53.173757Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 3.0 / 11  (27.3):   3%|▎         | 10/350 [00:00<00:33, 10.21it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 4.0 / 22  (18.2):   6%|▌         | 21/350 [00:01<00:09, 32.96it/s]2024-10-12T23:37:53.438597Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 49  (14.3):  14%|█▎        | 48/350 [00:01<00:07, 40.21it/s]2024-10-12T23:37:54.067475Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 51  (13.7):  14%|█▍        | 50/350 [00:01<00:07, 40.21it/s]2024-10-12T23:37:54.073242Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 52  (13.5):  15%|█▍        | 51/350 [00:01<00:07, 40.21it/s]2024-10-12T23:37:54.122878Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 53  (13.2):  15%|█▍        | 52/350 [00:01<00:07, 40.21it/s]2024-10-12T23:37:54.147067Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 54  (13.0):  15%|█▌        | 54/350 [00:01<00:06, 43.12it/s]2024-10-12T23:37:54.421062Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 56  (14.3):  16%|█▌        | 55/350 [00:02<00:06, 43.12it/s]2024-10-12T23:37:54.454113Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 8.0 / 60  (13.3):  17%|█▋        | 60/350 [00:02<00:10, 26.58it/s]evaluate.py23:37:54.486684Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename= lineno=198\n",
      "Average Metric: 12.0 / 75  (16.0):  21%|██        | 74/350 [00:02<00:07, 38.62it/s]2024-10-12T23:37:54.829856Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 81  (16.0):  23%|██▎       | 80/350 [00:02<00:06, 44.81it/s]filename12T23:37:54.901417Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 15.0 / 86  (17.4):  24%|██▍       | 85/350 [00:02<00:05, 44.81it/s]2024-10-12T23:37:54.973007Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 94  (18.1):  27%|██▋       | 94/350 [00:02<00:05, 49.84it/s]2024-10-12T23:37:55.165162Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 98  (17.3):  28%|██▊       | 97/350 [00:02<00:05, 49.84it/s]2024-10-12T23:37:55.408079Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 99  (17.2):  28%|██▊       | 98/350 [00:03<00:05, 49.84it/s]2024-10-12T23:37:55.415199Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 17.0 / 100  (17.0):  29%|██▊       | 100/350 [00:03<00:07, 35.69it/s] [4-10-12T23:37:55.438752Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 103  (17.5):  29%|██▉       | 102/350 [00:03<00:06, 35.69it/s]2024-10-12T23:37:55.612154Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19.0 / 110  (17.3):  31%|███       | 109/350 [00:03<00:07, 32.61it/s]2024-10-12T23:37:55.725176Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 119  (18.5):  34%|███▎      | 118/350 [00:03<00:06, 36.31it/s]]024-10-12T23:37:55.909428Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 127  (17.3):  36%|███▌      | 126/350 [00:03<00:05, 43.05it/s]2024-10-12T23:37:56.082698Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 129  (17.1):  37%|███▋      | 128/350 [00:03<00:05, 43.05it/s]2024-10-12T23:37:56.131167Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 25.0 / 139  (18.0):  39%|███▉      | 138/350 [00:04<00:05, 40.19it/s]1984-10-12T23:37:56.358899Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 27.0 / 144  (18.8):  41%|████      | 143/350 [00:04<00:05, 40.19it/s]2024-10-12T23:37:56.476496Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 149  (18.1):  42%|████▏     | 148/350 [00:04<00:04, 46.68it/s]2024-10-12T23:37:56.674538Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 150  (18.0):  43%|████▎     | 149/350 [00:04<00:04, 46.68it/s]2024-10-12T23:37:56.684456Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 152  (17.8):  43%|████▎     | 151/350 [00:04<00:05, 39.32it/s]2024-10-12T23:37:56.734456Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 153  (17.6):  43%|████▎     | 152/350 [00:04<00:05, 39.32it/s]2024-10-12T23:37:56.739814Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 27.0 / 154  (17.5):  44%|████▎     | 153/350 [00:04<00:05, 39.32it/s]2024-10-12T23:37:56.861904Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 34.0 / 180  (18.9):  51%|█████     | 179/350 [00:05<00:04, 37.07it/s]lineno0-12T23:37:57.506727Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 35.0 / 186  (18.8):  53%|█████▎    | 185/350 [00:05<00:04, 38.17it/s]=024-10-12T23:37:57.519784Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno198\n",
      "Average Metric: 35.0 / 190  (18.4):  54%|█████▍    | 189/350 [00:05<00:04, 38.17it/s]2024-10-12T23:37:57.679569Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 193  (18.1):  55%|█████▍    | 192/350 [00:05<00:03, 44.94it/s]2024-10-12T23:37:57.751614Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 35.0 / 194  (18.0):  55%|█████▌    | 193/350 [00:05<00:03, 44.94it/s]2024-10-12T23:37:57.776008Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 199  (18.1):  57%|█████▋    | 198/350 [00:05<00:03, 45.41it/s]2024-10-12T23:37:57.936805Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 203  (17.7):  58%|█████▊    | 202/350 [00:05<00:03, 41.10it/s]2024-10-12T23:37:57.999282Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 204  (17.6):  58%|█████▊    | 203/350 [00:05<00:03, 41.10it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 36.0 / 206  (17.5):  59%|█████▊    | 205/350 [00:05<00:03, 41.10it/s]2024-10-12T23:37:58.036730Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 213  (17.8):  61%|██████    | 212/350 [00:05<00:03, 37.67it/s]2024-10-12T23:37:58.298453Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 214  (17.8):  61%|██████    | 213/350 [00:05<00:03, 37.67it/s]2024-10-12T23:37:58.302692Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 39.0 / 221  (17.6):  63%|██████▎   | 220/350 [00:06<00:04, 31.66it/s]2024-10-12T23:37:58.561395Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 39.0 / 223  (17.5):  63%|██████▎   | 222/350 [00:06<00:04, 31.66it/s]2024-10-12T23:37:58.595005Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 230  (17.4):  65%|██████▌   | 229/350 [00:06<00:03, 33.34it/s] [24-10-12T23:37:58.800259Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 40.0 / 234  (17.1):  67%|██████▋   | 233/350 [00:06<00:03, 33.34it/s]evaluate.py23:37:58.828714Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 43.0 / 245  (17.6):  70%|██████▉   | 244/350 [00:06<00:02, 36.30it/s]2024-10-12T23:37:59.139275Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 45.0 / 250  (18.0):  71%|███████   | 249/350 [00:06<00:02, 37.04it/s]  24-10-12T23:37:59.191023Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno=198\n",
      "Average Metric: 45.0 / 252  (17.9):  72%|███████▏  | 251/350 [00:06<00:02, 37.04it/s]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 257  (17.9):  73%|███████▎  | 256/350 [00:07<00:01, 48.83it/s]2024-10-12T23:37:59.595450Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 46.0 / 258  (17.8):  73%|███████▎  | 257/350 [00:07<00:01, 48.83it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 273  (18.3):  78%|███████▊  | 272/350 [00:07<00:02, 34.07it/s]2024-10-12T23:37:59.875648Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 50.0 / 282  (17.7):  81%|████████  | 282/350 [00:07<00:01, 48.13it/s]2024-10-12T23:38:00.060874Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 293  (17.7):  83%|████████▎ | 292/350 [00:07<00:01, 49.93it/s]2024-10-12T23:38:00.352054Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 294  (17.7):  84%|████████▍ | 294/350 [00:08<00:01, 41.09it/s]] 24-10-12T23:38:00.360684Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 295  (17.6):  84%|████████▍ | 294/350 [00:08<00:01, 41.09it/s]2024-10-12T23:38:00.712592Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 297  (17.8):  85%|████████▍ | 296/350 [00:08<00:01, 41.09it/s]2024-10-12T23:38:00.760617Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 298  (17.8):  85%|████████▍ | 297/350 [00:08<00:01, 41.09it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 299  (17.7):  85%|████████▌ | 299/350 [00:08<00:02, 25.36it/s]2024-10-12T23:38:00.879661Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 53.0 / 302  (17.5):  86%|████████▌ | 301/350 [00:08<00:01, 25.36it/s]2024-10-12T23:38:01.007172Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 54.0 / 306  (17.6):  87%|████████▋ | 305/350 [00:08<00:01, 23.46it/s]2024-10-12T23:38:01.077093Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 332  (19.3):  95%|█████████▍| 331/350 [00:08<00:00, 43.10it/s]2024-10-12T23:38:01.285656Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 64.0 / 336  (19.0):  96%|█████████▌| 336/350 [00:08<00:00, 67.15it/s]198eno0-12T23:38:01.290812Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =\n",
      "Average Metric: 65.0 / 342  (19.0):  97%|█████████▋| 341/350 [00:09<00:00, 67.15it/s] 024-10-12T23:38:01.345582Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 67.0 / 350  (19.1): 100%|██████████| 350/350 [00:09<00:00, 38.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [0.57, 0.57, 22.86, 24.57, 19.14]\n",
      "Best score so far: 24.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]2024-10-12T23:38:01.468241Z [error    ] Failed to run or to evaluate example Example({'label': 'request_refund', 'text': 'I would like to cancel a purchase.', 'answer': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 2/150 [00:00<00:00, 187.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:38:02.307985Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<03:39,  1.59it/s]2024-10-12T23:38:02.441027Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 4  (0.0):   1%|          | 3/350 [00:00<01:57,  2.96it/s]2024-10-12T23:38:02.506925Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 9.0 / 29  (31.0):   8%|▊         | 28/350 [00:01<00:11, 28.74it/s]2024-10-12T23:38:03.109800Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 11.0 / 40  (27.5):  11%|█         | 39/350 [00:01<00:06, 45.34it/s]2024-10-12T23:38:03.291443Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 12.0 / 49  (24.5):  14%|█▎        | 48/350 [00:01<00:07, 38.38it/s]2024-10-12T23:38:03.666703Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 47.0 / 147  (32.0):  42%|████▏     | 146/350 [00:04<00:03, 55.47it/s]2024-10-12T23:38:06.164447Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 190  (30.0):  54%|█████▍    | 189/350 [00:05<00:03, 45.12it/s]2024-10-12T23:38:07.277000Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 59.0 / 194  (30.4):  55%|█████▌    | 193/350 [00:05<00:04, 37.74it/s]=024-10-12T23:38:07.285855Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno198\n",
      "Average Metric: 60.0 / 198  (30.3):  56%|█████▋    | 197/350 [00:05<00:04, 37.74it/s]]rror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 60.0 / 199  (30.2):  57%|█████▋    | 198/350 [00:05<00:04, 37.74it/s]2024-10-12T23:38:07.423949Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 68.0 / 227  (30.0):  65%|██████▍   | 226/350 [00:06<00:03, 39.67it/s]2024-10-12T23:38:08.134976Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 77.0 / 261  (29.5):  74%|███████▍  | 260/350 [00:07<00:02, 35.87it/s]2024-10-12T23:38:09.094599Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 81.0 / 273  (29.7):  78%|███████▊  | 272/350 [00:07<00:01, 46.77it/s]2024-10-12T23:38:09.401390Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 83.0 / 279  (29.7):  79%|███████▉  | 278/350 [00:07<00:01, 39.99it/s]2024-10-12T23:38:09.484477Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 90.0 / 297  (30.3):  85%|████████▍ | 296/350 [00:08<00:01, 39.06it/s]1984-10-12T23:38:09.925511Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 102.0 / 332  (30.7):  95%|█████████▍| 331/350 [00:08<00:00, 65.95it/s]2024-10-12T23:38:10.367687Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 103.0 / 334  (30.8):  95%|█████████▌| 333/350 [00:08<00:00, 65.95it/s]2024-10-12T23:38:10.381372Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 104.0 / 339  (30.7):  97%|█████████▋| 338/350 [00:08<00:00, 74.05it/s]filenameluate.evaluate9953Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] =evaluate.py lineno=198\n",
      "Average Metric: 104.0 / 350  (29.7): 100%|██████████| 350/350 [00:08<00:00, 39.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 29.71 for seed 2\n",
      "Scores so far: [0.57, 0.57, 22.86, 24.57, 19.14, 29.71]\n",
      "Best score so far: 29.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]2024-10-12T23:38:10.551645Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_wrong_exchange_rate', 'text': 'I bought an item and the exchange rate was wrong.', 'answer': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:10.725769Z [error    ] Failed to run or to evaluate example Example({'label': 'refund_not_showing_up', 'text': \"I keep checking to see if I've received a refund that I requested from a seller, but I'm not seeing the refund. I need you to help me get the refund.\", 'answer': 'refund_not_showing_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 2/150 [00:00<00:13, 10.90it/s]2024-10-12T23:38:11.154481Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_wrong_exchange_rate', 'text': 'I noticed an extra charge on the purchase that I made last Saturday on my account. Can you see if I received the correct exchange rate?', 'answer': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 4/150 [00:00<00:24,  6.08it/s]2024-10-12T23:38:11.321586Z [error    ] Failed to run or to evaluate example Example({'label': 'declined_cash_withdrawal', 'text': 'Why did I get declined when trying to get cash?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 5/150 [00:00<00:23,  6.06it/s]2024-10-12T23:38:11.478204Z [error    ] Failed to run or to evaluate example Example({'label': 'card_arrival', 'text': 'Have you sent out my card yet?', 'answer': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▍         | 7/150 [00:00<00:19,  7.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-12T23:38:11.494692Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "2024-10-12T23:38:11.495483Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1 / 7  (14.3):   2%|▏         | 6/350 [00:00<00:00, 626.62it/s]inenote.pyte.evaluateing', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] = =198\n",
      "Average Metric: 3 / 15  (20.0):   4%|▍         | 14/350 [00:00<00:00, 596.79it/s]=[-10-12T23:38:11.504769Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filenameevaluate.py lineno=198\n",
      "Average Metric: 8 / 27  (29.6):   7%|▋         | 26/350 [00:00<00:00, 597.03it/s] ilename12T23:38:11.510327Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.pylineno=198\n",
      "Average Metric: 10 / 38  (26.3):  11%|█         | 37/350 [00:00<00:00, 616.52it/s]198luate.pye.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] = lineno=\n",
      "Average Metric: 13 / 46  (28.3):  13%|█▎        | 45/350 [00:00<00:00, 592.55it/s]198or    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 17 / 54  (31.5):  15%|█▌        | 53/350 [00:00<00:00, 601.33it/s]2024-10-12T23:38:11.596607Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 19 / 61  (31.1):  17%|█▋        | 60/350 [00:00<00:00, 591.85it/s]evaluate.pyte.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename= lineno=198\n",
      "Average Metric: 23 / 71  (32.4):  20%|██        | 70/350 [00:00<00:00, 591.85it/s] ilenamer example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.pylineno=198\n",
      "Average Metric: 25 / 77  (32.5):  22%|██▏       | 76/350 [00:00<00:00, 591.85it/s]error    2T23:38:11.607230Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 28 / 84  (33.3):  24%|██▎       | 83/350 [00:00<00:00, 591.85it/s]=valuate.py23:38:11.608710Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename= lineno198\n",
      "Average Metric: 31 / 91  (34.1):  26%|██▌       | 90/350 [00:00<00:00, 591.85it/s]filenamer example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 32 / 99  (32.3):  28%|██▊       | 98/350 [00:00<00:00, 591.85it/s]=spy.evaluate.evaluate1538Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename=evaluate.pylineno198\n",
      "Average Metric: 36 / 108  (33.3):  31%|███       | 107/350 [00:00<00:00, 591.85it/s]linenovaluate.evaluate4263Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py =198\n",
      "Average Metric: 37 / 115  (32.2):  33%|███▎      | 114/350 [00:00<00:00, 591.85it/s]linenomer example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate =evaluate.py =198\n",
      "Average Metric: 38.0 / 122  (31.1):  35%|███▍      | 121/350 [00:00<00:00, 555.21it/s]linenote.py:38:11.640369Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] = =198\n",
      "Average Metric: 39.0 / 130  (30.0):  37%|███▋      | 129/350 [00:00<00:00, 555.21it/s]198enofor example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =\n",
      "Average Metric: 40.0 / 139  (28.8):  39%|███▉      | 138/350 [00:00<00:00, 555.21it/s]=valuate.py23:38:11.656329Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename= lineno198\n",
      "Average Metric: 104.0 / 350  (29.7): 100%|██████████| 350/350 [00:00<00:00, 797.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [0.57, 0.57, 22.86, 24.57, 19.14, 29.71, 29.71]\n",
      "Best score so far: 29.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]2024-10-12T23:38:12.116060Z [error    ] Failed to run or to evaluate example Example({'label': 'transfer_fee_charged', 'text': \"I don't think I was supposed to be charged so much.\", 'answer': 'transfer_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:12.285053Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_wrong_exchange_rate', 'text': 'When I was traveling abroad, the exchange rate was applied wrong.', 'answer': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  1%|▏         | 2/150 [00:00<00:13, 11.18it/s]2024-10-12T23:38:12.295867Z [error    ] Failed to run or to evaluate example Example({'label': 'reverted_card_payment', 'text': 'I believe my card payment has reverted', 'answer': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:12.305020Z [error    ] Failed to run or to evaluate example Example({'label': 'activate_my_card', 'text': 'Could you please tell me how to activate my new card?', 'answer': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:12.517022Z [error    ] Failed to run or to evaluate example Example({'label': 'cancel_transfer', 'text': 'My morning transaction needs to be canceled.', 'answer': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  3%|▎         | 5/150 [00:00<00:11, 12.33it/s]2024-10-12T23:38:12.528984Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_charge', 'text': \"I used my card to get cash then I was charged a fee that I shouldn't have been charged.\", 'answer': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:12.540401Z [error    ] Failed to run or to evaluate example Example({'label': 'reverted_card_payment', 'text': 'My card payment has been cancelled', 'answer': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:12.712053Z [error    ] Failed to run or to evaluate example Example({'label': 'transfer_fee_charged', 'text': 'When I was transferring money I was charged extra why?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 10/150 [00:00<00:07, 18.13it/s]2024-10-12T23:38:12.723425Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_top_up', 'text': 'My account is  new  why can I  not top up', 'answer': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:12.733321Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_charge', 'text': 'The bank charged me fees for withdrawing cash!', 'answer': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:12.743102Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_not_recognised', 'text': \"There is a payment made with my card that I don't recognize at all.\", 'answer': 'card_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:12.752468Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_amount_of_cash_received', 'text': 'i asked for 100 only got 80', 'answer': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:12.761474Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_cheque_or_cash_deposit', 'text': \"Why hasn't my balance been updated? I've deposited a few cheques some days ago!\", 'answer': 'balance_not_updated_after_cheque_or_cash_deposit'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:12.770736Z [error    ] Failed to run or to evaluate example Example({'label': 'request_refund', 'text': \"I don't want to buy this car anymore, can I cancel the transaction and get a quick refund back?\", 'answer': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:12.930879Z [error    ] Failed to run or to evaluate example Example({'label': 'beneficiary_not_allowed', 'text': 'Payment did not process', 'answer': 'beneficiary_not_allowed'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 12%|█▏        | 18/150 [00:00<00:06, 21.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 19 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/350 [00:00<?, ?it/s]2024-10-12T23:38:13.865689Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/350 [00:00<03:27,  1.68it/s]12T23:38:13.874234Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 48  (12.5):  13%|█▎        | 47/350 [00:01<00:07, 40.70it/s]2024-10-12T23:38:15.013572Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 6.0 / 49  (12.2):  14%|█▎        | 48/350 [00:01<00:07, 40.70it/s]2024-10-12T23:38:15.097589Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 7.0 / 57  (12.3):  16%|█▌        | 56/350 [00:01<00:08, 34.70it/s]]024-10-12T23:38:15.218377Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 71  (18.3):  20%|██        | 70/350 [00:02<00:06, 40.93it/s]2024-10-12T23:38:15.549277Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 99  (21.2):  28%|██▊       | 99/350 [00:02<00:05, 44.30it/s]2024-10-12T23:38:16.190789Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 21.0 / 100  (21.0):  28%|██▊       | 99/350 [00:02<00:05, 44.30it/s]2024-10-12T23:38:16.301926Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 29.0 / 124  (23.4):  35%|███▌      | 123/350 [00:03<00:06, 37.70it/s]=024-10-12T23:38:16.873490Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 31.0 / 133  (23.3):  38%|███▊      | 132/350 [00:03<00:06, 31.95it/s]dspy.evaluate.evaluate0059Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 32.0 / 138  (23.2):  39%|███▉      | 137/350 [00:03<00:05, 35.80it/s] 024-10-12T23:38:17.231343Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 38.0 / 156  (24.4):  44%|████▍     | 155/350 [00:04<00:06, 29.94it/s]dspy.evaluate.evaluate9599Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 168  (25.0):  48%|████▊     | 167/350 [00:04<00:04, 44.09it/s]2024-10-12T23:38:17.987631Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 43.0 / 178  (24.2):  51%|█████     | 177/350 [00:04<00:04, 40.86it/s]lineno0-12T23:38:18.244000Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 44.0 / 180  (24.4):  51%|█████     | 179/350 [00:05<00:04, 40.86it/s]2024-10-12T23:38:18.415742Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 183  (24.0):  52%|█████▏    | 182/350 [00:05<00:04, 35.44it/s] [24-10-12T23:38:18.455197Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 184  (23.9):  52%|█████▏    | 183/350 [00:05<00:04, 35.44it/s]2024-10-12T23:38:18.591645Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 51.0 / 216  (23.6):  61%|██████▏   | 215/350 [00:06<00:03, 41.68it/s]2024-10-12T23:38:19.331421Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 226  (25.2):  64%|██████▍   | 225/350 [00:06<00:02, 50.25it/s]2024-10-12T23:38:19.505525Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 227  (25.1):  65%|██████▍   | 226/350 [00:06<00:02, 50.25it/s]2024-10-12T23:38:19.526748Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 57.0 / 228  (25.0):  65%|██████▍   | 227/350 [00:06<00:02, 50.25it/s]2024-10-12T23:38:19.547444Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 62.0 / 246  (25.2):  70%|███████   | 245/350 [00:07<00:03, 26.77it/s]lineno0-12T23:38:20.394938Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 67.0 / 273  (24.5):  78%|███████▊  | 272/350 [00:07<00:01, 42.53it/s]2024-10-12T23:38:20.953165Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 69.0 / 285  (24.2):  81%|████████▏ | 285/350 [00:08<00:01, 37.98it/s] [24-10-12T23:38:21.312014Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 70.0 / 289  (24.2):  82%|████████▏ | 288/350 [00:08<00:01, 37.98it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 70.0 / 290  (24.1):  83%|████████▎ | 289/350 [00:08<00:01, 37.98it/s]2024-10-12T23:38:21.371041Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 77.0 / 309  (24.9):  88%|████████▊ | 308/350 [00:08<00:01, 34.40it/s]evaluate.pyte.evaluate2801Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename= lineno=198\n",
      "Average Metric: 83.0 / 326  (25.5):  93%|█████████▎| 325/350 [00:08<00:00, 66.07it/s]=spy.evaluate.evaluate2960Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno198\n",
      "Average Metric: 83.0 / 337  (24.6):  96%|█████████▌| 336/350 [00:08<00:00, 66.07it/s]2024-10-12T23:38:22.073528Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 350  (24.6): 100%|██████████| 350/350 [00:08<00:00, 39.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [0.57, 0.57, 22.86, 24.57, 19.14, 29.71, 29.71, 24.57]\n",
      "Best score so far: 29.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/150 [00:00<00:31,  4.75it/s]2024-10-12T23:38:22.396244Z [error    ] Failed to run or to evaluate example Example({'label': 'transaction_charged_twice', 'text': 'Why was I double charged?', 'answer': 'transaction_charged_twice'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:22.405644Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_not_recognised', 'text': \"There's a payment with my card that I definitely didn't do myself, never seen that name before.\", 'answer': 'card_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:22.414252Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_not_recognised', 'text': \"A payment that I didn't make appears in my app.\", 'answer': 'card_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:22.616071Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_top_up', 'text': \"Even though I added money ey to the card, I couldn't use it\", 'answer': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  4%|▍         | 6/150 [00:00<00:09, 15.04it/s]2024-10-12T23:38:22.785810Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_amount_of_cash_received', 'text': 'i did not get any money but still was charged', 'answer': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  5%|▌         | 8/150 [00:00<00:10, 13.75it/s]2024-10-12T23:38:22.797263Z [error    ] Failed to run or to evaluate example Example({'label': 'card_arrival', 'text': 'why hasnt my card come in yet?', 'answer': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:22.984374Z [error    ] Failed to run or to evaluate example Example({'label': 'extra_charge_on_statement', 'text': \"I don't understand why there is an extra €1 fee in my statement.\", 'answer': 'extra_charge_on_statement'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  7%|▋         | 11/150 [00:00<00:09, 14.30it/s]2024-10-12T23:38:23.243467Z [error    ] Failed to run or to evaluate example Example({'label': 'cancel_transfer', 'text': 'How fast can you fix an error in payment?  I made a payment in the wrong account yesterday and it needs to be adjusted by tomorrow for my rent.', 'answer': 'cancel_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "  9%|▊         | 13/150 [00:01<00:11, 11.50it/s]2024-10-12T23:38:23.254692Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_fee_charged', 'text': 'What is the fee charged for using my card?', 'answer': 'card_payment_fee_charged'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.417573Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_amount_of_cash_received', 'text': 'Cash withdrawal was incorrect at ATM.', 'answer': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 10%|█         | 15/150 [00:01<00:11, 11.51it/s]2024-10-12T23:38:23.576252Z [error    ] Failed to run or to evaluate example Example({'label': 'direct_debit_payment_not_recognised', 'text': 'I have an unknown debit charge in my statement, why?', 'answer': 'direct_debit_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.585666Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_card_payment', 'text': \"I made a payment that's pending. Will it go through?\", 'answer': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 11%|█▏        | 17/150 [00:01<00:11, 11.63it/s]2024-10-12T23:38:23.595877Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_charge', 'text': \"I used my card to get cash then I was charged a fee that I shouldn't have been charged.\", 'answer': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.749898Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_not_recognised', 'text': 'Payment I did not make.', 'answer': 'card_payment_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 13%|█▎        | 19/150 [00:01<00:11, 11.79it/s]2024-10-12T23:38:23.759698Z [error    ] Failed to run or to evaluate example Example({'label': 'card_arrival', 'text': 'My card never arrived.', 'answer': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.768145Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_not_recognised', 'text': \"There's a cash withdrawal I am certain I did not make\", 'answer': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.776871Z [error    ] Failed to run or to evaluate example Example({'label': 'request_refund', 'text': 'I want a refund on this.', 'answer': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.785601Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_top_up', 'text': 'My account is  new  why can I  not top up', 'answer': 'pending_top_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.794217Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_fee_charged', 'text': 'I was charged a fee for using my card. Can I check that in any way? It seems like there are occasions that I am charge for fees. Can you elaborate this?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.803589Z [error    ] Failed to run or to evaluate example Example({'label': 'transfer_not_received_by_recipient', 'text': \"Two days ago I did a transfer to another account within the country.  It doesn't appear the transfer went through.  I have verified the account number several times.  Could you please check on this for me?\", 'answer': 'transfer_not_received_by_recipient'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.814740Z [error    ] Failed to run or to evaluate example Example({'label': 'transfer_fee_charged', 'text': 'I use my card internationally to manage payments and I just noticed that you are adding additional fees.  Why?  I am a good customer and this has me thinking about leaving.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.822189Z [error    ] Failed to run or to evaluate example Example({'label': 'declined_cash_withdrawal', 'text': 'Why did I get declined when trying to get cash?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.831878Z [error    ] Failed to run or to evaluate example Example({'label': 'transaction_charged_twice', 'text': 'Hi, I was looking over my card receipts for the past week and I realize I had a charge put through two times for the same single restaurant visit. Can one of the charges be removed so that I can get the money back that was mistakenly taken from my account?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.840275Z [error    ] Failed to run or to evaluate example Example({'label': 'reverted_card_payment', 'text': 'My card payment has been cancelled', 'answer': 'reverted_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.848649Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_not_recognised', 'text': 'Somebody is taking money out of my account without my approval in another town separate from me. Please place a freeze on my account until I can make it to the bank.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.856626Z [error    ] Failed to run or to evaluate example Example({'label': 'transaction_charged_twice', 'text': 'I think there is a mistake.  I am being charged twice.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 21%|██▏       | 32/150 [00:01<00:03, 34.82it/s]2024-10-12T23:38:23.866431Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_card_payment', 'text': 'My card payment is showing pending however this transaction was a couple of days ago. Is there a reason why it it still pending?', 'answer': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.875083Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_card_payment', 'text': 'Why is the payment showing as pending from things I bought this morning?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.883711Z [error    ] Failed to run or to evaluate example Example({'label': 'refund_not_showing_up', 'text': \"I keep checking to see if I've received a refund that I requested from a seller, but I'm not seeing the refund. I need you to help me get the refund.\", 'answer': 'refund_not_showing_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.892514Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_bank_transfer', 'text': 'when will the balance on my account change form a transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.901030Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_bank_transfer', 'text': \"I made a bank transfer earlier from my UK account.  I don't see it yet, can you check the status?\", 'answer': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.910601Z [error    ] Failed to run or to evaluate example Example({'label': 'declined_cash_withdrawal', 'text': \"Why can't I take money from my account?\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:23.919715Z [error    ] Failed to run or to evaluate example Example({'label': 'refund_not_showing_up', 'text': 'A refund is taking too long.', 'answer': 'refund_not_showing_up'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:24.088734Z [error    ] Failed to run or to evaluate example Example({'label': 'direct_debit_payment_not_recognised', 'text': 'The app is showing a direct debit transaction that I did not perform'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 27%|██▋       | 40/150 [00:01<00:03, 34.65it/s]2024-10-12T23:38:24.099160Z [error    ] Failed to run or to evaluate example Example({'label': 'reverted_card_payment', 'text': \"I received a message from a seller stating they hadn't received my money even though it definitely came out of my account. The money has now been deposited back into my account. Please get this resolved as soon as possible.\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:24.321926Z [error    ] Failed to run or to evaluate example Example({'label': 'transfer_fee_charged', 'text': 'What is this extra fee while I was doing a transfer?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:24.487431Z [error    ] Failed to run or to evaluate example Example({'label': 'transaction_charged_twice', 'text': \"Looks like my card payment was made twice by mistake. I paid at the store earlier which rejected once, second time it worked. App stays at pending for one of the payments. Can you please remove one of them as it's wrong and clearly was declined?\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:24.498217Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_amount_of_cash_received', 'text': 'Why is my withdrawal wrong? I took out $100 but only received $20.', 'answer': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 30%|███       | 45/150 [00:02<00:04, 23.43it/s]2024-10-12T23:38:25.106339Z [error    ] Failed to run or to evaluate example Example({'label': 'pending_card_payment', 'text': 'Card payment is still pending, why is that the case?', 'answer': 'pending_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:25.115638Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_bank_transfer', 'text': 'Hi, I made a transfer from France two days ago and thought it would be here by now. Can you give me an update please?', 'answer': 'balance_not_updated_after_bank_transfer'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:25.124576Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_bank_transfer', 'text': \"I made a bank transfer but it doesn't seem to have gone through?\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 33%|███▎      | 49/150 [00:02<00:06, 14.55it/s]2024-10-12T23:38:25.240872Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_wrong_exchange_rate', 'text': \"The exchange rate you are using is really bad. This can't possibly be the official interbank exchange rate.\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:25.252206Z [error    ] Failed to run or to evaluate example Example({'label': 'request_refund', 'text': \"I don't want to buy this car anymore, can I cancel the transaction and get a quick refund back?\", 'answer': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:25.260776Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_not_recognised', 'text': \"My identity has been stolen. I still have my physical card but there are charges I didn't make on my account. How do I cancel this card or dispute the charges?\", 'answer': 'cash_withdrawal_not_recognised'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 35%|███▍      | 52/150 [00:03<00:06, 15.63it/s]2024-10-12T23:38:25.270503Z [error    ] Failed to run or to evaluate example Example({'label': 'extra_charge_on_statement', 'text': 'Why would there be an extra charge on my app?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:26.425559Z [error    ] Failed to run or to evaluate example Example({'label': 'activate_my_card', 'text': 'I just got my new card.  How can I activate it?', 'answer': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 37%|███▋      | 55/150 [00:04<00:12,  7.40it/s]2024-10-12T23:38:26.437016Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_not_recognised', 'text': \"My app shows cash I didn't get.\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:26.445614Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_exchange_rate_for_cash_withdrawal', 'text': 'I think the exchange rate for the cash I withdrew was wrong.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:26.454233Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_wrong_exchange_rate', 'text': 'Why is the exchange rate different on my recent purchase?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:26.463082Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_amount_of_cash_received', 'text': 'What do I do if I got the wrong amount at the ATM?', 'answer': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:26.621084Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_charge', 'text': 'While getting cash, I was charged a fee.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 41%|████      | 61/150 [00:04<00:08, 10.45it/s]2024-10-12T23:38:26.632061Z [error    ] Failed to run or to evaluate example Example({'label': 'card_arrival', 'text': 'How much longer until I get my new card?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:26.640763Z [error    ] Failed to run or to evaluate example Example({'label': 'beneficiary_not_allowed', 'text': 'Payment did not process', 'answer': 'beneficiary_not_allowed'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:26.649749Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_wrong_exchange_rate', 'text': 'I noticed an extra charge on the purchase that I made last Saturday on my account. Can you see if I received the correct exchange rate?', 'answer': 'card_payment_wrong_exchange_rate'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:26.658846Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_amount_of_cash_received', 'text': 'I did not receive the right amount of cash I requested', 'answer': 'wrong_amount_of_cash_received'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:26.666156Z [error    ] Failed to run or to evaluate example Example({'label': 'reverted_card_payment', 'text': 'I used my card to make a payment and wondered why the payment was reverted?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 45%|████▌     | 68/150 [00:04<00:06, 13.65it/s]2024-10-12T23:38:27.096812Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_exchange_rate_for_cash_withdrawal', 'text': 'The wrong exchange rate applied to my cash withdrawal.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:27.106571Z [error    ] Failed to run or to evaluate example Example({'label': 'request_refund', 'text': \"I'm interested in learning more about product refunds.\", 'answer': 'request_refund'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:27.115102Z [error    ] Failed to run or to evaluate example Example({'label': 'activate_my_card', 'text': 'Could you please tell me how to activate my new card?', 'answer': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 47%|████▋     | 71/150 [00:04<00:05, 13.57it/s]2024-10-12T23:38:27.127692Z [error    ] Failed to run or to evaluate example Example({'label': 'card_arrival', 'text': 'Have you sent out my card yet?', 'answer': 'card_arrival'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:27.288824Z [error    ] Failed to run or to evaluate example Example({'label': 'declined_card_payment', 'text': 'I was wondering why my card was declined'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:27.298134Z [error    ] Failed to run or to evaluate example Example({'label': 'declined_card_payment', 'text': \"My card payment didn't work\", 'answer': 'declined_card_payment'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 49%|████▉     | 74/150 [00:05<00:05, 14.11it/s]2024-10-12T23:38:27.422018Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_not_recognised', 'text': 'I hope you can help me. Someone has stolen my wallet and now I have noticed that they have been taking money from my account.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:27.431639Z [error    ] Failed to run or to evaluate example Example({'label': 'request_refund', 'text': \"I'm cancelling this charge. I still have not received what I bought from these people a while ago.\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 51%|█████     | 76/150 [00:05<00:05, 14.27it/s]2024-10-12T23:38:27.441698Z [error    ] Failed to run or to evaluate example Example({'label': 'wrong_exchange_rate_for_cash_withdrawal', 'text': 'When I received my cash; they had my exchange rate incorrect.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:27.550480Z [error    ] Failed to run or to evaluate example Example({'label': 'activate_my_card', 'text': 'I would like to have assistance with activating my card.', 'answer': 'activate_my_card'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 52%|█████▏    | 78/150 [00:05<00:04, 14.70it/s]2024-10-12T23:38:27.560936Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_charge', 'text': 'The bank charged me fees for withdrawing cash!', 'answer': 'cash_withdrawal_charge'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:27.570002Z [error    ] Failed to run or to evaluate example Example({'label': 'transfer_fee_charged', 'text': 'When I was transferring money I was charged extra why?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:27.577636Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_wrong_exchange_rate', 'text': 'A foreign purchase I made has the incorrect rate applied to it.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:27.586423Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_charge', 'text': \"Since when do you charge to make a withdrawal? I've always done it for free. So how much is it now?\"}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:27.596156Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_fee_charged', 'text': 'What is this extra fee?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:27.847973Z [error    ] Failed to run or to evaluate example Example({'label': 'declined_card_payment', 'text': 'Why are all my card payments being declined?'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 57%|█████▋    | 85/150 [00:05<00:03, 18.06it/s]2024-10-12T23:38:27.858055Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_not_recognised', 'text': 'I did not make this payment that I see in the App.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:28.019070Z [error    ] Failed to run or to evaluate example Example({'label': 'cash_withdrawal_not_recognised', 'text': 'I am using the app, and I see cash withdrawals that I did not authorize.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 58%|█████▊    | 87/150 [00:05<00:03, 16.52it/s]2024-10-12T23:38:28.030087Z [error    ] Failed to run or to evaluate example Example({'label': 'card_payment_wrong_exchange_rate', 'text': 'The wrong exchange rate was used when I purchased an item.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      "2024-10-12T23:38:28.199595Z [error    ] Failed to run or to evaluate example Example({'label': 'balance_not_updated_after_cheque_or_cash_deposit', 'text': 'I am still currently waiting for the cash that has been deposited into the account this morning.'}) (input_keys={'text'}) with <function adjusted_exact_match at 0x7eeb50175f70> due to Expected ['reasoning', 'label'] but got dict_keys([]). [dspy.teleprompt.bootstrap] filename=bootstrap.py lineno=211\n",
      " 61%|██████    | 91/150 [00:06<00:03, 15.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 92 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1 / 2  (50.0):   0%|          | 1/350 [00:00<00:18, 18.46it/s]2024-10-12T23:38:29.489559Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 3  (33.3):   1%|          | 3/350 [00:00<00:47,  7.35it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 1.0 / 4  (25.0):   1%|          | 3/350 [00:00<00:47,  7.35it/s]2024-10-12T23:38:29.844481Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2.0 / 6  (33.3):   1%|▏         | 5/350 [00:00<00:37,  9.21it/s]2024-10-12T23:38:29.877659Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 18.0 / 75  (24.0):  21%|██        | 74/350 [00:02<00:06, 41.69it/s]2024-10-12T23:38:32.086872Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 22.0 / 84  (26.2):  24%|██▎       | 83/350 [00:03<00:10, 25.63it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 52.0 / 175  (29.7):  50%|████▉     | 174/350 [00:06<00:07, 24.48it/s]2024-10-12T23:38:35.209023Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 58.0 / 191  (30.4):  54%|█████▍    | 190/350 [00:06<00:04, 35.22it/s]2024-10-12T23:38:35.609645Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 63.0 / 210  (30.0):  60%|██████    | 210/350 [00:06<00:03, 41.95it/s]filename12T23:38:36.021126Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 63.0 / 217  (29.0):  62%|██████▏   | 216/350 [00:06<00:03, 37.73it/s]2024-10-12T23:38:36.253030Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 63.0 / 218  (28.9):  62%|██████▏   | 217/350 [00:06<00:03, 37.73it/s]2024-10-12T23:38:36.257969Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 78.0 / 269  (29.0):  77%|███████▋  | 268/350 [00:08<00:02, 35.63it/s]2024-10-12T23:38:38.026040Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 79.0 / 276  (28.6):  79%|███████▊  | 275/350 [00:08<00:02, 26.61it/s]2024-10-12T23:38:38.240345Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 92.0 / 319  (28.8):  91%|█████████ | 318/350 [00:09<00:00, 53.91it/s]filename12T23:38:39.121695Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 93.0 / 324  (28.7):  92%|█████████▏| 323/350 [00:09<00:00, 56.63it/s]] ror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 103.0 / 350  (29.4): 100%|██████████| 350/350 [00:10<00:00, 34.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores so far: [0.57, 0.57, 22.86, 24.57, 19.14, 29.71, 29.71, 24.57, 29.43]\n",
      "Best score so far: 29.71\n",
      "9 candidate programs found.\n",
      "[('intent_classifier', Predict(StringSignature(intent -> reasoning, label\n",
      "    instructions=\"As a part of a banking issue traiging system, classify the intent of a natural language query into one of the 25 labels.\\nThe intent should exactly match one of the following:\\n['activate_my_card', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_arrival', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'declined_card_payment', 'declined_cash_withdrawal', 'direct_debit_payment_not_recognised', 'extra_charge_on_statement', 'pending_card_payment', 'pending_top_up', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_not_received_by_recipient', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal']\"\n",
      "    intent = Field(annotation=str required=True json_schema_extra={'desc': 'Intent of the query', '__dspy_field_type': 'input', 'prefix': 'Intent:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the output fields}. We ...', '__dspy_field_type': 'output'})\n",
      "    label = Field(annotation=str required=True json_schema_extra={'desc': 'Type of the intent; Should just be one of the 25 labels with no other text', '__dspy_field_type': 'output', 'prefix': 'Label:'})\n",
      ")))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]2024-10-12T23:38:40.168488Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/500 [00:00<03:50,  2.17it/s]2024-10-12T23:38:40.360622Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 6  (0.0):   1%|          | 5/500 [00:00<02:33,  3.22it/s]=024-10-12T23:38:40.426073Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 9.0 / 35  (25.7):   7%|▋         | 34/500 [00:01<00:18, 25.84it/s]2024-10-12T23:38:41.264847Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 13.0 / 68  (19.1):  13%|█▎        | 67/500 [00:02<00:09, 44.66it/s]2024-10-12T23:38:41.960259Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 30.0 / 123  (24.4):  24%|██▍       | 122/500 [00:03<00:12, 29.98it/s]1984-10-12T23:38:43.551950Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename=evaluate.py lineno=\n",
      "Average Metric: 41.0 / 143  (28.7):  28%|██▊       | 142/500 [00:04<00:10, 34.54it/s]2024-10-12T23:38:44.090314Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 42.0 / 160  (26.2):  32%|███▏      | 159/500 [00:04<00:08, 38.22it/s]2024-10-12T23:38:44.449526Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 43.0 / 164  (26.2):  33%|███▎      | 163/500 [00:04<00:08, 38.22it/s]2024-10-12T23:38:44.542359Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 43.0 / 166  (25.9):  33%|███▎      | 166/500 [00:04<00:09, 36.76it/s]1984-10-12T23:38:44.667871Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=\n",
      "Average Metric: 43.0 / 171  (25.1):  34%|███▍      | 170/500 [00:05<00:08, 36.76it/s]]024-10-12T23:38:44.678219Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 44.0 / 174  (25.3):  35%|███▍      | 173/500 [00:05<00:07, 43.37it/s]dspy.evaluate.evaluate2979Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=198\n",
      "Average Metric: 51.0 / 203  (25.1):  41%|████      | 203/500 [00:06<00:07, 38.03it/s]2024-10-12T23:38:45.871862Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 56.0 / 221  (25.3):  44%|████▍     | 220/500 [00:06<00:07, 36.09it/s]lineno0-12T23:38:46.310931Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 71.0 / 270  (26.3):  54%|█████▍    | 269/500 [00:07<00:04, 52.54it/s]2024-10-12T23:38:47.637031Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 73.0 / 275  (26.5):  55%|█████▍    | 274/500 [00:08<00:07, 31.63it/s] [24-10-12T23:38:47.861538Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 277  (26.7):  55%|█████▌    | 276/500 [00:08<00:07, 31.63it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 82.0 / 295  (27.8):  59%|█████▉    | 294/500 [00:08<00:05, 40.50it/s]2024-10-12T23:38:48.336118Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 89.0 / 317  (28.1):  63%|██████▎   | 316/500 [00:09<00:04, 41.29it/s]=024-10-12T23:38:48.778991Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 111.0 / 378  (29.4):  76%|███████▌  | 378/500 [00:10<00:03, 36.39it/s]=024-10-12T23:38:50.410565Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 128.0 / 435  (29.4):  87%|████████▋ | 434/500 [00:12<00:02, 31.09it/s]1984-10-12T23:38:52.010452Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=\n",
      "Average Metric: 133.0 / 453  (29.4):  90%|█████████ | 452/500 [00:12<00:00, 49.39it/s]2024-10-12T23:38:52.285685Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 138.0 / 466  (29.6):  93%|█████████▎| 465/500 [00:12<00:00, 64.14it/s]2024-10-12T23:38:52.454221Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 150.0 / 500  (30.0): 100%|██████████| 500/500 [00:13<00:00, 37.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result for base: 30.0, None, None\n"
     ]
    }
   ],
   "source": [
    "COMPILE_PROGRAM = False\n",
    "\n",
    "ft_results = {}\n",
    "for folder, llama in all_llamas.items():\n",
    "    print(\"Evaluating\", folder)\n",
    "    ft_results[folder] = {}\n",
    "    vanilla_program = IntentClassificationModule()\n",
    "    with dspy.context(lm=llama):\n",
    "        devset_result = evaluate_devset(vanilla_program)\n",
    "        ft_results[folder][\"vanilla\"] = {\"devset\": devset_result}\n",
    "\n",
    "        if COMPILE_PROGRAM:\n",
    "            bfrs_finetuned_program = bfrs_optimizer.compile(vanilla_program, trainset=ft_optimizer_trainset, valset=ft_optimizer_devset)\n",
    "            bfrs_finetuned_program.save(f\"simpleintent_1b_32_ft_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}_{folder.split('/')[-1]}.json\")\n",
    "        else:\n",
    "            bfrs_finetuned_program = IntentClassificationModule()\n",
    "            bfrs_finetuned_program.load(f\"simpleintent_1b_32_ft_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}_{folder.split('/')[-1]}.json\")\n",
    "        \n",
    "        llama_8b_bfrs_finetuned_eval = evaluate_devset(bfrs_finetuned_program)\n",
    "        ft_results[folder][\"bfrs\"] = {\"devset\": llama_8b_bfrs_finetuned_eval, \"true_labels\": None, \"testset\": None}\n",
    "        print(f\"result for {folder}: {llama_8b_bfrs_finetuned_eval}, None, None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/Llama-3.2-1B-Instruct:epochs-5-total-trained-steps-174': {'vanilla': {'devset': 13.8},\n",
       "  'bfrs': {'devset': 50.0, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-0-total-trained-steps-29': {'vanilla': {'devset': 21.8},\n",
       "  'bfrs': {'devset': 30.4, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-3-total-trained-steps-116': {'vanilla': {'devset': 13.8},\n",
       "  'bfrs': {'devset': 38.2, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-4-total-trained-steps-145': {'vanilla': {'devset': 14.0},\n",
       "  'bfrs': {'devset': 48.4, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-1-total-trained-steps-58': {'vanilla': {'devset': 15.8},\n",
       "  'bfrs': {'devset': 29.8, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-2-total-trained-steps-87': {'vanilla': {'devset': 23.0},\n",
       "  'bfrs': {'devset': 37.0, 'true_labels': None, 'testset': None}},\n",
       " 'base': {'vanilla': {'devset': 1.4},\n",
       "  'bfrs': {'devset': 30.0, 'true_labels': None, 'testset': None}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if True:\n",
    "    import json\n",
    "    with open(\"ft_results.json\", \"w\") as f:\n",
    "        json.dump(ft_results, f)\n",
    "else:\n",
    "    ft_results = json.load(open(\"ft_results.json\"))\n",
    "ft_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-13T01:03:09.033620Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lineno=198\n",
      "2024-10-13T01:03:09.043122Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 2 / 4  (50.0):   0%|          | 3/1000 [00:00<00:32, 30.53it/s]198['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.pylineno=\n",
      "Average Metric: 4 / 12  (33.3):   1%|          | 11/1000 [00:00<00:20, 48.11it/s]ror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 9 / 20  (45.0):   2%|▏         | 19/1000 [00:00<00:20, 48.11it/s] rror    3T01:03:09.056159Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.pylineno=198\n",
      "Average Metric: 11 / 28  (39.3):   3%|▎         | 27/1000 [00:00<00:20, 48.11it/s]=[24-10-13T01:03:09.059806Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filenameevaluate.py lineno=198\n",
      "Average Metric: 17 / 37  (45.9):   4%|▎         | 36/1000 [00:00<00:20, 48.11it/s]=024-10-13T01:03:09.060362Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 22 / 46  (47.8):   4%|▍         | 45/1000 [00:00<00:19, 48.11it/s]filenamer example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate =evaluate.py lineno=198\n",
      "Average Metric: 26 / 55  (47.3):   5%|▌         | 54/1000 [00:00<00:03, 303.38it/s]=24-10-13T01:03:09.068492Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluatefilename=evaluate.pylineno198\n",
      "Average Metric: 28 / 64  (43.8):   6%|▋         | 63/1000 [00:00<00:03, 303.38it/s]][24-10-13T01:03:09.071888Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 29 / 70  (41.4):   7%|▋         | 69/1000 [00:00<00:03, 303.38it/s]evaluate.py01:03:09.072349Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 32 / 80  (40.0):   8%|▊         | 79/1000 [00:00<00:03, 303.38it/s]]024-10-13T01:03:09.080386Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 37 / 89  (41.6):   9%|▉         | 88/1000 [00:00<00:03, 303.38it/s]198enome13T01:03:09.082034Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] evaluate.py =\n",
      "Average Metric: 38 / 97  (39.2):  10%|▉         | 96/1000 [00:00<00:02, 303.38it/s]lineno0-13T01:03:09.093597Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 40 / 105  (38.1):  10%|█         | 105/1000 [00:00<00:02, 392.18it/s]24-10-13T01:03:09.097103Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 44 / 115  (38.3):  11%|█▏        | 114/1000 [00:00<00:02, 392.18it/s]=valuate.pyte.evaluate3538Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename= lineno198\n",
      "Average Metric: 46 / 124  (37.1):  12%|█▏        | 123/1000 [00:00<00:02, 392.18it/s]=rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno198\n",
      "Average Metric: 49 / 137  (35.8):  14%|█▎        | 136/1000 [00:00<00:02, 392.18it/s] spy.evaluate.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filename=evaluate.py lineno=198\n",
      "Average Metric: 50 / 145  (34.5):  14%|█▍        | 144/1000 [00:00<00:02, 392.18it/s]evaluate.pyxample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 51 / 154  (33.1):  15%|█▌        | 153/1000 [00:00<00:02, 392.18it/s]=rror    3T01:03:09.142677Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 53 / 164  (32.3):  16%|█▋        | 163/1000 [00:00<00:02, 392.18it/s]1984-10-13T01:03:09.150477Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=\n",
      "Average Metric: 55 / 171  (32.2):  17%|█▋        | 170/1000 [00:00<00:01, 483.71it/s]] 24-10-13T01:03:09.151954Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 57 / 180  (31.7):  18%|█▊        | 179/1000 [00:00<00:01, 483.71it/s]198luate.py01:03:09.165039Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename= lineno=\n",
      "Average Metric: 60 / 190  (31.6):  19%|█▉        | 189/1000 [00:00<00:01, 483.71it/s]evaluate.py01:03:09.176549Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate = lineno=198\n",
      "Average Metric: 63 / 199  (31.7):  20%|█▉        | 198/1000 [00:00<00:01, 483.71it/s]198enovaluate.evaluate5954Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filenameevaluate.py =\n",
      "Average Metric: 63 / 208  (30.3):  21%|██        | 207/1000 [00:00<00:01, 483.71it/s]198enote.py01:03:09.186730Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate = =\n",
      "Average Metric: 65 / 217  (30.0):  22%|██▏       | 216/1000 [00:00<00:01, 483.71it/s] 024-10-13T01:03:09.192531Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 68 / 224  (30.4):  22%|██▏       | 223/1000 [00:00<00:01, 483.71it/s]= 24-10-13T01:03:09.199959Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 70 / 232  (30.2):  23%|██▎       | 231/1000 [00:00<00:01, 517.51it/s]198y.evaluate.evaluate0746Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py lineno=\n",
      "Average Metric: 73 / 243  (30.0):  24%|██▍       | 242/1000 [00:00<00:01, 517.51it/s]198luate.pyte.evaluateev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] = lineno=\n",
      "Average Metric: 76 / 252  (30.2):  25%|██▌       | 251/1000 [00:00<00:01, 517.51it/s]198eno0-13T01:03:09.214622Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py =\n",
      "Average Metric: 80.0 / 260  (30.8):  26%|██▌       | 259/1000 [00:00<00:01, 517.51it/s]=4-10-13T01:03:09.238602Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 83.0 / 267  (31.1):  27%|██▋       | 266/1000 [00:00<00:01, 517.51it/s]linenome 3T01:03:09.239432Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] =evaluate.py =198\n",
      "Average Metric: 88.0 / 276  (31.9):  28%|██▊       | 275/1000 [00:00<00:01, 517.51it/s]linenote.pyxample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename= =198\n",
      "Average Metric: 90.0 / 285  (31.6):  28%|██▊       | 284/1000 [00:00<00:01, 517.51it/s]198luate.pyxample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] = lineno=\n",
      "Average Metric: 94.0 / 294  (32.0):  29%|██▉       | 293/1000 [00:00<00:01, 537.00it/s]198y.evaluate.evaluate5844Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filenameevaluate.py lineno=\n",
      "Average Metric: 97.0 / 303  (32.0):  30%|███       | 302/1000 [00:00<00:01, 537.00it/s] [24-10-13T01:03:09.248792Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filenameevaluate.pylineno=198\n",
      "Average Metric: 98.0 / 312  (31.4):  31%|███       | 311/1000 [00:00<00:01, 537.00it/s] [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 103.0 / 321  (32.1):  32%|███▏      | 320/1000 [00:00<00:01, 537.00it/s]=[4-10-13T01:03:09.269012Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filenameevaluate.py lineno=198\n",
      "Average Metric: 106.0 / 332  (31.9):  33%|███▎      | 331/1000 [00:00<00:01, 537.00it/s]=[24-10-13T01:03:09.269887Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 108.0 / 340  (31.8):  34%|███▍      | 339/1000 [00:00<00:01, 537.00it/s]][24-10-13T01:03:09.272365Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 109.0 / 347  (31.4):  35%|███▍      | 347/1000 [00:00<00:01, 559.33it/s]198enote.pyxample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= =\n",
      "Average Metric: 113.0 / 356  (31.7):  36%|███▌      | 355/1000 [00:00<00:01, 559.33it/s] 024-10-13T01:03:09.290480Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 115.0 / 367  (31.3):  37%|███▋      | 366/1000 [00:00<00:01, 559.33it/s]=rror    3T01:03:09.295191Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 117.0 / 374  (31.3):  37%|███▋      | 373/1000 [00:00<00:01, 559.33it/s]linenote.pyxample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] = =198\n",
      "Average Metric: 120.0 / 382  (31.4):  38%|███▊      | 381/1000 [00:00<00:01, 559.33it/s]198luate.py01:03:09.336411Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate = lineno=\n",
      "Average Metric: 122.0 / 390  (31.3):  39%|███▉      | 389/1000 [00:00<00:01, 559.33it/s]lineno0-13T01:03:09.337126Zerror    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py =198\n",
      "Average Metric: 127.0 / 398  (31.9):  40%|███▉      | 397/1000 [00:00<00:01, 559.33it/s]2024-10-13T01:03:09.356326Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 132.0 / 408  (32.4):  41%|████      | 407/1000 [00:00<00:01, 559.33it/s]198luate.py01:03:09.358611Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename= lineno=\n",
      "Average Metric: 136.0 / 416  (32.7):  42%|████▏     | 415/1000 [00:00<00:01, 574.38it/s]=valuate.pyxample in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename= lineno198\n",
      "Average Metric: 140.0 / 425  (32.9):  42%|████▏     | 424/1000 [00:00<00:01, 574.38it/s]linenote.py01:03:09.379169Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename= =198\n",
      "Average Metric: 145.0 / 433  (33.5):  43%|████▎     | 432/1000 [00:00<00:00, 574.38it/s]=spy.evaluate.evaluate1425Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filenameevaluate.pylineno198\n",
      "Average Metric: 149.0 / 442  (33.7):  44%|████▍     | 441/1000 [00:00<00:00, 574.38it/s]]024-10-13T01:03:09.387547Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 152.0 / 452  (33.6):  45%|████▌     | 451/1000 [00:00<00:00, 574.38it/s]lineno   3T01:03:09.403880Z [] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 154.0 / 460  (33.5):  46%|████▌     | 459/1000 [00:00<00:00, 574.38it/s]=[24-10-13T01:03:09.420453Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate]filenameevaluate.py lineno=198\n",
      "Average Metric: 155.0 / 468  (33.1):  47%|████▋     | 467/1000 [00:00<00:00, 574.38it/s]198y.evaluate.evaluate2004Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. []filenameevaluate.py lineno=\n",
      "Average Metric: 157.0 / 476  (33.0):  48%|████▊     | 475/1000 [00:00<00:00, 577.37it/s]2024-10-13T01:03:09.450779Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 162.0 / 485  (33.4):  48%|████▊     | 484/1000 [00:00<00:00, 577.37it/s]198enomer example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py =\n",
      "Average Metric: 166.0 / 493  (33.7):  49%|████▉     | 492/1000 [00:00<00:00, 577.37it/s]] 24-10-13T01:03:09.500127Zerror    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 170.0 / 501  (33.9):  50%|█████     | 500/1000 [00:00<00:00, 577.37it/s]evaluate.py01:03:09.516135Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] = lineno=198\n",
      "Average Metric: 176.0 / 514  (34.2):  51%|█████▏    | 513/1000 [00:00<00:00, 577.37it/s]linenovaluate.evaluate3383Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py =198\n",
      "Average Metric: 181.0 / 521  (34.7):  52%|█████▏    | 520/1000 [00:01<00:00, 577.37it/s]198luate.py01:03:09.548227Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] = lineno=\n",
      "Average Metric: 184.0 / 529  (34.8):  53%|█████▎    | 528/1000 [00:01<00:00, 577.37it/s]=rror for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno198\n",
      "Average Metric: 315.0 / 1000  (31.5): 100%|██████████| 1000/1000 [00:01<00:00, 708.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating meta-llama/Llama-3.2-1B-Instruct:epochs-5-total-trained-steps-174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]2024-10-13T01:03:15.391919Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|          | 1/1000 [00:04<1:12:31,  4.36s/it]error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 0.0 / 2  (0.0):   0%|          | 1/1000 [00:04<1:12:31,  4.36s/it]2024-10-13T01:03:15.407531Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 58.0 / 92  (63.0):   9%|▉         | 91/1000 [00:08<00:41, 21.85it/s]2024-10-13T01:03:19.802348Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 65.0 / 101  (64.4):  10%|█         | 100/1000 [00:09<00:53, 16.87it/s]] 24-10-13T01:03:20.475090Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 67.0 / 105  (63.8):  10%|█         | 105/1000 [00:09<00:59, 15.13it/s] [24-10-13T01:03:20.855156Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace.dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 69.0 / 108  (63.9):  11%|█         | 107/1000 [00:10<01:06, 13.37it/s]evaluate.py01:03:21.105876Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 70.0 / 110  (63.6):  11%|█         | 110/1000 [00:10<01:11, 12.49it/s]2024-10-13T01:03:21.373010Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 71.0 / 112  (63.4):  11%|█         | 111/1000 [00:10<01:11, 12.49it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 116  (63.8):  12%|█▏        | 115/1000 [00:10<01:08, 13.00it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 74.0 / 117  (63.2):  12%|█▏        | 116/1000 [00:10<01:08, 13.00it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 78.0 / 124  (62.9):  12%|█▏        | 123/1000 [00:10<00:58, 14.98it/s]2024-10-13T01:03:22.029412Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 86.0 / 135  (63.7):  13%|█▎        | 134/1000 [00:11<00:48, 17.92it/s]evaluate.py01:03:22.502412Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename= lineno=198\n",
      "Average Metric: 93.0 / 145  (64.1):  14%|█▍        | 145/1000 [00:12<00:52, 16.43it/s]2024-10-13T01:03:23.174070Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 100.0 / 153  (65.4):  15%|█▌        | 152/1000 [00:12<00:50, 16.68it/s] 24-10-13T01:03:23.488677Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.pylineno=198\n",
      "Average Metric: 100.0 / 154  (64.9):  15%|█▌        | 153/1000 [00:12<00:50, 16.68it/s]2024-10-13T01:03:23.513246Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 102.0 / 157  (65.0):  16%|█▌        | 156/1000 [00:12<00:40, 20.98it/s]2024-10-13T01:03:23.665509Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 105.0 / 161  (65.2):  16%|█▌        | 161/1000 [00:12<00:50, 16.70it/s]]024-10-13T01:03:23.987053Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 105.0 / 162  (64.8):  16%|█▌        | 161/1000 [00:12<00:50, 16.70it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 125.0 / 190  (65.8):  19%|█▉        | 190/1000 [00:14<00:35, 22.67it/s]2024-10-13T01:03:25.380820Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 125.0 / 191  (65.4):  19%|█▉        | 190/1000 [00:14<00:35, 22.67it/s]2024-10-13T01:03:25.385119Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 142.0 / 258  (55.0):  26%|██▌       | 258/1000 [00:18<00:44, 16.84it/s]filename13T01:03:29.461989Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 143.0 / 260  (55.0):  26%|██▌       | 260/1000 [00:18<00:43, 16.96it/s]2024-10-13T01:03:29.604788Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 167.0 / 303  (55.1):  30%|███       | 302/1000 [00:20<00:42, 16.36it/s]2024-10-13T01:03:32.051572Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 168.0 / 306  (54.9):  30%|███       | 305/1000 [00:21<00:40, 17.12it/s]2024-10-13T01:03:32.308573Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 173.0 / 324  (53.4):  32%|███▏      | 323/1000 [00:22<01:00, 11.16it/s]2024-10-13T01:03:33.842709Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 175.0 / 328  (53.4):  33%|███▎      | 327/1000 [00:22<00:52, 12.74it/s]2024-10-13T01:03:33.914529Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 181.0 / 354  (51.1):  35%|███▌      | 353/1000 [00:23<00:27, 23.11it/s]2024-10-13T01:03:34.910542Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 181.0 / 356  (50.8):  36%|███▌      | 356/1000 [00:24<00:32, 20.07it/s]=024-10-13T01:03:35.151031Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filenameevaluate.py lineno=198\n",
      "Average Metric: 181.0 / 358  (50.6):  36%|███▌      | 357/1000 [00:24<00:32, 20.07it/s]2024-10-13T01:03:35.221193Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 181.0 / 359  (50.4):  36%|███▌      | 358/1000 [00:24<00:31, 20.07it/s]2024-10-13T01:03:35.230607Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 181.0 / 360  (50.3):  36%|███▌      | 360/1000 [00:24<00:27, 22.95it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 182.0 / 365  (49.9):  36%|███▋      | 364/1000 [00:24<00:34, 18.23it/s]2024-10-13T01:03:35.636229Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 184.0 / 373  (49.3):  37%|███▋      | 372/1000 [00:25<00:33, 18.74it/s]2024-10-13T01:03:36.286271Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 184.0 / 374  (49.2):  37%|███▋      | 374/1000 [00:25<00:40, 15.29it/s]2024-10-13T01:03:36.317554Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 184.0 / 375  (49.1):  37%|███▋      | 374/1000 [00:25<00:40, 15.29it/s]2024-10-13T01:03:36.323213Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 184.0 / 378  (48.7):  38%|███▊      | 377/1000 [00:25<00:47, 13.05it/s]Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 187.0 / 387  (48.3):  39%|███▊      | 386/1000 [00:26<00:38, 15.80it/s]filename13T01:03:37.070030Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate =evaluate.py lineno=198\n",
      "Average Metric: 190.0 / 400  (47.5):  40%|███▉      | 399/1000 [00:26<00:21, 28.37it/s]  24-10-13T01:03:37.399214Z [error    Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 200.0 / 419  (47.7):  42%|████▏     | 418/1000 [00:28<00:50, 11.54it/s]2024-10-13T01:03:39.177508Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 201.0 / 421  (47.7):  42%|████▏     | 420/1000 [00:28<00:51, 11.29it/s]2024-10-13T01:03:39.235882Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 216.0 / 458  (47.2):  46%|████▌     | 457/1000 [00:30<00:18, 28.62it/s]2024-10-13T01:03:41.172596Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 224.0 / 482  (46.5):  48%|████▊     | 482/1000 [00:32<00:45, 11.37it/s]2024-10-13T01:03:43.231817Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 240.0 / 504  (47.6):  50%|█████     | 503/1000 [00:33<00:28, 17.44it/s]2024-10-13T01:03:44.179490Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 245.0 / 516  (47.5):  52%|█████▏    | 515/1000 [00:33<00:34, 14.15it/s]2024-10-13T01:03:44.947353Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 246.0 / 518  (47.5):  52%|█████▏    | 518/1000 [00:33<00:27, 17.67it/s] 024-10-13T01:03:45.043080Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate]filename=evaluate.py lineno=198\n",
      "Average Metric: 249.0 / 524  (47.5):  52%|█████▏    | 523/1000 [00:34<00:31, 15.31it/s]2024-10-13T01:03:45.607890Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 253.0 / 530  (47.7):  53%|█████▎    | 530/1000 [00:34<00:24, 19.58it/s]=024-10-13T01:03:45.687179Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno198\n",
      "Average Metric: 253.0 / 531  (47.6):  53%|█████▎    | 530/1000 [00:34<00:24, 19.58it/s]2024-10-13T01:03:45.750058Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 268.0 / 564  (47.5):  56%|█████▋    | 563/1000 [00:36<00:31, 13.68it/s]2024-10-13T01:03:47.946500Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 270.0 / 568  (47.5):  57%|█████▋    | 568/1000 [00:36<00:21, 19.64it/s]2024-10-13T01:03:48.064547Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 272.0 / 572  (47.6):  57%|█████▋    | 571/1000 [00:37<00:28, 15.17it/s]2024-10-13T01:03:48.400672Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 272.0 / 573  (47.5):  57%|█████▋    | 572/1000 [00:37<00:28, 15.17it/s] [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 272.0 / 575  (47.3):  57%|█████▋    | 574/1000 [00:37<00:28, 15.17it/s]2024-10-13T01:03:48.431977Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 278.0 / 593  (46.9):  59%|█████▉    | 593/1000 [00:38<00:17, 22.69it/s]2024-10-13T01:03:49.490675Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 289.0 / 610  (47.4):  61%|██████    | 609/1000 [00:39<00:25, 15.08it/s]2024-10-13T01:03:50.437334Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 290.0 / 612  (47.4):  61%|██████    | 611/1000 [00:39<00:21, 17.88it/s]2024-10-13T01:03:50.681008Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 300.0 / 633  (47.4):  63%|██████▎   | 633/1000 [00:40<00:21, 16.89it/s]]024-10-13T01:03:51.838485Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate filename=evaluate.py lineno=198\n",
      "Average Metric: 315.0 / 657  (47.9):  66%|██████▌   | 656/1000 [00:42<00:22, 15.12it/s]lineno0-13T01:03:53.381731Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py =198\n",
      "Average Metric: 325.0 / 674  (48.2):  67%|██████▋   | 673/1000 [00:43<00:16, 20.22it/s]2024-10-13T01:03:54.197663Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 326.0 / 679  (48.0):  68%|██████▊   | 679/1000 [00:43<00:15, 20.39it/s]filename13T01:03:54.487720Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] =evaluate.py lineno=198\n",
      "Average Metric: 330.0 / 686  (48.1):  69%|██████▊   | 686/1000 [00:44<00:20, 15.67it/s]2024-10-13T01:03:55.090953Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 342.0 / 747  (45.8):  75%|███████▍  | 747/1000 [00:47<00:13, 19.04it/s]2024-10-13T01:03:58.459067Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 351.0 / 767  (45.8):  77%|███████▋  | 767/1000 [00:48<00:11, 20.90it/s]2024-10-13T01:03:59.498352Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 366.0 / 789  (46.4):  79%|███████▉  | 788/1000 [00:49<00:13, 15.87it/s]2024-10-13T01:04:00.828588Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 375.0 / 851  (44.1):  85%|████████▌ | 850/1000 [00:53<00:09, 15.80it/s]2024-10-13T01:04:04.698620Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 376.0 / 861  (43.7):  86%|████████▌ | 860/1000 [00:54<00:08, 16.79it/s]2024-10-13T01:04:05.341848Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 376.0 / 869  (43.3):  87%|████████▋ | 869/1000 [00:54<00:06, 21.54it/s]2024-10-13T01:04:05.713440Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 379.0 / 879  (43.1):  88%|████████▊ | 879/1000 [00:55<00:09, 12.38it/s]2024-10-13T01:04:06.739184Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 381.0 / 882  (43.2):  88%|████████▊ | 882/1000 [00:55<00:08, 14.02it/s]2024-10-13T01:04:06.891277Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 382.0 / 886  (43.1):  88%|████████▊ | 885/1000 [00:56<00:09, 12.36it/s]2024-10-13T01:04:07.130490Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 383.0 / 888  (43.1):  89%|████████▊ | 887/1000 [00:56<00:09, 12.36it/s]2024-10-13T01:04:07.157440Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 388.0 / 895  (43.4):  89%|████████▉ | 894/1000 [00:56<00:06, 15.95it/s]2024-10-13T01:04:07.530458Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [dspy.evaluate.evaluate] filename=evaluate.py lineno=198\n",
      "Average Metric: 447.0 / 966  (46.3):  96%|█████████▋| 965/1000 [01:00<00:01, 25.30it/s]linenovaluate.evaluate5131Z [error    ] Error for example in dev set: \t\t Expected ['reasoning', 'label'] but got dict_keys([]). Set `provide_traceback=True` to see the stack trace. [] filename=evaluate.py =198\n",
      "Average Metric: 473.0 / 1000  (47.3): 100%|██████████| 1000/1000 [01:00<00:00, 16.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# Now we need to evaluate the test set\n",
    "best_non_base_model = max([x for x in ft_results.keys() if x != \"base\"], key=lambda x: ft_results[x][\"bfrs\"][\"devset\"])\n",
    "print(\"Best non-base model:\", best_non_base_model)\n",
    "base_and_best = {\"base\": all_llamas[\"base\"], best_non_base_model: all_llamas[best_non_base_model]}\n",
    "\n",
    "for folder, llama in base_and_best.items():\n",
    "    print(\"Evaluating\", folder)\n",
    "    vanilla_program = IntentClassificationModule()\n",
    "    vanilla_program.load(f\"simpleintent_1b_32_ft_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}_{folder.split('/')[-1]}.json\")\n",
    "    with dspy.context(lm=llama):\n",
    "        testset_result = evaluate_testset(vanilla_program)\n",
    "        ft_results[folder][\"bfrs\"][\"testset\"] = testset_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/Llama-3.2-1B-Instruct:epochs-5-total-trained-steps-174': {'bfrs': {'testset': 47.3}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-0-total-trained-steps-29': {'vanilla': {'devset': 21.8},\n",
       "  'bfrs': {'devset': 30.4, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-3-total-trained-steps-116': {'vanilla': {'devset': 13.8},\n",
       "  'bfrs': {'devset': 38.2, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-4-total-trained-steps-145': {'vanilla': {'devset': 14.0},\n",
       "  'bfrs': {'devset': 48.4, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-1-total-trained-steps-58': {'vanilla': {'devset': 15.8},\n",
       "  'bfrs': {'devset': 29.8, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-2-total-trained-steps-87': {'vanilla': {'devset': 23.0},\n",
       "  'bfrs': {'devset': 37.0, 'true_labels': None, 'testset': None}},\n",
       " 'base': {'bfrs': {'testset': 31.5}},\n",
       " 'best_non_base_model': {}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if True:\n",
    "    ft_results = json.load(open(\"ft_results.json\"))\n",
    "    print(ft_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data for plotting\n",
    "models = []\n",
    "vanilla_devset = []\n",
    "bfrs_devset = []\n",
    "vanilla_testset = []\n",
    "bfrs_testset = []\n",
    "\n",
    "for model, results in ft_results.items():\n",
    "    if model == \"base\":\n",
    "        models.append(\"base\")\n",
    "    else:\n",
    "        epoch = model.split(':')[1].split('-')[1]\n",
    "        models.append(int(epoch))  # Store epoch as integer for proper sorting\n",
    "    vanilla_devset.append(results['vanilla']['devset'])\n",
    "    bfrs_devset.append(results['bfrs']['devset'])\n",
    "    vanilla_testset.append(results['vanilla']['testset'])\n",
    "    bfrs_testset.append(results['bfrs']['testset'])\n",
    "\n",
    "# Sort the data by epoch, keeping \"base\" at the beginning\n",
    "sorted_data = sorted(zip(models, vanilla_devset, bfrs_devset, vanilla_testset, bfrs_testset),\n",
    "                     key=lambda x: (x[0] != \"base\", x[0]))\n",
    "models, vanilla_devset, bfrs_devset, vanilla_testset, bfrs_testset = zip(*sorted_data)\n",
    "\n",
    "# Convert back to string labels for x-axis\n",
    "models = [\"base\" if m == \"base\" else f\"Epoch {m}\" for m in models]\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot lines\n",
    "ax.plot(models, vanilla_devset, marker='o', label='Vanilla Dev', linestyle='-', color='skyblue')\n",
    "ax.plot(models, bfrs_devset, marker='s', label='BFRS Dev', linestyle='-', color='lightgreen')\n",
    "ax.plot(models, vanilla_testset, marker='^', label='Vanilla Test', linestyle='--', color='navy')\n",
    "ax.plot(models, bfrs_testset, marker='D', label='BFRS Test', linestyle='--', color='darkgreen')\n",
    "\n",
    "# Add value labels on top of each point\n",
    "for i, v in enumerate(zip(vanilla_devset, bfrs_devset, vanilla_testset, bfrs_testset)):\n",
    "    for j, val in enumerate(v):\n",
    "        ax.annotate(f'{val:.1f}', (i, val), xytext=(0, 5), \n",
    "                    textcoords='offset points', ha='center', va='bottom',\n",
    "                    fontsize=8, rotation=45)\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Model Performance Comparison Across Epochs')\n",
    "ax.set_xticks(range(len(models)))\n",
    "ax.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "# Add a grid for better readability\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'vanilla'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Vanilla Dev: 28.8\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# BFRS Dev: 42.0\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Vanilla Test: 32.3\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# BFRS Test: 43.1\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     print(\"No scores found for Epoch 5\")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model, results \u001b[38;5;129;01min\u001b[39;00m ft_results\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model, \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvanilla\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevset\u001b[39m\u001b[38;5;124m'\u001b[39m], results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbfrs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevset\u001b[39m\u001b[38;5;124m'\u001b[39m], results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvanilla\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtestset\u001b[39m\u001b[38;5;124m'\u001b[39m], results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbfrs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtestset\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'vanilla'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vanilla Dev: 28.8\n",
    "# BFRS Dev: 42.0\n",
    "# Vanilla Test: 32.3\n",
    "# BFRS Test: 43.1\n",
    "# else:\n",
    "#     print(\"No scores found for Epoch 5\")\n",
    "\n",
    "for model, results in ft_results.items():\n",
    "    print(model, results['vanilla']['devset'], results['bfrs']['devset'], results['vanilla']['testset'], results['bfrs']['testset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta-llama/Llama-3.2-1B-Instruct:epochs-5-total-trained-steps-174': {'bfrs': {'testset': 47.3}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-0-total-trained-steps-29': {'vanilla': {'devset': 21.8},\n",
       "  'bfrs': {'devset': 30.4, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-3-total-trained-steps-116': {'vanilla': {'devset': 13.8},\n",
       "  'bfrs': {'devset': 38.2, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-4-total-trained-steps-145': {'vanilla': {'devset': 14.0},\n",
       "  'bfrs': {'devset': 48.4, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-1-total-trained-steps-58': {'vanilla': {'devset': 15.8},\n",
       "  'bfrs': {'devset': 29.8, 'true_labels': None, 'testset': None}},\n",
       " 'meta-llama/Llama-3.2-1B-Instruct:epochs-2-total-trained-steps-87': {'vanilla': {'devset': 23.0},\n",
       "  'bfrs': {'devset': 37.0, 'true_labels': None, 'testset': None}},\n",
       " 'base': {'bfrs': {'testset': 31.5}},\n",
       " 'best_non_base_model': {}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'vanilla'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     models\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Extract epoch information\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m vanilla_devset\u001b[38;5;241m.\u001b[39mappend(\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvanilla\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevset\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     18\u001b[0m bfrs_devset\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbfrs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevset\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     19\u001b[0m vanilla_testset\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvanilla\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtestset\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'vanilla'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data for plotting\n",
    "models = []\n",
    "vanilla_devset = []\n",
    "bfrs_devset = []\n",
    "vanilla_testset = []\n",
    "bfrs_testset = []\n",
    "\n",
    "for model, results in ft_results.items():\n",
    "    if model == \"base\":\n",
    "        models.append(\"base\")\n",
    "    else:\n",
    "        models.append(\"Epoch \" + model.split(':')[1].split('-')[1])  # Extract epoch information\n",
    "    vanilla_devset.append(results['vanilla']['devset'])\n",
    "    bfrs_devset.append(results['bfrs']['devset'])\n",
    "    vanilla_testset.append(results['vanilla'].get('testset', None))\n",
    "    bfrs_testset.append(results['bfrs'].get('testset', None))\n",
    "\n",
    "# Sort the data by epoch, keeping \"base\" at the beginning\n",
    "sorted_data = sorted(zip(models, vanilla_devset, bfrs_devset, vanilla_testset, bfrs_testset),\n",
    "                     key=lambda x: (x[0] != \"base\", x[0]))\n",
    "models, vanilla_devset, bfrs_devset, vanilla_testset, bfrs_testset = zip(*sorted_data)\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(models[i], \"vanilla_devset\", vanilla_devset[i], \"bfrs_devset\", bfrs_devset[i], \"vanilla_testset\", vanilla_testset[i], \"bfrs_testset\", bfrs_testset[i])\n",
    "\n",
    "# Set up the plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "# Adjust bar positions and width\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "# Plot bars for Dev Set (top graph)\n",
    "ax1.bar(x - width/2, vanilla_devset, width, label='Vanilla Dev', color='skyblue')\n",
    "ax1.bar(x + width/2, bfrs_devset, width, label='BFRS Dev', color='lightgreen')\n",
    "\n",
    "# Add value labels on top of each bar for Dev Set\n",
    "for i, v in enumerate(vanilla_devset):\n",
    "    ax1.text(i - width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "for i, v in enumerate(bfrs_devset):\n",
    "    ax1.text(i + width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Customize the Dev Set plot\n",
    "ax1.set_ylabel('Dev Set Scores')\n",
    "ax1.set_title('Model Performance Comparison Across Epochs (Dev Set)')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Find the highest devset score and its corresponding model\n",
    "highest_devset_score = max(bfrs_devset)\n",
    "highest_score_model = models[bfrs_devset.index(highest_devset_score)]\n",
    "\n",
    "print(highest_devset_score, highest_score_model, bfrs_devset[models.index(highest_score_model)])\n",
    "\n",
    "# Prepare data for the bottom graph\n",
    "# Prepare data for the bottom graph (Test Set)\n",
    "base_vanilla_testset = vanilla_testset[models.index(\"base\")]\n",
    "base_bfrs_testset = bfrs_testset[models.index(\"base\")]\n",
    "\n",
    "best_model_index = bfrs_devset.index(highest_devset_score)\n",
    "best_vanilla_testset = vanilla_testset[best_model_index]\n",
    "best_bfrs_testset = bfrs_testset[best_model_index]\n",
    "\n",
    "print(\"best_vanilla_testset\", best_vanilla_testset, \"best_bfrs_testset\", best_bfrs_testset)\n",
    "print(\"base_vanilla_testset\", base_vanilla_testset, \"base_bfrs_testset\", base_bfrs_testset)\n",
    "\n",
    "# Plot bars for Test Set (bottom graph)\n",
    "models_to_plot = [\"Base Model\", f\"Best Model ({highest_score_model})\"]\n",
    "x_test = np.arange(len(models_to_plot))\n",
    "\n",
    "ax2.bar(x_test - width/2, [base_vanilla_testset, best_vanilla_testset], width, label='Vanilla Test', color='coral')\n",
    "ax2.bar(x_test + width/2, [base_bfrs_testset, best_bfrs_testset], width, label='BFRS Test', color='lightseagreen')\n",
    "\n",
    "# Add value labels on top of each bar for Test Set\n",
    "for i, v in enumerate([base_vanilla_testset, best_vanilla_testset]):\n",
    "    ax2.text(i - width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "for i, v in enumerate([base_bfrs_testset, best_bfrs_testset]):\n",
    "    ax2.text(i + width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Customize the Test Set plot\n",
    "ax2.set_ylabel('Test Set Scores')\n",
    "ax2.set_title('Model Performance Comparison (Test Set)')\n",
    "ax2.set_xticks(x_test)\n",
    "ax2.set_xticklabels(models_to_plot)\n",
    "ax2.legend()\n",
    "ax2.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dspy.teleprompt import MIPROv2\n",
    "# gpt4o = dspy.LM(model=\"gpt-4o\", **MODEL_PARAMETERS)\n",
    "\n",
    "# COMPILE_PROGRAM = True\n",
    "\n",
    "# with dspy.context(lm=current_best):\n",
    "#     vanilla_program = IntentClassificationModule()\n",
    "#     if COMPILE_PROGRAM:\n",
    "#         # eval_kwargs = dict(display_progress=True, display_table=0, num_threads=NUM_THREADS)\n",
    "#         teleprompter = MIPROv2(prompt_model=gpt4o, task_model=current_best, metric=metric, num_candidates=10, init_temperature=0.9, verbose=True, num_threads=NUM_THREADS, max_errors=1000)\n",
    "#         compiled_program = teleprompter.compile(vanilla_program, trainset=optimizer_trainset, valset=optimizer_valset, num_trials=30, max_bootstrapped_demos=MAX_BOOTSTRAPPED_DEMOS,max_labeled_demos=MAX_LABELED_DEMOS, requires_permission_to_run=False)\n",
    "#         compiled_program.save(f\"simpleintent_1b_32_ft_mipro_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}.json\")\n",
    "#     else:\n",
    "#         compiled_program = IntentClassificationModule()\n",
    "#         compiled_program.load(f\"simpleintent_1b_32_ft_mipro_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}.json\")\n",
    "#     llama_8b_ft_mipro_eval = evaluate_devset(compiled_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, lets give the base 8B model a fair chance by prompt optimizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can compare all iterations of this pipeline\n",
    "print(f\"Results for HotPotQA fine-tuning LLaMa 8B with a starting trainset\")\n",
    "print(f\"    70B model (vanilla program): {llama_70b_base_eval}\")\n",
    "print(f\"    70B model (bfrs program): {llama_70b_bfrs_eval}\")\n",
    "print(f\"    8B model (vanilla program): {vanilla_8b_base_eval}\")\n",
    "print(f\"    8B model (bfrs program): {llama_8b_bfrs_eval}\")\n",
    "print(f\"    8B model (finetuned program): {llama_8b_finetuned_eval}\")\n",
    "print(f\"    8B model (finetuned bfrs program): {llama_8b_bfrs_finetuned_eval}\")\n",
    "print(f\"    8B model (finetuned mipro program): {llama_8b_ft_mipro_eval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Let's now use the new offline batch inference to evaluate the finetuned model with optimized program on the entire devset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement once done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"Stop here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving\n",
    "\n",
    "This is the second biggest unknown\n",
    "I imagine it to be easy, but crazier things have happened\n",
    "\n",
    "I need to keep a reference or link to the LLM forge job inside the LM.finetune method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how do I get the ray llm image!\n",
    "\n",
    "We'll start by running the rayllm CLI command below to start the workflow to generate the service yaml configuration:\n",
    "```bash\n",
    "mkdir /home/ray/default/deploy/services\n",
    "cd /home/ray/default/deploy/services\n",
    "rayllm gen-config \n",
    "```\n",
    "\n",
    "<img src=\"assets/cli.png\" width=500 alt=\"todo! get this inage of what I need to serve\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch offline inference\n",
    "- Compare running inference using \n",
    "    - Ray Data \n",
    "    - multithreading on local VLLM thru HTTP\n",
    "    - Multithreading to Ray Serve instance thru HTTP\n",
    "- Dev time estimate: 7 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"background-color: yellow;\">&nbsp;🛑 IMPORTANT&nbsp;</b>: Please `Terminate` your service from the Service page to avoid depleting your free trial credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "!python src/clear_cell_nums.py\n",
    "!find . | grep -E \".ipynb_checkpoints\" | xargs rm -rf\n",
    "!find . | grep -E \"(__pycache__|\\.pyc|\\.pyo)\" | xargs rm -rf\n",
    "!rm -rf __pycache__ data .HF_TOKEN deploy/services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MARK: Synthetic 70B Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets do some data analysis and cleaning\n",
    "# First we will convert the data to a pandas dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: Move\n",
    "# For realism of this scenario, we are going to delete all our labels except for our test set(which is cheating and we wouldn't have in production) and our 100 true labeled examples\n",
    "\n",
    "def delete_labels(dataset):\n",
    "    for example in dataset:\n",
    "        if \"label\" in example:\n",
    "            del example[\"label\"]\n",
    "    return dataset\n",
    "\n",
    "trainset_to_label = delete_labels(trainset_to_label)\n",
    "# Convert collected_data to a pandas DataFrame\n",
    "data_dict = {\n",
    "    'example': [item[0][\"text\"] for item in collected_data],\n",
    "    'label': [item[1][\"label\"] for item in collected_data],\n",
    "    'reasoning': [item[1][\"reasoning\"] for item in collected_data]\n",
    "}\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"collected_data.csv\", index=False)\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"collected_data.csv\")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Lets see how many labels are invalid (not in the top 25 most common labels)\n",
    "df['label'].value_counts()\n",
    "df_cleaned = df[df['label'].isin(labels_in_use)]\n",
    "print(\"Length of cleaned dataframe:\", len(df_cleaned))\n",
    "\n",
    "# Save the cleaned DataFrame to a CSV file\n",
    "df_cleaned.to_csv(\"collected_data_cleaned.csv\", index=False)\n",
    "\n",
    "dspy.settings.configure(experimental=True, lm=llama_70b)\n",
    "\n",
    "from dspy.teleprompt.finetune_teleprompter import bootstrap_data,bootstrap_data_for_round, convert_to_module_level_message_data    \n",
    "\n",
    "vanilla_program = IntentClassificationModule()\n",
    "data = bootstrap_data(vanilla_program, trainset_to_label, metric=fake_metric, num_threads=NUM_THREADS, max_errors=10000)\n",
    "data_example_ind_map = {data_dict[\"example_ind\"]: idx for idx, data_dict in enumerate(data)}\n",
    "# Convert the data to prompt completion format\n",
    "dataset = convert_to_module_level_message_data(data, program=vanilla_program, exclude_demos=True)\n",
    "\n",
    "training_data = data.copy()\n",
    "for idx, data_dict in enumerate(training_data):\n",
    "    fields_to_keep = [\"example\", \"example_ind\", \"prediction\"]\n",
    "    training_data[idx] = {k: v for k, v in data_dict.items() if k in fields_to_keep}\n",
    "    training_data[idx].update({\"finetunable_data\": dataset[idx]})\n",
    "\n",
    "print(training_data[0])\n",
    "\n",
    "filtered_training_data = [x for x in training_data if x[\"prediction\"].label in labels_in_use]\n",
    "TRAIN_SIZE_ADJUSTED = min(2000, len(filtered_training_data) - DEV_SIZE - PROMPT_OPT_TRAIN_SIZE - PROMPT_OPT_DEV_SIZE)\n",
    "print(len(filtered_training_data), TRAIN_SIZE_ADJUSTED)\n",
    "\n",
    "# save the training data for future use\n",
    "\n",
    "if True:\n",
    "    filtered_training_data = ujson.load(open(\"training_data.json\", \"r\"))\n",
    "    TRAIN_SIZE_ADJUSTED = min(2000, len(filtered_training_data) - DEV_SIZE - PROMPT_OPT_TRAIN_SIZE - PROMPT_OPT_DEV_SIZE)\n",
    "else:\n",
    "    with open(\"training_data.json\", \"w\") as f:\n",
    "        ujson.dump(filtered_training_data, f)\n",
    "\n",
    "ft_trainset = filtered_training_data[:TRAIN_SIZE_ADJUSTED]\n",
    "ft_devset = filtered_training_data[TRAIN_SIZE_ADJUSTED:TRAIN_SIZE_ADJUSTED+DEV_SIZE]\n",
    "optimizer_trainset = filtered_training_data[TRAIN_SIZE_ADJUSTED+DEV_SIZE:TRAIN_SIZE_ADJUSTED+DEV_SIZE+PROMPT_OPT_TRAIN_SIZE]\n",
    "optimizer_valset = filtered_training_data[TRAIN_SIZE_ADJUSTED+DEV_SIZE+PROMPT_OPT_TRAIN_SIZE:TRAIN_SIZE_ADJUSTED+DEV_SIZE+PROMPT_OPT_TRAIN_SIZE+PROMPT_OPT_DEV_SIZE]\n",
    "\n",
    "def convert_example_predictions_to_example(dataset):\n",
    "    data = []\n",
    "    for item in dataset:\n",
    "        data.append(dspy.Example(text=item[\"example\"][\"text\"], label=item[\"prediction\"][\"label\"], reasoning=item[\"prediction\"][\"reasoning\"]).with_inputs(\"text\"))\n",
    "    return data\n",
    "\n",
    "ft_devset_examples = convert_example_predictions_to_example(ft_devset)\n",
    "optimizer_trainset = convert_example_predictions_to_example(optimizer_trainset)\n",
    "optimizer_valset = convert_example_predictions_to_example(optimizer_valset)\n",
    "\n",
    "evaluate_devset = Evaluate(devset=ft_devset_examples, metric=metric, num_threads=NUM_THREADS, display_progress=True, max_errors=10000)\n",
    "\n",
    "# Note: Maybe dont use devset here\n",
    "dataset_filenames = {f\"trainset_data_banking_{TRAIN_SIZE}.jsonl\": ft_trainset, f\"trainset_val_data_banking_{DEV_SIZE}.jsonl\": ft_devset}\n",
    "\n",
    "for filename, data in dataset_filenames.items():\n",
    "    # we first need to convert the data to be only the messages and to be in proper messages format\n",
    "    messages_format = [{\"messages\": data_dict[\"finetunable_data\"]} for data_dict in data]\n",
    "    # print(messages_format[0])\n",
    "\n",
    "    write_jsonl(filename, messages_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MARK: Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import Ensemble\n",
    "\n",
    "# testing ensemble\n",
    "top_programs = []\n",
    "\n",
    "for folder, llama in all_llamas.items():\n",
    "    with dspy.context(lm=llama):\n",
    "        vanilla_program = IntentClassificationModule()\n",
    "        bfrs_finetuned_program = bfrs_optimizer.compile(vanilla_program, trainset=optimizer_trainset, valset=optimizer_valset)\n",
    "        devset_result = evaluate_devset(bfrs_finetuned_program)\n",
    "\n",
    "        def wrapped_program(*args, **kwargs):\n",
    "            with dspy.context(lm=llama):\n",
    "                return bfrs_finetuned_program(*args, **kwargs)\n",
    "        top_programs.append((wrapped_program, llama, devset_result))\n",
    "\n",
    "top_3_devset = sorted(top_programs, key=lambda x: x[2], reverse=True)[:3]\n",
    "\n",
    "teleprompter = Ensemble(reduce_fn=dspy.majority, size=None)\n",
    "# print(top_3_devset)\n",
    "programs = [p[0] for p in top_3_devset]\n",
    "# print(programs)\n",
    "compiled_program = teleprompter.compile(programs)\n",
    "# # print(compiled_program)\n",
    "eval_result = evaluate_devset(compiled_program)\n",
    "eval_testset = evaluate_testset(compiled_program)\n",
    "print(f\"result for best_ensemble: {eval_result}, {eval_true_labels}, {eval_testset}\")\n",
    "ft_results[folder][\"best_ensemble\"] = {\"devset\": eval_result, \"true_labels\": eval_true_labels, \"testset\": eval_testset}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MARK: Prediction no CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy.settings.configure(experimental=True)\n",
    "\n",
    "from dspy.teleprompt.finetune_teleprompter import bootstrap_data, bootstrap_data_for_round, convert_to_module_level_message_data    \n",
    "\n",
    "class IntentClassificationPredictModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.intent_classifier = dspy.Predict(IntentClassification)\n",
    "        self.valid_labels = set([\"activate_my_card\", \"cancel_transfer\", \"cash_withdrawal_charge\", \"declined_card_payment\", \"declined_cash_withdrawal\", \"direct_debit_payment_not_recognised\", \"extra_charge_on_statement\", \"pending_card_payment\", \"pending_top_up\", \"Refund_not_showing_up\", \"request_refund\", \"reverted_card_payment\", \"transaction_charged_twice\", \"transfer_fee_charged\", \"transfer_not_received_by_recipient\", \"wrong_amount_of_cash_received\", \"wrong_exchange_rate_for_cash_withdrawal\"])\n",
    "\n",
    "    def forward(self, text):\n",
    "        prediction = self.intent_classifier(intent=text)\n",
    "        sanitized_prediction = dspy.Prediction(label=prediction.label.lower().strip().replace(\" \", \"_\"))\n",
    "        # if sanitized_prediction.label not in self.valid_labels:\n",
    "        #     for label in self.valid_labels:\n",
    "        #         if label in sanitized_prediction.label:\n",
    "        #             sanitized_prediction.label = label\n",
    "        #             break\n",
    "        #     # this means that the prediction was not in the valid labels\n",
    "        #     # Could do edit distance or something more sophisticated here\n",
    "        #     # but for now just take the first\n",
    "        #     sanitized_prediction.label = self.valid_labels[0]\n",
    "        return sanitized_prediction\n",
    "\n",
    "def convert_examples_to_messages(examples):\n",
    "    manual_traces = []\n",
    "    module = IntentClassificationPredictModule()\n",
    "    for example in examples:\n",
    "        example[\"intent\"] = example[\"text\"]\n",
    "        example = example.with_inputs(\"intent\")\n",
    "        manual_traces.append((module.intent_classifier, example.inputs(), example))\n",
    "\n",
    "    data = []\n",
    "    # traces are (pred, inputs, outputs)\n",
    "    adapter = dspy.ChatAdapter()\n",
    "    for pred, inputs, outputs in manual_traces:\n",
    "        messages = adapter.format(pred.signature, [], inputs)\n",
    "        formatted_completion = adapter.format_completion(pred.signature, outputs)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": formatted_completion})\n",
    "        data.append({\"messages\": messages})\n",
    "\n",
    "    return data\n",
    "\n",
    "train_path = f\"ft_trainset_data_banking_no_cot_{len(ft_trainset)}.jsonl\"\n",
    "eval_path = f\"ft_valset_data_banking_no_cot_{len(devset)}.jsonl\"\n",
    "\n",
    "write_jsonl(train_path, convert_examples_to_messages(ft_trainset))\n",
    "write_jsonl(eval_path, convert_examples_to_messages(devset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.modules.lm import TrainingMethod\n",
    "\n",
    "\n",
    "method = TrainingMethod.SFT\n",
    "\n",
    "kwargs = {\n",
    "    \"hyperparameters\": {\n",
    "        \"num_devices\": 4,\n",
    "        \"trainer_resources\": None,\n",
    "        \"worker_resources\": None,\n",
    "        \"generation_config\": {\n",
    "            \"prompt_format\": {\n",
    "                \"system\": \"<|start_header_id|>system<|end_header_id|>\\n\\n{instruction}<|eot_id|>\",\n",
    "                \"user\": \"<|start_header_id|>user<|end_header_id|>\\n{instruction}<|eot_id|>\",\n",
    "                \"assistant\": \"<|start_header_id|>assistant<|end_header_id|>\\n\\n{instruction}<|eot_id|>\",\n",
    "                \"trailing_assistant\": \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    "                \"bos\": \"<|begin_of_text|>\",\n",
    "                \"system_in_user\": False,\n",
    "                \"default_system_message\": \"\"\n",
    "            },\n",
    "        },\n",
    "        \"learning_rate\": 3e-5,\n",
    "        \"num_epochs\": 6,\n",
    "        \"train_batch_size_per_device\": 32\n",
    "    },\n",
    "    \"use_lora\": True,\n",
    "    # TODO: I think this needs to be set dynamically\n",
    "    # \"lora_dynamic_folder\": \"dspy/lora_weights/prodjob_qmulcjw4x8z599m8hkyja8tbmi/meta-llama/Llama-3.2-1B-Instruct\"\n",
    "}\n",
    "\n",
    "SKIP_FT = False\n",
    "if not SKIP_FT:\n",
    "    # TODO: Get job working with LLMForge\n",
    "    student_llama_1b = dspy.TrainableAnyscale(model=\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "    future = student_llama_1b.get_finetune(method, train_path, eval_path, **kwargs)\n",
    "    checkpoint_names = future.result()\n",
    "\n",
    "    model_names = checkpoint_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "if True:\n",
    "    with open(\"model_names_predict.json\", \"r\") as f:\n",
    "        model_names = json.load(f)\n",
    "else:\n",
    "    with open(\"model_names_predict.json\", \"w\") as f:\n",
    "        json.dump(checkpoint_names, f)\n",
    "    # model_names = checkpoint_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command for easy copying: \n",
    "\n",
    "llama_1b = dspy.LM(model=\"openai/meta-llama/Llama-3.2-1B-Instruct\", **LOCAL_API_PARAMETERS, **MODEL_PARAMETERS)\n",
    "finetuned_llamas_1b = {f: dspy.LM(model=\"openai/\" + f, **LOCAL_API_PARAMETERS, **MODEL_PARAMETERS) for f in model_names}\n",
    "all_llamas = {**finetuned_llamas_1b, \"base\": llama_1b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x.model for x in all_llamas.values()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collected_data_filtered[0]\n",
    "def collected_data_to_example(data):\n",
    "    return dspy.Example(text=data[\"example\"][\"text\"], label=data[\"prediction\"][\"label\"]).with_inputs(\"text\")\n",
    "\n",
    "collected_data_examples = [collected_data_to_example(x) for x in collected_data_filtered]\n",
    "# collected_data_examples[0]\n",
    "\n",
    "devset_synthetic = collected_data_examples[:DEV_SIZE]\n",
    "ft_optimizer_devset = collected_data_examples[DEV_SIZE:DEV_SIZE+OPTIMIZER_NUM_VAL]\n",
    "ft_optimizer_trainset = collected_data_examples[DEV_SIZE+OPTIMIZER_NUM_VAL:]\n",
    "\n",
    "evaluate_devset = Evaluate(devset=devset_synthetic, metric=metric, num_threads=NUM_THREADS, display_progress=True, max_errors=10000)\n",
    "\n",
    "print(len(devset_synthetic), len(ft_optimizer_trainset), len(ft_optimizer_devset))\n",
    "print(devset_synthetic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPILE_PROGRAM = True\n",
    "\n",
    "dspy.settings.configure(experimental=True, lm=None)\n",
    "\n",
    "ft_results = {}\n",
    "for folder, llama in all_llamas.items():\n",
    "    ft_results[folder] = {}\n",
    "    vanilla_program = IntentClassificationModule()\n",
    "    with dspy.context(lm=llama):\n",
    "        devset_result = evaluate_devset(vanilla_program)\n",
    "        ft_results[folder][\"vanilla\"] = {\"devset\": devset_result, \"testset\": None}\n",
    "\n",
    "        if COMPILE_PROGRAM:\n",
    "            bfrs_finetuned_program = bfrs_optimizer.compile(vanilla_program, trainset=ft_optimizer_trainset, valset=ft_optimizer_devset)\n",
    "            bfrs_finetuned_program.save(f\"simpleintent_predict_1b_32_ft_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}_{folder.split('/')[-1]}.json\")\n",
    "        else:\n",
    "            bfrs_finetuned_program = IntentClassificationModule()\n",
    "            bfrs_finetuned_program.load(f\"simpleintent_predict_1b_32_ft_bfrs_{MAX_BOOTSTRAPPED_DEMOS}_{MAX_LABELED_DEMOS}_{NUM_CANDIDATE_PROGRAMS}_{folder.split('/')[-1]}.json\")\n",
    "        \n",
    "        llama_8b_bfrs_finetuned_eval = evaluate_devset(bfrs_finetuned_program)\n",
    "        ft_results[folder][\"bfrs\"] = {\"devset\": llama_8b_bfrs_finetuned_eval, \"true_labels\": None, \"testset\": None}\n",
    "        print(f\"result for {folder}: {llama_8b_bfrs_finetuned_eval}, None, None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_ft_results = json.load(open(\"ft_results.json\", \"r\"))\n",
    "combined_ft_results = {\"cot\": original_ft_results, \"no_cot\": ft_results}\n",
    "\n",
    "combined_ft_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data for plotting\n",
    "models = []\n",
    "vanilla_devset = []\n",
    "bfrs_devset = []\n",
    "vanilla_testset = []\n",
    "bfrs_testset = []\n",
    "\n",
    "for model, results in ft_results.items():\n",
    "    if model == \"base\":\n",
    "        models.append(\"base\")\n",
    "    else:\n",
    "        models.append(\"Epoch \" + model.split(':')[1].split('-')[1])  # Extract epoch information\n",
    "    vanilla_devset.append(results['vanilla']['devset'])\n",
    "    bfrs_devset.append(results['bfrs']['devset'])\n",
    "    vanilla_testset.append(results['vanilla']['testset'])\n",
    "    bfrs_testset.append(results['bfrs']['testset'])\n",
    "\n",
    "# Sort the data by epoch, keeping \"base\" at the beginning\n",
    "sorted_data = sorted(zip(models, vanilla_devset, bfrs_devset, vanilla_testset, bfrs_testset),\n",
    "                     key=lambda x: (x[0] != \"base\", x[0]))\n",
    "models, vanilla_devset, bfrs_devset, vanilla_testset, bfrs_testset = zip(*sorted_data)\n",
    "\n",
    "for i in range(len(models)):\n",
    "    print(models[i], \"vanilla_devset\", vanilla_devset[i], \"bfrs_devset\", bfrs_devset[i], \"vanilla_testset\", vanilla_testset[i], \"bfrs_testset\", bfrs_testset[i])\n",
    "\n",
    "# Set up the plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "# Adjust bar positions and width\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "# Plot bars for Dev Set (top graph)\n",
    "ax1.bar(x - width/2, vanilla_devset, width, label='Vanilla Dev', color='skyblue')\n",
    "ax1.bar(x + width/2, bfrs_devset, width, label='BFRS Dev', color='lightgreen')\n",
    "\n",
    "# Add value labels on top of each bar for Dev Set\n",
    "for i, v in enumerate(vanilla_devset):\n",
    "    ax1.text(i - width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "for i, v in enumerate(bfrs_devset):\n",
    "    ax1.text(i + width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Customize the Dev Set plot\n",
    "ax1.set_ylabel('Dev Set Scores')\n",
    "ax1.set_title('Model Performance Comparison Across Epochs (Dev Set)')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Find the highest devset score and its corresponding model\n",
    "highest_devset_score = max(bfrs_devset)\n",
    "highest_score_model = models[bfrs_devset.index(highest_devset_score)]\n",
    "\n",
    "print(highest_devset_score, highest_score_model, bfrs_devset[models.index(highest_score_model)])\n",
    "\n",
    "# Prepare data for the bottom graph\n",
    "# Prepare data for the bottom graph (Test Set)\n",
    "base_vanilla_testset = vanilla_testset[models.index(\"base\")]\n",
    "base_bfrs_testset = bfrs_testset[models.index(\"base\")]\n",
    "\n",
    "best_model_index = bfrs_devset.index(highest_devset_score)\n",
    "best_vanilla_testset = vanilla_testset[best_model_index]\n",
    "best_bfrs_testset = bfrs_testset[best_model_index]\n",
    "\n",
    "print(\"best_vanilla_testset\", best_vanilla_testset, \"best_bfrs_testset\", best_bfrs_testset)\n",
    "print(\"base_vanilla_testset\", base_vanilla_testset, \"base_bfrs_testset\", base_bfrs_testset)\n",
    "\n",
    "# Plot bars for Test Set (bottom graph)\n",
    "models_to_plot = [\"Base Model\", f\"Best Model ({highest_score_model})\"]\n",
    "x_test = np.arange(len(models_to_plot))\n",
    "\n",
    "ax2.bar(x_test - width/2, [base_vanilla_testset, best_vanilla_testset], width, label='Vanilla Test', color='coral')\n",
    "ax2.bar(x_test + width/2, [base_bfrs_testset, best_bfrs_testset], width, label='BFRS Test', color='lightseagreen')\n",
    "\n",
    "# Add value labels on top of each bar for Test Set\n",
    "for i, v in enumerate([base_vanilla_testset, best_vanilla_testset]):\n",
    "    ax2.text(i - width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "for i, v in enumerate([base_bfrs_testset, best_bfrs_testset]):\n",
    "    ax2.text(i + width/2, v, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Customize the Test Set plot\n",
    "ax2.set_ylabel('Test Set Scores')\n",
    "ax2.set_title('Model Performance Comparison (Test Set)')\n",
    "ax2.set_xticks(x_test)\n",
    "ax2.set_xticklabels(models_to_plot)\n",
    "ax2.legend()\n",
    "ax2.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # {'cot': {'meta-llama/Llama-3.2-1B-Instruct:epochs-2-total-trained-steps-69': {'vanilla': {'devset': 26.2,\n",
    "#     'testset': 28.4},\n",
    "#    'bfrs': {'devset': 32.4, 'true_labels': None, 'testset': 32.4}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-5-total-trained-steps-138': {'vanilla': {'devset': 28.8,\n",
    "#     'testset': 32.3},\n",
    "#    'bfrs': {'devset': 42.0, 'true_labels': None, 'testset': 43.1}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-4-total-trained-steps-115': {'vanilla': {'devset': 28.2,\n",
    "#     'testset': 32.5},\n",
    "#    'bfrs': {'devset': 37.2, 'true_labels': None, 'testset': 38.6}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-3-total-trained-steps-92': {'vanilla': {'devset': 30.2,\n",
    "#     'testset': 34.1},\n",
    "#    'bfrs': {'devset': 38.4, 'true_labels': None, 'testset': 37.5}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-1-total-trained-steps-46': {'vanilla': {'devset': 15.6,\n",
    "#     'testset': 14.6},\n",
    "#    'bfrs': {'devset': 27.6, 'true_labels': None, 'testset': 29.0}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-0-total-trained-steps-23': {'vanilla': {'devset': 22.6,\n",
    "#     'testset': 20.4},\n",
    "#    'bfrs': {'devset': 29.0, 'true_labels': None, 'testset': 32.1}},\n",
    "#   'base': {'vanilla': {'devset': 1.4, 'testset': 1.9},\n",
    "#    'bfrs': {'devset': 27.8, 'true_labels': None, 'testset': 28.9}}},\n",
    "#  'no_cot': {'meta-llama/Llama-3.2-1B-Instruct:epochs-0-total-trained-steps-29': {'vanilla': {'devset': 21.4,\n",
    "#     'testset': 22.2},\n",
    "#    'bfrs': {'devset': 34.8, 'true_labels': None, 'testset': 37.9}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-5-total-trained-steps-174': {'vanilla': {'devset': 43.8,\n",
    "#     'testset': 45.1},\n",
    "#    'bfrs': {'devset': 43.8, 'true_labels': None, 'testset': 45.1}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-1-total-trained-steps-58': {'vanilla': {'devset': 14.6,\n",
    "#     'testset': 16.3},\n",
    "#    'bfrs': {'devset': 34.4, 'true_labels': None, 'testset': 36.2}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-2-total-trained-steps-87': {'vanilla': {'devset': 37.8,\n",
    "#     'testset': 41.8},\n",
    "#    'bfrs': {'devset': 37.8, 'true_labels': None, 'testset': 41.8}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-4-total-trained-steps-145': {'vanilla': {'devset': 45.0,\n",
    "#     'testset': 46.3},\n",
    "#    'bfrs': {'devset': 45.0, 'true_labels': None, 'testset': 46.3}},\n",
    "#   'meta-llama/Llama-3.2-1B-Instruct:epochs-3-total-trained-steps-116': {'vanilla': {'devset': 45.2,\n",
    "#     'testset': 45.9},\n",
    "#    'bfrs': {'devset': 45.2, 'true_labels': None, 'testset': 45.9}},\n",
    "#   'base': {'vanilla': {'devset': 9.4, 'testset': 8.6},\n",
    "#    'bfrs': {'devset': 36.4, 'true_labels': None, 'testset': 38.8}}}}\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def extract_data(results, key):\n",
    "    return {\n",
    "        model: {\n",
    "            'vanilla': data['vanilla'][key],\n",
    "            'bfrs': data['bfrs'][key]\n",
    "        }\n",
    "        for model, data in results.items()\n",
    "    }\n",
    "\n",
    "cot_devset = extract_data(combined_ft_results['cot'], 'devset')\n",
    "no_cot_devset = extract_data(combined_ft_results['no_cot'], 'devset')\n",
    "print(no_cot_devset)\n",
    "\n",
    "# Prepare data for plotting\n",
    "models = list(cot_devset.keys())\n",
    "x = np.arange(len(models))\n",
    "width = 0.2\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 20))\n",
    "\n",
    "# Top graph\n",
    "ax1.bar(x - 1.5*width, [cot_devset[m]['vanilla'] for m in models], width, label='CoT Vanilla')\n",
    "ax1.bar(x - 0.5*width, [cot_devset[m]['bfrs'] for m in models], width, label='CoT BFRS')\n",
    "ax1.bar(x + 0.5*width, [no_cot_devset[m]['vanilla'] for m in models], width, label='No CoT Vanilla')\n",
    "ax1.bar(x + 1.5*width, [no_cot_devset[m]['bfrs'] for m in models], width, label='No CoT BFRS')\n",
    "\n",
    "ax1.set_ylabel('Devset Score')\n",
    "ax1.set_title('CoT vs No CoT: Vanilla and BFRS on Devset')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(models, rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "\n",
    "# Find best models\n",
    "best_cot = max(cot_devset.items(), key=lambda x: x[1]['bfrs'])[0]\n",
    "best_no_cot = max(no_cot_devset.items(), key=lambda x: x[1]['bfrs'])[0]\n",
    "\n",
    "# Bottom graph\n",
    "models = ['Best CoT', 'Best No CoT']\n",
    "x = np.arange(len(models))\n",
    "\n",
    "cot_data = ft_results['cot'][best_cot]\n",
    "no_cot_data = ft_results['no_cot'][best_no_cot]\n",
    "\n",
    "ax2.bar(x - 1.5*width, [cot_data['vanilla']['devset'], no_cot_data['vanilla']['devset']], width, label='Vanilla Devset')\n",
    "ax2.bar(x - 0.5*width, [cot_data['bfrs']['devset'], no_cot_data['bfrs']['devset']], width, label='BFRS Devset')\n",
    "ax2.bar(x + 0.5*width, [cot_data['vanilla']['testset'], no_cot_data['vanilla']['testset']], width, label='Vanilla Testset')\n",
    "ax2.bar(x + 1.5*width, [cot_data['bfrs']['testset'], no_cot_data['bfrs']['testset']], width, label='BFRS Testset')\n",
    "\n",
    "ax2.set_ylabel('Score')\n",
    "ax2.set_title('Best CoT vs Best No CoT: Devset and Testset Results')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(models)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
