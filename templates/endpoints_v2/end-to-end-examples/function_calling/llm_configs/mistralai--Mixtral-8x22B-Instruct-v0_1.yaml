runtime_env:
  env_vars:
    HUGGING_FACE_HUB_TOKEN: insert_your_hf_token_here

model_loading_config:
  model_id: mistralai/Mixtral-8x22B-Instruct-v0.1
  model_source: mistralai/Mixtral-8x22B-Instruct-v0.1

generation:
  prompt_format:
    add_system_tags_even_if_message_is_empty: false
    assistant: '{tool_calls}{instruction} </s> '
    bos: '<s> '
    default_system_message: Always assist with care, respect, and truth. Respond
      with utmost utility yet securely. Avoid harmful, unethical, prejudiced, or
      negative content. Ensure replies promote fairness and positivity.
    strip_whitespace: true
    system: "{instruction}\n\n "
    system_in_last_user: true
    system_in_user: true
    tool: '[TOOL_RESULTS] {instruction} [/TOOL_RESULTS]'
    tool_calls: ' [TOOL_CALLS] {instruction}'
    tools_list: '[AVAILABLE_TOOLS] {instruction} [/AVAILABLE_TOOLS] '
    tools_list_in_last_user: true
    tools_list_in_user: true
    trailing_assistant: ''
    user: '{tools_list}[INST] {system}{instruction} [/INST]'
  stopping_sequences: []

input_modality: text

llm_engine: VLLMEngine
engine_kwargs:
  max_num_batched_tokens: null
  max_num_seqs: 192
  tokenizer_pool_extra_config:
    runtime_env:
      pip: null
  tokenizer_pool_size: 2
  trust_remote_code: true

max_request_context_length: 65536

accelerator_type: H100
tensor_parallelism:
  degree: 8

deployment_config:
  autoscaling_config:
    target_ongoing_requests: 96
  max_ongoing_requests: 192

json_mode:
  enabled: false

lora_config: null
