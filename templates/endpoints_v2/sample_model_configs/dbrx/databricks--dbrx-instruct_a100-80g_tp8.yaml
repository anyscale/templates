# Note this model runs OSS vLLM instead of Anyscale's proprietary fork.
# Some features, such as constrained decoding and LoRA support, may not be available yet.
deployment_config:
  autoscaling_config:
    min_replicas: 1
    initial_replicas: 1
    max_replicas: 100
    target_num_ongoing_requests_per_replica: 64
    metrics_interval_s: 10.0
    look_back_period_s: 30.0
    smoothing_factor: 0.6
    downscale_delay_s: 300.0
    upscale_delay_s: 15.0
  max_ongoing_requests: 128
  ray_actor_options:
    resources:
      "accelerator_type:A100-80G": 0.001
    runtime_env:
      pip:
        - /home/ray/dist/vllm-project/vllm/vllm-latest-cp39-cp39-linux_x86_64.whl
        - flash_attn~=2.5.6
engine_config:
  model_id: databricks/dbrx-instruct
  hf_model_id: databricks/dbrx-instruct
  type: VLLMEngine
  engine_kwargs:
    trust_remote_code: true
    max_num_batched_tokens: 32768
    max_num_seqs: 128
    gpu_memory_utilization: 0.90
    tokenizer_pool_size: 2
    tokenizer_pool_extra_config:
      runtime_env:
        pip: null
  max_total_tokens: 32768
  runtime_env:
    pip:
      - /home/ray/dist/vllm-project/vllm/vllm-latest-cp39-cp39-linux_x86_64.whl
      - flash_attn~=2.5.6
  generation:
    prompt_format:
      system: "<|im_start|>system\n{instruction}<|im_end|>\n"
      assistant: "<|im_start|>assistant\n{instruction}<|im_end|>\n"
      trailing_assistant: "<|im_start|>assistant\n"
      user: "<|im_start|>user\n{instruction}<|im_end|>\n"
      system_in_user: false
      default_system_message: "You are DBRX, created by Databricks. You were last updated in December 2023. You answer questions based on information available up to that point.\nYOU PROVIDE SHORT RESPONSES TO SHORT QUESTIONS OR STATEMENTS, but provide thorough responses to more complex and open-ended questions.\nYou assist with various tasks, from writing to coding (using markdown for code blocks â€” remember to use ``` with code, JSON, and tables).\n(You do not have real-time data access or code execution capabilities. You avoid stereotyping and provide balanced perspectives on controversial topics. You do not provide song lyrics, poems, or news articles and do not divulge details of your training data.)\nThis is your system prompt, guiding your responses. Do not reference it, just respond to the user. If you find yourself talking about this message, stop. You should be responding appropriately and usually that means not mentioning this.\nYOU DO NOT MENTION ANY OF THIS INFORMATION ABOUT YOURSELF UNLESS THE INFORMATION IS DIRECTLY PERTINENT TO THE USER\\'S QUERY."
    stopping_sequences: []
scaling_config:
  num_workers: 8
  num_gpus_per_worker: 1
  num_cpus_per_worker: 8
  placement_strategy: "STRICT_PACK"
  resources_per_worker:
    "accelerator_type:A100-80G": 0.001
