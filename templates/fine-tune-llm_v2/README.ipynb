{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Llama-3, Mistral and Mixtral with Anyscale\n",
    "\n",
    "**⏱️ Time to complete**: 2.5 hours for 7/8B models (9 hours for 13B, 25 hours for 70B)\n",
    "\n",
    "The guide below walks you through the steps required for fine-tuning of LLMs. This template provides an easy to configure solution for ML Platform teams, Infrastructure engineers, and Developers to fine-tune LLMs.\n",
    "\n",
    "### Popular base models to fine-tune\n",
    "\n",
    "- meta-llama/Meta-Llama-3-8B-Instruct (Full-param and LoRA)\n",
    "- meta-llama/Meta-Llama-3-70B-Instruct (Full-param and LoRA)\n",
    "- mistralai/Mistral-7B-Instruct-v0.1 (Full-param and LoRA)\n",
    "- mistralai/Mixtral-8x7b (LoRA only)\n",
    "\n",
    "A full list of supported models is in the [FAQ](#faqs) section. In the end we provide more guides in form of [cookbooks](#cookbooks) and [end-to-end examples](#end-to-end-examples) that provide more detailed information about using this template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Launch a fine-tuning job\n",
    "\n",
    "We provide example configurations under the `./training_configs` directory for different base models and accelerator types. You can use these as a starting point for your own fine-tuning jobs. The full-list of public configurations that are customizable see [Anyscale docs](https://docs.anyscale.com/reference/finetuning-config-api).\n",
    "\n",
    "**Optional**: You can get a WandB API key from [WandB](https://wandb.ai/authorize) to track the fine-tuning process. If not provided, you can only track the experiments through the standard output logs.\n",
    "\n",
    "Next, you can launch a fine-tuning job with your WandB API key passed as an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Optional] You can set the WandB API key to track model performance\n",
    "# !export WANDB_API_KEY={YOUR_WANDB_API_KEY}\n",
    "\n",
    "# Launch a LoRA fine-tuning job for Llama 3 8B with 16 A10s\n",
    "!python main.py training_configs/lora/llama-3-8b.yaml\n",
    "\n",
    "# Launch a full-param fine-tuning job for Llama 3 8B with 16 A10s\n",
    "# !python main.py training_configs/full_param/llama-3-8b.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the command runs, you can monitor a number of built-in metrics in the `Metrics` tab under `Ray Dashboard`, such as the number of GPU nodes and GPU utilization.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/anyscale/templates/main/templates/fine-tune-llm_v2/assets/gpu-usage.png\" width=500px/>\n",
    "\n",
    "Depending on whether you are running LoRA or full-param fine-tuning, you can continue with step 2(a) or step 2(b). To learn more about LoRA vs. full-parameter, see the cookbooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Step 2(a) - Serving the LoRA fine-tuned model\n",
    "\n",
    "Upon the job completion, you can see the LoRA weight storage location and model ID in the log, such as the one below:\n",
    "\n",
    "```shell\n",
    "Note: LoRA weights will also be stored in path {ANYSCALE_ARTIFACT_STORAGE}/lora_fine_tuning under meta-llama/Llama-2-8b-chat-hf:sql:12345 bucket.\n",
    "```\n",
    "\n",
    "You can specify this URI as the dynamic_lora_loading_path [docs](https://docs.anyscale.com/examples/deploy-llms#more-guides) in the llm serving template, and then query the endpoint.\n",
    "\n",
    "> Note: Such LoRA model IDs follow the format `{base_model_id}:{suffix}:{id}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 2(b) - Serving the full-parameter fine-tuned model\n",
    "\n",
    "Once the fine-tuning job is complete, you can view the stored full-parameter fine-tuned checkpoint at the very end of the job logs. Here is an example fine-tuning job output:\n",
    "\n",
    "```shell\n",
    "Best checkpoint is stored in:\n",
    "{ANYSCALE_ARTIFACT_STORAGE}/username/llmforge-finetuning/meta-llama/Llama-2-70b-hf/TorchTrainer_2024-01-25_18-07-48/TorchTrainer_b3de9_00000_0_2024-01-25_18-07-48/checkpoint_000000\n",
    "```\n",
    "\n",
    "Follow the [Learn how to bring your own models](https://docs.anyscale.com/examples/deploy-llms#more-guides) section under the llm serving template to serve this fine-tuned model with the specified storage uri."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cookbooks\n",
    "\n",
    "After you are with the above, you can find recipies that extend the functionality of this template under the cookbooks folder:\n",
    "\n",
    "* [Optimizing Cost and Performance for Finetuning](cookbooks/optimize_cost/README.md)\n",
    "* [Continue fine-tuning from a previous checkpoint](cookbooks/continue_from_checkpoint/README.md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end Examples\n",
    "\n",
    "Here is a list of end-to-end examples that involve more steps such as data preprocessing, evaluation, etc but with a main focus on improving model quality via fine-tuning.\n",
    "\n",
    "* [Fine-tuning for Function calling on custom data](end-to-end-examples/fine-tune-function-calling/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## FAQs\n",
    "\n",
    "### Where can I view the bucket where my LoRA weights are stored?\n",
    "\n",
    "All the LoRA weights are stored under the URI `${ANYSCALE_ARTIFACT_STORAGE}/lora_fine_tuning` where `ANYSCALE_ARTIFACT_STORAGE` is an environmental variable in your workspace.\n",
    "\n",
    "### How can I fine-tune using my own data?\n",
    "\n",
    "The training configs provided in this template all train on the [GSM8k dataset](https://huggingface.co/datasets/gsm8k) which requires a context length of 512 tokens. How to ensure the correct format for your own dataset is described in https://docs.endpoints.anyscale.com/fine-tuning/dataset-prep.\n",
    "\n",
    "Open the file under `training_configs` and update `train_path` and `valid_path` to your training- and evaluation file.\n",
    "\n",
    "### How do I customize the fine-tuning job?\n",
    "\n",
    "You can edit the values, such as `context_length`, `num_epoch`, `train_batch_size_per_device` and `eval_batch_size_per_device` to customize the fine-tuning job. You may be able to reach higher model-quality if you tweak the learning rate but also possibly introduce learning instabilities that can be monitored in [WandB](https://wandb.ai/authorize). In addition, the deepspeed configs are provided within this template in case you want to customize them.\n",
    "\n",
    "### What's the full list of supported models?\n",
    "\n",
    "This is a growing list but it includes the following models:\n",
    "\n",
    "- mistralai/Mistral-7B-Instruct-v0.1\n",
    "- mistralai/Mixtral-8x7b\n",
    "- meta-llama/Llama-2-7b-chat-hf\n",
    "- meta-llama/Llama-2-13b-hf\n",
    "- meta-llama/Llama-2-13b-chat-hf\n",
    "- meta-llama/Llama-2-70b-hf\n",
    "- meta-llama/Llama-2-70b-chat-hf\n",
    "- meta-llama/Meta-Llama-3-8B\n",
    "- meta-llama/Meta-Llama-3-8B-Instruct\n",
    "- meta-llama/Meta-Llama-3-70B\n",
    "- meta-llama/Meta-Llama-3-70B-Instruct\n",
    "\n",
    "In general, any model that is compatible with the architecture of these models can be fine-tuned using the same configs as the base models.\n",
    "\n",
    "NOTE: currently mixture of expert models (such as `mistralai/Mixtral-8x7B)` only support LoRA fine-tuning\n",
    "\n",
    "### Should I use LoRA or full-parameter fine-tuning?\n",
    "\n",
    "There is no general answer to this but here are some things to consider:\n",
    "\n",
    "- The quality of the fine-tuned models will, in most cases, be comparable if not the same\n",
    "- LoRA shines if...\n",
    "    - ... you want to serve many fine-tuned models at once yourself\n",
    "    - ... you want to rapidly experiment (because fine-tuning, downloading and serving the model take less time)\n",
    "- Full-parameter shines if...\n",
    "    - ... you want to make sure that your fine-tuned model has the maximum quality\n",
    "    - ... you want to serve only one fine-tuned version of the model\n",
    "\n",
    "You can learn more about this in one of our [blogposts](https://www.anyscale.com/blog/fine-tuning-llms-lora-or-full-parameter-an-in-depth-analysis-with-llama-2).\n",
    "There, you'll also find some guidance on the LoRA parameters and why, in most cases, you don't need to change them.\n",
    "\n",
    "### How can I get even more control?\n",
    "\n",
    "This template fine-tunes with Anyscale's library `llmforge`, which uses [DeepSpeed](https://github.com/microsoft/DeepSpeed) and [Ray Train](https://docs.ray.io/en/latest/train/train.html) for distributed training.\n",
    "You can study main.py to find out how we call the `lmforge dev finetune` API with a YAML that specifies the fine-tuning workload.\n",
    "You can call `lmforge dev finetune` yourself and gain control by modifying the training config YAMLs in this template.\n",
    "For anything that goes beyond using `llmforge`, you can build your own fine-tuning stack on Anyscale.\n",
    "\n",
    "### What's with the `main` file that is created during fine-tuning?\n",
    "\n",
    "It's an artifact of our fine-tuning libraries. Please ignore it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
