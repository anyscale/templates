{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preference Tuning for Summarization using Synthetic Data\n",
    "\n",
    "**⏱️ Time to complete**: 10 hours\n",
    "\n",
    "Preference tuning is a powerful tool that can optimize LLMs towards complex preferences that cannot easily captured through supervised fine-tuning. However, manually annotating preferences between model outputs using human raters can be extremely time-consuming and expensive. Instead, synthetic preference data can be generated by scoring responses with large foundation models, allowing for much cheaper and scalable data collection!\n",
    "\n",
    "Here we'll go through an end-to-end example for preference tuning of an open-source language model with synthetic data, covering scalable methodologies for data preprocessing, fine-tuning and evaluation, using Ray. We will focus on the task of summarization for the [CNN/DailyMail](https://huggingface.co/datasets/abisee/cnn_dailymail) dataset. \n",
    "\n",
    "This notebook is based on the following blog post: `TODO`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Data Preprocessing](#step-1-data-preprocessing): In this section we cover how we can prepare preference data for the summarization task using an LLM-as-a-judge. \n",
    "    1. [Generate Multiple Choice Questions From Articles](#part-a-generate-multiple-choice-questions-from-articles)\n",
    "    2. [Generate Summaries and Scores](#part-b-generate-summaries--scores)\n",
    "    3. [Generate Preference Tuning Data](#part-c-generate-preference-tuning-data)\n",
    "2. [DPO Finetuning](#step-2-fine-tuning): This section will cover how you can fine-tune an open source model on the preference data on the Anyscale platform.\n",
    "3. [Evaluation](#step-3-evaluation): The section will lay down a blue-print for evaluation and compare performance to that of closed source models like OpenAI's GPT-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make the necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import textwrap\n",
    "\n",
    "import ray.data\n",
    "import datasets\n",
    "\n",
    "\n",
    "from src.utils.models import DataSchema\n",
    "from src.utils.common import print_wrapped\n",
    "\n",
    "os.environ[\"PYTHONPATH\"] = f\"{os.environ.get('PYTHONPATH', '')}:src\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Synthetic Data Generation\n",
    "\n",
    "First, let's inspect the training dataset and look at an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "955eaa1f532d4fbab0735f23e5ea4d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517bcbe80be04dafaa40ef31bc2e2402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f2d77647d84a3aa818edfa9fdcf1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7803687c10394e589ca26b85ba965033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/259M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34047e03dece4ba193c8812544298dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/34.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d727e02ae92b4e2ab8e50b9db6eab9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/30.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafb587991e74ecb9b837e0286657945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a801bc924754d7ebbcddceb077143f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f116e109da4e4385abe286184a9103d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a024bdf686fb49a9b5cef149f9082bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4fbcd84689409681400b7221c63ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90eeb81038849b5a6fecca4b5f1889c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f88755f289c4927a360f976fe1ab683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/259M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d834887426423e811d59ed7bc7da9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/34.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c2b889152343799efbf5f49c1ade51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/30.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7924c113e34f0e91e2cc7192cf94e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4012d179c3e54d1daef14b0de46c9829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c2f8f7e5c9d4007a68b5917994b7532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 12:04:56,395\tINFO worker.py:1603 -- Connecting to existing Ray cluster at address: 10.0.21.126:6379...\n",
      "2024-08-16 12:04:56,400\tINFO worker.py:1779 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-ujamras9pcvamresjwww6p5jr4.i.anyscaleuserdata.com \u001b[39m\u001b[22m\n",
      "2024-08-16 12:04:56,404\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_d3e147f0bc0554b452c97a1fb7d4cbbb46505ca5.zip' (1.13MiB) to Ray cluster...\n",
      "2024-08-16 12:04:56,407\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_d3e147f0bc0554b452c97a1fb7d4cbbb46505ca5.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(autoscaler +30s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
      "\u001b[36m(autoscaler +30s)\u001b[0m [autoscaler] [48CPU-192GB] Upscaling 1 node(s).\n",
      "\u001b[36m(autoscaler +32s)\u001b[0m [autoscaler] [48CPU-192GB|m5.12xlarge] [us-east-1a] [on-demand] Launched 1 instances.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 12:05:55,375\tINFO dataset.py:2373 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
      "2024-08-16 12:05:55,379\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-16_11-08-34_539321_2359/logs/ray-data\n",
      "2024-08-16 12:05:55,379\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5220b5f3fe4a11ab2dc31aead147ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 1:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b4b13c879c4cd482a854a7e3de1acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_ds = datasets.load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\", split=\"train\").shuffle(\n",
    "    seed=21\n",
    ")\n",
    "# extract a subset of 20000 articles\n",
    "hf_ds_subset = hf_ds.select(range(20000))\n",
    "\n",
    "ray_ds = ray.data.from_huggingface(hf_ds_subset)\n",
    "raw_example = ray_ds.take(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article': 'Scam: Lisa Harrison, 34, promised customers low currency rates on '\n",
      "            'US dollars and special deals . A wedding planner who stole '\n",
      "            \"£80,000 from couples in a bid to satisfy an 'out-of-control' \"\n",
      "            'online gambling addiction has been jailed. Lisa Harrison, 34, '\n",
      "            'began taking money from her clients in summer 2013 by enticing '\n",
      "            'them with low currency rates on US dollars and flight upgrades. '\n",
      "            'She took money from 19 couples who had entrusted their savings to '\n",
      "            'her after being promised the wedding of their dreams. It is '\n",
      "            'understood that the company she worked for, iPlan New York, '\n",
      "            'specialised in weddings in New York City. Her website '\n",
      "            \"iplannewyork.com, which has been taken down, said: 'iPlan New \"\n",
      "            'York was set up to create and style the perfect tailor made '\n",
      "            \"wedding for couples travelling to New York to get married! 'We \"\n",
      "            'are passionate about what we do and passionate about New York! We '\n",
      "            'have experience in planning NYC weddings for couples from all '\n",
      "            \"over the world.' But she was arrested in December last year after \"\n",
      "            'eventually coming clean to her victims in an email and saying she '\n",
      "            'had been forced to close her business. Police soon found she had '\n",
      "            'taken £80,107 from the couples and spent a staggering £77,933 on '\n",
      "            \"gambling sites Paddy Power and William Hill. The business' \"\n",
      "            'Facebook page has also been deleted, but outraged victims have '\n",
      "            'shared their victims on a wedding forum. One victim called '\n",
      "            \"Jennifer wrote in November 2013: 'I had previously given Lisa a \"\n",
      "            \"positive review because our vow renewal went wonderful. 'Little \"\n",
      "            \"did I know until last week that she didn't even pay the vendors \"\n",
      "            \"that helped with our ceremony. 'I am so disgusted and can't \"\n",
      "            'fathom such an act. We paid her in full and to think that our '\n",
      "            \"photographer didn't even get paid is just astonishing to me. 'I \"\n",
      "            'feel so horrible for the other couples that had their perfect day '\n",
      "            \"planned and this woman decided to perform such an act. 'I pray \"\n",
      "            'for each of you in hopes that you will be able to move on from '\n",
      "            'this and live a healthy and happy life with your significant '\n",
      "            \"other. 'I can't believe this woman took our money and did such an \"\n",
      "            'unthinkable act. God bless all of you and I hope this mess gets '\n",
      "            \"corrected quickly.' While another anonymous victim posted a copy \"\n",
      "            'of the email they claim they had been sent by Harrison when she '\n",
      "            \"admitted the scam. It read: 'I have to announce the closure of \"\n",
      "            \"iPlan New York. 'For some time now I have been battling against a \"\n",
      "            'gambling addiction that has seen me lose all of the company money '\n",
      "            \"including money paid to me by you for services and dollars. 'I \"\n",
      "            'cannot go on another day with this situation as this illness has '\n",
      "            'taken me over completely and I have to both face up to the '\n",
      "            'consequences of my actions and seek help for the debilitating '\n",
      "            \"addiction. 'I am extremely ill with it and need to seek help as \"\n",
      "            \"soon as possible. 'I am completely devastated that not only have \"\n",
      "            'I lost money of yours but betrayed your trust as a wedding '\n",
      "            \"planner. 'Right now I am uncertain as to what the future holds \"\n",
      "            'with regards to future weddings already planned, I will be in '\n",
      "            'touch with the suppliers in NYC to inform them also. Sentence: '\n",
      "            'Harrison, of Earith, Cambridgeshire, was jailed for two years at '\n",
      "            \"Peterborough Crown Court, above . 'I will today be having my \"\n",
      "            'computer and all electronic devices ceased (sic) under an '\n",
      "            'intervention and handing myself into the police to give a '\n",
      "            \"statement and to tell them everything. 'No doubt you will be \"\n",
      "            'informing the police too and for those purposes it will be the '\n",
      "            'Cambridgeshire Constabulary and my full name is Lisa Harrison and '\n",
      "            \"I will be handing myself in after sending these emails. 'I won’t \"\n",
      "            'be able to reply to any emails or calls for the time being as I '\n",
      "            \"will not have access. 'I am truly from the bottom of my heart so \"\n",
      "            'sorry for everything, as with addictions I thought I had '\n",
      "            'everything under control and was in denial that I could put '\n",
      "            'everything right, which I have been trying so desperately to do. '\n",
      "            \"'As soon as and if I am able to communicate further about any \"\n",
      "            \"outstanding issues I will do so. Lisa.' Posting on an online \"\n",
      "            'review site for the wedding service, one former customer said: '\n",
      "            \"'We are due to go in less than 48 hours and we have nothing!! She \"\n",
      "            \"has now closed down her website too! She has left us devastated!' \"\n",
      "            \"Another, using the name Shaun, wrote: 'Alarm bells rang for me \"\n",
      "            'when she asked for all our spending money cos she had a deal on a '\n",
      "            \"currency card. While one woman, using the name Andrea, said: 'I \"\n",
      "            'am absolutely devastated for anyone who has used iPlan New York '\n",
      "            \"and subsequently been let down'. She added that she had a 'gut \"\n",
      "            \"feeling' not to pay upfront. Harrison, of Earith, Cambridgeshire, \"\n",
      "            'admitted fraudulent trading and was jailed for two years at '\n",
      "            'Peterborough Crown Court on Tuesday. Det Sgt Iain Moor, from '\n",
      "            \"Cambridgeshire Constabulary, said: 'This was an extremely \"\n",
      "            'distressing case for the 19 couples who lost life savings and had '\n",
      "            \"their dream day ruined by Harrison. 'I hope the victims received \"\n",
      "            'some comfort in the prison sentence imposed on Harrison, meaning '\n",
      "            \"they can now start to re-build their lives.'\",\n",
      " 'highlights': 'Lisa Harrison enticed clients with low currency rates and '\n",
      "               'flight upgrades .\\n'\n",
      "               'She took money from 19 couples who were promised dream '\n",
      "               'weddings .\\n'\n",
      "               'Harrison spent nearly £78,000 on gambling sites including '\n",
      "               'Paddy Power .\\n'\n",
      "               'She admitted the scam to victims in an email before handing '\n",
      "               'herself in .\\n'\n",
      "               \"Outraged victims say they are 'disgusted' and have been left \"\n",
      "               \"'devastated'\\n\"\n",
      "               \"In email Harrison says she will 'seek help for the \"\n",
      "               \"debilitating addiction'\\n\"\n",
      "               'She admitted fraudulent trading and was jailed for two years '\n",
      "               'on Tuesday .',\n",
      " 'id': '4feb82c680166f0b8f90bf3a6f9779b04f229325'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(raw_example, width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to get preference data for pairs of summaries generated from the same article. Traditionally, this would involve generating summaries using the base model you wish to fine-tune and asking human annotators to provide a rating for each sample. In this example, we will employ a _synthetic_ summary scoring method using an LLM as a judge. We score the correctness of a summary using the following metrics:\n",
    "\n",
    "**Summary Scoring Metrics**\n",
    "1. Multiple choice Q&A accuracy:\n",
    "    - Given the original text, we use an LLM judge to generate 5 multiple choice questions about the text.\n",
    "    - We then ask the LLM judge to answer the questions using only the summary, and record the number of questions correctly answered.\n",
    "2. Word count: We simply count the number of words in the summary.\n",
    "\n",
    "This allows us to construct a simple preference function between two summaries:\n",
    "\n",
    "**Preference Function**\n",
    "1. If both summary responses attain more than 3/5 multiple choice questions correct, we will prefer the shorter response. We do not care about Q&A accuracy beyond 3 correct answers, since the summary should not contain all information from the text.\n",
    "2. Otherwise, we select the response that leads to more correctly answered multiple choice questions.\n",
    "\n",
    "To generate the preference pairs, we will generate 10 summaries from each article using the model we wish to fine-tune. Then, we will randomly sample pairs of summaries and use our preference function to annotate the preference between them.\n",
    "\n",
    "For this example, we will use `Mistral-7B-Instruct-v0.1` as the base model to fine-tune and `Llama-3.1-70B-Instruct` as a judge. Note that mistral-instruct is already instruction tuned, so that given a prompt to do summarization it might do a good job, but it may not be aligned with how we want the summarization to look like. We can use preference data to further align the instruct variant towards our specific needs.\n",
    "\n",
    "Combining all this together, our data pre-processing pipeline is going to look as follows: \n",
    "\n",
    "![preprocessing](./assets/preprocessing.png?1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a): Generate Multiple Choice Questions from Articles\n",
    "\n",
    "First, we will generate the multiple choice questions and answers for each article using `Llama-3.1-8B-Instruct` (or `70B` if you have A100/H100s). Leveraging vLLM and Ray, we can very easily scale this generation process across multiple GPUs.\n",
    "\n",
    "\n",
    ">  **_NOTE:_**  We provide two sets of configs: One with a 8B parameter model as the judge, and another with the 70B model. Using the 8B model is recommended for quicker runtimes, since we make use of highly available A10Gs. For good performance, and to replicate the results in our blog, you should use the 70B judge model which uses A100s. \n",
    "\n",
    "The following command will run the [src/scripts/generate_questions.py](./src/scripts/generate_questions.py) script, which generates the questions and answers and saves them in `.parquet` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mOutput\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +1.4s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mSubmitting job with config JobConfig(name='preference-tuning-summarization-question-generation', image_uri='localhost:5555/anyscale/endpoints_aica:0.5.0-6402', compute_config=None, env_vars=None, py_modules=None, cloud=None, project=None, ray_version=None, job_queue_config=None).\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +3.6s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mUsing workspace runtime dependencies env vars: {'WANDB_API_KEY': 'cbc4aed2de2d9c9acb21324a3297b85b7299479b'}.\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +3.6s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mUploading local dir '.' to cloud storage.\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +5.0s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mIncluding workspace-managed pip dependencies.\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +5.6s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mJob 'preference-tuning-summarization-question-generation' submitted, ID: 'prodjob_sdaruzx8uu3c2bu3x5dn6gpf77'.\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +5.6s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mView the job in the UI: https://console.anyscale.com/jobs/prodjob_sdaruzx8uu3c2bu3x5dn6gpf77\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +5.6s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mUse `--wait` to wait for the job to run and stream logs.\u001b[0m\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!anyscale job submit -f configs/jobs/8b_judge/generate_questions_job.yaml\n",
    "# Optional: use the 70b model for better performance (runs on A100s)\n",
    "# !anyscale job submit -f configs/jobs/70b_judge/generate_questions_job.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the job, you should see the remote path to the folder with Q&A in the logs.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./assets/question_generation_done.png?\" alt=\"Evaluation\" width=800>\n",
    "</p>\n",
    "\n",
    " Make sure to make note to use it for the next steps! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the link to the output folder from the previous job\n",
    "qa_folder = \"s3://air-example-data/preference-tuning-summarization-example/qa_generation/qa_annotations_full_train/\"\n",
    "qa_ds = ray.data.read_parquet(qa_folder)\n",
    "# The dataset is small, we can materalize it\n",
    "example_rows = qa_ds.materialize().take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT:\n",
      "Built behind three sets of double gates, it boasts 12 bedrooms, 23 bathrooms and\n",
      "a 27-car garage. This 25-acre estate in Beverly Hills, Los Angeles, has  been\n",
      "put on the market for $195million - making it the most expensive property for\n",
      "sale in America. Dubbed 'Palazzo di Amore' (or 'Palace of Love'), the sprawling\n",
      "villa is accessible via a quarter-mile-long drive through a tree-lined path and\n",
      "a vineyard. It features more than 35,000 square feet of living space, including\n",
      "a two-story entrance hall with two sweeping staircases and a detached\n",
      "guesthouse. Scroll down for video . Sprawling: This villa in Beverly Hills, Los\n",
      "Angeles, boasts 12 bedrooms, 23 bathrooms and a 27-car garage. Above, the\n",
      "property features more than 35,000 square feet of living space, including a two-\n",
      "story entrance hall with a chandelier and two sweeping staircases . Production:\n",
      "The mansion has its own vineyard, which creates 400 to 500 cases of wine a year\n",
      "under the label, Beverly Hills Vineyards. Above, the property's 13,000-bottle\n",
      "wine cellar, featuring bottles of syrah, cabernet and sauvignon blanc, alongside\n",
      "other wines . Spacious: It also includes a 15,000-square-foot entertainment\n",
      "complex, complete with a disco/ballroom, a revolving dance floor, a DJ booth and\n",
      "a laser-light system. Inside the complex, as many as 250 guests can make use of\n",
      "a 50-seat theater and a bowling alley . Stunning: The mansion can host up to\n",
      "1,000 people. Guests are greeted by an Italian-made fountain carved of Carrara\n",
      "marble (pictured) Wealthy businessmen: The property is being sold by real estate\n",
      "entrepreneur and billionaire Jeff Greene (left). Right, developer Mohamed Hadid\n",
      "(pictured) worked on the mansion with the aid of architect Bob Ray Offenhauser\n",
      "and designer Alberto Pint . It also includes a 15,000-square-foot entertainment\n",
      "complex, complete with a disco/ballroom, a revolving dance floor, a DJ booth and\n",
      "a laser-light system. The mansion is being sold by real estate entrepreneur Jeff\n",
      "Greene, who owns properties in Florida, New York and California, the LA\n",
      "Times reported. Mr Greene, 59, who refers to the Mediterranean-style California\n",
      "property as 'a palace for the modern era', bought it in 2007 for $35million. He\n",
      "then spent eight years and $25million expanding the residence to its current\n",
      "size. Now, its master suite alone sits at a whopping 5,000 square feet. The\n",
      "villa was developed by Mohamed Hadid, who specializes in large estates, with the\n",
      "aid of architect Bob Ray Offenhauser and designer Alberto Pint. Mr Hadid was\n",
      "married to The Real Housewives of Beverly Hills star Yolanda Foster, 50,  from\n",
      "1994 until 2000. The couple have three children together. Well-furnished: Mr\n",
      "Greene, 59, who refers to the Mediterranean-style California property as 'a\n",
      "palace for the modern era', bought it in 2007 for $35million. He then spent\n",
      "eight years and $25million expanding the residence to its current size. Above, a\n",
      "sitting room . Beautiful: Outside the mansion, residents can swim in a 128-foot\n",
      "reflecting pool, relax in a Turkish-style spa and walk through gardens .\n",
      "Breathtaking scenery: The huge villa boasts spectacular views (pictured) of the\n",
      "West Side of Los Angeles, Century City and the sea . Inside the entertainment\n",
      "complex, up to 250 guests can make use of a 50-seat theater, a bowling alley and\n",
      "a game room under hand-painted ceilings. They can exit the complex via a\n",
      "floating-style, glass-floor pathway, which sits over several swimming pools\n",
      "lined by 70-year-old olive trees. Once outside, residents can swim in a 128-foot\n",
      "reflecting pool, relax in a Turkish-style spa, walk through formal gardens and\n",
      "play on a tennis court. They can also visit the beautiful vineyard, which\n",
      "produces 400 to 500 cases of wine a year under its own private label, Beverly\n",
      "Hills Vineyards. Fit for royalty: The property has been put on the market for\n",
      "$195million - making it the most expensive property for sale in America . 25\n",
      "acres of land: The property (pictured) is listed under agents Joyce Rey and\n",
      "Stacy Gottula, of Coldwell Banker Previews International . The mansion, which\n",
      "boasts spectacular views of the West Side of Los Angeles, Century City and the\n",
      "sea, can host up to 1,000 people, with on-site parking for as many as 150\n",
      "vehicles, according to KTLA 5. Guests are greeted at the front doors by an\n",
      "Italian-made fountain carved of Carrara marble. The property is listed as the\n",
      "priciest home for sale in the U.S. under agents Joyce Rey and Stacy Gottula, of\n",
      "Coldwell Banker Previews International. Mr Greene, who has been renting the\n",
      "villa out for $475,000 a month and married his wife, Mei Sze Greene, there in\n",
      "2007 with Mike Tyson as the best man, said he had always intended to sell it,\n",
      "but construction was not completed 'until literally a month ago', according to\n",
      "the Wall Street Journal. Another perspective: Mr Greene said he had always\n",
      "intended to sell it, but construction was not completed 'until literally a month\n",
      "ago' Couple: Mr Greene, who has been renting the villa out for $475,000 a month\n",
      "and married his wife, Mei Sze Greene (both picture) there in 2007 with Mike\n",
      "Tyson as the best man, said he had always intended to sell it, but construction\n",
      "was only completed a month ago . 'Honestly, I didn’t think it was going to be\n",
      "this much work,' he said, adding that the mansion has been mostly rented out to\n",
      "members of Saudi royalty. In March, a similarly-sized mansion in nearby Holmby\n",
      "Hills sold for $102million, according to official records. However, it had just\n",
      "five acres of land. 'This property is five times the size of that,' said\n",
      "Gottula. Other mansions have recently sold in Los Angeles - but none for more\n",
      "than $100million. While Jeff Greene's sprawling 25-acre estate is on the market\n",
      "for $195million, this property will not even set you back $200. At $188, this\n",
      "house in Flint, Michigan, is believed to be the cheapest house publicly listed\n",
      "for sale in America. The property, listed on Realtor.com, is described as being\n",
      "a 'Fixer Upper Home, Needs lots of work, has major fire damage, seller selling\n",
      "AS IS'. Built in 1928, just before the Great Depression, it covers just 1,225\n",
      "square feet, with three bedrooms, a single bath and a one-car garage. Contrast:\n",
      "At $188, this three-bedroom house in Flint, Michigan, is believed to be the\n",
      "cheapest property on the market in America . Flint, which has a population of\n",
      "less than 100,000, was one of the hardest hit cities before and during the\n",
      "recession, USA Today reported. Now, the city's median household income  is just\n",
      "above $27,000 - significantly lower than the national average of just more than\n",
      "$51,000. The house is located at 2518 Dakota Avenue, just off Michigan's Route\n",
      "59 and not far from I-475.\n",
      "\n",
      "QUESTIONS:\n",
      "Q1) Who is the real estate entrepreneur selling the Palazzo di Amore estate? A.\n",
      "Bob Ray Offenhauser B. Alberto Pint C. Joyce Rey D. Jeff Greene E. Mohamed Hadid\n",
      "Q2) How many bedrooms and bathrooms does the Palazzo di Amore estate have? A. 20\n",
      "bedrooms, 30 bathrooms B. 10 bedrooms, 15 bathrooms C. 12 bedrooms, 23 bathrooms\n",
      "D. 12 bedrooms, 20 bathrooms E. 15 bedrooms, 25 bathrooms  Q3) What is the\n",
      "approximate size of the master suite in the Palazzo di Amore estate? A. 3,000\n",
      "square feet B. 10,000 square feet C. 2,000 square feet D. 5,000 square feet E.\n",
      "1,000 square feet  Q4) What is the name of the 25-acre estate in Beverly Hills,\n",
      "Los Angeles, that has been put on the market for $195 million? A. The Palace of\n",
      "Love B. None of the above C. Palazzo di Amore D. A and C E. Beverly Hills\n",
      "Vineyards  Q5) How much did Jeff Greene originally buy the Palazzo di Amore\n",
      "estate for in 2007? A. $50 million B. $35 million C. $20 million D. $10 million\n",
      "E. $100 million\n",
      "\n",
      "ANSWERS:\n",
      "['D' 'C' 'D' 'D' 'B']\n",
      "\n",
      "'================================================================================'\n",
      "TEXT:\n",
      "Abortions outnumber live births among African American women living in New York\n",
      "City, according to a new health report. Newly released Department of Health and\n",
      "Mental Hygiene figures show black women had 31,328 'crude induced terminations'\n",
      "in 2012, compared with 24,758 'live births'. The terminations comprised more\n",
      "than 42 percent of the Big Apple's total number. Birth rate: The report found\n",
      "that the 2012 citywide crude birth rate was 14.8 births per 1,000 population,\n",
      "the lowest rate since 1979 when . the rate was also 14.8 . Changes: New York's\n",
      "abortion rate has fallen below 40 percent for the first time in at least a\n",
      "decade, according to the report . The second highest number of abortions were\n",
      "for Hispanic at 22,917, with this group's live births reaching 36,642. Both\n",
      "groups outnumbered abortions for whites and Asian and Pacific Islanders, which\n",
      "had 9,704 and 4,493 terminations respectively. Women aged 20-29 had the most\n",
      "abortions among all ethnicities, with more women in Brooklyn choosing to\n",
      "terminate rather than have a child. The . abortion ratio citywide fell to just\n",
      "over 37 per cent in 2012 - a record low . since 1970 when abortion was legalized\n",
      "in New York. Anti-abortion and religious groups have hit out at the figures,\n",
      "describing abortion as a 'problem' which the city is failing to adequately\n",
      "address. Statistics: Abortions outnumbered live births among New York City's\n",
      "black community in 2012, according to a new report by the Department of Health\n",
      "and Mental Hygiene (stock picture) In the interests of the fetus: Religious\n",
      "groups are unsurprisingly outraged at the report's abortion figures, believing\n",
      "that women don't have the right to make decisions about their own bodies .\n",
      "\n",
      "QUESTIONS:\n",
      "Q1) What was the citywide crude birth rate in New York City in 2012? A. 30\n",
      "births per 1,000 population B. 10 births per 1,000 population C. 25 births per\n",
      "1,000 population D. 20 births per 1,000 population E. 14.8 births per 1,000\n",
      "population  Q2) What was the reaction of anti-abortion and religious groups to\n",
      "the abortion figures in the report? A. They were pleased with the decline in\n",
      "abortion rates B. They were indifferent to the report's findings C. They were\n",
      "outraged and described abortion as a 'problem' D. They were neutral and did not\n",
      "comment E. They were surprised by the low number of abortions  Q3) Which ethnic\n",
      "group had the second highest number of abortions in New York City in 2012? A.\n",
      "African American B. White C. Other D. Asian and Pacific Islanders E. Hispanic\n",
      "Q4) What was the abortion ratio citywide in New York City in 2012? A. 37 percent\n",
      "B. 25 percent C. 50 percent D. 30 percent E. 40 percent  Q5) What was the number\n",
      "of 'crude induced terminations' among African American women in New York City in\n",
      "2012? A. 24,758 B. 36,642 C. 31,328 D. 40,000 E. 20,000\n",
      "\n",
      "ANSWERS:\n",
      "['E' 'C' 'E' 'A' 'C']\n",
      "\n",
      "'================================================================================'\n",
      "TEXT:\n",
      "(CNN) -- An Orange County, California, man has been indicted on one federal\n",
      "count of knowingly attempting to provide material support and resources to al\n",
      "Qaeda, federal authorities said Friday. The indictment also charges 24-year-old\n",
      "Sinh Vinh Ngo Nguyen, also known as Hasan Abu Omar Ghannoum, with one count of\n",
      "making a false statement to obtain a passport to facilitate an act of\n",
      "international terrorism. Nguyen of Garden Grove was arrested Friday morning in\n",
      "Santa Ana attempting to boarding a bus to Mexico, FBI spokeswoman Laura Eimiller\n",
      "said. \"Investigators do not believe Nguyen was traveling with others, nor are\n",
      "they aware of a continuing threat to the public at this time, based on his\n",
      "alleged activities,\" she said. Eimiller did not detail the alleged activities,\n",
      "and the indictment did not spell out any specifics of the alleged actions.\n",
      "Nguyen was scheduled to make an initial appearance in U.S. District Court in\n",
      "Santa Ana later in the day, authorities said. CNN's Chelsea J. Carter\n",
      "contributed to this report.\n",
      "\n",
      "QUESTIONS:\n",
      "Q1) What was Sinh Vinh Ngo Nguyen attempting to do when he was arrested? A.\n",
      "Crossing the border into Canada B. Applying for a passport C. Boarding a bus to\n",
      "Mexico D. Boarding a plane to the Middle East E. Making a false statement to\n",
      "authorities  Q2) What was Sinh Vinh Ngo Nguyen charged with in addition to\n",
      "attempting to provide material support to al Qaeda? A. Attempting to board a\n",
      "plane to the Middle East B. Making a false statement to obtain a passport C.\n",
      "Providing material support to ISIS D. Attempting to cross the border into Mexico\n",
      "E. Making a false statement to authorities  Q3) What organization was Sinh Vinh\n",
      "Ngo Nguyen allegedly trying to support? A. Hamas B. al Qaeda C. ISIS D. The\n",
      "Muslim Brotherhood E. The Taliban  Q4) Where was Sinh Vinh Ngo Nguyen arrested?\n",
      "A. Mexico B. Santa Ana C. Orange County D. U.S. District Court E. Garden Grove\n",
      "Q5) What was the status of the threat to the public according to investigators?\n",
      "A. High and ongoing B. Low and contained C. Moderate and increasing D. There was\n",
      "no threat E. There was no information available\n",
      "\n",
      "ANSWERS:\n",
      "['C' 'B' 'B' 'B' 'B']\n",
      "\n",
      "'================================================================================'\n"
     ]
    }
   ],
   "source": [
    "for row in example_rows:\n",
    "    print_wrapped(\"TEXT\", row[DataSchema.ARTICLE])\n",
    "    print_wrapped(\"QUESTIONS\", row[DataSchema.MCQ_QUESTIONS])\n",
    "    print_wrapped(\"ANSWERS\", str(row[DataSchema.GROUND_TRUTH_MCQ_ANSWERS]))\n",
    "    pprint.pprint(\"=\" * 80, width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Generate Summaries + Scores\n",
    "\n",
    "Next, we will generate 10 summaries for each article in the training set and score them with our Q&A judging setup. \n",
    "\n",
    "The following command will run the [generate_summaries_and_scores.py](src/scripts/generate_summaries_and_scores.py) script, which takes in the folder with generated questions + articles and stores the results to a new folder of `.parquet` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mOutput\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +1.1s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mSubmitting job with config JobConfig(name='preference-tuning-summarization-question-generation', image_uri='localhost:5555/anyscale/endpoints_aica:0.5.0-6402', compute_config=None, env_vars=None, py_modules=None, cloud=None, project=None, ray_version=None, job_queue_config=None).\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +3.5s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mUsing workspace runtime dependencies env vars: {'WANDB_API_KEY': 'cbc4aed2de2d9c9acb21324a3297b85b7299479b'}.\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +3.5s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mUploading local dir '.' to cloud storage.\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +4.5s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mIncluding workspace-managed pip dependencies.\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +5.1s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mJob 'preference-tuning-summarization-question-generation' submitted, ID: 'prodjob_8m2iu1lcd44s2e7q95rcrxvzzx'.\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +5.1s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mView the job in the UI: https://console.anyscale.com/jobs/prodjob_8m2iu1lcd44s2e7q95rcrxvzzx\u001b[0m\n",
      "\u001b[0m\u001b[1m\u001b[36m(anyscale +5.1s)\u001b[0m \u001b[0m\u001b[0m\u001b[0m\u001b[0mUse `--wait` to wait for the job to run and stream logs.\u001b[0m\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!anyscale job submit -f configs/jobs/8b_judge/generate_summaries_train_job.yaml \n",
    "# Optional: use the 70b model for better performance (runs on A100s)\n",
    "# !anyscale job submit -f configs/jobs/70b_judge/generate_summaries_train_job.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab41ab9e885e4b848252edc04381f813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parquet Files Sample 0:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 12:07:01,737\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-16_11-08-34_539321_2359/logs/ray-data\n",
      "2024-08-16 12:07:01,738\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705f73ac5a4f49b7b19127ad29033d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadParquet 1:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd5916f79cb4e7fa808a1969765879a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 2:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72c5d38df48412f87e682d6c76f9ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/96 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# replace with the link to the generated summaries\n",
    "summary_folder = \"s3://air-example-data/preference-tuning-summarization-example/summary_generation_base/train/\"\n",
    "summary_ds = ray.data.read_parquet(summary_folder)\n",
    "example_rows = summary_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT:\n",
      "(RollingStone.com) -- Jennifer Lawrence, the 20-year-old Oscar nominee for Best\n",
      "Actress, is sitting in a fancy Manhattan hotel sipping tea and feeling a little\n",
      "out of place. See, she grew up in Louisville, Kentucky, where her dad owned a\n",
      "construction company and her mom ran a summer camp. They had land and horses.\n",
      "She loved to fish. She was a total tomboy: field hockey, softball, basketball on\n",
      "an all-boys team. (\"I was so dykey.\") One of her nicknames was Nitro. She lives\n",
      "in Los Angeles now, but \"little redneck things still come out.\" Like what? \"I'm\n",
      "attracted to my brother. Stuff like that.\" 10 Best Movies of 2010 . At 14, she\n",
      "decided she wanted to be an actress and dragged her mom to New York for\n",
      "auditions. The people at Reese's Peanut Butter Cups told her she was the best\n",
      "they'd ever seen. Her mom told her they were lying. (Her mom didn't like showbiz\n",
      "much.) She auditioned for the role of Bella in \"Twilight,\" which would have been\n",
      "perfect if Bella were a badass, but since she's a frightened waif, Lawrence\n",
      "ended up not getting the part. Which was for the best because the role she did\n",
      "get was for \"Winter's Bone,\" in which she's fantastic: harrowing and tender as\n",
      "the 17-year-old daughter of an Ozarks meth-cooker who's fighting to take care of\n",
      "her little brother and sister. This article appears in the February 17, 2011\n",
      "issue of Rolling Stone. The issue is available now on newsstands and will appear\n",
      "in the online archive February 4. To prep for the part, Lawrence learned how to\n",
      "shoot a gun and field-dress squirrels. She already knew how to chop wood: \"I\n",
      "went through a wood-chopping phase when I was nine or 10.\" She says she hasn't\n",
      "even bothered preparing an Oscar speech: \"I have been practicing my losing face,\n",
      "though. Do you want to see it?\" (For the record, it's a very good losing face.)\n",
      "Peter Travers Reviews 'Winter's Bone' Later this year comes \"X-Men: First\n",
      "Class,\" where she'll play the mutant Mystique, blue-skinned and topless. (\"Did I\n",
      "feel naked being naked?\" she asks, so you don't have to. \"Yeah. Totally.\") But\n",
      "before that there's Jodie Foster's \"The Beaver,\" premiering in May, in which she\n",
      "appears alongside a certifiable Mel Gibson. Which means she has some crazy Mel\n",
      "Gibson stories, right? She leans in close. \"If I say, 'Off the record' -- that\n",
      "means you can't print it, right?' \" Right. \"OK. So, off the record ...\" She's\n",
      "learning. Photos: 2011 Screen Actors Guild Award Winners . Copyright © 2011\n",
      "Rolling Stone.\n",
      "\n",
      "QUESTIONS:\n",
      "Q1) Where did Jennifer Lawrence grow up? A. The Ozarks B. Manhattan C. Los\n",
      "Angeles, California D. New York City, New York E. Louisville, Kentucky  Q2) What\n",
      "is the name of the movie in which Jennifer Lawrence will play the mutant\n",
      "Mystique? A. Winter's Bone B. X-Men: First Class C. The Beaver D. Twilight E.\n",
      "The Hunger Games  Q3) What is one skill Jennifer Lawrence learned to prepare for\n",
      "her role in \"Winter's Bone\"? A. How to play field hockey B. How to chop wood C.\n",
      "How to ride a horse D. How to act like a frightened waif E. How to shoot a gun\n",
      "Q4) Why did Jennifer Lawrence's mom take her to New York at the age of 14? A. To\n",
      "visit relatives B. To attend a sports tournament C. To go shopping D. For\n",
      "auditions E. For a family vacation  Q5) What was Jennifer Lawrence's role in the\n",
      "movie \"Winter's Bone\"? A. A character in a Jodie Foster movie B. A mutant with\n",
      "blue skin C. A character in a Reese's Peanut Butter Cups commercial D. A\n",
      "frightened waif E. A 17-year-old daughter of an Ozarks meth-cooker\n",
      "\n",
      "MODEL GENERATED_SUMMARY:\n",
      "Jennifer Lawrence, an Oscar-nominated actress from Kentucky, reflects on her\n",
      "journey from a tomboy to a successful actress in Hollywood. She talks about her\n",
      "love for field hockey, softball, and basketball, and her nickname \"Nitro.\"\n",
      "Lawrence auditioned for the role of Bella in \"Twilight\" but didn't get it, but\n",
      "went on to star in \"Winter's Bone,\" where she received critical acclaim. She\n",
      "discusses her preparation for the role, including learning how to shoot a gun\n",
      "and field-dress squirrels. Lawrence also talks about her upcoming roles in\n",
      "\"X-Men: First Class\" and \"The Beaver,\" and shares some crazy Mel Gibson stories.\n",
      "\n",
      "ANSWERS:\n",
      "['E' 'B' 'E' 'D' 'E']\n",
      "\n",
      "JUDGE ANSWERS FROM SUMMARY:\n",
      "['E', 'B', 'E', 'Unsure', 'Unsure']\n",
      "\n",
      "'===================================================================================================='\n"
     ]
    }
   ],
   "source": [
    "from src.utils.models import DataSchema\n",
    "\n",
    "for row in example_rows:\n",
    "    print_wrapped(\"TEXT\", row[DataSchema.ARTICLE])\n",
    "    print_wrapped(\"QUESTIONS\", row[DataSchema.MCQ_QUESTIONS])\n",
    "    print_wrapped(\"MODEL GENERATED SUMMARY\", row[DataSchema.SUMMARY_GENERATION_RAW_OUTPUT])\n",
    "    print_wrapped(\"ANSWERS\", str(row[DataSchema.GROUND_TRUTH_MCQ_ANSWERS]))\n",
    "    print_wrapped(\"JUDGE ANSWERS FROM SUMMARY\", str(row[DataSchema.JUDGE_MCQ_ANSWERS]))\n",
    "    pprint.pprint(\"=\" * 100, width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Generate Preference Tuning Data\n",
    "\n",
    "Next, we will generate 10 summaries for each article in the training set and score them with our Q&A judging setup. \n",
    "\n",
    "The following command will run the [generate_dpo_data.py](src/scripts/generate_dpo_data.py) script, which takes in the folder of summaries and outputs `.jsonl` files for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/scripts/generate_dpo_data.py configs/training_data_generation/mistral_8b.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 12:23:43,661\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-16_11-08-34_539321_2359/logs/ray-data\n",
      "2024-08-16 12:23:43,661\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> TaskPoolMapOperator[ExpandPaths] -> TaskPoolMapOperator[ReadFiles] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1310be7fc9634a2eb12521bff1c17037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ExpandPaths 1:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ebd4ac242447ff8867bd547d505b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadFiles 2:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a717068930a645dd82307bfb01fe3a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 3:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10b8bcb65fb471291f7b4c974176946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect the results\n",
    "# Replace with the link to your validation file\n",
    "validation_file = \"s3://air-example-data/preference-tuning-summarization-example/dpo_training_data/valid.jsonl\"\n",
    "\n",
    "valid_ds = ray.data.read_json(validation_file)\n",
    "example_rows = valid_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chosen': [{'content': \"Given the following text, create a very short summary that is at most 2 sentences.\\n\\nText:\\nBy . Tamara Cohen, Political Reporter . PUBLISHED: . 18:32 EST, 27 January 2013 . | . UPDATED: . 08:48 EST, 28 January 2013 . Deputy Prime Minister Nick Clegg and his wife Miriam are determined to keep the education of their 11-year-old son 'out of politics' Nick Clegg yesterday defended the possibility he may send his children to private schools as it emerged he and his wife Miriam have not even visited their local state school. He said the education of his 11-year-old son Antonio, who starts secondary school this year, should not be used as 'a political football' and that the couple would do 'what's best' for their children although he was braced for criticism. Last week the Liberal Democrat leader told listeners to his radio show he would send his son to a private school if he failed to find a place in a good comprehensive, saying he would use the state system 'if it works out', but that there is 'huge competition' for places in London. But Mr Clegg, who attended Westminster public school, has apparently not looked around nearby Ark Putney academy in south-west London, it was revealed yesterday by its headmaster Mark Phillips. Mr Phillips who has turned the school around since he was hired three years ago, said the school which was once in special measures but is now lauded by the Government for its improvements, could provide an 'exceptional' education for any child and that there was no need to pay fees for schooling. Unless the Cleggs had visited 'under cover' he had not seen them, he said.'I am always very clear that all parents living locally are welcome to choose our school and it is important that every parent comes with their child and takes an objective look to see whether what we offer will meet the needs of their child', he said. 'It wouldn't claim to be the answer to every child and every parent. But I hope that if a parent does come, and sees an environment their child will thrive in, they will pick us...I am confident they will do exceptionally well. I don't believe you have to pay for it.' Mr Clegg told the BBC's Andrew Marr Show yesterday that he and his wife will do whatever is in the interests of their son . If he chooses to educate his children . privately, Mr Clegg is likely to be accused of hypocrisy after using a . speech last year to attack 'the great rift in our education system' caused by many of the best schools being fee-paying and said it had a . 'corrosive' effect on society and the economy. In . an interview on BBC1's Andrew Marr Show, he said: 'I accept that it's a . dilemma for anyone in public life, particularly in politics, how do you . balance that with the fact Miriam and I have small children, and the . approach Miriam and I took right from the outset was to keep our . children completely out of politics. 'We . never put them in front of the camera or to make them or their . education a political football. 'I totally accept that when we make a . decision that'll be subject to public commentary, criticism and so on, . but in the meantime we want to protect the privacy of an 11-year-old boy . and make the decision that we as parents think is best for our son.' The deadline for applying for entry to Ark Putney for 2013-14 was last October. The school is part of the Ark academy chain, set up in 2004, whose chairman is Paul Marshall, one of the Liberal Democrats' biggest donors. Last year 62 per cent of pupils gained at least five good GCSEs, prompting schools minister Nick Gibb to write to Mr Phillips to congratulate him on the 'excellent results' saying the school was in the top 100 best-performing, based on sustained improvements every year since 2008. However Michael Gove last year approved the sale of five acres of playing fields at the school including six tennis courts, a football pitch and a playground, to developers to fund refurbishments, after a £40million revamp under the Building Schools for the Future programme was cancelled. Alumni of Ark Putney, which used to be Elliott School, include actor Pierce Brosnan, and 1960s England bowler Geoff Arnold. Former Welsh secretary Peter Hain sent his children to the school, which was the scene of the Christmas play in the film Love, Actually. David Cameron has said his children will attend state school, but George Osborne has been criticised for sending his to the fee-paying preparatory school in Kensington that he attended.\",\n",
       "   'role': 'user'},\n",
       "  {'content': \"Nick Clegg and his wife Miriam are considering sending their 11-year-old son Antonio to a private school, despite their previous claims that they would use the state system. Clegg has not visited Ark Putney Academy, a nearby state school, but its headmaster, Mark Phillips, claims that the school could provide an 'exceptional' education for any child and that there is no need to pay fees for schooling. The deadline for applying to Ark Putney for 2013-14 was last October and the school is part of the Ark academy chain, set up in 2004, whose chairman is Paul Marshall, one of the Liberal Democrats' biggest donors.\",\n",
       "   'role': 'assistant'}],\n",
       " 'rejected': [{'content': \"Given the following text, create a very short summary that is at most 2 sentences.\\n\\nText:\\nBy . Tamara Cohen, Political Reporter . PUBLISHED: . 18:32 EST, 27 January 2013 . | . UPDATED: . 08:48 EST, 28 January 2013 . Deputy Prime Minister Nick Clegg and his wife Miriam are determined to keep the education of their 11-year-old son 'out of politics' Nick Clegg yesterday defended the possibility he may send his children to private schools as it emerged he and his wife Miriam have not even visited their local state school. He said the education of his 11-year-old son Antonio, who starts secondary school this year, should not be used as 'a political football' and that the couple would do 'what's best' for their children although he was braced for criticism. Last week the Liberal Democrat leader told listeners to his radio show he would send his son to a private school if he failed to find a place in a good comprehensive, saying he would use the state system 'if it works out', but that there is 'huge competition' for places in London. But Mr Clegg, who attended Westminster public school, has apparently not looked around nearby Ark Putney academy in south-west London, it was revealed yesterday by its headmaster Mark Phillips. Mr Phillips who has turned the school around since he was hired three years ago, said the school which was once in special measures but is now lauded by the Government for its improvements, could provide an 'exceptional' education for any child and that there was no need to pay fees for schooling. Unless the Cleggs had visited 'under cover' he had not seen them, he said.'I am always very clear that all parents living locally are welcome to choose our school and it is important that every parent comes with their child and takes an objective look to see whether what we offer will meet the needs of their child', he said. 'It wouldn't claim to be the answer to every child and every parent. But I hope that if a parent does come, and sees an environment their child will thrive in, they will pick us...I am confident they will do exceptionally well. I don't believe you have to pay for it.' Mr Clegg told the BBC's Andrew Marr Show yesterday that he and his wife will do whatever is in the interests of their son . If he chooses to educate his children . privately, Mr Clegg is likely to be accused of hypocrisy after using a . speech last year to attack 'the great rift in our education system' caused by many of the best schools being fee-paying and said it had a . 'corrosive' effect on society and the economy. In . an interview on BBC1's Andrew Marr Show, he said: 'I accept that it's a . dilemma for anyone in public life, particularly in politics, how do you . balance that with the fact Miriam and I have small children, and the . approach Miriam and I took right from the outset was to keep our . children completely out of politics. 'We . never put them in front of the camera or to make them or their . education a political football. 'I totally accept that when we make a . decision that'll be subject to public commentary, criticism and so on, . but in the meantime we want to protect the privacy of an 11-year-old boy . and make the decision that we as parents think is best for our son.' The deadline for applying for entry to Ark Putney for 2013-14 was last October. The school is part of the Ark academy chain, set up in 2004, whose chairman is Paul Marshall, one of the Liberal Democrats' biggest donors. Last year 62 per cent of pupils gained at least five good GCSEs, prompting schools minister Nick Gibb to write to Mr Phillips to congratulate him on the 'excellent results' saying the school was in the top 100 best-performing, based on sustained improvements every year since 2008. However Michael Gove last year approved the sale of five acres of playing fields at the school including six tennis courts, a football pitch and a playground, to developers to fund refurbishments, after a £40million revamp under the Building Schools for the Future programme was cancelled. Alumni of Ark Putney, which used to be Elliott School, include actor Pierce Brosnan, and 1960s England bowler Geoff Arnold. Former Welsh secretary Peter Hain sent his children to the school, which was the scene of the Christmas play in the film Love, Actually. David Cameron has said his children will attend state school, but George Osborne has been criticised for sending his to the fee-paying preparatory school in Kensington that he attended.\",\n",
       "   'role': 'user'},\n",
       "  {'content': 'Deputy Prime Minister Nick Clegg has defended the possibility of sending his children to private schools, stating that their education should not be used as a political football. He and his wife Miriam have not visited their local state school, but the headmaster of Ark Putney academy in London, where they were invited to attend, said the school could provide an \"exceptional\" education for any child and that parents should come to see it firsthand before making a decision.',\n",
       "   'role': 'assistant'}],\n",
       " 'num_words_chosen': 105,\n",
       " 'num_words_rejected': 79,\n",
       " 'accuracy_chosen': 3,\n",
       " 'accuracy_rejected': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:\n",
      "Given the following text, create a very short summary that is at most 2\n",
      "sentences.  Text: By . Tamara Cohen, Political Reporter . PUBLISHED: . 18:32\n",
      "EST, 27 January 2013 . | . UPDATED: . 08:48 EST, 28 January 2013 . Deputy Prime\n",
      "Minister Nick Clegg and his wife Miriam are determined to keep the education of\n",
      "their 11-year-old son 'out of politics' Nick Clegg yesterday defended the\n",
      "possibility he may send his children to private schools as it emerged he and his\n",
      "wife Miriam have not even visited their local state school. He said the\n",
      "education of his 11-year-old son Antonio, who starts secondary school this year,\n",
      "should not be used as 'a political football' and that the couple would do\n",
      "'what's best' for their children although he was braced for criticism. Last week\n",
      "the Liberal Democrat leader told listeners to his radio show he would send his\n",
      "son to a private school if he failed to find a place in a good comprehensive,\n",
      "saying he would use the state system 'if it works out', but that there is 'huge\n",
      "competition' for places in London. But Mr Clegg, who attended Westminster public\n",
      "school, has apparently not looked around nearby Ark Putney academy in south-west\n",
      "London, it was revealed yesterday by its headmaster Mark Phillips. Mr Phillips\n",
      "who has turned the school around since he was hired three years ago, said the\n",
      "school which was once in special measures but is now lauded by the Government\n",
      "for its improvements, could provide an 'exceptional' education for any child and\n",
      "that there was no need to pay fees for schooling. Unless the Cleggs had visited\n",
      "'under cover' he had not seen them, he said.'I am always very clear that all\n",
      "parents living locally are welcome to choose our school and it is important that\n",
      "every parent comes with their child and takes an objective look to see whether\n",
      "what we offer will meet the needs of their child', he said. 'It wouldn't claim\n",
      "to be the answer to every child and every parent. But I hope that if a parent\n",
      "does come, and sees an environment their child will thrive in, they will pick\n",
      "us...I am confident they will do exceptionally well. I don't believe you have to\n",
      "pay for it.' Mr Clegg told the BBC's Andrew Marr Show yesterday that he and his\n",
      "wife will do whatever is in the interests of their son . If he chooses to\n",
      "educate his children . privately, Mr Clegg is likely to be accused of hypocrisy\n",
      "after using a . speech last year to attack 'the great rift in our education\n",
      "system' caused by many of the best schools being fee-paying and said it had a .\n",
      "'corrosive' effect on society and the economy. In . an interview on BBC1's\n",
      "Andrew Marr Show, he said: 'I accept that it's a . dilemma for anyone in public\n",
      "life, particularly in politics, how do you . balance that with the fact Miriam\n",
      "and I have small children, and the . approach Miriam and I took right from the\n",
      "outset was to keep our . children completely out of politics. 'We . never put\n",
      "them in front of the camera or to make them or their . education a political\n",
      "football. 'I totally accept that when we make a . decision that'll be subject to\n",
      "public commentary, criticism and so on, . but in the meantime we want to protect\n",
      "the privacy of an 11-year-old boy . and make the decision that we as parents\n",
      "think is best for our son.' The deadline for applying for entry to Ark Putney\n",
      "for 2013-14 was last October. The school is part of the Ark academy chain, set\n",
      "up in 2004, whose chairman is Paul Marshall, one of the Liberal Democrats'\n",
      "biggest donors. Last year 62 per cent of pupils gained at least five good GCSEs,\n",
      "prompting schools minister Nick Gibb to write to Mr Phillips to congratulate him\n",
      "on the 'excellent results' saying the school was in the top 100 best-performing,\n",
      "based on sustained improvements every year since 2008. However Michael Gove last\n",
      "year approved the sale of five acres of playing fields at the school including\n",
      "six tennis courts, a football pitch and a playground, to developers to fund\n",
      "refurbishments, after a £40million revamp under the Building Schools for the\n",
      "Future programme was cancelled. Alumni of Ark Putney, which used to be Elliott\n",
      "School, include actor Pierce Brosnan, and 1960s England bowler Geoff Arnold.\n",
      "Former Welsh secretary Peter Hain sent his children to the school, which was the\n",
      "scene of the Christmas play in the film Love, Actually. David Cameron has said\n",
      "his children will attend state school, but George Osborne has been criticised\n",
      "for sending his to the fee-paying preparatory school in Kensington that he\n",
      "attended.\n",
      "\n",
      "CHOSEN RESPONSE:\n",
      "Nick Clegg and his wife Miriam are considering sending their 11-year-old son\n",
      "Antonio to a private school, despite their previous claims that they would use\n",
      "the state system. Clegg has not visited Ark Putney Academy, a nearby state\n",
      "school, but its headmaster, Mark Phillips, claims that the school could provide\n",
      "an 'exceptional' education for any child and that there is no need to pay fees\n",
      "for schooling. The deadline for applying to Ark Putney for 2013-14 was last\n",
      "October and the school is part of the Ark academy chain, set up in 2004, whose\n",
      "chairman is Paul Marshall, one of the Liberal Democrats' biggest donors.\n",
      "\n",
      "REJECTED RESPONSE:\n",
      "Deputy Prime Minister Nick Clegg has defended the possibility of sending his\n",
      "children to private schools, stating that their education should not be used as\n",
      "a political football. He and his wife Miriam have not visited their local state\n",
      "school, but the headmaster of Ark Putney academy in London, where they were\n",
      "invited to attend, said the school could provide an \"exceptional\" education for\n",
      "any child and that parents should come to see it firsthand before making a\n",
      "decision.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in example_rows:\n",
    "    print_wrapped(\"PROMPT\", row[\"chosen\"][0][\"content\"])\n",
    "    print_wrapped(\"CHOSEN RESPONSE\", row[\"chosen\"][1][\"content\"])\n",
    "    print_wrapped(\"REJECTED RESPONSE\", row[\"rejected\"][1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Fine-tuning\n",
    "\n",
    "Now that we have the pre-processed dataset, we are ready to fine-tune `Mistral-7B-Instruct-v0.1` using DPO. On Anyscale, we've created an easy-to-use interface to do preference-tuning using `DPO`. We leverage Ray to overlap reference model log-probability calculation with model training to improve GPU utilization. Most implementations compute log probabilities synchronously with model training,\n",
    "\n",
    "![hf model](assets/hf_dpo.png)\n",
    "\n",
    "While our implementation using Ray is asynchronous:  \n",
    "\n",
    "\n",
    "![assistant model](assets/anyscale_dpo.png)\n",
    "\n",
    "Further, our use of Ray Data also implies that the compute configuration for the reference model can be completely decoupled with the policy model. For example, reference model calculation can run on a different node (with configurable number of GPUs, etc) with zero code changes needed. \n",
    "\n",
    "\n",
    "To get started with DPO training, we provide the config for DPO in [configs/mistral_dpo_summarization.yaml](configs/mistral_dpo_summarization.yaml) . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat configs/mistral_dpo_summarization.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the below command from the root directory for the template (`~/default`): \n",
    "\n",
    "```\n",
    "llmforge anyscale finetune end-to-end-examples/fine-tune-preference/configs/mistral_dpo_summarization.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Evaluation\n",
    "\n",
    "Let's evaluate our trained model. Here we'll use two baselines: (1) the base model before finetuning (reference model in DPO) and (2) GPT-4o.\n",
    "\n",
    "## Evaluation strategy\n",
    "\n",
    "Our evaluation strategy involves the same Q&A scoring system as used while generating the preference data. \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./assets/eval.png?\" alt=\"Evaluation\" width=800>\n",
    "</p>\n",
    "\n",
    "We evaluate the baseline model and the trained DPO model on the test set. \n",
    "\n",
    "## Obtain summaries on the test set\n",
    "First, we'll need to obtain the summaries (and scores) for both the models on the given test set. \n",
    "\n",
    "For the baseline model, you can simply run the below command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!anyscale job submit -f configs/jobs/8b_judge/generate_summaries_eval_baseline_job.yaml\n",
    "# Optional: use the 70b model for better performance (runs on A100s)\n",
    "# !anyscale job submit -f configs/jobs/70b_judge/generate_summaries_eval_baseline_job.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the fine-tuned DPO model, we provide a dummy config in [configs/summary_generation/8b_judge/mistral_finetuned_eval.yaml](configs/summary_generation/8b_judge/mistral_finetuned_eval.yaml). If you used the default training config provided, the model would be trained using LoRA and you should have a path to the LoRA weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode: eval\n",
      "input_folder: s3://air-example-data/preference-tuning-summarization-example/qa_generation/qa_annotations_full_test\n",
      "inference_type: offline\n",
      "model_inference_config:\n",
      "  model_id_or_path: mistralai/Mistral-7B-Instruct-v0.1 # <---- Modify with s3 link to full param weights if you did full-param training\n",
      "  adapter_id_or_path: <lora_path_here> # <---  Add path to lora weights here. If you did full param training, you can instead remove this field.\n",
      "  temperature: 0\n",
      "  top_p: 0.95\n",
      "  scaling_config:\n",
      "    batch_size: 64\n",
      "    concurrency: 2\n",
      "    num_gpus_per_instance: 1\n",
      "    accelerator_type: A10G\n",
      "num_generations: 1\n",
      "judge_inference_config:\n",
      "  model_id_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct\n",
      "  temperature: 0\n",
      "  scaling_config:\n",
      "    batch_size: 64\n",
      "    concurrency: 3\n",
      "    num_gpus_per_instance: 2\n",
      "    accelerator_type: A10G\n",
      "num_mcq_questions: 5\n"
     ]
    }
   ],
   "source": [
    "!cat configs/summary_generation/8b_judge/mistral_finetuned_eval.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!anyscale job submit -f configs/jobs/8b_judge/generate_summaries_eval_finetuned_job.yaml\n",
    "# Optional: use the 70b model for better performance (runs on A100s)\n",
    "# !anyscale job submit -f configs/jobs/70b_judge/generate_summaries_eval_finetuned_job.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the logs for the above jobs, you should see the final path to the output summaries for both the models. \n",
    "\n",
    "Optionally, you can also obtain the summaries and scores for the `gpt-4o` model from OpenAI. Simply run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!anyscale job submit -f configs/jobs/8b_judge/generate_summaries_eval_gpt_job.yaml\n",
    "# Optional: use the 70b model for better performance (runs on A100s)\n",
    "# !anyscale job submit -f configs/jobs/70b_judge/generate_summaries_eval_gpt_job.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Evaluation Statistics\n",
    "\n",
    "We've provided a convenient script [get_eval_stats.py](src/scripts/get_eval_stats.py) to get evaluation statistics and obtain the \"win rate\" of the DPO model (the percentage of times the DPO model performs better than the baseline). We've provided an example configuration below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to substitute -outputs-path with your path\n",
    "!python src/scripts/get_eval_stats.py --outputs-path s3://air-example-data/preference-tuning-summarization-example/summary_generation_dpo_model/test/ --baseline-outputs-path s3://air-example-data/preference-tuning-summarization-example/summary_generation_base/test/  \n",
    "\n",
    "# (Optional): if you obtained results for GPT-4o, you should uncomment and run the following command instead\n",
    "# !python src/scripts/get_eval_stats.py --outputs-path s3://air-example-data/preference-tuning-summarization-example/summary_generation_dpo_model/test/ --baseline-outputs-path s3://air-example-data/preference-tuning-summarization-example/summary_generation_base/test/  --gpt4o-outputs-path <add-path-to-gpt4o-results>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the following results for the 70B model:\n",
    "\n",
    "```text \n",
    "╒═════════════════════════════╤═══════════╤════════════╤═══════════╕\n",
    "│           Metric            │   Model   │  Baseline  │  GPT-4o   │\n",
    "╞═════════════════════════════╪═══════════╪════════════╪═══════════╡\n",
    "│        Accuracy >=3         │ 65.4286 % │ 43.0476 %  │ 37.2381 % │\n",
    "├─────────────────────────────┼───────────┼────────────┼───────────┤\n",
    "│        Accuracy >=4         │ 25.7143 % │ 13.5238 %  │ 10.0000 % │\n",
    "├─────────────────────────────┼───────────┼────────────┼───────────┤\n",
    "│     Median Compression      │ 11.5794 % │ 12.7316 %  │ 8.0496 %  │\n",
    "├─────────────────────────────┼───────────┼────────────┼───────────┤\n",
    "│      Mean Compression       │ 13.0029 % │ 14.3444 %  │ 9.3554 %  │\n",
    "├─────────────────────────────┼───────────┼────────────┼───────────┤\n",
    "│      Summary Too Long       │ 0.0000 %  │  0.0000 %  │ 0.0000 %  │\n",
    "├─────────────────────────────┼───────────┼────────────┼───────────┤\n",
    "│ Contains Invalid Characters │ 0.0000 %  │  0.0952 %  │ 0.0000 %  │\n",
    "╘═════════════════════════════╧═══════════╧════════════╧═══════════╛\n",
    "\n",
    "\n",
    "Model Win Rate against Baseline: 74.0000 %\n",
    "GPT-4o Win Rate against Baseline: 64.8095 %\n",
    "```\n",
    "\n",
    "Our fine-tuned model is able to generate much better summaries, that are more concise (compression ratio is lower) with lesser out-of-distribution characters (gibberish tokens) than the baseline. You can see more details on the same in our blog!\n",
    "\n",
    "| **NOTE:** The evaluation results will differ if you used the 8B model which is less capable as a LLM-judge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congrats! You have now fine-tuned an open source model on preference data. As a quick recap, here's what we demonstrated in this notebook:\n",
    "1. Synthetically generating preference data for DPO \n",
    "2. DPO fine-tuning of a language model on the Anyscale Platform\n",
    "4. Evaluating the model against the baseline and GPT-4o, and analysing the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
