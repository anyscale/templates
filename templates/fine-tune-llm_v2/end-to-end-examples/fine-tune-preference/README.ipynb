{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preference Tuning for Summarization using Synthetic Data\n",
    "\n",
    "**‚è±Ô∏è Time to complete**: 10 hours\n",
    "\n",
    "Alignment of LLMs has traditionally been broken down into two post-training stages: Supervised fine-tuning (SFT) followed by preference tuning (aka RLHF). SFT requires high quality data collection where each data sample illustrates behavior which we would like the LLM to imitate exactly. While for some tasks like SQL generation and math reasoning, it is feasible to collect the ground truth data, this approach does not always scale easily to align for subjective use cases (ex. chat, summarization, etc.). \n",
    "\n",
    "On the other hand, preference tuning only requires information about whether a given response is preferred to another response. Each data sample consists of a chosen and rejected completion for a given prompt, such that the chosen completion is preferred over the rejected completion. Preference tuning is thus a powerful tool that can optimize LLMs towards complex preferences that cannot be easily captured through supervised fine-tuning. However, manually annotating preferences between model outputs using human raters can be extremely time-consuming and expensive. Instead, synthetic preference data can be generated by scoring responses with large foundation models, allowing for much cheaper and scalable data collection!\n",
    "\n",
    "Here we'll go through an end-to-end example for preference tuning of an open-source language model with synthetic data, covering scalable methodologies for data preprocessing, fine-tuning and evaluation, using Ray. We will focus on the task of summarization for the [CNN/DailyMail](https://huggingface.co/datasets/abisee/cnn_dailymail) dataset. \n",
    "\n",
    "\n",
    "Notebook guide:\n",
    "- üîÑ REPLACE indicates to replace with your unique values\n",
    "- üí° INSIGHT indicates infrastructure insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Data Preprocessing](#step-1-data-preprocessing): In this section we cover how we can prepare preference data for the summarization task using an LLM-as-a-judge. \n",
    "    1. [Generate Multiple Choice Questions From Articles](#part-a-generate-multiple-choice-questions-from-articles)\n",
    "    2. [Generate Summaries and Scores](#part-b-generate-summaries--scores)\n",
    "    3. [Generate Preference Tuning Data](#part-c-generate-preference-tuning-data)\n",
    "2. [DPO Finetuning](#step-2-fine-tuning): This section will cover how you can fine-tune an open source model on the preference data on the Anyscale platform.\n",
    "3. [Evaluation](#step-3-evaluation): The section will lay down a blue-print for evaluation and compare performance to that of closed source models like OpenAI's GPT-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Running the jobs in this notebook requires a HuggingFace token that can access [Llama-3.1-70B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct) and [Mistral-7B-Instruct-v0.1](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1). For GPT-4o evaluation, you'd also need a valid `OPENAI_API_KEY`.  Make sure to provide `HF_TOKEN` and `OPENAI_API_KEY` by defining it under dependencies in your cluster setup.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./assets/env_var.png?\" alt=\"Environment variable\" width=800>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make the necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "\n",
    "import ray.data\n",
    "import datasets\n",
    "\n",
    "from src.utils.models import DataSchema\n",
    "from src.utils.common import print_wrapped\n",
    "\n",
    "os.environ[\"PYTHONPATH\"] = f\"{os.environ.get('PYTHONPATH', '')}:src\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Synthetic Data Generation\n",
    "\n",
    "First, let's inspect the training dataset and look at an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_ds = datasets.load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\", split=\"train\")\n",
    "\n",
    "raw_example = hf_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article': 'LONDON, England (Reuters) -- Harry Potter star Daniel Radcliffe '\n",
      "            'gains access to a reported ¬£20 million ($41.1 million) fortune as '\n",
      "            \"he turns 18 on Monday, but he insists the money won't cast a \"\n",
      "            'spell on him. Daniel Radcliffe as Harry Potter in \"Harry Potter '\n",
      "            'and the Order of the Phoenix\" To the disappointment of gossip '\n",
      "            'columnists around the world, the young actor says he has no plans '\n",
      "            'to fritter his cash away on fast cars, drink and celebrity '\n",
      "            'parties. \"I don\\'t plan to be one of those people who, as soon as '\n",
      "            'they turn 18, suddenly buy themselves a massive sports car '\n",
      "            'collection or something similar,\" he told an Australian '\n",
      "            'interviewer earlier this month. \"I don\\'t think I\\'ll be '\n",
      "            'particularly extravagant. \"The things I like buying are things '\n",
      "            'that cost about 10 pounds -- books and CDs and DVDs.\" At 18, '\n",
      "            'Radcliffe will be able to gamble in a casino, buy a drink in a '\n",
      "            'pub or see the horror film \"Hostel: Part II,\" currently six '\n",
      "            'places below his number one movie on the UK box office chart. '\n",
      "            \"Details of how he'll mark his landmark birthday are under wraps. \"\n",
      "            'His agent and publicist had no comment on his plans. \"I\\'ll '\n",
      "            'definitely have some sort of party,\" he said in an interview. '\n",
      "            '\"Hopefully none of you will be reading about it.\" Radcliffe\\'s '\n",
      "            'earnings from the first five Potter films have been held in a '\n",
      "            'trust fund which he has not been able to touch. Despite his '\n",
      "            'growing fame and riches, the actor says he is keeping his feet '\n",
      "            'firmly on the ground. \"People are always looking to say \\'kid '\n",
      "            'star goes off the rails,\\'\" he told reporters last month. \"But I '\n",
      "            'try very hard not to go that way because it would be too easy for '\n",
      "            'them.\" His latest outing as the boy wizard in \"Harry Potter and '\n",
      "            'the Order of the Phoenix\" is breaking records on both sides of '\n",
      "            'the Atlantic and he will reprise the role in the last two films.  '\n",
      "            \"Watch I-Reporter give her review of Potter's latest ¬ª . There is \"\n",
      "            'life beyond Potter, however. The Londoner has filmed a TV movie '\n",
      "            'called \"My Boy Jack,\" about author Rudyard Kipling and his son, '\n",
      "            'due for release later this year. He will also appear in \"December '\n",
      "            'Boys,\" an Australian film about four boys who escape an '\n",
      "            'orphanage. Earlier this year, he made his stage debut playing a '\n",
      "            'tortured teenager in Peter Shaffer\\'s \"Equus.\" Meanwhile, he is '\n",
      "            \"braced for even closer media scrutiny now that he's legally an \"\n",
      "            'adult: \"I just think I\\'m going to be more sort of fair game,\" he '\n",
      "            'told Reuters. E-mail to a friend . Copyright 2007 Reuters. All '\n",
      "            'rights reserved.This material may not be published, broadcast, '\n",
      "            'rewritten, or redistributed.',\n",
      " 'highlights': 'Harry Potter star Daniel Radcliffe gets ¬£20M fortune as he '\n",
      "               'turns 18 Monday .\\n'\n",
      "               'Young actor says he has no plans to fritter his cash away .\\n'\n",
      "               \"Radcliffe's earnings from first five Potter films have been \"\n",
      "               'held in trust fund .',\n",
      " 'id': '42c027e4ff9730fbb3de84c1af0d2c506e41c3e4'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(raw_example, width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the example article above. Our goal is to train a model to summarize it accurately, with a preference for short summaries, making sure we also preserve important details. In this guide, we will employ a _synthetic_ summary scoring method using another LLM as a judge. We score the correctness of a summary using the following metrics:\n",
    "\n",
    "**Summary Scoring Metrics**\n",
    "1. Multiple choice Q&A accuracy:\n",
    "    - Given the original text, we use an LLM judge to generate 5 multiple choice questions about the text.\n",
    "    - We then ask the LLM judge to answer the questions using only the summary, and record the number of questions correctly answered.\n",
    "2. Word count: We simply count the number of words in the summary.\n",
    "\n",
    "This allows us to construct a simple preference function between two summaries:\n",
    "\n",
    "**Preference Function**\n",
    "1. If both summary responses attain more than 3/5 multiple choice questions correct, we will prefer the shorter response. We do not care about Q&A accuracy beyond 3 correct answers, since the summary should not contain all information from the text.\n",
    "2. Otherwise, we select the response that leads to more correctly answered multiple choice questions.\n",
    "\n",
    "We consider a subset of 21,000 articles in this example. To generate the preference pairs, we will generate 10 summaries from each article using the model we wish to fine-tune. Then, we will randomly sample pairs of summaries and use our preference function to annotate the preference between them.\n",
    "\n",
    "For this example, we will use `Mistral-7B-Instruct-v0.1` as the base model to fine-tune and `Llama-3.1-70B-Instruct` as a judge. Note that mistral-instruct is already instruction tuned, so that given a prompt to do summarization it might do a good job, but it may not be aligned with how we want the summarization to look like. We can use preference data to further align the instruct variant towards our specific needs.\n",
    "\n",
    "We've provided a helpful visualization here:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./assets/preference_function.png?\" alt=\"Preference function\" width=800>\n",
    "</p>\n",
    "\n",
    "Combining all this together, our data pre-processing pipeline is going to look as follows: \n",
    "\n",
    "![preprocessing](./assets/preprocessing.png?1)\n",
    "\n",
    "üí° INSIGHT: \n",
    "Our synthetic preference data collection looks pretty involved at first glance. The key ideas in plain English are as follows:\n",
    "- We use a combination of Q&A scoring + word length to indicate like/dislike (our preference function) given a pair of summaries.\n",
    "- Our ultimate goal is to generate (chosen, rejected) pairs to train our reference model and evaluate it based on this criteria.\n",
    "- We use another LLM (judge model) to generate said questions for each article. This model is also used in our scoring system. (To see how many questions can be answered from a summary)\n",
    "- To generate training data, we first sample candidate summaries from the reference model for each article. We then obtain scores for each summary from the judge. Using the scores, we select pairs of summaries and mark our like/dislike to form (chosen, rejected) pairs for the actual training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a): Generate Multiple Choice Questions from Articles\n",
    "\n",
    "First, we will generate the multiple choice questions and answers for each article using `Llama-3.1-8B-Instruct` (or `70B` if A100/H100s are available). Leveraging vLLM and Ray, we can very easily scale this generation process across multiple GPUs.\n",
    "\n",
    ">  **_NOTE:_**  We provide two sets of configs: One with an 8B parameter model as the judge, and another with the 70B model. Using the 8B model is recommended, since we make use of highly available A10Gs. For good performance, and to replicate the results in our blog, you should use the 70B judge model which uses A100s (but these are harder to obtain on-demand)\n",
    "\n",
    "The following command will run the [src/scripts/generate_questions.py](./src/scripts/generate_questions.py) script, which generates the questions and answers and saves them in `.parquet` files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "üí° INSIGHT:  \n",
    "We are running this script as an anyscale job. The resources required by each step are requested at runtime and provisioned by Anyscale's autoscaler based on availability and quotas. You are free to change the [qa_generation](./configs/qa_generation) config in any way. The important parameters regarding resources are `accelerator_type`, `num_gpus_per_instance`, and `concurrency`. This script will generate 5 multiple choice question and answer pairs per article for 21k examples. According to the [llama_8b](./configs/qa_generation/llama_8b.yaml) config we are requesting 3 replicas of 4xA10G machines processing a batch-size of 128 examples each which saturates the GPUs all the way through.\n",
    "\n",
    "This step will take ~75 min for 8B running on A10s and ~?? for 70B running on A100s.\n",
    "\n",
    "```bash\n",
    "anyscale job submit -f configs/jobs/8b_judge/generate_questions_job.yaml\n",
    "# Optional: use the 70b model for better performance (runs on A100s)\n",
    "# anyscale job submit -f configs/jobs/70b_judge/generate_questions_job.yaml\n",
    "```\n",
    "\n",
    "> **NOTE**: We recommend that you execute all the commands in this notebook in a terminal. Make sure you `cd` into the directory of this notebook (and the `src` files) before executing the commands. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the job, you should see the remote path to the folder with Q&A in the logs.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./assets/question_generation_done.png?\" alt=\"Evaluation\" width=800>\n",
    "</p>\n",
    "\n",
    " Make sure to make note to use it for the next steps! \n",
    "\n",
    " üîÑ REPLACE the resulting S3 URI here. If you want to skip the prior step, you can continue with the prepared example data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this with the link to the output folder from the previous job\n",
    "qa_folder = \"s3://air-example-data/preference-tuning-summarization-example/qa_generation/qa_annotations_full_train/\"\n",
    "qa_ds = ray.data.read_parquet(qa_folder)\n",
    "# The dataset is small, we can materalize it\n",
    "example_rows = qa_ds.materialize().take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT:\n",
      "From balloon-popping lasers to Wolverine-style claws, there are numerous concept\n",
      "and protoype weapons designed by wannabe superhero inventors. But, a magician\n",
      "has not only created a wristband that turns the wearer into Pyro from the Marvel\n",
      "comics, he is selling it for $174 (¬£111) online. Named after the comic book\n",
      "mutant, the Pyro band features four chambers that fires four fireballs, and it\n",
      "can be controlled from the wrist or remotely. Scroll down for video . Pyro\n",
      "(pictured) was designed by New Hampshire magician Adam Wilber. It features four\n",
      "separate chambers for four multiple shots and can be controlled either from the\n",
      "wrist or remotely . Its inventor, Adam Wilber explained: ‚ÄòFire. Since the dawn\n",
      "of time it has been the reward at the end of man's quest. Both creator and\n",
      "destroyer, it has historically been the element hardest to control. ‚ÄòUntil now.\n",
      "Your quest is over. The power of fire in the palm of your hand. That's the power\n",
      "of Pyro.' It is available from the Ellusionist site, and ships internationally.\n",
      "The band resembles a watch and can be concealed under a sleeve. Pressing a\n",
      "button on the device shoots the fireballs, or a remote control can be used to\n",
      "fire them from a distance of up to 30ft (nine metres) away. The band resembles a\n",
      "watch and can be concealed under a sleeve (pictured left).¬†It uses so-called\n",
      "Flash Cotton, or Flash Paper that fits inside the barrels. A heater coil then\n",
      "ignites the material when the button is pressed, forcing the flame to fire from\n",
      "the chambers . The device is named after Marvel comic book character Pyro,\n",
      "played by Adam Burton in the X-Men franchise (pictured). In the series, Pyro is\n",
      "a so-called Class 4 mutant that can create and control fire . If smartwatches\n",
      "from the likes of Apple and Motorola don't appeal to you, a German inventor has\n",
      "built a powerful alternative. Dubbed Bond Inspired LaserWatch, the timepiece was\n",
      "designed at home by a hobbyist using a metal case, screws, and a built-in laser\n",
      "pointer. The designer recently demonstrated the power of the laser by popping\n",
      "balloons and lighting matches from around 3ft (one metre) away. It is the\n",
      "brainchild of Wuppertal-based Patrick Priebe. It uses so-called Flash Cotton, or\n",
      "Flash Paper that fits inside the barrels. A heater coil then ignites the\n",
      "material when the button is pressed, forcing the flame to fire from the\n",
      "chambers. The pack contains enough of this material for up to 50 uses. Refills\n",
      "then start at $8 (¬£4). Flash material is used by magicians to create fast\n",
      "burning flames for tricks. Mr Wilber describes Pryo as a ‚Äòbadass professional\n",
      "device‚Äô, and as a result only over 18s are allowed to purchase or use the fire\n",
      "shooter. The site ships internationally, but a disclaimer stresses that the\n",
      "device ‚Äòcontains dangerous elements‚Äô that are governed by the laws of the\n",
      "country in which is it bought. Buyers have to agree to the terms and conditions,\n",
      "and watch an instructional safety video by Adam Wilber, before buying the\n",
      "device. It is recommended, and has been built for, magicians. ‚ÄòIn the lead up to\n",
      "release we sent a number of Pyro units out to some of the most creative up-and-\n",
      "comers in the industry to put the unit through its paces,‚Äô explained\n",
      "Ellusionist. ‚ÄòEvery single person that received Pyrocalled us up and raved about\n",
      "it. Pyro has ignited an excitement within them. Pressing a button on the device\n",
      "shoots the fireballs, or a remote control (pictured) can be used from up to 30ft\n",
      "(nine metres) away. It costs $174 (¬£111) and ships internationally. ¬†Buyers have\n",
      "to agree to the terms and conditions, and watch a safety video before buying. It\n",
      "is recommended, and has been built for, magicians . Mr Wilber (pictured in a\n",
      "promotional video) describes Pryo as a ‚Äòbadass professional device‚Äô, and as a\n",
      "result only over 18s are allowed to purchase or use the fire shooter .\n",
      "\n",
      "QUESTIONS:\n",
      "Q1) Who designed the Pyro wristband? A. Steve Jobs B. Patrick Priebe C. Adam\n",
      "Wilber D. Adam Burton E. Elon Musk  Q2) What is the maximum distance from which\n",
      "the Pyro wristband can be controlled remotely? A. 20ft B. 50ft C. 10ft D. 40ft\n",
      "E. 30ft  Q3) What is the name of the wristband that shoots fireballs? A. Marvel\n",
      "Band B. Fire Starter C. Fireball Wristband D. Pyro Band E. Flame Shooter  Q4)\n",
      "What is the recommended use of the Pyro wristband? A. For magicians B. For\n",
      "military use C. For outdoor events D. For personal protection E. For children's\n",
      "parties  Q5) What is the price of the Pyro wristband? A. $174 B. $250 C. $50 D.\n",
      "$200 E. $100\n",
      "\n",
      "ANSWERS:\n",
      "['C' 'E' 'D' 'A' 'A']\n",
      "\n",
      "'================================================================================'\n",
      "TEXT:\n",
      "Washington (CNN) -- When two focus groups met earlier this week -- conducted\n",
      "using \"Walmart moms\" or women ages 29-54 who've shopped at the big-box retailer\n",
      "recently, they revealed the secret behind how this crucial demographic decides\n",
      "whom they vote for this year: Google. \"You Google it,\" said participants from\n",
      "North Carolina when asked about their voting decision process. \"Probably the\n",
      "night before,\" said another North Carolina woman, on when she looks up\n",
      "information on candidates. The women were part of two, ten-person groups in\n",
      "North Carolina and Louisiana on Monday night that were underwritten by Walmart.\n",
      "In both states, female Democratic Senators are running in tight reelection\n",
      "races, meaning that the women in the focus groups represent an essential\n",
      "category of voters Democrats need to keep those seats and hold on to control of\n",
      "the Senate. The racially, ethnically and educationally diverse group of mothers\n",
      "expressed concern about the future throughout most of the three-hours of focus\n",
      "grouping. Many were concerned about Ebola and less so about ISIS. They can\n",
      "recall the negative ads in their respective Senate races, but on the whole,\n",
      "don't know the candidates well. And even though Republicans have tried to tie\n",
      "every Democrat to President Barack Obama, the women didn't see the unpopular\n",
      "president as a campaign issue, even if they think he is doing a bad job. What\n",
      "was most striking in the group, however, was how distant the Senate races in\n",
      "each state felt to the women. According to the Center for Responsive Politics,\n",
      "in Louisiana's Senate race, between Democrat Mary Landrieu, Republican Bill\n",
      "Cassidy and independent Rob Maness, almost $40 million has been spent. Upwards\n",
      "of $80 million has been spent in the race between Thom Tillis and Kay Hagan in\n",
      "North Carolina. All that money, though, has bought very little with these women.\n",
      "\"Nothing is going to change,\" said Lauren, a 44-year old North Carolinian.\n",
      "Politicians \"stand where they stand. Nothing is going to change the next two\n",
      "weeks. It is going to be like you are cramming for a test.\" Their interest\n",
      "doesn't mean they aren't concerned, however. The Walmart moms of this particular\n",
      "focus group say they are worried about the future, anxious about their children\n",
      "and feel like politicians in Washington don't understand their daily struggle.\n",
      "We are \"out of site, out of mind,\" said Jennifer, a 38-year old cafeteria worker\n",
      "and mother of one. \"Unless you are out there serving that child at school, or\n",
      "helping that student with just learning how to be nice with one another... or\n",
      "you are getting up at 4:30 in the morning so you can beat the rush hour and get\n",
      "to work on time.\" After a slight pause, she added. \"They don't [understand],\n",
      "they can't.\" When asked what one message they would communicate to leaders in\n",
      "Washington, the women struck a similar tune: My representatives in Washington\n",
      "have lost touch with their roots and don't understand my struggle. \"I wish you\n",
      "could have been in my shoes, and seen [the] struggle of a single parent,\" said\n",
      "Theodosia, a 40-year old women who voted for Obama in 2012. \"I remember where I\n",
      "came from,\" said Andrea, a 32-year old mother of three who voted for Romney. \"I\n",
      "work hard for everything I have, tangible and intangible,\" said Jennifer. Her\n",
      "comment resonated with the women, they nodded as she said it. In North Carolina,\n",
      "most of the mothers recalled very little about Hagan or Tillis. Hagan, they\n",
      "said, was trying to portray Tillis as unstable, while Tillis was trying to cast\n",
      "Hagan as another vote for Obama, the women said. But other than that, not much\n",
      "stuck. In Louisiana, where there was slightly more definition, the women\n",
      "struggled to name all three candidates. The women could remember Landrieu's\n",
      "positive ad -- including a \"cute\" one with her father -- and recalled attacks\n",
      "that \"she doesn't even live here any more.\" (Earlier this year, questions about\n",
      "Landrieu's residency were raised by a story in the Washington Post that said the\n",
      "senator doesn't own her own house in Louisiana and, instead, lives at her home\n",
      "on Capitol Hill in Washington, D.C. The senator has vehemently denied the\n",
      "charge.) \"If she doesn't live here, how is she supposed to know what the true\n",
      "problems are,\" said one woman. \"How is she supposed to know?\" But that is really\n",
      "where the recollections ended. What did universally stick, however, was that all\n",
      "the campaigning has been negative. \"All I get from all of those [ads] is don't\n",
      "vote for that person, because they are a bad person, vote for me,\" said one\n",
      "woman in North Carolina. When asked what the Landrieu campaign wanted voters to\n",
      "think about Cassidy, one woman in New Orleans put it this way: \"That he is the\n",
      "devil.\" The reason they feel disconnected, according to women in both North\n",
      "Carolina and Louisiana, is that the people who represent them in Washington are\n",
      "of little concern to them because those politicians could never fathom their\n",
      "daily struggle. The women told stories about struggling to pay for their\n",
      "children's education, their health care and their groceries. They talked about\n",
      "dealing with their spouse's job loss or trying to make ends meet with little.\n",
      "They also became animated when talking about the upcoming holidays and how they\n",
      "plan to save money to provide all they can or their kids. And when reflecting on\n",
      "all of this, the women said the same thing: The politicians asking for my vote\n",
      "don't get all of this. \"Moms say politicians 'don't get it' and need to 'walk in\n",
      "my shoes,'\" read a memo about the conversation from Neil Newhouse and Margie\n",
      "Omero, two pollsters who helped organize the group. \"This is a perennial Walmart\n",
      "mom complaint that frankly only gets louder with each conversation.\" This\n",
      "sentiment was encapsulated by Jennifer, the woman from North Carolina who said\n",
      "she struggled for everything she has. \"Once they go home to the farm, it isn't a\n",
      "dirty farm,\" she said of when lawmakers leave North Carolina and go to\n",
      "Washington. When they come home, she said, their farm \"is a clean farm... with a\n",
      "tractor that would make John Deere faint.\"\n",
      "\n",
      "QUESTIONS:\n",
      "Q1) What demographic was the focus of the two focus groups conducted in North\n",
      "Carolina and Louisiana? A. Retirees B. Small business owners C. College students\n",
      "D. Walmart moms (women ages 29-54 who've shopped at Walmart recently) E. Young\n",
      "professionals  Q2) What was a common concern among the focus group participants?\n",
      "A. The economy B. Healthcare C. The future and their children's well-being D.\n",
      "Immigration E. Foreign policy  Q3) What message did the focus group participants\n",
      "want to communicate to leaders in Washington? A. That they need to support a\n",
      "specific policy B. That they need to focus on the economy C. That they need to\n",
      "improve their negative ads D. That they have lost touch with their roots and\n",
      "don't understand their daily struggle E. That they need to be more involved in\n",
      "their communities  Q4) What was the primary way the focus group participants\n",
      "said they decide whom to vote for? A. Google B. Watching debates C. Talking to\n",
      "friends and family D. Reading newspapers E. Watching TV ads  Q5) How did the\n",
      "focus group participants feel about the politicians running in their respective\n",
      "Senate races? A. They were somewhat informed but neutral B. They were very\n",
      "supportive of one candidate C. They were very opposed to all candidates D. They\n",
      "didn't know the candidates well and felt disconnected E. They were very informed\n",
      "and enthusiastic\n",
      "\n",
      "ANSWERS:\n",
      "['D' 'C' 'D' 'A' 'D']\n",
      "\n",
      "'================================================================================'\n",
      "TEXT:\n",
      "(CNN) -- Top British officials paid a visit Saturday to leaders of Libya's\n",
      "opposition government, the beneficiary of the first NATO helicopter attacks on\n",
      "ruler Moammar Gadhafi' military vehicles, equipment and forces. Foreign\n",
      "Secretary William Hague and International Development Secretary Andrew Mitchell\n",
      "traveled to Benghazi, where they reiterated support for the Transitional\n",
      "National Council. According to a statement, Mitchell announced new support for\n",
      "the clearing of mines in besieged cities, including Misrata. He and Hague\n",
      "visited a Benghazi hospital treating those wounded in the conflict. The visit,\n",
      "which included a discussion of the country's possible future, followed\n",
      "helicopter attacks by British and French forces on the regime's military. \"This\n",
      "successful engagement demonstrates the unique capabilities brought to bear by\n",
      "attack helicopters,\" said Lt. Gen. Charles Bouchard, who commands NATO's Libya\n",
      "operation. \"We will continue to use these assets whenever and wherever needed,\n",
      "using the same precision as we do in all of our missions.\" British forces,\n",
      "flying from the HMS Ocean, used Apache helicopters for the overnight strikes,\n",
      "according to the Ministry of Defence. French helicopters took off from the\n",
      "assault ship Tonnerre, the ministry said in a statement. The Apaches struck a\n",
      "regime radar installation and a military checkpoint, both located around Brega,\n",
      "a key oil town in the east, British officials said. Hellfire missiles and 30mm\n",
      "cannon were used to destroy the targets, they said. Royal Air Force ground\n",
      "attack aircraft destroyed another military installation, while a separate\n",
      "mission hammered two ammunition bunkers in central Libya, according to the\n",
      "statement. A French military spokesman said 20 targets, including vehicles, were\n",
      "destroyed. Several helicopters responded to small-arms fire from the ground, but\n",
      "none were hit, he said. \"The use of attack helicopters provides the NATO\n",
      "operation with additional flexibility to track and engage pro-Gadhafi forces who\n",
      "deliberately target civilians and attempt to hide in populated areas,\" NATO said\n",
      "in a statement. Meanwhile, a string of explosions -- at least 10 -- rocked the\n",
      "Libyan capital of Tripoli early Saturday evening, CNN journalists reported. Six\n",
      "more explosions were heard early Sunday. One of the explosions struck an old\n",
      "military station about 25 kilometers (16 miles) south of the city, a government\n",
      "official said. There also was fighting in the western city of Zintan. According\n",
      "to Mamdouh Dardair, a rebel fighter, portions of the town were hit by a large\n",
      "number of rockets fired by Gadhafi forces. The rockets damaged infrastructure,\n",
      "but there were no immediate reports of injuries. CNN could not confirm the\n",
      "account. On Friday, fighting continued in the western town of Yefren, where\n",
      "NATO-allied aircraft destroyed government tanks and personnel carriers,\n",
      "officials said. NATO warplanes belonging to the United Kingdom's Royal Air Force\n",
      "fired Paveway guided bombs and destroyed two main battle tanks and two armored\n",
      "personnel carriers belonging to Libya's military, said Maj. Gen. John Lorimer,\n",
      "strategic communication officer for the chief of the defense staff. The\n",
      "airstrikes occurred Thursday, he said. NATO reported that government forces were\n",
      "continuing \"to attack the peoples of the western highlands,\" Lorimer said.\n",
      "Meanwhile, rebels claimed to liberate Yefren and the nearby town of Kikla, both\n",
      "of which are about 25 miles (40 kilometers) east of their stronghold in Zintan,\n",
      "one rebel fighter said. Talhat al-Jiwayli, a rebel on the front lines in Zintan,\n",
      "also said that anti-Gadhafi forces were surrounding the town of al-Rayyana, more\n",
      "than seven miles northeast of Zintan. A resolution approved by the U.N. Security\n",
      "Council in March authorized member states \"to take all necessary measures to\n",
      "protect civilians under threat of attack in the country, including Benghazi,\n",
      "while excluding a foreign occupation force of any form on any part of Libyan\n",
      "territory.\" . CNN's Kareem Khadder and Michael Martinez contributed to this\n",
      "report.\n",
      "\n",
      "QUESTIONS:\n",
      "Q1) What type of helicopters did British forces use for the overnight strikes on\n",
      "Gadhafi's military? A. French helicopters B. Royal Air Force helicopters C.\n",
      "Apache helicopters D. NATO helicopters E. US helicopters  Q2) What was\n",
      "authorized by the U.N. Security Council in March? A. The use of attack\n",
      "helicopters by NATO B. The protection of civilians under threat of attack in\n",
      "Libya C. The overthrow of Gadhafi's government D. A foreign occupation force in\n",
      "Libya E. The establishment of a new government in Libya  Q3) Who visited the\n",
      "leaders of Libya's opposition government in Benghazi? A. Libyan officials B. Top\n",
      "British officials C. NATO officials D. US officials E. French officials  Q4)\n",
      "What was the result of the NATO helicopter attacks on Gadhafi's military? A. The\n",
      "attacks were unsuccessful B. Multiple targets, including vehicles and military\n",
      "installations, were destroyed C. Gadhafi's forces surrendered D. Several\n",
      "helicopters were destroyed E. No targets were hit  Q5) What was the purpose of\n",
      "the visit by British officials to Benghazi? A. To reiterate support for the\n",
      "Transitional National Council B. To discuss a ceasefire with Gadhafi C. To\n",
      "provide humanitarian aid D. To negotiate a peace treaty E. To discuss a foreign\n",
      "occupation force\n",
      "\n",
      "ANSWERS:\n",
      "['C' 'B' 'B' 'B' 'A']\n",
      "\n",
      "'================================================================================'\n"
     ]
    }
   ],
   "source": [
    "for row in example_rows:\n",
    "    print_wrapped(\"TEXT\", row[DataSchema.ARTICLE])\n",
    "    print_wrapped(\"QUESTIONS\", row[DataSchema.MCQ_QUESTIONS])\n",
    "    print_wrapped(\"ANSWERS\", str(row[DataSchema.GROUND_TRUTH_MCQ_ANSWERS]))\n",
    "    pprint.pprint(\"=\" * 80, width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): Generate Summaries + Scores\n",
    "\n",
    "Next, we will generate 10 summaries for each article in the training set and score them with our Q&A judging setup. \n",
    "\n",
    "The following command will run the [generate_summaries_and_scores.py](src/scripts/generate_summaries_and_scores.py) script, which takes in the folder with generated questions + articles and stores the results to a new folder of `.parquet` files. This script will use the model under training to produce 10 summaries per each example on all of the input data examples. Followed by each summarization, it will also perform summary accuracy measurement, asking the down-stream LLM to answer the questions generated earlier solely based on the summaries generated by the desired model. \n",
    "\n",
    "üîÑ REPLACE the S3 URI in [`configs/summary_generation/8b_judge/mistral_finetuned_eval.yaml`](configs/summary_generation/8b_judge/mistral_finetuned_eval.yaml) with the path to the folder with generated questions from the previous job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This job will take ~420 min for 8B on A10Gs and ~300 min for 70B on A100s given the default configurations.\n",
    "\n",
    "\n",
    "```bash\n",
    "anyscale job submit -f configs/jobs/8b_judge/generate_summaries_train_job.yaml \n",
    "# Optional: use the 70b model for better performance (runs on A100s)\n",
    "# anyscale job submit -f configs/jobs/70b_judge/generate_summaries_train_job.yaml\n",
    "```\n",
    "\n",
    "üí° INSIGHT: If your job is unable to acquire the specified resources, it might indicate a lack of availability of GPUs. Try decreasing the `concurrency` argument for reference model or the judge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîÑ REPLACE the below S3 URI with the link to the generated summaries from the job. You can optionally skip the previous with the example dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with the link to the generated summaries\n",
    "summary_folder = \"s3://air-example-data/preference-tuning-summarization-example/summary_generation_base/train/\"\n",
    "summary_ds = ray.data.read_parquet(summary_folder)\n",
    "example_rows = summary_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT:\n",
      "(RollingStone.com) -- Jennifer Lawrence, the 20-year-old Oscar nominee for Best\n",
      "Actress, is sitting in a fancy Manhattan hotel sipping tea and feeling a little\n",
      "out of place. See, she grew up in Louisville, Kentucky, where her dad owned a\n",
      "construction company and her mom ran a summer camp. They had land and horses.\n",
      "She loved to fish. She was a total tomboy: field hockey, softball, basketball on\n",
      "an all-boys team. (\"I was so dykey.\") One of her nicknames was Nitro. She lives\n",
      "in Los Angeles now, but \"little redneck things still come out.\" Like what? \"I'm\n",
      "attracted to my brother. Stuff like that.\" 10 Best Movies of 2010 . At 14, she\n",
      "decided she wanted to be an actress and dragged her mom to New York for\n",
      "auditions. The people at Reese's Peanut Butter Cups told her she was the best\n",
      "they'd ever seen. Her mom told her they were lying. (Her mom didn't like showbiz\n",
      "much.) She auditioned for the role of Bella in \"Twilight,\" which would have been\n",
      "perfect if Bella were a badass, but since she's a frightened waif, Lawrence\n",
      "ended up not getting the part. Which was for the best because the role she did\n",
      "get was for \"Winter's Bone,\" in which she's fantastic: harrowing and tender as\n",
      "the 17-year-old daughter of an Ozarks meth-cooker who's fighting to take care of\n",
      "her little brother and sister. This article appears in the February 17, 2011\n",
      "issue of Rolling Stone. The issue is available now on newsstands and will appear\n",
      "in the online archive February 4. To prep for the part, Lawrence learned how to\n",
      "shoot a gun and field-dress squirrels. She already knew how to chop wood: \"I\n",
      "went through a wood-chopping phase when I was nine or 10.\" She says she hasn't\n",
      "even bothered preparing an Oscar speech: \"I have been practicing my losing face,\n",
      "though. Do you want to see it?\" (For the record, it's a very good losing face.)\n",
      "Peter Travers Reviews 'Winter's Bone' Later this year comes \"X-Men: First\n",
      "Class,\" where she'll play the mutant Mystique, blue-skinned and topless. (\"Did I\n",
      "feel naked being naked?\" she asks, so you don't have to. \"Yeah. Totally.\") But\n",
      "before that there's Jodie Foster's \"The Beaver,\" premiering in May, in which she\n",
      "appears alongside a certifiable Mel Gibson. Which means she has some crazy Mel\n",
      "Gibson stories, right? She leans in close. \"If I say, 'Off the record' -- that\n",
      "means you can't print it, right?' \" Right. \"OK. So, off the record ...\" She's\n",
      "learning. Photos: 2011 Screen Actors Guild Award Winners . Copyright ¬© 2011\n",
      "Rolling Stone.\n",
      "\n",
      "QUESTIONS:\n",
      "Q1) Where did Jennifer Lawrence grow up? A. The Ozarks B. Manhattan C. Los\n",
      "Angeles, California D. New York City, New York E. Louisville, Kentucky  Q2) What\n",
      "is the name of the movie in which Jennifer Lawrence will play the mutant\n",
      "Mystique? A. Winter's Bone B. X-Men: First Class C. The Beaver D. Twilight E.\n",
      "The Hunger Games  Q3) What is one skill Jennifer Lawrence learned to prepare for\n",
      "her role in \"Winter's Bone\"? A. How to play field hockey B. How to chop wood C.\n",
      "How to ride a horse D. How to act like a frightened waif E. How to shoot a gun\n",
      "Q4) Why did Jennifer Lawrence's mom take her to New York at the age of 14? A. To\n",
      "visit relatives B. To attend a sports tournament C. To go shopping D. For\n",
      "auditions E. For a family vacation  Q5) What was Jennifer Lawrence's role in the\n",
      "movie \"Winter's Bone\"? A. A character in a Jodie Foster movie B. A mutant with\n",
      "blue skin C. A character in a Reese's Peanut Butter Cups commercial D. A\n",
      "frightened waif E. A 17-year-old daughter of an Ozarks meth-cooker\n",
      "\n",
      "MODEL GENERATED_SUMMARY:\n",
      "Jennifer Lawrence, an Oscar-nominated actress from Kentucky, reflects on her\n",
      "journey from a tomboy to a successful actress in Hollywood. She talks about her\n",
      "love for field hockey, softball, and basketball, and her nickname \"Nitro.\"\n",
      "Lawrence auditioned for the role of Bella in \"Twilight\" but didn't get it, but\n",
      "went on to star in \"Winter's Bone,\" where she received critical acclaim. She\n",
      "discusses her preparation for the role, including learning how to shoot a gun\n",
      "and field-dress squirrels. Lawrence also talks about her upcoming roles in\n",
      "\"X-Men: First Class\" and \"The Beaver,\" and shares some crazy Mel Gibson stories.\n",
      "\n",
      "ANSWERS:\n",
      "['E' 'B' 'E' 'D' 'E']\n",
      "\n",
      "JUDGE ANSWERS FROM SUMMARY:\n",
      "['E', 'B', 'E', 'Unsure', 'Unsure']\n",
      "\n",
      "'===================================================================================================='\n"
     ]
    }
   ],
   "source": [
    "from src.utils.models import DataSchema\n",
    "\n",
    "for row in example_rows:\n",
    "    print_wrapped(\"TEXT\", row[DataSchema.ARTICLE])\n",
    "    print_wrapped(\"QUESTIONS\", row[DataSchema.MCQ_QUESTIONS])\n",
    "    print_wrapped(\"MODEL GENERATED SUMMARY\", row[DataSchema.SUMMARY_GENERATION_RAW_OUTPUT])\n",
    "    print_wrapped(\"ANSWERS\", str(row[DataSchema.GROUND_TRUTH_MCQ_ANSWERS]))\n",
    "    print_wrapped(\"JUDGE ANSWERS FROM SUMMARY\", str(row[DataSchema.JUDGE_MCQ_ANSWERS]))\n",
    "    pprint.pprint(\"=\" * 100, width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c): Generate Preference Tuning Data\n",
    "\n",
    "The final step for getting our data ready! We'll now generate (chosen, rejected) summary pairs for each article based on the scores.\n",
    "\n",
    "The following command will run the [generate_dpo_data.py](src/scripts/generate_dpo_data.py) script, which takes in the folder of summaries and outputs `.jsonl` files for training and validation.\n",
    "\n",
    "üîÑ REPLACE the S3 URI in [`configs/training_data_generation/mistral_8b.yaml`](configs/training_data_generation/mistral_8b.yaml) with the path to the folder with generated summaries from the previous job\n",
    "\n",
    "Run the following command in the terminal to generate DPO data:\n",
    "```bash\n",
    "python src/scripts/generate_dpo_data.py configs/training_data_generation/mistral_8b.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the results\n",
    "# Replace with the link to your validation file\n",
    "validation_file = \"s3://air-example-data/preference-tuning-summarization-example/dpo_training_data/valid.jsonl\"\n",
    "\n",
    "valid_ds = ray.data.read_json(validation_file)\n",
    "example_rows = valid_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT:\n",
      "Given the following text, create a very short summary that is at most 2\n",
      "sentences.  Text: By . Tamara Cohen, Political Reporter . PUBLISHED: . 18:32\n",
      "EST, 27 January 2013 . | . UPDATED: . 08:48 EST, 28 January 2013 . Deputy Prime\n",
      "Minister Nick Clegg and his wife Miriam are determined to keep the education of\n",
      "their 11-year-old son 'out of politics' Nick Clegg yesterday defended the\n",
      "possibility he may send his children to private schools as it emerged he and his\n",
      "wife Miriam have not even visited their local state school. He said the\n",
      "education of his 11-year-old son Antonio, who starts secondary school this year,\n",
      "should not be used as 'a political football' and that the couple would do\n",
      "'what's best' for their children although he was braced for criticism. Last week\n",
      "the Liberal Democrat leader told listeners to his radio show he would send his\n",
      "son to a private school if he failed to find a place in a good comprehensive,\n",
      "saying he would use the state system 'if it works out', but that there is 'huge\n",
      "competition' for places in London. But Mr Clegg, who attended Westminster public\n",
      "school, has apparently not looked around nearby Ark Putney academy in south-west\n",
      "London, it was revealed yesterday by its headmaster Mark Phillips. Mr Phillips\n",
      "who has turned the school around since he was hired three years ago, said the\n",
      "school which was once in special measures but is now lauded by the Government\n",
      "for its improvements, could provide an 'exceptional' education for any child and\n",
      "that there was no need to pay fees for schooling. Unless the Cleggs had visited\n",
      "'under cover' he had not seen them, he said.'I am always very clear that all\n",
      "parents living locally are welcome to choose our school and it is important that\n",
      "every parent comes with their child and takes an objective look to see whether\n",
      "what we offer will meet the needs of their child', he said. 'It wouldn't claim\n",
      "to be the answer to every child and every parent. But I hope that if a parent\n",
      "does come, and sees an environment their child will thrive in, they will pick\n",
      "us...I am confident they will do exceptionally well. I don't believe you have to\n",
      "pay for it.' Mr Clegg told the BBC's Andrew Marr Show yesterday that he and his\n",
      "wife will do whatever is in the interests of their son . If he chooses to\n",
      "educate his children . privately, Mr Clegg is likely to be accused of hypocrisy\n",
      "after using a . speech last year to attack 'the great rift in our education\n",
      "system' caused by many of the best schools being fee-paying and said it had a .\n",
      "'corrosive' effect on society and the economy. In . an interview on BBC1's\n",
      "Andrew Marr Show, he said: 'I accept that it's a . dilemma for anyone in public\n",
      "life, particularly in politics, how do you . balance that with the fact Miriam\n",
      "and I have small children, and the . approach Miriam and I took right from the\n",
      "outset was to keep our . children completely out of politics. 'We . never put\n",
      "them in front of the camera or to make them or their . education a political\n",
      "football. 'I totally accept that when we make a . decision that'll be subject to\n",
      "public commentary, criticism and so on, . but in the meantime we want to protect\n",
      "the privacy of an 11-year-old boy . and make the decision that we as parents\n",
      "think is best for our son.' The deadline for applying for entry to Ark Putney\n",
      "for 2013-14 was last October. The school is part of the Ark academy chain, set\n",
      "up in 2004, whose chairman is Paul Marshall, one of the Liberal Democrats'\n",
      "biggest donors. Last year 62 per cent of pupils gained at least five good GCSEs,\n",
      "prompting schools minister Nick Gibb to write to Mr Phillips to congratulate him\n",
      "on the 'excellent results' saying the school was in the top 100 best-performing,\n",
      "based on sustained improvements every year since 2008. However Michael Gove last\n",
      "year approved the sale of five acres of playing fields at the school including\n",
      "six tennis courts, a football pitch and a playground, to developers to fund\n",
      "refurbishments, after a ¬£40million revamp under the Building Schools for the\n",
      "Future programme was cancelled. Alumni of Ark Putney, which used to be Elliott\n",
      "School, include actor Pierce Brosnan, and 1960s England bowler Geoff Arnold.\n",
      "Former Welsh secretary Peter Hain sent his children to the school, which was the\n",
      "scene of the Christmas play in the film Love, Actually. David Cameron has said\n",
      "his children will attend state school, but George Osborne has been criticised\n",
      "for sending his to the fee-paying preparatory school in Kensington that he\n",
      "attended.\n",
      "\n",
      "CHOSEN RESPONSE:\n",
      "Nick Clegg and his wife Miriam are considering sending their 11-year-old son\n",
      "Antonio to a private school, despite their previous claims that they would use\n",
      "the state system. Clegg has not visited Ark Putney Academy, a nearby state\n",
      "school, but its headmaster, Mark Phillips, claims that the school could provide\n",
      "an 'exceptional' education for any child and that there is no need to pay fees\n",
      "for schooling. The deadline for applying to Ark Putney for 2013-14 was last\n",
      "October and the school is part of the Ark academy chain, set up in 2004, whose\n",
      "chairman is Paul Marshall, one of the Liberal Democrats' biggest donors.\n",
      "\n",
      "REJECTED RESPONSE:\n",
      "Deputy Prime Minister Nick Clegg has defended the possibility of sending his\n",
      "children to private schools, stating that their education should not be used as\n",
      "a political football. He and his wife Miriam have not visited their local state\n",
      "school, but the headmaster of Ark Putney academy in London, where they were\n",
      "invited to attend, said the school could provide an \"exceptional\" education for\n",
      "any child and that parents should come to see it firsthand before making a\n",
      "decision.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in example_rows:\n",
    "    print_wrapped(\"PROMPT\", row[\"chosen\"][0][\"content\"])\n",
    "    print_wrapped(\"CHOSEN RESPONSE\", row[\"chosen\"][1][\"content\"])\n",
    "    print_wrapped(\"REJECTED RESPONSE\", row[\"rejected\"][1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Fine-tuning\n",
    "\n",
    "Now that we have the pre-processed dataset, we are ready to fine-tune `Mistral-7B-Instruct-v0.1` using DPO. On Anyscale, we've created an easy-to-use interface to do preference-tuning using DPO. We leverage Ray to overlap reference model log-probability calculation with model training to improve GPU utilization. Most implementations compute log probabilities synchronously with model training,\n",
    "\n",
    "![hf model](./assets/hf_dpo.png)\n",
    "\n",
    "While our implementation using Ray is asynchronous:  \n",
    "\n",
    "\n",
    "![assistant model](./assets/anyscale_dpo.png)\n",
    "\n",
    "Further, our use of Ray Data also implies that the compute configuration for the reference model can be completely decoupled with the policy model. For example, reference model calculation can run on a different node (with configurable number of GPUs, etc) with zero code changes needed. \n",
    "\n",
    "> **NOTE** Make sure you've gove over the [user guides](https://docs.anyscale.com/category/fine-tuning-beta) for fine-tuning to understand the different configurations available\n",
    "\n",
    "To get started with DPO training, we provide the config for DPO in [configs/mistral_dpo_summarization.yaml](configs/mistral_dpo_summarization.yaml) . \n",
    "\n",
    " üîÑ REPLACE the training and validation file paths in the config with the output file paths in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id: mistralai/Mistral-7B-Instruct-v0.1\n",
      "# Example summarization dataset with 10k examples for training with an average of 2.2k tokens per sample. \n",
      "# Make sure to replace `train_path` and `valid_path` with the path to the files you generated\n",
      "train_path: s3://air-example-data/preference-tuning-summarization/train.jsonl\n",
      "valid_path: s3://air-example-data/preference-tuning-summarization/valid.jsonl\n",
      "\n",
      "task: \"preference_tuning\"\n",
      "context_length: 4096\n",
      "# For DPO, it is recommended to set a high `num_data_blocks_per_device` to not bottleneck the logp processor.\n",
      "num_data_blocks_per_device: 32\n",
      "# Runs training on 6 GPUs\n",
      "num_devices: 6\n",
      "train_batch_size_per_device: 2\n",
      "eval_batch_size_per_device: 2\n",
      "learning_rate: 5e-6\n",
      "num_epochs: 3\n",
      "no_gradient_checkpoint: False\n",
      "output_dir: /mnt/local_storage/\n",
      "# Deepspeed configuration, you can provide your own deepspeed setup\n",
      "deepspeed:\n",
      "  config_path: configs/zero_3.json\n",
      "worker_resources:\n",
      "  accelerator_type:A10G: 1\n",
      "flash_attention_2: True\n",
      "padding: \"longest\"\n",
      "preference_tuning_config:\n",
      "  beta: 0.01\n",
      "  logprob_processor_scaling_config:\n",
      "    custom_resources:\n",
      "      accelerator_type:A10G: 1 # custom resource per worker.\n",
      "    # Runs reference model logp calculation on 4 GPUs\n",
      "    concurrency: 4\n",
      "    batch_size: 2\n",
      "lora_config:\n",
      "  r: 8\n",
      "  lora_alpha: 16\n",
      "  lora_dropout: 0.05\n",
      "  target_modules:\n",
      "    - q_proj\n",
      "    - k_proj\n",
      "    - v_proj\n",
      "    - o_proj\n",
      "    - gate_proj\n",
      "    - up_proj\n",
      "    - down_proj\n",
      "  modules_to_save: []\n",
      "  bias: \"none\"\n",
      "  fan_in_fan_out: false\n",
      "  init_lora_weights: true\n"
     ]
    }
   ],
   "source": [
    "!cat configs/mistral_dpo_summarization.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can fine-tune the model now by submitting it as an Anyscale job: \n",
    "\n",
    "```bash\n",
    "anyscale job submit configs/jobs/mistral_dpo_job.yaml\n",
    "```\n",
    "\n",
    "This should take about 8 hours. \n",
    "\n",
    "üí° INSIGHT: This fine-tuning job inherits the compute configuration of the current workspace - meaning the job runs on a CPU-only head node with auto-scaling enabled. Sometimes, the nodes you get with auto-scaling can be in-efficient for fine-tuning due to inter-node communication costs (Say you get 2 4xA10 nodes instead of 8xA10s due to availability). You can explicitly set the compute configuration for the job with a set number of worker nodes to avoid this. More on compute configurations here: https://docs.anyscale.com/configuration/compute-configuration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Evaluation\n",
    "\n",
    "Let's evaluate our trained model. Here we'll use two baselines: (1) the base model before finetuning (reference model in DPO) and (2) GPT-4o.\n",
    "\n",
    "## Evaluation strategy\n",
    "\n",
    "Our evaluation strategy involves the same Q&A scoring system as used while generating the preference data. \n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"./assets/eval.png?\" alt=\"Evaluation\" width=800>\n",
    "</p>\n",
    "\n",
    "We evaluate the baseline model and the trained DPO model on the test set. \n",
    "\n",
    "## Obtain summaries on the test set\n",
    "First, we'll need to obtain the summaries (and scores) for both the models on the given test set. \n",
    "\n",
    "For the baseline model, you can simply run the below command:\n",
    "```bash\n",
    "anyscale job submit -f configs/jobs/8b_judge/generate_summaries_eval_baseline_job.yaml\n",
    "# Optional: use the 70b model for better performance (runs on A100s)\n",
    "# anyscale job submit -f configs/jobs/70b_judge/generate_summaries_eval_baseline_job.yaml \n",
    "```\n",
    "\n",
    "This should take ~10 min for the 8B model and the 70B model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the fine-tuned DPO model, we provide a dummy config in [configs/summary_generation/8b_judge/mistral_finetuned_eval.yaml](configs/summary_generation/8b_judge/mistral_finetuned_eval.yaml). If you used the default training config provided, the model would be trained using LoRA and you should have a path to the LoRA weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode: eval\n",
      "input_folder: s3://air-example-data/preference-tuning-summarization-example/qa_generation/qa_annotations_full_test\n",
      "inference_type: offline\n",
      "model_inference_config:\n",
      "  # Modify with s3 link to full param weights if you did full-param training\n",
      "  model_id_or_path: mistralai/Mistral-7B-Instruct-v0.1\n",
      "\n",
      "  # Add path to lora weights here. If you did full param training, you can instead remove this field.\n",
      "  adapter_id_or_path: s3://large-dl-models-mirror/finetuning_template/mistral_dpo_summarization_lora\n",
      "\n",
      "  temperature: 0\n",
      "  top_p: 0.95\n",
      "  scaling_config:\n",
      "    batch_size: 64\n",
      "    concurrency: 2\n",
      "    num_gpus_per_instance: 2\n",
      "    accelerator_type: A10G\n",
      "num_generations: 1\n",
      "judge_inference_config:\n",
      "  model_id_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct\n",
      "  temperature: 0\n",
      "  scaling_config:\n",
      "    batch_size: 64\n",
      "    concurrency: 3\n",
      "    num_gpus_per_instance: 2\n",
      "    accelerator_type: A10G\n",
      "num_mcq_questions: 5\n"
     ]
    }
   ],
   "source": [
    "!cat configs/summary_generation/8b_judge/mistral_finetuned_eval.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " üîÑ REPLACE the `adapter_id_or_path` entry in the config with the path to your LoRA weights before proceeding (if you used the fine-tuning defaults). Alternatively, make sure to replace `model_id_or_path` entry (and remove the `adapter_id_or_path` entry) if you did full-param fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to evaluate our fine-tuned model: \n",
    "\n",
    "> **NOTE**: Make sure to add your `WANDB_API_KEY` as an environment variable in the dependencies tab if you wish to track progress of your run on WandB.\n",
    "\n",
    "```bash\n",
    "anyscale job submit -f configs/jobs/8b_judge/generate_summaries_eval_finetuned_job.yaml\n",
    "# Optional: use the 70b model for better performance (runs on A100s)\n",
    "# anyscale job submit -f configs/jobs/70b_judge/generate_summaries_eval_finetuned_job.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the logs for the above jobs, you should see the final path to the output summaries for both the models. \n",
    "\n",
    "Optionally, you can also obtain the summaries and scores for the `gpt-4o` model from OpenAI. Simply run: \n",
    "\n",
    "```bash\n",
    "anyscale job submit -f configs/jobs/8b_judge/generate_summaries_eval_gpt_job.yaml\n",
    "# Optional: use the 70b model for better performance (runs on A100s)\n",
    "# anyscale job submit -f configs/jobs/70b_judge/generate_summaries_eval_gpt_job.yaml\n",
    "```\n",
    "\n",
    "This should take about ~10 min for the 8B model and the 70B model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Evaluation Statistics\n",
    "\n",
    "We've provided a convenient script [get_eval_stats.py](src/scripts/get_eval_stats.py) to get evaluation statistics and obtain the \"win rate\" of the DPO model (the percentage of times the DPO model performs better than the baseline). We've provided an example configuration below. \n",
    "\n",
    "```bash \n",
    "# make sure to substitute -outputs-path with your path\n",
    "python src/scripts/get_eval_stats.py --outputs-path s3://air-example-data/preference-tuning-summarization-example/summary_generation_dpo_model/test/ --baseline-outputs-path s3://air-example-data/preference-tuning-summarization-example/summary_generation_base/test/  \n",
    "\n",
    "# (Optional): if you obtained results for GPT-4o, you should uncomment and run the following command instead\n",
    "# python src/scripts/get_eval_stats.py --outputs-path s3://air-example-data/preference-tuning-summarization-example/summary_generation_dpo_model/test/ --baseline-outputs-path s3://air-example-data/preference-tuning-summarization-example/summary_generation_base/test/  --gpt4o-outputs-path <add-path-to-gpt4o-results>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the following results for the 70B model:\n",
    "\n",
    "```text \n",
    "‚ïí‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï§‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïï\n",
    "‚îÇ           Metric            ‚îÇ   Model   ‚îÇ  Baseline  ‚îÇ  GPT-4o   ‚îÇ\n",
    "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
    "‚îÇ        Accuracy >=3         ‚îÇ 65.4286 % ‚îÇ 43.0476 %  ‚îÇ 37.2381 % ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ        Accuracy >=4         ‚îÇ 25.7143 % ‚îÇ 13.5238 %  ‚îÇ 10.0000 % ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ     Median Compression      ‚îÇ 11.5794 % ‚îÇ 12.7316 %  ‚îÇ 8.0496 %  ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ      Mean Compression       ‚îÇ 13.0029 % ‚îÇ 14.3444 %  ‚îÇ 9.3554 %  ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ      Summary Too Long       ‚îÇ 0.0000 %  ‚îÇ  0.0000 %  ‚îÇ 0.0000 %  ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ Contains Invalid Characters ‚îÇ 0.0000 %  ‚îÇ  0.0952 %  ‚îÇ 0.0000 %  ‚îÇ\n",
    "‚ïò‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïß‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïõ\n",
    "\n",
    "\n",
    "Model Win Rate against Baseline: 74.0000 %\n",
    "GPT-4o Win Rate against Baseline: 64.8095 %\n",
    "```\n",
    "\n",
    "Our fine-tuned model is able to generate much better summaries, that are more concise (compression ratio is lower) with lesser out-of-distribution characters (gibberish tokens) than the baseline. You can see more details on the same in our blog!\n",
    "\n",
    "| **NOTE:** The evaluation results will differ if you used the 8B model which is less capable as a LLM-judge (and thus the numbers can be less accurate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congrats! You have now fine-tuned an open source model on preference data. As a quick recap, here's what we demonstrated in this notebook:\n",
    "1. Synthetically generating preference data for DPO \n",
    "2. DPO fine-tuning of a language model on the Anyscale Platform\n",
    "4. Evaluating the model against the baseline and GPT-4o, and analysing the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
