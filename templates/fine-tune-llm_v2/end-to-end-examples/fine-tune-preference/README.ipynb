{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preference Tuning for Summarization using Synthetic Data\n",
    "\n",
    "**⏱️ Time to complete**:\n",
    "\n",
    "Preference tuning is a powerful tool that can optimize LLMs towards complex preferences that can not easily captured through supervised fine-tuning. However, manually annotating preferences between model outputs using human raters can be extremely time-consuming and expensive. In this example, we demonstrate how preference data can be synthetically generated by leveraging larger LLMs to score a model's outputs.\n",
    "\n",
    "\n",
    "We will focus on the task of summarization for the [CNN/DailyMail](https://huggingface.co/datasets/abisee/cnn_dailymail) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Data Preprocessing](#step-1-data-preprocessing): In this section we cover how we can prepare preference data for the summarization task using an LLM-as-a-judge.\n",
    "2. [DPO Finetuning](#step-2-fine-tuning): This section will cover how you can fine-tune an open source model on the preference data on the Anyscale platform.\n",
    "3. [Evaluation](#step-3-evaluation): The section will lay down a blue-print for evaluation and compare performance to that of closed source models like OpenAI's GPT-4.\n",
    "4. [Iterative-DPO](#step-4-iterative): An optional step to further boost performance with iterative preference-tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make the necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import datasets\n",
    "import openai\n",
    "\n",
    "import ray.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9cd1f30ac9495299dc17033953a370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0190fd3dfba4810bba16985d36f5342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c4d81e5eed4b6099536c5eb608bd8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f7df3644034110b3ea3d3d863b2466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/259M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9fc197f2b45429a9d15d0c8d1469cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/34.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418270b995494c05b8eb5d1ed9434f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/30.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d039875a81d444b972289c26d429777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc7b2cdd28e4456a2466a3959af7149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847a2b74b1fd4af6bb98a49b048a193f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378cd23005d94055b389e12a41b7a2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf1a0d1cc2d4f17a9547b97386ce14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2241a79f57854e5a9486a050b957a15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/257M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7899d09f0ea2492980ad2adde6919b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/259M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b706e4c599a4da6a9c6c7af806e9c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/34.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8257f520a49d45b38d2f598943a8fd64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/30.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db13122fd3a4cf98b0f3510b9ee10ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb36cf661534df6ab1a7f87b7d3cdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9464e312f3c74edf89bc4b1aafa0828d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 11:11:41,594\tINFO worker.py:1596 -- Connecting to existing Ray cluster at address: 10.0.4.151:6379...\n",
      "2024-08-09 11:11:41,601\tINFO worker.py:1772 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-m4a38rehf7miww178mefsrumy2.i.anyscaleuserdata.com \u001b[39m\u001b[22m\n",
      "2024-08-09 11:11:41,603\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_571a453227fe1f71a0db8d4c7877fab901d9fc29.zip' (0.10MiB) to Ray cluster...\n",
      "2024-08-09 11:11:41,604\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_571a453227fe1f71a0db8d4c7877fab901d9fc29.zip'.\n",
      "2024-08-09 11:11:49,781\tINFO dataset.py:2416 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
      "2024-08-09 11:11:49,784\tINFO streaming_executor.py:108 -- Starting execution of Dataset. Full logs are in /tmp/ray/session_2024-08-09_10-34-55_275931_2296/logs/ray-data\n",
      "2024-08-09 11:11:49,785\tINFO streaming_executor.py:109 -- Execution plan of Dataset: InputDataBuffer[Input] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3daffc123143729be380f2b3bb6c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 1: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730acc5e68be479d8c10ca46308b456e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0 bundle [00:00, ? bundle/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(autoscaler +1h53m32s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n"
     ]
    }
   ],
   "source": [
    "hf_ds = datasets.load_dataset(\"abisee/cnn_dailymail\", '3.0.0', split=\"train\").shuffle(seed=21)\n",
    "# extract a subset of 20000 articles\n",
    "hf_ds_subset =  hf_ds.select(range(20000))\n",
    "\n",
    "ray_ds = ray.data.from_huggingface(hf_ds_subset)\n",
    "raw_example = ray_ds.take(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Article Questions\n",
    "\n",
    "For each article, we need to generate 5 multiple choice questions using Llama-70B-Instruct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'article': 'Scam: Lisa Harrison, 34, promised customers low currency rates on US dollars and '\n",
      "            'special deals . A wedding planner who stole £80,000 from couples in a bid to satisfy '\n",
      "            \"an 'out-of-control' online gambling addiction has been jailed. Lisa Harrison, 34, \"\n",
      "            'began taking money from her clients in summer 2013 by enticing them with low currency '\n",
      "            'rates on US dollars and flight upgrades. She took money from 19 couples who had '\n",
      "            'entrusted their savings to her after being promised the wedding of their dreams. It '\n",
      "            'is understood that the company she worked for, iPlan New York, specialised in '\n",
      "            'weddings in New York City. Her website iplannewyork.com, which has been taken down, '\n",
      "            \"said: 'iPlan New York was set up to create and style the perfect tailor made wedding \"\n",
      "            \"for couples travelling to New York to get married! 'We are passionate about what we \"\n",
      "            'do and passionate about New York! We have experience in planning NYC weddings for '\n",
      "            \"couples from all over the world.' But she was arrested in December last year after \"\n",
      "            'eventually coming clean to her victims in an email and saying she had been forced to '\n",
      "            'close her business. Police soon found she had taken £80,107 from the couples and '\n",
      "            'spent a staggering £77,933 on gambling sites Paddy Power and William Hill. The '\n",
      "            \"business' Facebook page has also been deleted, but outraged victims have shared their \"\n",
      "            \"victims on a wedding forum. One victim called Jennifer wrote in November 2013: 'I had \"\n",
      "            'previously given Lisa a positive review because our vow renewal went wonderful. '\n",
      "            \"'Little did I know until last week that she didn't even pay the vendors that helped \"\n",
      "            \"with our ceremony. 'I am so disgusted and can't fathom such an act. We paid her in \"\n",
      "            \"full and to think that our photographer didn't even get paid is just astonishing to \"\n",
      "            \"me. 'I feel so horrible for the other couples that had their perfect day planned and \"\n",
      "            \"this woman decided to perform such an act. 'I pray for each of you in hopes that you \"\n",
      "            'will be able to move on from this and live a healthy and happy life with your '\n",
      "            \"significant other. 'I can't believe this woman took our money and did such an \"\n",
      "            \"unthinkable act. God bless all of you and I hope this mess gets corrected quickly.' \"\n",
      "            'While another anonymous victim posted a copy of the email they claim they had been '\n",
      "            \"sent by Harrison when she admitted the scam. It read: 'I have to announce the closure \"\n",
      "            \"of iPlan New York. 'For some time now I have been battling against a gambling \"\n",
      "            'addiction that has seen me lose all of the company money including money paid to me '\n",
      "            \"by you for services and dollars. 'I cannot go on another day with this situation as \"\n",
      "            'this illness has taken me over completely and I have to both face up to the '\n",
      "            \"consequences of my actions and seek help for the debilitating addiction. 'I am \"\n",
      "            \"extremely ill with it and need to seek help as soon as possible. 'I am completely \"\n",
      "            'devastated that not only have I lost money of yours but betrayed your trust as a '\n",
      "            \"wedding planner. 'Right now I am uncertain as to what the future holds with regards \"\n",
      "            'to future weddings already planned, I will be in touch with the suppliers in NYC to '\n",
      "            'inform them also. Sentence: Harrison, of Earith, Cambridgeshire, was jailed for two '\n",
      "            \"years at Peterborough Crown Court, above . 'I will today be having my computer and \"\n",
      "            'all electronic devices ceased (sic) under an intervention and handing myself into the '\n",
      "            \"police to give a statement and to tell them everything. 'No doubt you will be \"\n",
      "            'informing the police too and for those purposes it will be the Cambridgeshire '\n",
      "            'Constabulary and my full name is Lisa Harrison and I will be handing myself in after '\n",
      "            \"sending these emails. 'I won’t be able to reply to any emails or calls for the time \"\n",
      "            \"being as I will not have access. 'I am truly from the bottom of my heart so sorry for \"\n",
      "            'everything, as with addictions I thought I had everything under control and was in '\n",
      "            'denial that I could put everything right, which I have been trying so desperately to '\n",
      "            \"do. 'As soon as and if I am able to communicate further about any outstanding issues \"\n",
      "            \"I will do so. Lisa.' Posting on an online review site for the wedding service, one \"\n",
      "            \"former customer said: 'We are due to go in less than 48 hours and we have nothing!! \"\n",
      "            \"She has now closed down her website too! She has left us devastated!' Another, using \"\n",
      "            \"the name Shaun, wrote: 'Alarm bells rang for me when she asked for all our spending \"\n",
      "            'money cos she had a deal on a currency card. While one woman, using the name Andrea, '\n",
      "            \"said: 'I am absolutely devastated for anyone who has used iPlan New York and \"\n",
      "            \"subsequently been let down'. She added that she had a 'gut feeling' not to pay \"\n",
      "            'upfront. Harrison, of Earith, Cambridgeshire, admitted fraudulent trading and was '\n",
      "            'jailed for two years at Peterborough Crown Court on Tuesday. Det Sgt Iain Moor, from '\n",
      "            \"Cambridgeshire Constabulary, said: 'This was an extremely distressing case for the 19 \"\n",
      "            \"couples who lost life savings and had their dream day ruined by Harrison. 'I hope the \"\n",
      "            'victims received some comfort in the prison sentence imposed on Harrison, meaning '\n",
      "            \"they can now start to re-build their lives.'\",\n",
      " 'highlights': 'Lisa Harrison enticed clients with low currency rates and flight upgrades .\\n'\n",
      "               'She took money from 19 couples who were promised dream weddings .\\n'\n",
      "               'Harrison spent nearly £78,000 on gambling sites including Paddy Power .\\n'\n",
      "               'She admitted the scam to victims in an email before handing herself in .\\n'\n",
      "               \"Outraged victims say they are 'disgusted' and have been left 'devastated'\\n\"\n",
      "               \"In email Harrison says she will 'seek help for the debilitating addiction'\\n\"\n",
      "               'She admitted fraudulent trading and was jailed for two years on Tuesday .',\n",
      " 'id': '4feb82c680166f0b8f90bf3a6f9779b04f229325'}\n"
     ]
    }
   ],
   "source": [
    "import pprint \n",
    "pprint.pprint(raw_example, width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data pre-processing is going to look as follows: \n",
    "\n",
    "![preprocessing](./assets/preprocessing.png?1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Instructions for pre-processing\n",
    "\n",
    "\\<We have the relevant preprocessing code in `utils/generate_questions.py` and `utils/generate_summaries.py`. You can run data generation as an Anyscale job with configs/generate_questions_job.yaml and configs/generate_summaries_job.yaml.\\>\n",
    "\n",
    "\\<After preprocessing, here's an example for the Q&A generated by Llama 70B and here's an example for the summaries generated by Mistral 7B Instruct \\>\n",
    "\n",
    "\n",
    "\\<We sample chosen and rejected messages from the summaries based on the Q&A Accuracy score. We use a threshold of 3/5 for classifying examples as 'chosen' and 'rejected'. Here's an example training dataset sample for the DPO model\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Fine-tuning\n",
    "\n",
    "Now that we have the pre-processed dataset, we are ready to fine-tune `Mistral-7B-Instruct-v0.1` using DPO. On Anyscale, we've created an easy-to-use interface to do preference-tuning using `DPO`. We leverage Ray to overlap reference model log-probability calculation with model training to improve GPU utilization. Most implementations compute log probabilities synchronously with model training,\n",
    "\n",
    "![hf model](assets/hf_dpo.png)\n",
    "\n",
    "While our implementation using Ray is asynchronous:  \n",
    "\n",
    "\n",
    "![assistant model](assets/anyscale_dpo.png)\n",
    "\n",
    "Further, our use of Ray Data also implies that the compute configuration for the reference model can be completely decoupled with the policy model. For example, reference model calculation can run on a different node with zero code changes needed. \n",
    "\n",
    "\n",
    "To get started with DPO training, we provide the config for DPO in [configs/mistral_dpo_summarization.yaml](configs/mistral_dpo_summarization.yaml) . \n",
    "\n",
    "\n",
    "TODO: The provided config uses 6 and 2 A10s and doesn't utilize GPUs properly. We should improve logprob processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id: mistralai/Mistral-7B-Instruct-v0.1\n",
      "# Example summarization dataset with 10k examples for training with an average of 2.2k tokens per sample\n",
      "train_path: s3://air-example-data/preference-tuning-summarization/train.jsonl\n",
      "valid_path: s3://air-example-data/preference-tuning-summarization/valid.jsonl\n",
      "task: \"preference_tuning\"\n",
      "context_length: 4096\n",
      "# For DPO, it is recommended to set a high `num_data_blocks_per_device` to not bottleneck the logp processor.\n",
      "# We recommend not going beyond 20 so as to not spawn too many Ray actors. \n",
      "num_data_blocks_per_device: 16\n",
      "num_devices: 6 # <--- runs training on 6 GPUs\n",
      "train_batch_size_per_device: 2\n",
      "eval_batch_size_per_device: 2\n",
      "learning_rate: 5e-6\n",
      "num_epochs: 3\n",
      "no_gradient_checkpoint: False\n",
      "output_dir: /mnt/local_storage/\n",
      "deepspeed:\n",
      "  config_path: deepspeed_configs/zero_3.json\n",
      "worker_resources:\n",
      "  accelerator_type:A10G: 1\n",
      "flash_attention_2: True\n",
      "padding: \"longest\"\n",
      "preference_tuning_config:\n",
      "  beta: 0.01\n",
      "  logprob_processor_scaling_config:\n",
      "    custom_resources:\n",
      "      accelerator_type:A10G: 1\n",
      "    concurrency: 2 # <--- runs reference model logp calculation on 2 GPUs\n",
      "    batch_size: 2\n",
      "lora_config:\n",
      "  r: 8\n",
      "  lora_alpha: 16\n",
      "  lora_dropout: 0.05\n",
      "  target_modules:\n",
      "    - q_proj\n",
      "    - k_proj\n",
      "    - v_proj\n",
      "    - o_proj\n",
      "    - gate_proj\n",
      "    - up_proj\n",
      "    - down_proj\n",
      "  modules_to_save: []\n",
      "  bias: \"none\"\n",
      "  fan_in_fan_out: false\n",
      "  init_lora_weights: true"
     ]
    }
   ],
   "source": [
    "!cat configs/mistral_dpo_summarization.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!llmforge anyscale finetune end-to-end-examples/fine-tune-preference/configs/mistral_dpo_summarization.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Evaluation\n",
    "\n",
    "Let's evaluate our trained model. Here we'll use two baselines: (1) the base model before finetuning (reference model in DPO) and (2) GPT-4o.\n",
    "\n",
    "## Evaluation strategy\n",
    "\n",
    "Our evaluation strategy involves the same Q&A scoring system as used while generating the preference data. \\<TODO: Add more here\\>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Iterative-DPO (optional)\n",
    "\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
