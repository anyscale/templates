# Preference Tuning for Summarization using Synthetic Data

**â±ï¸ Time to complete**: \<TODO\>

Preference tuning is a powerful tool that can optimize LLMs towards complex preferences that cannot easily captured through supervised fine-tuning. However, manually annotating preferences between model outputs using human raters can be extremely time-consuming and expensive. Instead, synthetic preference data can be generated by scoring responses with large foundation models, allowing for much cheaper and scalable data collection!

Here we'll go through an end-to-end example for preference tuning of an open-source language model with synthetic data, covering scalable methodologies for data preprocessing, fine-tuning and evaluation, using Ray. 

We will focus on the task of summarization for the [CNN/DailyMail](https://huggingface.co/datasets/abisee/cnn_dailymail) dataset. 

# Table of Contents
1. [Data Preprocessing](#step-1-data-preprocessing): In this section we cover how we can prepare preference data for the summarization task using an LLM-as-a-judge. 
2. [DPO Finetuning](#step-2-fine-tuning): This section will cover how you can fine-tune an open source model on the preference data on the Anyscale platform.
3. [Evaluation](#step-3-evaluation): The section will lay down a blue-print for evaluation and compare performance to that of closed source models like OpenAI's GPT-4.

First, let's make the necessary imports


```python
import os
import datasets

import ray.data

import pprint
import textwrap

os.environ["PYTHONPATH"] = f"{os.environ.get('PYTHONPATH', '')}:src"
```

# Step 1: Synthetic Data Generation

First, let's inspect the training dataset and look at an example. 


```python
hf_ds = datasets.load_dataset("abisee/cnn_dailymail", "3.0.0", split="train").shuffle(
    seed=21
)
# extract a subset of 20000 articles
hf_ds_subset = hf_ds.select(range(20000))

ray_ds = ray.data.from_huggingface(hf_ds_subset)
raw_example = ray_ds.take(1)[0]
```


```python
pprint.pprint(raw_example, width=80)
```

    {'article': 'Scam: Lisa Harrison, 34, promised customers low currency rates on '
                'US dollars and special deals . A wedding planner who stole '
                "Â£80,000 from couples in a bid to satisfy an 'out-of-control' "
                'online gambling addiction has been jailed. Lisa Harrison, 34, '
                'began taking money from her clients in summer 2013 by enticing '
                'them with low currency rates on US dollars and flight upgrades. '
                'She took money from 19 couples who had entrusted their savings to '
                'her after being promised the wedding of their dreams. It is '
                'understood that the company she worked for, iPlan New York, '
                'specialised in weddings in New York City. Her website '
                "iplannewyork.com, which has been taken down, said: 'iPlan New "
                'York was set up to create and style the perfect tailor made '
                "wedding for couples travelling to New York to get married! 'We "
                'are passionate about what we do and passionate about New York! We '
                'have experience in planning NYC weddings for couples from all '
                "over the world.' But she was arrested in December last year after "
                'eventually coming clean to her victims in an email and saying she '
                'had been forced to close her business. Police soon found she had '
                'taken Â£80,107 from the couples and spent a staggering Â£77,933 on '
                "gambling sites Paddy Power and William Hill. The business' "
                'Facebook page has also been deleted, but outraged victims have '
                'shared their victims on a wedding forum. One victim called '
                "Jennifer wrote in November 2013: 'I had previously given Lisa a "
                "positive review because our vow renewal went wonderful. 'Little "
                "did I know until last week that she didn't even pay the vendors "
                "that helped with our ceremony. 'I am so disgusted and can't "
                'fathom such an act. We paid her in full and to think that our '
                "photographer didn't even get paid is just astonishing to me. 'I "
                'feel so horrible for the other couples that had their perfect day '
                "planned and this woman decided to perform such an act. 'I pray "
                'for each of you in hopes that you will be able to move on from '
                'this and live a healthy and happy life with your significant '
                "other. 'I can't believe this woman took our money and did such an "
                'unthinkable act. God bless all of you and I hope this mess gets '
                "corrected quickly.' While another anonymous victim posted a copy "
                'of the email they claim they had been sent by Harrison when she '
                "admitted the scam. It read: 'I have to announce the closure of "
                "iPlan New York. 'For some time now I have been battling against a "
                'gambling addiction that has seen me lose all of the company money '
                "including money paid to me by you for services and dollars. 'I "
                'cannot go on another day with this situation as this illness has '
                'taken me over completely and I have to both face up to the '
                'consequences of my actions and seek help for the debilitating '
                "addiction. 'I am extremely ill with it and need to seek help as "
                "soon as possible. 'I am completely devastated that not only have "
                'I lost money of yours but betrayed your trust as a wedding '
                "planner. 'Right now I am uncertain as to what the future holds "
                'with regards to future weddings already planned, I will be in '
                'touch with the suppliers in NYC to inform them also. Sentence: '
                'Harrison, of Earith, Cambridgeshire, was jailed for two years at '
                "Peterborough Crown Court, above . 'I will today be having my "
                'computer and all electronic devices ceased (sic) under an '
                'intervention and handing myself into the police to give a '
                "statement and to tell them everything. 'No doubt you will be "
                'informing the police too and for those purposes it will be the '
                'Cambridgeshire Constabulary and my full name is Lisa Harrison and '
                "I will be handing myself in after sending these emails. 'I wonâ€™t "
                'be able to reply to any emails or calls for the time being as I '
                "will not have access. 'I am truly from the bottom of my heart so "
                'sorry for everything, as with addictions I thought I had '
                'everything under control and was in denial that I could put '
                'everything right, which I have been trying so desperately to do. '
                "'As soon as and if I am able to communicate further about any "
                "outstanding issues I will do so. Lisa.' Posting on an online "
                'review site for the wedding service, one former customer said: '
                "'We are due to go in less than 48 hours and we have nothing!! She "
                "has now closed down her website too! She has left us devastated!' "
                "Another, using the name Shaun, wrote: 'Alarm bells rang for me "
                'when she asked for all our spending money cos she had a deal on a '
                "currency card. While one woman, using the name Andrea, said: 'I "
                'am absolutely devastated for anyone who has used iPlan New York '
                "and subsequently been let down'. She added that she had a 'gut "
                "feeling' not to pay upfront. Harrison, of Earith, Cambridgeshire, "
                'admitted fraudulent trading and was jailed for two years at '
                'Peterborough Crown Court on Tuesday. Det Sgt Iain Moor, from '
                "Cambridgeshire Constabulary, said: 'This was an extremely "
                'distressing case for the 19 couples who lost life savings and had '
                "their dream day ruined by Harrison. 'I hope the victims received "
                'some comfort in the prison sentence imposed on Harrison, meaning '
                "they can now start to re-build their lives.'",
     'highlights': 'Lisa Harrison enticed clients with low currency rates and '
                   'flight upgrades .\n'
                   'She took money from 19 couples who were promised dream '
                   'weddings .\n'
                   'Harrison spent nearly Â£78,000 on gambling sites including '
                   'Paddy Power .\n'
                   'She admitted the scam to victims in an email before handing '
                   'herself in .\n'
                   "Outraged victims say they are 'disgusted' and have been left "
                   "'devastated'\n"
                   "In email Harrison says she will 'seek help for the "
                   "debilitating addiction'\n"
                   'She admitted fraudulent trading and was jailed for two years '
                   'on Tuesday .',
     'id': '4feb82c680166f0b8f90bf3a6f9779b04f229325'}


Now, we need to get preference data for pairs of summaries generated from the same article. Traditionally, this would involve generating summaries using the base model you wish to fine-tune and asking human annotators to provide a rating for each sample. In this example, we will employ a _synthetic_ summary scoring method using an LLM as a judge. We score the correctness of a summary using the following metrics:

**Summary Scoring Metrics**
1. Multiple choice Q&A accuracy:
    - Given the original text, we use an LLM judge to generate 5 multiple choice questions about the text.
    - We then ask the LLM judge to answer the questions using only the summary, and record the number of questions correctly answered.
2. Word count: We simply count the number of words in the summary.

This allows us to construct a simple preference function between two summaries:

**Preference Function**
1. If both summary responses attain more than 3/5 multiple choice questions correct, we will prefer the shorter response. We do not care about Q&A accuracy beyond 3 correct answers, since the summary should not contain all information from the text.
2. Otherwise, we select the response that leads to more correctly answered multiple choice questions.

To generate the preference pairs, we will generate 10 summaries from each article using the model we wish to fine-tune. Then, we will randomly sample pairs of summaries and use our preference function to annotate the preference between them.

For this example, we will use `Mistral-7B-Instruct-v0.1` as the base model to fine-tune and `Llama-3.1-70B-Instruct` as a judge. Note that mistral-instruct is already instruction tuned, so that given a prompt to do summarization it might do a good job, but it may not be aligned with how we want the summarization to look like. We can use preference data to further align the instruct variant towards our specific needs.

Combining all this together, our data pre-processing pipeline is going to look as follows: 

![preprocessing](./assets/preprocessing.png?1)

### Generate Multiple Choice Questions from Articles

First, we will generate the multiple choice questions and answers for each article using `Llama-3.1-70B-Instruct`. Leveraging vLLM and Ray, we can very easily scale this generation process across multiple GPUs.


>  **_NOTE:_**  We provide two sets of configs: One with a 8B parameter model as the judge, and another with the 70B model. Using the 8B model is recommended for quicker runtimes, since we make use of highly available A10Gs. For good performance, and to replicate the results in our blog, you should use the 70B judge model which uses A100s.

The following command will run the [src/scripts/generate_questions.py](./src/scripts/generate_questions.py) script, which generates the questions and answers and saves them in `.parquet` files.


```python
!anyscale job submit -f configs/jobs/8b_judge/generate_questions_job.yaml
# Optional: use the 70b model for better performance (runs on A100s)
# !anyscale job submit -f configs/jobs/70b_judge/generate_questions_job.yaml
```

    [1m[36mOutput[0m[0m
    [0m[1m[36m(anyscale +1.4s)[0m [0m[0m[0m[0mSubmitting job with config JobConfig(name='preference-tuning-summarization-question-generation', image_uri='localhost:5555/anyscale/endpoints_aica:0.5.0-6402', compute_config=None, env_vars=None, py_modules=None, cloud=None, project=None, ray_version=None, job_queue_config=None).[0m
    [0m[1m[36m(anyscale +3.6s)[0m [0m[0m[0m[0mUsing workspace runtime dependencies env vars: {'WANDB_API_KEY': 'cbc4aed2de2d9c9acb21324a3297b85b7299479b'}.[0m
    [0m[1m[36m(anyscale +3.6s)[0m [0m[0m[0m[0mUploading local dir '.' to cloud storage.[0m
    [0m[1m[36m(anyscale +5.0s)[0m [0m[0m[0m[0mIncluding workspace-managed pip dependencies.[0m
    [0m[1m[36m(anyscale +5.6s)[0m [0m[0m[0m[0mJob 'preference-tuning-summarization-question-generation' submitted, ID: 'prodjob_sdaruzx8uu3c2bu3x5dn6gpf77'.[0m
    [0m[1m[36m(anyscale +5.6s)[0m [0m[0m[0m[0mView the job in the UI: https://console.anyscale.com/jobs/prodjob_sdaruzx8uu3c2bu3x5dn6gpf77[0m
    [0m[1m[36m(anyscale +5.6s)[0m [0m[0m[0m[0mUse `--wait` to wait for the job to run and stream logs.[0m
    [0m[0m

At the end of the job, you should see the remote path to the folder with Q&A. Make sure to make note to use it for the next steps! 


```python
# Replace this with the link to the output folder from the previous job
qa_folder = "s3://air-example-data/preference-tuning-summarization-example/qa_generation/qa_annotations_full_train/"
qa_ds = ray.data.read_parquet(qa_folder)
# The dataset is small, we can materalize it
example_rows = qa_ds.materialize().take(3)
```


```python
from src.utils.models import DataSchema

for row in example_rows:
    print("TEXT:")
    print(textwrap.fill(row[DataSchema.ARTICLE], width=80))
    print("QUESTIONS:")
    print(textwrap.fill(row[DataSchema.MCQ_QUESTIONS], width=80))
    print("ANSWERS:")
    print(textwrap.fill(str(row[DataSchema.GROUND_TRUTH_MCQ_ANSWERS]), width=80))
    pprint.pprint("=" * 100, width=80)
```

    TEXT:
    (RollingStone.com) -- Jennifer Lawrence, the 20-year-old Oscar nominee for Best
    Actress, is sitting in a fancy Manhattan hotel sipping tea and feeling a little
    out of place. See, she grew up in Louisville, Kentucky, where her dad owned a
    construction company and her mom ran a summer camp. They had land and horses.
    She loved to fish. She was a total tomboy: field hockey, softball, basketball on
    an all-boys team. ("I was so dykey.") One of her nicknames was Nitro. She lives
    in Los Angeles now, but "little redneck things still come out." Like what? "I'm
    attracted to my brother. Stuff like that." 10 Best Movies of 2010 . At 14, she
    decided she wanted to be an actress and dragged her mom to New York for
    auditions. The people at Reese's Peanut Butter Cups told her she was the best
    they'd ever seen. Her mom told her they were lying. (Her mom didn't like showbiz
    much.) She auditioned for the role of Bella in "Twilight," which would have been
    perfect if Bella were a badass, but since she's a frightened waif, Lawrence
    ended up not getting the part. Which was for the best because the role she did
    get was for "Winter's Bone," in which she's fantastic: harrowing and tender as
    the 17-year-old daughter of an Ozarks meth-cooker who's fighting to take care of
    her little brother and sister. This article appears in the February 17, 2011
    issue of Rolling Stone. The issue is available now on newsstands and will appear
    in the online archive February 4. To prep for the part, Lawrence learned how to
    shoot a gun and field-dress squirrels. She already knew how to chop wood: "I
    went through a wood-chopping phase when I was nine or 10." She says she hasn't
    even bothered preparing an Oscar speech: "I have been practicing my losing face,
    though. Do you want to see it?" (For the record, it's a very good losing face.)
    Peter Travers Reviews 'Winter's Bone' Later this year comes "X-Men: First
    Class," where she'll play the mutant Mystique, blue-skinned and topless. ("Did I
    feel naked being naked?" she asks, so you don't have to. "Yeah. Totally.") But
    before that there's Jodie Foster's "The Beaver," premiering in May, in which she
    appears alongside a certifiable Mel Gibson. Which means she has some crazy Mel
    Gibson stories, right? She leans in close. "If I say, 'Off the record' -- that
    means you can't print it, right?' " Right. "OK. So, off the record ..." She's
    learning. Photos: 2011 Screen Actors Guild Award Winners . Copyright Â© 2011
    Rolling Stone.
    QUESTIONS:
    Q1) Where did Jennifer Lawrence grow up? A. The Ozarks B. Manhattan C. Los
    Angeles, California D. New York City, New York E. Louisville, Kentucky  Q2) What
    is the name of the movie in which Jennifer Lawrence will play the mutant
    Mystique? A. Winter's Bone B. X-Men: First Class C. The Beaver D. Twilight E.
    The Hunger Games  Q3) What is one skill Jennifer Lawrence learned to prepare for
    her role in "Winter's Bone"? A. How to play field hockey B. How to chop wood C.
    How to ride a horse D. How to act like a frightened waif E. How to shoot a gun
    Q4) Why did Jennifer Lawrence's mom take her to New York at the age of 14? A. To
    visit relatives B. To attend a sports tournament C. To go shopping D. For
    auditions E. For a family vacation  Q5) What was Jennifer Lawrence's role in the
    movie "Winter's Bone"? A. A character in a Jodie Foster movie B. A mutant with
    blue skin C. A character in a Reese's Peanut Butter Cups commercial D. A
    frightened waif E. A 17-year-old daughter of an Ozarks meth-cooker
    ANSWERS:
    ['E' 'B' 'E' 'D' 'E']
    '===================================================================================================='


### Generate Summaries + Scores

Next, we will generate 10 summaries for each article in the training set and score them with our Q&A judging setup. 

The following command will run the `TODO` script, which takes in the folder of questions and generates the results to a new folder of `.parquet` files.


```python
!anyscale job submit -f configs/jobs/8b_judge/generate_summaries_train_job.yaml 
# Optional: use the 70b model for better performance (runs on A100s)
# !anyscale job submit -f configs/jobs/70b_judge/generate_summaries_train_job.yaml 
```

    [1m[36mOutput[0m[0m
    [0m[1m[36m(anyscale +1.1s)[0m [0m[0m[0m[0mSubmitting job with config JobConfig(name='preference-tuning-summarization-question-generation', image_uri='localhost:5555/anyscale/endpoints_aica:0.5.0-6402', compute_config=None, env_vars=None, py_modules=None, cloud=None, project=None, ray_version=None, job_queue_config=None).[0m
    [0m[1m[36m(anyscale +3.5s)[0m [0m[0m[0m[0mUsing workspace runtime dependencies env vars: {'WANDB_API_KEY': 'cbc4aed2de2d9c9acb21324a3297b85b7299479b'}.[0m
    [0m[1m[36m(anyscale +3.5s)[0m [0m[0m[0m[0mUploading local dir '.' to cloud storage.[0m
    [0m[1m[36m(anyscale +4.5s)[0m [0m[0m[0m[0mIncluding workspace-managed pip dependencies.[0m
    [0m[1m[36m(anyscale +5.1s)[0m [0m[0m[0m[0mJob 'preference-tuning-summarization-question-generation' submitted, ID: 'prodjob_8m2iu1lcd44s2e7q95rcrxvzzx'.[0m
    [0m[1m[36m(anyscale +5.1s)[0m [0m[0m[0m[0mView the job in the UI: https://console.anyscale.com/jobs/prodjob_8m2iu1lcd44s2e7q95rcrxvzzx[0m
    [0m[1m[36m(anyscale +5.1s)[0m [0m[0m[0m[0mUse `--wait` to wait for the job to run and stream logs.[0m
    [0m[0m


```python
# replace with the link to the generated summaries
summary_folder = "s3://air-example-data/preference-tuning-summarization-example/summary_generation_base/train/"
summary_ds = ray.data.read_parquet(summary_folder)
example_rows = summary_ds.take(1)
```


```python
from src.utils.models import DataSchema

for row in example_rows:
    print("TEXT:")
    print(textwrap.fill(row[DataSchema.ARTICLE], width=80))
    print("QUESTIONS:")
    print(textwrap.fill(row[DataSchema.MCQ_QUESTIONS], width=80))
    print("MODEL GENERATED SUMMARY:")
    print(textwrap.fill(row[DataSchema.SUMMARY_GENERATION_RAW_OUTPUT], width=80))
    print("ANSWERS:")
    print(textwrap.fill(str(row[DataSchema.GROUND_TRUTH_MCQ_ANSWERS]), width=80))
    print("JUDGE ANSWERS FROM SUMMARY:")
    print(textwrap.fill(str(row[DataSchema.JUDGE_MCQ_ANSWERS]), width=80))
    pprint.pprint("=" * 100, width=80)
```

    TEXT:
    A 43-year-old mother has died in a house fire in Mount Helen, near Ballarat.
    Police originally feared the woman and her son and daughter, both 21, had died
    in the blaze but they have been safely located, theÂ Ballarat Courier reported. A
    neighbour said she heard a 'whooshing' noise like a firecracker and a loud
    explosion before the fire started at about 1.30am on Friday. Two women and a man
    feared dead in house fire at Mount Helen, Victoria . Next-door neighbour
    Margaret Bell witnessed the explosion and called 000. 'I got up to grab a drink
    of water and I went back to bed,' Ms Bell told Daily Mail Australia. 'Then I
    heard a noise, you know how when a firecracker goes off it makes that whooshing
    sort of a noise, then that stopped and I heard a big explosion.' Ms Bell got out
    of bed and looked out her window to see the house in flames so she called the
    fire service. She added that the family had moved to Mount Helen from Ballarat
    just over one week ago. 'I'd spoken to the lady and her son, she was telling me
    a bit about herself,' she said. A body has reportedly been found but not
    identified and a mother, 43, and her son and daughter, both 21, are still
    unaccounted for . 'They'd moved out here because it's nice and quiet out here.
    'It's really sad to think they might have been in the house.' Detective senior
    sergeant Dave Hermit said two dogs were found dead at the property. The fire
    took 20 firefighters 90 minutes to bring under control, and the house was
    completely destroyed. Country Fire Authority operations officer Kade Dowie said
    investigators believed the family were in the process of moving into the home.
    'Investigations are continuing but the story from the neighbours is that they'd
    only recently moved in, as in last weekend,' Mr Dowie told Daily Mail Australia.
    Mr Dowie said the scene was handed over to the police forensics and arson squad
    on Friday morning but crews struggled to access inside the property. 'The
    intensity of the fire caused the ceiling and roof to collapse, which is causing
    difficulty with extinguishing and accessing,' he said. The cause of the fire is
    not yet known.
    QUESTIONS:
    Q1) What was the condition of the house after the fire? A. Partially damaged B.
    Slightly damaged C. Unknown D. Completely destroyed E. Not affected  Q2) Where
    did the house fire occur? A. Mount Helen B. Ballarat C. Sydney D. Melbourne E.
    Perth  Q3) How long did it take firefighters to bring the fire under control? A.
    30 minutes B. 2 hours C. 3 hours D. 60 minutes E. 90 minutes  Q4) What is the
    current status of the cause of the fire? A. It is still unknown B. It was a
    cooking accident C. It was a gas leak D. It was an electrical fault E. It was an
    arson attack  Q5) What was the age of the mother who died in the house fire? A.
    43 B. 21 C. 30 D. 50 E. 60
    MODEL GENERATED SUMMARY:
    A 43-year-old mother and her two children, aged 21, have died in a house fire in
    Mount Helen, near Ballarat. The family had recently moved to the area. The cause
    of the fire is not yet known.
    ANSWERS:
    ['D' 'A' 'E' 'A' 'A']
    JUDGE ANSWERS FROM SUMMARY:
    ['Unsure', 'A', 'Unsure', 'A', 'A']
    '===================================================================================================='


### Generate Preference Tuning Data

Next, we will generate 10 summaries for each article in the training set and score them with our Q&A judging setup. 

The following command will run the `TODO` script, which takes in the folder of summaries and outputs `.jsonl` files for training and validation.


```python
!python src/scripts/generate_dpo_data.py configs/training_data_generation/mistral_8b.yaml
```


```python
# Replace with the link to your validation file
validation_file = "s3://air-example-data/preference-tuning-summarization-example/dpo_training_data/valid.jsonl"

valid_ds = ray.data.read_json(validation_file)
example_rows = valid_ds.take(1)
```


```python
for row in example_rows:
    print("PROMPT:")
    print(textwrap.fill(row["chosen"][0]["content"], width=80))
    print("\nCHOSEN RESPONSE: ")
    print(textwrap.fill(row["chosen"][1]["content"], width=80))
    print("\nREJECTED RESPONSE: ")
    print(textwrap.fill(row["rejected"][1]["content"], width=80))
```

    PROMPT:
    Given the following text, create a very short summary that is at most 2
    sentences.  Text: By . Tamara Cohen, Political Reporter . PUBLISHED: . 18:32
    EST, 27 January 2013 . | . UPDATED: . 08:48 EST, 28 January 2013 . Deputy Prime
    Minister Nick Clegg and his wife Miriam are determined to keep the education of
    their 11-year-old son 'out of politics' Nick Clegg yesterday defended the
    possibility he may send his children to private schools as it emerged he and his
    wife Miriam have not even visited their local state school. He said the
    education of his 11-year-old son Antonio, who starts secondary school this year,
    should not be used as 'a political football' and that the couple would do
    'what's best' for their children although he was braced for criticism. Last week
    the Liberal Democrat leader told listeners to his radio show he would send his
    son to a private school if he failed to find a place in a good comprehensive,
    saying he would use the state system 'if it works out', but that there is 'huge
    competition' for places in London. But Mr Clegg, who attended Westminster public
    school, has apparently not looked around nearby Ark Putney academy in south-west
    London, it was revealed yesterday by its headmaster Mark Phillips. Mr Phillips
    who has turned the school around since he was hired three years ago, said the
    school which was once in special measures but is now lauded by the Government
    for its improvements, could provide an 'exceptional' education for any child and
    that there was no need to pay fees for schooling. Unless the Cleggs had visited
    'under cover' he had not seen them, he said.'I am always very clear that all
    parents living locally are welcome to choose our school and it is important that
    every parent comes with their child and takes an objective look to see whether
    what we offer will meet the needs of their child', he said. 'It wouldn't claim
    to be the answer to every child and every parent. But I hope that if a parent
    does come, and sees an environment their child will thrive in, they will pick
    us...I am confident they will do exceptionally well. I don't believe you have to
    pay for it.' Mr Clegg told the BBC's Andrew Marr Show yesterday that he and his
    wife will do whatever is in the interests of their son . If he chooses to
    educate his children . privately, Mr Clegg is likely to be accused of hypocrisy
    after using a . speech last year to attack 'the great rift in our education
    system' caused by many of the best schools being fee-paying and said it had a .
    'corrosive' effect on society and the economy. In . an interview on BBC1's
    Andrew Marr Show, he said: 'I accept that it's a . dilemma for anyone in public
    life, particularly in politics, how do you . balance that with the fact Miriam
    and I have small children, and the . approach Miriam and I took right from the
    outset was to keep our . children completely out of politics. 'We . never put
    them in front of the camera or to make them or their . education a political
    football. 'I totally accept that when we make a . decision that'll be subject to
    public commentary, criticism and so on, . but in the meantime we want to protect
    the privacy of an 11-year-old boy . and make the decision that we as parents
    think is best for our son.' The deadline for applying for entry to Ark Putney
    for 2013-14 was last October. The school is part of the Ark academy chain, set
    up in 2004, whose chairman is Paul Marshall, one of the Liberal Democrats'
    biggest donors. Last year 62 per cent of pupils gained at least five good GCSEs,
    prompting schools minister Nick Gibb to write to Mr Phillips to congratulate him
    on the 'excellent results' saying the school was in the top 100 best-performing,
    based on sustained improvements every year since 2008. However Michael Gove last
    year approved the sale of five acres of playing fields at the school including
    six tennis courts, a football pitch and a playground, to developers to fund
    refurbishments, after a Â£40million revamp under the Building Schools for the
    Future programme was cancelled. Alumni of Ark Putney, which used to be Elliott
    School, include actor Pierce Brosnan, and 1960s England bowler Geoff Arnold.
    Former Welsh secretary Peter Hain sent his children to the school, which was the
    scene of the Christmas play in the film Love, Actually. David Cameron has said
    his children will attend state school, but George Osborne has been criticised
    for sending his to the fee-paying preparatory school in Kensington that he
    attended.
    
    CHOSEN RESPONSE: 
    Nick Clegg and his wife Miriam are considering sending their 11-year-old son
    Antonio to a private school, despite their previous claims that they would use
    the state system. Clegg has not visited Ark Putney Academy, a nearby state
    school, but its headmaster, Mark Phillips, claims that the school could provide
    an 'exceptional' education for any child and that there is no need to pay fees
    for schooling. The deadline for applying to Ark Putney for 2013-14 was last
    October and the school is part of the Ark academy chain, set up in 2004, whose
    chairman is Paul Marshall, one of the Liberal Democrats' biggest donors.
    
    REJECTED RESPONSE
    Deputy Prime Minister Nick Clegg has defended the possibility of sending his
    children to private schools, stating that their education should not be used as
    a political football. He and his wife Miriam have not visited their local state
    school, but the headmaster of Ark Putney academy in London, where they were
    invited to attend, said the school could provide an "exceptional" education for
    any child and that parents should come to see it firsthand before making a
    decision.


# Step 2: Fine-tuning

Now that we have the pre-processed dataset, we are ready to fine-tune `Mistral-7B-Instruct-v0.1` using DPO. On Anyscale, we've created an easy-to-use interface to do preference-tuning using `DPO`. We leverage Ray to overlap reference model log-probability calculation with model training to improve GPU utilization. Most implementations compute log probabilities synchronously with model training,

<img src="https://raw.githubusercontent.com/anyscale/templates/main/templates/fine-tune-llm_v2/end-to-end-examples/fine-tune-preference/assets/hf_dpo.png"/>

While our implementation using Ray is asynchronous:  


<img src="https://raw.githubusercontent.com/anyscale/templates/main/templates/fine-tune-llm_v2/end-to-end-examples/fine-tune-preference/assets/anyscale_dpo.png"/>

Further, our use of Ray Data also implies that the compute configuration for the reference model can be completely decoupled with the policy model. For example, reference model calculation can run on a different node (with configurable number of GPUs, etc) with zero code changes needed. 


To get started with DPO training, we provide the config for DPO in [configs/mistral_dpo_summarization.yaml](configs/mistral_dpo_summarization.yaml) . 


```python
!cat configs/mistral_dpo_summarization.yaml
```

You can run the below command from the root directory for the template (`~/default`): 

```
llmforge anyscale finetune end-to-end-examples/fine-tune-preference/configs/mistral_dpo_summarization.yaml
```

# Step 3: Evaluation

Let's evaluate our trained model. Here we'll use two baselines: (1) the base model before finetuning (reference model in DPO) and (2) GPT-4o.

## Evaluation strategy

Our evaluation strategy involves the same Q&A scoring system as used while generating the preference data. 

<p align="center">
  <img src="./assets/eval.png?" alt="Evaluation" width=800>
</p>

We evaluate the baseline model and the trained DPO model on the test set. 

## Obtain summaries on the test set
First, we'll need to obtain the summaries (and scores) for both the models on the given test set. 

For the baseline model, you can simply run the below command:


```python
!anyscale job submit -f configs/jobs/8b_judge/generate_summaries_eval_baseline_job.yaml
# Optional: use the 70b model for better performance (runs on A100s)
# !anyscale job submit -f configs/jobs/70b_judge/generate_summaries_eval_baseline_job.yaml
```

For the fine-tuned DPO model, we provide a dummy config in [configs/summary_generation/mistral_finetuned_eval.yaml](configs/summary_generation/mistral_finetuned_eval.yaml). If you used the default training config provided, the model would be trained using LoRA and you should have a path to the LoRA weights. Make sure to download the weights locally (using `aws` or `gcloud` CLI depending on the remote path). Enter the local path to the weights in the config. (Make sure that the weights are in the same directory as the current notebook to be included in the job).  


```python
!cat configs/jobs/8b_judge/generate_summaries_eval_finetuned_job.yaml
```

    mode: eval
    input_folder: s3://air-example-data/preference-tuning-summarization-example/qa_generation/qa_annotations_full_test
    model_inference_config:
      model_id_or_path: mistralai/Mistral-7B-Instruct-v0.1
      adapter_id_or_path: <path to lora model> # <--- Add the local path to your lora weights here
      temperature: 0
      top_p: 0.95
      scaling_config:
        batch_size: 128
        concurrency: 2
        num_gpus: 1
        custom_resources:
          accelerator_type:H100: 1
    num_generations: 1
    judge_inference_config:
      model_id_or_path: meta-llama/Meta-Llama-3.1-70B-Instruct
      temperature: 0
      scaling_config:
        batch_size: 128
        concurrency: 3
        num_gpus: 2
        custom_resources:
          accelerator_type:H100: 1
    num_mcq_questions: 5



```python
!anyscale job submit -f configs/jobs/8b_judge/generate_summaries_eval_finetuned_job.yaml
# Optional: use the 70b model for better performance (runs on A100s)
# !anyscale job submit -f configs/jobs/70b_judge/generate_summaries_eval_finetuned_job.yaml
```

In the logs for the above jobs, you should see the final path to the output summaries for both the models. 

Optionally, you can also obtain the summaries and scores for the `gpt-4o` model from OpenAI. Simply run:


```python
!anyscale job submit -f configs/jobs/8b_judge/generate_summaries_eval_gpt_job.yaml
# Optional: use the 70b model for better performance (runs on A100s)
# !anyscale job submit -f configs/jobs/70b_judge/generate_summaries_eval_gpt_job.yaml
```

## Get Evaluation Statistics

We've provided a convenient script `src/scripts/get_eval_stats.py` to get evaluation statistics and obtain the "win rate" of the DPO model (the percentage of times the DPO model performs better than the baseline). We've provided an example configuration below. 


```python
# make sure to substitute -outputs-path with your path
!python src/scripts/get_eval_stats.py --outputs-path s3://air-example-data/preference-tuning-summarization-example/summary_generation_dpo_model/test/ --baseline-outputs-path s3://air-example-data/preference-tuning-summarization-example/summary_generation_base/test/  

# (Optional): if you obtained results for GPT-4o, you should uncomment and run the following command instead
# !python src/scripts/get_eval_stats.py --outputs-path s3://air-example-data/preference-tuning-summarization-example/summary_generation_dpo_model/test/ --baseline-outputs-path s3://air-example-data/preference-tuning-summarization-example/summary_generation_base/test/  --gpt4o-outputs-path <add-path-to-gpt4o-results>
```

You should see the following results for the 70B model:

```text 
â•’â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â••
â”‚           Metric            â”‚   Model   â”‚  Baseline  â”‚  GPT-4o   â”‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡
â”‚        Accuracy >=3         â”‚ 65.4286 % â”‚ 43.0476 %  â”‚ 37.2381 % â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        Accuracy >=4         â”‚ 25.7143 % â”‚ 13.5238 %  â”‚ 10.0000 % â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Median Compression      â”‚ 11.5794 % â”‚ 12.7316 %  â”‚ 8.0496 %  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      Mean Compression       â”‚ 13.0029 % â”‚ 14.3444 %  â”‚ 9.3554 %  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      Summary Too Long       â”‚ 0.0000 %  â”‚  0.0000 %  â”‚ 0.0000 %  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Contains Invalid Characters â”‚ 0.0000 %  â”‚  0.0952 %  â”‚ 0.0000 %  â”‚
â•˜â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•›


Model Win Rate against Baseline: 74.0000 %
GPT-4o Win Rate against Baseline: 64.8095 %
```

Our fine-tuned model is able to generate much better summaries, that are more concise (compression ratio is lower) with lesser out-of-distribution characters (gibberish tokens) than the baseline. You can see more details on the same in our blog!

| **NOTE:** The evaluation results will differ if you used the 8B model which is less capable as a LLM-judge. 

## Summary

Congrats! You have now fine-tuned an open source model on preference data. As a quick recap, here's what we demonstrated in this notebook:
1. Synthetically generating preference data for DPO 
2. DPO fine-tuning of a language model on the Anyscale Platform
4. Evaluating the model against the baseline and GPT-4o, and analysing the results.
