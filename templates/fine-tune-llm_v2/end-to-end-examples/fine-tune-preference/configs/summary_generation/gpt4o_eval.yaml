mode: eval
inference_type: online
input_folder:  s3://anyscale-production-data-cld-hph1wut9q59u5n6pqjvvgazkv4/org_4snvy99zwbmh4gbtk64jfqggmj/cld_hph1wut9q59u5n6pqjvvgazkv4/artifact_storage/preference_tuning_summarization_example/qa_annotations_full_test
model_inference_config:
  model_id: gpt-4o
  base_url: https://api.openai.com/v1
  api_key_env_var: OPENAI_API_KEY
  temperature: 0
  max_tokens: 4096
  scaling_config:
    concurrency: 5
num_mcq_questions: 5
num_generations: 1
judge_inference_config:
  model_id_or_path: meta-llama/Meta-Llama-3.1-70B-Instruct
  temperature: 0
  scaling_config:
    batch_size: 128
    concurrency: 3
    num_gpus: 2
    custom_resources:
      accelerator_type_h100_80g: 1
