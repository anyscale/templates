
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Workspaces\n",
    "\n",
    "Welcome! You are currently in a Workspace, which is a persistent cloud IDE connected to a Ray cluster.\n",
    "\n",
    "In this tutorial, you will learn:\n",
    "1. Basic workspace features such as git repo persistence, NFS mounts, cloud storage, and SSH authentication.\n",
    "2. Ray cluster management features, such as adding multiple worker nodes.\n",
    "3. Ray monitoring features such as viewing tasks in the dashboard.\n",
    "4. Dependency management.\n",
    "\n",
    "## \"Hello world\" in workspaces\n",
    "\n",
    "Let's start by checking that Ray is working properly in your workspace. You can do this by running the following cell to execute a simple parallel Ray program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "@ray.remote\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "futures = [square.remote(x) for x in range(100)]\n",
    "results = ray.get(futures)\n",
    "print(\"Success!\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace Basics\n",
    "\n",
    "An Anyscale Workspace is a cloud IDE where you can develop and test Ray programs. Let's get started by creating a new git repo in this workspace. Workspaces will persist the tracked files in this git repo across restarts (as well as files not in a git repos).\n",
    "\n",
    "We'll use the repo later on to author and run a simple Ray app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir my_repo && cd my_repo && git init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up SSH authentication (optional)\n",
    "\n",
    "Anyscale generates a unique SSH key per user, which is accessible at `~/.ssh/id_rsa.pub`. If you'd like, you can [add this key to GitHub](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account) in order to access private repositories from the workspace.\n",
    "\n",
    "The public key to add is outputted by the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ~/.ssh/id_rsa.pub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NFS Mounts\n",
    "\n",
    "Workspace local storage is limited to 1GB, so we recommend only using it to store git repos and smaller files. To persist larger files, you can save data to NFS mounts and cloud storage.\n",
    "\n",
    "Here are a few handy NFS mounts included:\n",
    "- `/mnt/shared_storage` is a mount shared across all users of your organization\n",
    "- `/mnt/user_storage` is a mount for your user account\n",
    "\n",
    "NFS storage can be read and written from the workspace, as well as from any node in the Ray cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"hello world\" > /mnt/user_storage/persisted_file.txt && cat /mnt/user_storage/persisted_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cloud Storage\n",
    "\n",
    "Access built-in cloud storage using the `$ANYSCALE_ARTIFACT_STORAGE` URI as a prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp /mnt/user_storage/persisted_file.txt $ANYSCALE_ARTIFACT_STORAGE/persisted_object.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp $ANYSCALE_ARTIFACT_STORAGE/persisted_object.txt /tmp/object.txt && cat /tmp/object.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray cluster management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workspace is connected to a Ray cluster. Click on the resources bar on the top right corner of the screen to open the cluster control panel. This panel shows a summary of Ray resource utilization, and you can use this panel to configure the cluster resources.\n",
    "\n",
    "<img src=\"assets/resource-panel.png\" height=400px/>\n",
    "\n",
    "### Configuring the Workspace node\n",
    "\n",
    "The workspace node is the machine this notebook is running inside. You may wish to change the instance type of the workspace node specifically, e.g., to increase the available memory or add a GPU. Click the pencil icon in order to change the workspace node. Note that changing the workspace node will restart the workspace IDE.\n",
    "\n",
    "<img src=\"assets/edit-workspace-node.png\" height=300px/>\n",
    "<img src=\"assets/edit-workspace-dialog.png\" width=400px/>\n",
    "\n",
    "### Adding worker nodes\n",
    "\n",
    "To parallelize beyond the resources available to the workspace node, add additional worker nodes to the Ray cluster. Click \"Add a node type\" to add a number of nodes of a certain type to the cluster. While most use cases only require a single worker node type, you can add multiple distinct node types (e.g., high-CPU and GPU nodes) to the workspace as well.\n",
    "\n",
    "<img src=\"assets/add-node-type.png\" height=300px/>\n",
    "<img src=\"assets/add-node-dialog.png\" height=300px/>\n",
    "\n",
    "### Using \"Auto\" workers mode\n",
    "\n",
    "To let Ray automatically select what kind of worker nodes to add to the cluster, check the \"Auto-select machines\" box. Ray will try to autoscale cluster worker nodes to balance cost and performance. In auto mode, you cannot configure worker node types, but the resources panel will show which node types have been launched.\n",
    "\n",
    "We recommend using auto mode if you do not have specific cluster requirements, and are ok with waiting for the autoscaler to add nodes on-demand to the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring Ray applications\n",
    "\n",
    "In this section, we'll author a simple Ray python script and go over the tools available to monitor its execution. Let's take the opportunity to create a `my_app.py` file in the `my_repo` git repo you created earlier.\n",
    "\n",
    "You can click on the \"File Explorer\" in the left pane of VSCode to create the new file. Copy paste the following program into the file:\n",
    "\n",
    "```python\n",
    "import ray, time\n",
    "\n",
    "@ray.remote\n",
    "def do_some_work():\n",
    "    print(\"Doing work\")\n",
    "    time.sleep(5)\n",
    "    return \"Done\"\n",
    "\n",
    "ray.get([do_some_work.remote() for _ in range(100)])\n",
    "````\n",
    "\n",
    "Then, use the next cell or the VSCode terminal to run the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python my_repo/my_app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Ray log output\n",
    "\n",
    "After running `my_app.py`, you should see output of the form `(do_some_work pid=29848) Doing work [repeated 4x across cluster]`. The prefix of the log message shows the function name, PID of the worker that ran the function, and if run on a remote worker, the node IP.\n",
    "\n",
    "The result of the log message contains stdout and stderr from the function execution. Ray will also deduplicate repetitive logs from parallel execution of functions across the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring program execution\n",
    "\n",
    "Depending on the cluster size, the above script may take some time to run. Try playing around with the number of worker machines, increasing the sleep time, or the number of function calls. Use the tools overviewed below to understand how Ray parallelizes the program.\n",
    "\n",
    "Let's overview some of the tools available to monitor Ray program execution in workspaces.\n",
    "\n",
    "**Resources Panel**\n",
    "\n",
    "The resources panel provides basic stats about cluster utilization, as well as an indication of which worker nodes are being used. Use the resource panel as a quick overview of cluster status before diving deeper into the Ray dashboard.\n",
    "\n",
    "<img src=\"assets/resources-panel-stats.png\" height=400px/>\n",
    "\n",
    "**Ray dashboard > Jobs**\n",
    "\n",
    "To see the status of an active or previously run Ray job, navigate to `Ray Dashboard > Jobs` in the UI. Here you will see an overview of job progress, logs, and the ability to drill down into individual task and actors.\n",
    "\n",
    "<img src=\"assets/ray-dashboard-jobs.png\" height=400px/>\n",
    "\n",
    "**Ray dashboard > Metrics**\n",
    "\n",
    "View the aggregate time-series metrics for the cluster in order to diagnose job execution efficiency. The `Ray Dashboard > Metrics` page offers metrics on Ray tasks, actors, as well as hardware resource utilization of the cluster.\n",
    "\n",
    "<img src=\"assets/ray-dashboard-metrics.png\" height=400px/>\n",
    "\n",
    "**Logs Tab**\n",
    "\n",
    "View and search over Ray cluster and application logs in the Logs tab.\n",
    "\n",
    "<img src=\"assets/logs-tab.png\" height=400px/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Management\n",
    "\n",
    "In order to run code across a cluster, Ray ships code and other library dependencies to other machines in [runtime envs](https://docs.ray.io/en/latest/ray-core/handling-dependencies.html). In workspaces, the code and installed PyPI packages are automatically added to the runtime env to be used by Ray.\n",
    "\n",
    "To try this out, run the following command to install the `emoji` package. You'll see a notification that the package has been registered with the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Navigate to the `Dependencies` tab of the workspace, and you should see the `emoji` package in the list there. You can use this UI to edit the workspace runtime dependencies, or the UI.\n",
    "\n",
    "<img src=\"assets/dependencies-tab.png\" height=400px/>\n",
    "\n",
    "Run the following cell to check that the `emoji` package is successfully installed on the cluster (to check this properly, make sure the cluster has at least one worker node added)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import emoji\n",
    "import time\n",
    "\n",
    "# Reset the Ray session in the notebook kernel to pick up new dependencies.\n",
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "\n",
    "@ray.remote\n",
    "def f():\n",
    "    print(emoji.emojize('Dependencies are :thumbs_up:'))\n",
    "    time.sleep(5)\n",
    "\n",
    "ray.get([f.remote() for _ in range(100)])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Now you know everything you need to build scalable Ray applications in Anyscale Workspaces. Check out the template gallery and Ray documentation to learn more about what you can do with Ray and Anyscale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook:\n",
    "- Set up a basic development project in a workspace.\n",
    "- Showed how to use different types of persistent storage.\n",
    "- Demoed how to build and debug basic Ray application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
