{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4719f38-0166-4b80-a03f-290255b5c528",
   "metadata": {},
   "source": [
    "# OpenAI whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa04be4-6913-43bb-b20f-93b2cde52acc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cluster_storage/pypi/lib/python3.10/site-packages/whisper/timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    }
   ],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca8fe87e-2912-46b1-8a27-5271b2ffbc9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cluster_storage/pypi/lib/python3.10/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " My thought I have nobody by a beauty and will as you poured. Mr. Rochester is sub in that so-don't find simplest, and devoted about, to let might in a\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "result = model.transcribe(\"sample-en.mp3\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50542e68-b306-4c12-ae72-a8a2b21347db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: zh\n",
      "DecodingOptions(task='transcribe', language=None, temperature=0.0, sample_len=None, best_of=None, beam_size=None, patience=None, length_penalty=None, prompt=None, prefix=None, suppress_tokens='-1', suppress_blank=True, without_timestamps=False, max_initial_timestamp=1.0, fp16=False)\n",
      "从前,为了探寻皮膚年轻的秘密,我们修变了整个大自然。向前走,思主看看,看你能否找到他。他在空中,在地上,或者就是职务的生命。\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(\"sample-ch.mp3\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# decode the audio\n",
    "options = whisper.DecodingOptions(fp16 = False)\n",
    "print(options)\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# print the recognized text\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44e2e40-87fd-4321-8ace-bbe0a9a9dd65",
   "metadata": {},
   "source": [
    "# class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "100147ec-02da-4914-9142-07844f4a4898",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ray/anaconda3/lib/python3.10/site-packages/whisper/timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20230314'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import whisper\n",
    "whisper.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e917c970-c629-4a20-a475-347e5e0f5414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'ffmpeg' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mffmpeg\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mffmpeg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'ffmpeg' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import ffmpeg\n",
    "ffmpeg.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de17e7a3-50a6-46a0-8b10-34e3f08be862",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Whisper:\n",
    "    def __init(self):\n",
    "        self.model = whisper.load_model(\"base\")\n",
    "    def __call__(self, audio_batch):\n",
    "        audios = audio_batch['bytes']\n",
    "        languages = []\n",
    "        for audio in audios:\n",
    "            with tempfile.NamedTemporaryFile() as f:\n",
    "                f.write(audio)\n",
    "                audios_np = whisper.load_audio(f.name)\n",
    "                audios_np = whisper.pad_or_trim(audios_np)\n",
    "                mel =  whisper.log_mel_spectrogram(audio_np).to(self.model.device)\n",
    "                \n",
    "                _, probs = self.model.detect_lanuage(mel)\n",
    "                languages.append(max(probs, key=probs.get))\n",
    "                \n",
    "        return {\"lanuage\": languages}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95733ff1-681d-4855-8705-09f3245beb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ray.data.read_binary_files([\"\",\"\"])\n",
    "ds = ds.map_batches(\n",
    "    whisper,\n",
    "    batch_size = 2,\n",
    "    computer = ray.data.ActorPoolStragegy(min_size=1, max_size=20)\n",
    "    # num_gpus=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
