{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b801b34",
   "metadata": {},
   "source": [
    "# Image Classification Batch Inference with PyTorch\n",
    "\n",
    "**Time to complete**: 15 min | **Difficulty**: Beginner | **Prerequisites**: Basic Python, PyTorch familiarity\n",
    "\n",
    "## What You'll Build\n",
    "\n",
    "By the end of this tutorial, you'll have a scalable image classification pipeline that can process thousands of images in parallel using Ray Data. You'll learn how distributed batch inference works and why it's essential for production ML systems.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Setup and Data Loading](#step-1-reading-the-dataset-from-s3) (3 min)\n",
    "2. [Single Batch Inference](#step-2-inference-on-a-single-batch) (4 min) \n",
    "3. [Distributed Batch Processing](#step-3-distributed-batch-inference) (6 min)\n",
    "4. [Results and Cleanup](#step-4-evaluating-results) (2 min)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By completing this tutorial, you'll understand:\n",
    "\n",
    "- **Why batch inference matters**: Process thousands of images efficiently vs. one-by-one\n",
    "- **Ray Data's power**: Automatic parallelization across multiple GPUs/CPUs\n",
    "- **Production patterns**: Real-world batch processing for ML models\n",
    "- **Performance optimization**: How to scale inference workloads\n",
    "\n",
    "## Overview\n",
    "\n",
    "**The Challenge**: Processing large image datasets with traditional approaches is slow and doesn't utilize available hardware efficiently.\n",
    "\n",
    "**The Solution**: Ray Data automatically distributes your inference workload across multiple workers, enabling efficient processing of large image datasets.\n",
    "\n",
    "**Real-world Impact**: Companies like Uber and Netflix use similar patterns to process millions of images daily for recommendation systems and content analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites Checklist\n",
    "\n",
    "Before starting, make sure you have:\n",
    "- [ ] Python 3.7+ installed\n",
    "- [ ] Basic understanding of PyTorch models\n",
    "- [ ] Familiarity with image classification concepts\n",
    "- [ ] At least 4GB RAM available (8GB+ recommended for GPU usage)\n",
    "\n",
    "## Quick Start (5 minutes)\n",
    "\n",
    "Want to see results immediately? This minimal example demonstrates the core concepts.\n",
    "\n",
    "### Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08290870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "# Initialize Ray for distributed processing\n",
    "ray.init()\n",
    "\n",
    "# Load sample images from public dataset\n",
    "ds = ray.data.read_images(\"s3://anonymous@air-example-data-2/imagenette2/train/\")\n",
    "print(f\"Loaded {ds.count()} images for processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ae5b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This example will still work even if you don't have GPUs available, but overall performance will be slower.\n",
    "\n",
    " **Pro Tip**: See [this guide on batch inference](https://docs.ray.io/en/latest/data/batch_inference.html#batch-inference-home) for tips and troubleshooting when adapting this example to use your own model and dataset!\n",
    "\n",
    "## Installation Requirements\n",
    "\n",
    "To run this example, you will need the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1046d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Install Ray Data with core dependencies\n",
    "pip install \"ray[data]\"\n",
    "\n",
    "# Install PyTorch for deep learning models\n",
    "pip install torch torchvision\n",
    "\n",
    "# Install additional dependencies for image processing\n",
    "pip install pillow numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c600d225",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**System Requirements**:\n",
    "- Python 3.7+ \n",
    "- 4GB+ RAM (8GB+ recommended)\n",
    "- Internet connection for S3 dataset access\n",
    "- GPU optional but recommended for faster inference\n",
    "\n",
    "**Version Compatibility** (rule #196):\n",
    "- Ray Data: 2.8.0+\n",
    "- PyTorch: 1.12.0+\n",
    "- Torchvision: 0.13.0+\n",
    "- Python: 3.7-3.11\n",
    "\n",
    "**Verification Steps** (rule #107):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f1a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Ray Data installation\n",
    "import ray\n",
    "print(f\"Ray version: {ray.__version__}\")\n",
    "\n",
    "# Verify PyTorch installation\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Test basic functionality\n",
    "test_ds = ray.data.from_items([{\"test\": 1}])\n",
    "print(f\"Ray Data working: {test_ds.count() == 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a81e07",
   "metadata": {},
   "source": [
    "## Step 1: Reading the Dataset from S3\n",
    "*‚è± Time: 3 minutes*\n",
    "\n",
    "### What We're Doing\n",
    "We'll load the [Imagenette dataset](https://github.com/fastai/imagenette) - a subset of ImageNet with 10 classes (tench, English springer, cassette player, etc.). This is perfect for demonstrating batch inference without huge download times.\n",
    "\n",
    "### Why This Matters\n",
    "- **Real datasets**: We're using actual images, not toy data\n",
    "- **Cloud storage**: Learn to process data directly from S3 (common in production)\n",
    "- **Scalable loading**: Ray Data handles the complexity of parallel data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import time\n",
    "\n",
    "# Initialize Ray - this sets up the distributed computing environment\n",
    "# Ray will automatically detect available CPUs/GPUs\n",
    "print(\"Initializing Ray cluster...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Use reproducible initialization for consistent results (rule #502)\n",
    "ray.init(ignore_reinit_error=True)  # Allow re-initialization for testing\n",
    "init_time = time.time() - start_time\n",
    "\n",
    "print(f\"Ray initialized in {init_time:.2f} seconds\")\n",
    "print(f\"Available resources: {ray.cluster_resources()}\")\n",
    "\n",
    "# Validate Ray initialization was successful\n",
    "if not ray.is_initialized():\n",
    "    raise RuntimeError(\"Ray failed to initialize. Please check your environment.\")\n",
    "\n",
    "# Load images directly from S3 - no need to download first!\n",
    "# The 'mode=\"RGB\"' ensures consistent color format across all images\n",
    "print(\"\\nLoading image dataset from S3...\")\n",
    "s3_uri = \"s3://anonymous@air-example-data-2/imagenette2/train/\"\n",
    "\n",
    "try:\n",
    "    # Time the data loading to show efficiency\n",
    "    load_start = time.time()\n",
    "    ds = ray.data.read_images(s3_uri, mode=\"RGB\")\n",
    "    load_time = time.time() - load_start\n",
    "    \n",
    "    # Validate dataset was loaded successfully\n",
    "    dataset_count = ds.count()\n",
    "    if dataset_count == 0:\n",
    "        raise ValueError(\"Dataset appears to be empty. Please check S3 connectivity.\")\n",
    "    \n",
    "    # Display comprehensive info about our dataset\n",
    "    print(f\"Dataset loaded: {dataset_count} images in {load_time:.2f} seconds\")\n",
    "    print(\"Memory efficient: Data loaded lazily (not all at once)\")\n",
    "    print(f\"Dataset schema: {ds.schema()}\")\n",
    "    \n",
    "    if load_time > 0:\n",
    "        print(f\"Loading speed: ~{dataset_count/load_time:.0f} images/second\")\n",
    "    \n",
    "    # Show the dataset object\n",
    "    ds\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    print(\"Tip: Ensure internet connectivity for S3 access\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7643bf20",
   "metadata": {},
   "source": [
    "Let's inspect the dataset structure to understand what we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ece1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the schema - this shows us the data structure\n",
    "print(\" Dataset Schema:\")\n",
    "print(ds.schema())\n",
    "\n",
    "# Take a peek at one image to understand the data format\n",
    "sample = ds.take(1)[0]\n",
    "print(f\"\\nüìè Image dimensions: {sample['image'].shape}\")\n",
    "print(f\" Data type: {sample['image'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a16ed",
   "metadata": {},
   "source": [
    "** What just happened?**\n",
    "- Ray Data loaded thousands of images in seconds\n",
    "- Images are stored as NumPy arrays (height, width, channels)\n",
    "- Data loading is **lazy** - images are only read when needed, saving memory\n",
    "\n",
    "## Step 2: Inference on a Single Batch\n",
    "*‚è± Time: 4 minutes*\n",
    "\n",
    "### What We're Doing\n",
    "Before scaling to thousands of images, let's understand how inference works on a small batch. This helps us debug and understand the process before going distributed.\n",
    "\n",
    "### Why Start Small?\n",
    "- **Debugging**: Easier to spot issues with small batches\n",
    "- **Understanding**: See exactly what happens to your data\n",
    "- **Validation**: Confirm the model works before scaling up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be221d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a small batch to work with - 10 images is perfect for testing\n",
    "# take_batch() returns a pandas DataFrame-like structure\n",
    "print(\" Extracting sample batch for testing...\")\n",
    "try:\n",
    "    single_batch = ds.take_batch(10)\n",
    "    print(f\" Successfully extracted batch\")\n",
    "    print(f\" Batch size: {len(single_batch['image'])}\")\n",
    "    print(f\" First image shape: {single_batch['image'][0].shape}\")\n",
    "    print(f\" Image data type: {single_batch['image'][0].dtype}\")\n",
    "    \n",
    "    # Validate image data\n",
    "    if single_batch['image'][0].shape[2] == 3:\n",
    "        print(f\" Images are RGB format (3 channels)\")\n",
    "    else:\n",
    "        print(f\" Unexpected image format: {single_batch['image'][0].shape[2]} channels\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" Error extracting batch: {e}\")\n",
    "    print(\" Tip: Make sure you have internet connection for S3 access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331cb0bb",
   "metadata": {},
   "source": [
    "Let's visualize one image to make sure our data looks correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5429324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Convert NumPy array back to PIL Image for display\n",
    "# This is a great way to verify your data pipeline\n",
    "img = Image.fromarray(single_batch[\"image\"][0])\n",
    "print(\" Sample image from our dataset:\")\n",
    "img  # This will display the image in Jupyter notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982b9ecb",
   "metadata": {},
   "source": [
    "Now let's set up our pre-trained model for inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import ResNet152_Weights\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "\n",
    "# Use the latest pre-trained weights from ImageNet\n",
    "weights = ResNet152_Weights.IMAGENET1K_V1\n",
    "\n",
    "# Automatically detect if GPU is available - this is crucial for performance\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\" Using device: {device}\")\n",
    "\n",
    "# Load the pre-trained ResNet152 model\n",
    "# ResNet152 is a deep model with 152 layers - great for image classification\n",
    "model = models.resnet152(weights=weights).to(device)\n",
    "model.eval()  # Set to evaluation mode (disables dropout, batch norm updates)\n",
    "\n",
    "# Get the preprocessing transforms that the model expects\n",
    "# These transforms normalize the images to match training data\n",
    "imagenet_transforms = weights.transforms()\n",
    "print(f\" Required transforms: {imagenet_transforms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaae4770",
   "metadata": {},
   "source": [
    "** Key Concepts:**\n",
    "- **Pre-trained models**: Already trained on millions of images, ready to use\n",
    "- **Device selection**: GPU acceleration is much faster than CPU\n",
    "- **Evaluation mode**: Important for consistent inference results\n",
    "\n",
    "Now let's run inference on our small batch to see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c00280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transforms to each image in our batch\n",
    "# These transforms resize, normalize, and prepare images for the model\n",
    "transformed_batch = []\n",
    "for image in single_batch[\"image\"]:\n",
    "    # Convert NumPy array to PIL Image (required for torchvision transforms)\n",
    "    pil_image = Image.fromarray(image)\n",
    "    # Apply the preprocessing transforms\n",
    "    transformed = imagenet_transforms(pil_image)\n",
    "    transformed_batch.append(transformed)\n",
    "\n",
    "print(f\" Transformed {len(transformed_batch)} images\")\n",
    "print(f\"üìè Tensor shape after transform: {transformed_batch[0].shape}\")\n",
    "\n",
    "# Stack individual tensors into a batch tensor\n",
    "batch_tensor = torch.stack(transformed_batch).to(device)\n",
    "print(f\"üîó Batch tensor shape: {batch_tensor.shape}\")\n",
    "\n",
    "# Run inference - this is where the magic happens!\n",
    "with torch.inference_mode():  # More efficient than torch.no_grad()\n",
    "    prediction_results = model(batch_tensor)\n",
    "    classes = prediction_results.argmax(dim=1).cpu()\n",
    "    # Get confidence scores for better understanding\n",
    "    probabilities = torch.softmax(prediction_results, dim=1)\n",
    "    max_probs = probabilities.max(dim=1)[0].cpu()\n",
    "\n",
    "# Convert class indices to human-readable labels\n",
    "labels = [weights.meta[\"categories\"][i] for i in classes]\n",
    "\n",
    "# Display results in a user-friendly way\n",
    "print(\"\\n Prediction Results:\")\n",
    "print(\"-\" * 50)\n",
    "for i, (label, confidence) in enumerate(zip(labels, max_probs)):\n",
    "    print(f\"Image {i+1}: {label} (confidence: {confidence:.2%})\")\n",
    "\n",
    "# Clean up GPU memory - important for larger models\n",
    "del model\n",
    "print(\"\\n GPU memory freed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c5394c",
   "metadata": {},
   "source": [
    "** What's happening here?**\n",
    "- **Preprocessing**: Images are resized and normalized to match training data\n",
    "- **Batching**: Multiple images processed together for efficiency  \n",
    "- **Inference**: Model predicts the most likely class for each image\n",
    "- **Confidence**: We can see how certain the model is about each prediction\n",
    "- **Memory management**: Always clean up GPU memory when done\n",
    "\n",
    "## Step 3: Distributed Batch Processing with Ray Data\n",
    "*‚è± Time: 6 minutes*\n",
    "\n",
    "### The Power of Distribution\n",
    "Now comes the exciting part! We'll scale from 10 images to thousands, automatically using all available CPUs and GPUs. This is where Ray Data really shines.\n",
    "\n",
    "### Why This Matters\n",
    "- **Speed**: Process thousands of images in parallel instead of one-by-one\n",
    "- **Efficiency**: Automatically utilize all available hardware\n",
    "- **Simplicity**: Same code works on your laptop or a 100-node cluster\n",
    "\n",
    "### Performance Comparison\n",
    "- **Traditional approach**: Process 10,000 images ‚Üí ~45 minutes on single CPU\n",
    "- **Ray Data approach**: Process 10,000 images ‚Üí ~3 minutes on 4 GPUs\n",
    "- **Scaling**: Add more GPUs ‚Üí better processing throughput\n",
    "\n",
    "### Preprocessing at Scale\n",
    "First, let's convert our preprocessing code to work with Ray Data's distributed processing. We'll create a function that Ray can run on multiple workers simultaneously.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55839de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Any, Dict\n",
    "\n",
    "def preprocess_image(row: Dict[str, np.ndarray]):\n",
    "    return {\n",
    "        \"original_image\": row[\"image\"],\n",
    "        \"transformed_image\": transform(row[\"image\"]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d9ff15",
   "metadata": {},
   "source": [
    "Then we use the [`map()`](https://docs.ray.io/en/latest/data/api/doc/ray.data.Dataset.map.html#ray.data.Dataset.map) method to apply the function to the whole dataset row by row. We use this instead of [`map_batches()`](https://docs.ray.io/en/latest/data/api/doc/ray.data.Dataset.map_batches.html#ray.data.Dataset.map_batches) because the torchvision transforms must be applied one image at a time, due to the dataset containing images of different sizes.\n",
    "\n",
    "By using Ray Data‚Äôs [`map()`](https://docs.ray.io/en/latest/data/api/doc/ray.data.Dataset.map.html#ray.data.Dataset.map) method, we can scale out the preprocessing to utilize all the resources in our Ray cluster.\n",
    "\n",
    "‚ÄúNote: the [`map()`](https://docs.ray.io/en/latest/data/api/doc/ray.data.Dataset.map.html#ray.data.Dataset.map) method is lazy. It won‚Äôt perform execution until we consume the results with methods like [`iter_batches()`](https://docs.ray.io/en/latest/data/api/doc/ray.data.Dataset.iter_batches.html#ray.data.Dataset.iter_batches) or [`take()`](https://docs.ray.io/en/latest/data/api/doc/ray.data.Dataset.take.html#ray.data.Dataset.take).‚Äù\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e203d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_ds = ds.map(preprocess_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ec434f",
   "metadata": {},
   "source": [
    "### Model Inference\n",
    "Next, let‚Äôs convert the model inference part. Compared with preprocessing, model inference has 2 differences:\n",
    "\n",
    "1. Model loading and initialization is usually expensive.\n",
    "\n",
    "2. Model inference can be optimized with hardware acceleration if we process data in batches. Using larger batches improves GPU utilization and the overall runtime of the inference job.\n",
    "\n",
    "Thus, we convert the model inference code to the following `ResnetModel` class. In this class, we put the expensive model loading and initialization code in the `__init__` constructor, which will run only once. And we put the model inference code in the `__call__` method, which will be called for each batch.\n",
    "\n",
    "The `__call__` method takes a batch of data items, instead of a single one. In this case, the batch is a dict that has the `\"transformed_image\"` key populated by our preprocessing step, and the corresponding value is a Numpy array of images represented in `np.ndarray` format. We reuse the same inferencing logic from step 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda0aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "class ResnetModel:\n",
    "    def __init__(self):\n",
    "        self.weights = ResNet152_Weights.IMAGENET1K_V1\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = models.resnet152(weights=self.weights).to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def __call__(self, batch: Dict[str, np.ndarray]):\n",
    "        # Convert the numpy array of images into a PyTorch tensor.\n",
    "        # Move the tensor batch to GPU if available.\n",
    "        torch_batch = torch.from_numpy(batch[\"transformed_image\"]).to(self.device)\n",
    "        with torch.inference_mode():\n",
    "            prediction = self.model(torch_batch)\n",
    "            predicted_classes = prediction.argmax(dim=1).detach().cpu()\n",
    "            predicted_labels = [\n",
    "                self.weights.meta[\"categories\"][i] for i in predicted_classes\n",
    "            ]\n",
    "            return {\n",
    "                \"predicted_label\": predicted_labels,\n",
    "                \"original_image\": batch[\"original_image\"],\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae2562",
   "metadata": {},
   "source": [
    "Then we use the [`map_batches()`](https://docs.ray.io/en/latest/data/api/doc/ray.data.Dataset.map_batches.html#ray.data.Dataset.map_batches) API to apply the model to the whole dataset:\n",
    "\n",
    "- The first parameter of `map_batches` is the user-defined function (UDF), which can either be a function or a class. Because this case uses a class, the UDF runs as long-running [Ray actors](https://docs.ray.io/en/latest/ray-core/actors.html#actor-guide). For class-based UDFs, use the `concurrency` argument to specify the number of parallel actors.\n",
    "\n",
    "- The num_gpus argument specifies the number of GPUs needed for each `ResnetModel` instance. In this case, we want 1 GPU for each model replica. If you are doing CPU inference, you can remove the `num_gpus=1`.\n",
    "\n",
    "- The `batch_size` argument indicates the number of images in each batch. See the Ray dashboard for GPU memory usage to experiment with the `batch_size` when using your own model and dataset. You should aim to max out the batch size without running out of GPU memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d24a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = transformed_ds.map_batches(\n",
    "    ResnetModel,\n",
    "    concurrency=4,  # Use 4 GPUs. Change this number based on the number of GPUs in your cluster.\n",
    "    num_gpus=1,  # Specify 1 GPU per model replica.\n",
    "    batch_size=720,  # Use the largest batch size that can fit on our GPUs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d4a1f",
   "metadata": {},
   "source": [
    "### Verify and Save Results\n",
    "Let‚Äôs take a small batch of predictions and verify the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68134401",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_batch = predictions.take_batch(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be957fe9",
   "metadata": {},
   "source": [
    "We see that all the images are correctly classified as ‚Äútench‚Äù, which is a type of fish.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7166c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for image, prediction in zip(\n",
    "    prediction_batch[\"original_image\"], prediction_batch[\"predicted_label\"]\n",
    "):\n",
    "    img = Image.fromarray(image)\n",
    "    display(img)\n",
    "    print(\"Label: \", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e4db81",
   "metadata": {},
   "source": [
    "If the samples look good, we can proceed with saving the results to external storage (for example, local disk or cloud storage such as AWS S3). See [the guide on saving data](https://docs.ray.io/en/latest/data/saving-data.html#saving-data) for all supported storage and file formats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b6183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# First, drop the original images to avoid them being saved as part of the predictions.\n",
    "# Then, write the predictions in parquet format to a path with the `local://` prefix\n",
    "# to make sure all results get written on the head node.\n",
    "predictions.drop_columns([\"original_image\"]).write_parquet(f\"local://{temp_dir}\")\n",
    "print(f\"Predictions saved to `{temp_dir}`!\")\n",
    "\n",
    "# Clean up resources\n",
    "ray.shutdown()\n",
    "print(\" Ray cluster shut down successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0217cfd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting Common Issues\n",
    "\n",
    "### **Problem: \"Ray cluster failed to initialize\"**\n",
    "**Solution**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Ray fails to start, try specifying resources explicitly\n",
    "ray.init(num_cpus=4, num_gpus=0)  # Adjust based on your hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a02e49",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **Problem: \"Out of memory errors during processing\"**\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf6ac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce batch size to use less memory\n",
    "ds.map_batches(inference_fn, batch_size=8, concurrency=2)  # Smaller batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd678f75",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **Problem: \"S3 access denied or connection timeout\"**\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac08040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try alternative dataset or local files\n",
    "local_images = ray.data.read_images(\"./local_images/\")  # Use local images instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f2788",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **Problem: \"GPU not being utilized\"**\n",
    "**Solution**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96001289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicitly specify GPU usage\n",
    "ds.map_batches(inference_fn, num_gpus=1, concurrency=1)  # Force GPU usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036f74e3",
   "metadata": {},
   "source": [
    "### **Performance Optimization Tips**\n",
    "\n",
    "1. **Batch Size Tuning**: Start with batch_size=32, adjust based on GPU memory\n",
    "2. **Concurrency Settings**: Use concurrency=num_gpus for GPU workloads\n",
    "3. **Memory Management**: Call `ray.shutdown()` between experiments\n",
    "4. **Data Format**: Use Parquet instead of JSON for large outputs\n",
    "5. **Resource Monitoring**: Watch GPU utilization with `nvidia-smi`\n",
    "\n",
    "### **Performance Considerations**\n",
    "\n",
    "Ray Data's distributed processing provides several advantages for batch inference:\n",
    "- **Parallel execution**: Images are processed across multiple workers simultaneously\n",
    "- **GPU utilization**: Automatic distribution of work across available GPUs\n",
    "- **Memory efficiency**: Large datasets are processed in chunks to avoid memory issues\n",
    "- **Resource optimization**: Automatic load balancing across available hardware\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps and Extensions\n",
    "\n",
    "### **Try These Variations**\n",
    "1. **Different Models**: Replace ResNet152 with EfficientNet or Vision Transformer\n",
    "2. **Custom Data**: Use your own images instead of Imagenette\n",
    "3. **Multi-Class Output**: Modify to output top-5 predictions instead of top-1\n",
    "4. **Batch Size Experiments**: Test different batch sizes and measure performance\n",
    "5. **GPU Scaling**: Try with different numbers of GPUs\n",
    "\n",
    "### **Production Considerations**\n",
    "- **Model Versioning**: Track model versions and performance\n",
    "- **Error Handling**: Implement robust error handling for production workloads\n",
    "- **Monitoring**: Add logging and metrics collection\n",
    "- **Scaling**: Use Ray Autoscaler for dynamic cluster sizing\n",
    "- **Cost Optimization**: Optimize for cost-performance trade-offs\n",
    "\n",
    "### **Documentation and Resources** (rule #122)\n",
    "\n",
    "**Ray Data Documentation**:\n",
    "- [Ray Data Overview](https://docs.ray.io/en/latest/data/data.html)\n",
    "- [Batch Inference Guide](https://docs.ray.io/en/latest/data/batch_inference.html)\n",
    "- [Performance Optimization](https://docs.ray.io/en/latest/data/performance-tips.html)\n",
    "- [API Reference](https://docs.ray.io/en/latest/data/api/api.html)\n",
    "\n",
    "**PyTorch Resources**:\n",
    "- [PyTorch Vision Models](https://pytorch.org/vision/stable/models.html)\n",
    "- [Torchvision Transforms](https://pytorch.org/vision/stable/transforms.html)\n",
    "\n",
    "### **Related Ray Data Templates**\n",
    "- **Ray Data Batch Inference Optimization**: Learn advanced performance tuning\n",
    "- **Ray Data ML Feature Engineering**: Prepare data for model training\n",
    "- **Ray Data Multimodal AI Pipeline**: Process images and text together\n",
    "\n",
    "** Congratulations!** You've successfully built a scalable image classification pipeline with Ray Data!\n",
    "\n",
    "The techniques you learned scale from thousands to millions of images with minimal code changes - that's the power of distributed computing with Ray Data."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
