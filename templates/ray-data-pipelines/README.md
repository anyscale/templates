# Ray Summit 2025 Training: Building scalable, multi-modal data processing pipelines with Ray Data

**Workshop Duration**: 3 hours | **Difficulty**: Intermediate to Advanced | **Prerequisites**: Data engineering experience, Python knowledge

This template demonstrates advanced Ray Data capabilities through three use cases covering batch inference optimization, ETL processing, and unstructured data ingestion.

## Use cases

| Use Case | Duration | Focus Area | Description |
|----------|----------|------------|-------------|
| **[Batch Inference Optimization](https://console.anyscale.com/template-preview/summit25-raydata-pipelines?file=%252Ffiles%252Fbatch-inference-optimization)** | 65 min | ML Inference | Build optimized ML batch inference pipelines using Ray Data's actor-based patterns. Learn to eliminate common bottlenecks and achieve 10-100x performance improvements. |
| **[ETL Processing & Optimization](https://console.anyscale.com/template-preview/summit25-raydata-pipelines?file=%252Ffiles%252Fetl-optimization)** | 40 min | Data Engineering | Process large-scale ETL workflows using TPC-H benchmark data. Master distributed transformations, joins, and data warehouse integration patterns. |
| **[Unstructured Data Ingestion](https://console.anyscale.com/template-preview/summit25-raydata-pipelines?file=%252Ffiles%252Funstructured-data-ingestion)** | 35 min | Document Processing | Transform unstructured documents from data lakes into structured, analytics-ready datasets. Learn document processing, text extraction, and metadata enrichment. |

## Learning outcomes

By the end of this workshop, you'll understand how to:

- **Optimize ML inference** using Ray Data's stateful actors and distributed processing
- **Build production ETL pipelines** that scale from gigabytes to petabytes
- **Process unstructured data** at enterprise scale with document ingestion workflows
- **Apply Ray Data patterns** for real-world data engineering challenges

