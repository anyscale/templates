{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 1: Inference Fundamentals\n",
        "\n",
        "**Time to complete**: 20 min | **Difficulty**: Beginner | **Prerequisites**: Basic Python, ML model concepts\n",
        "\n",
        "**[← Back to Overview](README.md)** | **[Continue to Part 2 →](02-advanced-optimization.md)**\n",
        "\n",
        "---\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "In this part, you'll understand the fundamentals of batch inference optimization by comparing inefficient and efficient approaches:\n",
        "- How to set up Ray Data for accelerated inference (CPU or GPU)\n",
        "- Why naive inference patterns create performance bottlenecks\n",
        "- How Ray Data's actor-based pattern solves these problems\n",
        "- How to implement optimized inference with proper resource allocation for both CPU and GPU\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Introduction and Setup](#introduction-and-setup)\n",
        "2. [The Wrong Way: Inefficient Batch Inference](#the-wrong-way-inefficient-batch-inference)\n",
        "3. [Why the Naive Approach Fails](#why-the-naive-approach-fails)\n",
        "4. [The Right Way: Optimized with Ray Data](#the-right-way-optimized-with-ray-data)\n",
        "\n",
        "---\n",
        "\n",
        "## Introduction and Setup\n",
        "\n",
        "Batch inference is the process of running ML model predictions on large batches of data. While this sounds straightforward, naive implementations create severe performance bottlenecks that prevent production deployment. This part shows you the difference between inefficient and optimized approaches using real-world examples.\n",
        "\n",
        "### What You'll Learn\n",
        "\n",
        "By comparing inefficient and optimized implementations, you'll understand:\n",
        "- **Why** repeated model loading destroys performance\n",
        "- **How** Ray Data's actor pattern solves the problem\n",
        "- **When** to apply specific optimization techniques\n",
        "- **What** parameters to tune for your workload\n",
        "\n",
        "### Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-10 16:32:19,037\tINFO worker.py:1771 -- Connecting to existing Ray cluster at address: 10.0.71.116:6379...\n",
            "2025-10-10 16:32:19,049\tINFO worker.py:1942 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://session-77uweunq3awbhqefvry4lwcqq5.i.anyscaleuserdata.com \u001b[39m\u001b[22m\n",
            "2025-10-10 16:32:19,056\tINFO packaging.py:380 -- Pushing file package 'gcs://_ray_pkg_21cbb801d2a37fbeb0421b1464bfc910a4f77070.zip' (0.15MiB) to Ray cluster...\n",
            "2025-10-10 16:32:19,057\tINFO packaging.py:393 -- Successfully pushed file package 'gcs://_ray_pkg_21cbb801d2a37fbeb0421b1464bfc910a4f77070.zip'.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ray cluster initialized for batch inference optimization\n",
            "Available resources: {'anyscale/node-group:8CPU-32GB': 10.0, 'node:10.0.104.3': 1.0, 'anyscale/provider:aws': 11.0, 'CPU': 80.0, 'memory': 377957122048.0, 'object_store_memory': 105537718267.0, 'anyscale/cpu_only:true': 11.0, 'anyscale/region:us-west-2': 11.0, 'node:10.0.99.160': 1.0, 'node:10.0.116.84': 1.0, 'node:10.0.93.34': 1.0, 'node:10.0.109.213': 1.0, 'node:10.0.94.252': 1.0, 'node:10.0.83.124': 1.0, 'anyscale/node-group:head': 1.0, 'node:__internal_head__': 1.0, 'node:10.0.71.116': 1.0, 'node:10.0.100.254': 1.0, 'node:10.0.83.247': 1.0, 'node:10.0.127.67': 1.0}\n",
            "Ray Data progress bars enabled\n",
            "\n",
            "Using device: cpu\n",
            "No GPU detected - examples will run on CPU\n"
          ]
        }
      ],
      "source": [
        "import ray\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import time\n",
        "\n",
        "# Initialize Ray for distributed processing\n",
        "ray.init(ignore_reinit_error=True)\n",
        "\n",
        "print(\"Ray cluster initialized for batch inference optimization\")\n",
        "print(f\"Available resources: {ray.cluster_resources()}\")\n",
        "\n",
        "# Configure Ray Data for optimal performance monitoring\n",
        "try:\n",
        "    ctx = ray.data.DataContext.get_current()\n",
        "    ctx.enable_progress_bars = True\n",
        "    ctx.enable_operator_progress_bars = True\n",
        "    print(\"Ray Data progress bars enabled\")\n",
        "except Exception as e:\n",
        "    print(f\"Note: Could not configure Ray Data context (progress bars disabled): {e}\")\n",
        "    print(\"This doesn't affect functionality - continuing with notebook...\")\n",
        "\n",
        "# Detect hardware availability\n",
        "HAS_GPU = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if HAS_GPU else \"cpu\")\n",
        "\n",
        "print(f\"\\nUsing device: {device}\")\n",
        "if HAS_GPU:\n",
        "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
        "    print(\"GPU detected - examples will use GPU acceleration\")\n",
        "else:\n",
        "    print(\"No GPU detected - examples will run on CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Tip:</b> **GPU acceleration**: This template works on both CPU-only and GPU clusters, code automatically detects GPUs and uses `num_gpus=1` for acceleration, set the num\n",
        "</div>\n",
        "\n",
        "All optimization concepts (actor-based loading, batching, concurrency) apply equally to both environments.\n",
        "\n",
        "\n",
        "### Load Demo Dataset\n",
        "\n",
        "For this demonstration, you'll use the Imagenette dataset, which provides a realistic subset of ImageNet with 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = ray.data.read_images(\n",
        "        \"s3://anonymous@air-example-data-2/imagenette2/train/\",\n",
        "        mode=\"RGB\"\n",
        "    ) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## The Wrong Way: Inefficient Batch Inference\n",
        "\n",
        "This section demonstrates a common anti-pattern in ML inference systems. Understanding why this approach fails is essential before learning the optimized solution.\n",
        "\n",
        "When models are loaded repeatedly for each batch, the initialization overhead dominates processing time. This pattern is unfortunately common in production systems where developers haven't considered the cost of model loading operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-10 16:32:24,722\tINFO dataset.py:3248 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
            "2025-10-10 16:32:24,724\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_2_0\n",
            "2025-10-10 16:32:24,779\tINFO streaming_executor.py:159 -- Starting execution of Dataset dataset_2_0. Full logs are in /tmp/ray/session_2025-10-10_16-23-49_015346_2333/logs/ray-data\n",
            "2025-10-10 16:32:24,780\tINFO streaming_executor.py:160 -- Execution plan of Dataset dataset_2_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> TaskPoolMapOperator[MapBatches(inefficient_inference)] -> LimitOperator[limit=1000]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbf05689fae648ae8b5a76f03a123a87",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running 0: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c823745c332477782b1c08b05075a2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- ListFiles 1: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c10655cd9504bf5829d554f911f2a6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- ReadFiles 2: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "483bf71e2cd94da0b0b0186e7320d839",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- MapBatches(inefficient_inference) 3: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc393b86136f42f58dad0fcabaec4d80",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- limit=1000 4: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-10 16:32:24,834\tWARNING resource_manager.py:134 -- ⚠️  Ray's object store is configured to use only 27.9% of available memory (98.3GiB out of 352.0GiB total). For optimal Ray Data performance, we recommend setting the object store to at least 50% of available memory. You can do this by setting the 'object_store_memory' parameter when calling ray.init() or by setting the RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION environment variable.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /home/ray/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0.00/230M [00:00<?, ?B/s]d=2681, ip=10.0.83.247)\u001b[0m \n",
            "  4%|▍         | 9.62M/230M [00:00<00:02, 100MB/s]ip=10.0.83.247)\u001b[0m \n",
            "  9%|▉         | 20.4M/230M [00:00<00:02, 107MB/s]ip=10.0.83.247)\u001b[0m \n",
            " 18%|█▊        | 40.6M/230M [00:00<00:01, 155MB/s]ip=10.0.83.247)\u001b[0m \n",
            " 27%|██▋       | 62.6M/230M [00:00<00:00, 184MB/s]ip=10.0.83.247)\u001b[0m \n",
            "100%|██████████| 230M/230M [00:01<00:00, 206MB/s] ip=10.0.83.247)\u001b[0m \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Model loading (per batch) took: 2.28 seconds\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Processing batch of 4 images...\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Current device: cpu\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Created temporary directory: /tmp/tmprg965k1x\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Processing image 1/4\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Saved temporary tensor to /tmp/tmprg965k1x/temp_image_0.pt\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Processing image 2/4\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Saved temporary tensor to /tmp/tmprg965k1x/temp_image_1.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 230M/230M [00:01<00:00, 219MB/s] ip=10.0.99.160)\u001b[0m \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Processing image 3/4\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Saved temporary tensor to /tmp/tmprg965k1x/temp_image_2.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 213M/230M [00:01<00:00, 228MB/s] ip=10.0.83.124)\u001b[0m \n",
            "100%|██████████| 230M/230M [00:01<00:00, 222MB/s] ip=10.0.83.124)\u001b[0m \n",
            "100%|██████████| 230M/230M [00:01<00:00, 198MB/s] ip=10.0.127.67)\u001b[0m \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /home/ray/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Model loading (per batch) took: 0.83 seconds\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Current device: cpu\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Created temporary directory: /tmp/tmpn284ef0j\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Processing image 3/4\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Saved temporary tensor to /tmp/tmpn284ef0j/temp_image_2.pt\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Created temporary directory: /tmp/tmphxpnmgzh\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Model loading (per batch) took: 0.94 seconds\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Current device: cpu\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Created temporary directory: /tmp/tmpheyjga4m\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Processing image 1/4\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Saved temporary tensor to /tmp/tmpheyjga4m/temp_image_0.pt\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2586, ip=10.0.83.124)\u001b[0m Created temporary directory: /tmp/tmpzclazsjf\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2586, ip=10.0.83.124)\u001b[0m Created temporary directory: /tmp/tmpyfdzhkko\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2586, ip=10.0.83.124)\u001b[0m Model loading (per batch) took: 0.83 seconds\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2586, ip=10.0.83.124)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2586, ip=10.0.83.124)\u001b[0m Current device: cpu\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Created temporary directory: /tmp/tmp88uiu6p6\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2586, ip=10.0.83.124)\u001b[0m Processing image 3/4\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2586, ip=10.0.83.124)\u001b[0m Saved temporary tensor to /tmp/tmpyfdzhkko/temp_image_2.pt\u001b[32m [repeated 60x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0.00/230M [00:00<?, ?B/s]\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            " 89%|████████▉ | 206M/230M [00:01<00:00, 216MB/s]\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(MapBatches(inefficient_inference) pid=2603, ip=10.0.100.254)\u001b[0m Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /home/ray/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2594, ip=10.0.99.160)\u001b[0m Model loading (per batch) took: 0.90 seconds\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2594, ip=10.0.99.160)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2594, ip=10.0.99.160)\u001b[0m Current device: cpu\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2594, ip=10.0.99.160)\u001b[0m Created temporary directory: /tmp/tmp071ys1ue\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2594, ip=10.0.99.160)\u001b[0m Processing image 1/4\u001b[32m [repeated 31x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2594, ip=10.0.99.160)\u001b[0m Saved temporary tensor to /tmp/tmp071ys1ue/temp_image_0.pt\u001b[32m [repeated 31x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 230M/230M [00:01<00:00, 196MB/s] ip=10.0.100.254)\u001b[0m \n",
            " 93%|█████████▎| 214M/230M [00:01<00:00, 245MB/s] ip=10.0.104.3)\u001b[0m \n",
            "100%|██████████| 230M/230M [00:01<00:00, 226MB/s] ip=10.0.104.3)\u001b[0m \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(MapBatches(inefficient_inference) pid=2603, ip=10.0.100.254)\u001b[0m Created temporary directory: /tmp/tmptfhup_w_\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 75.8M/230M [00:00<00:00, 207MB/s]ip=10.0.116.84)\u001b[0m \n",
            " 96%|█████████▌| 220M/230M [00:01<00:00, 214MB/s] ip=10.0.116.84)\u001b[0m \n",
            "100%|██████████| 230M/230M [00:01<00:00, 209MB/s] ip=10.0.116.84)\u001b[0m \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(MapBatches(inefficient_inference) pid=2594, ip=10.0.99.160)\u001b[0m Created temporary directory: /tmp/tmp_ujrbvmu\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /home/ray/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Model loading (per batch) took: 0.83 seconds\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Current device: cpu\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Created temporary directory: /tmp/tmpb2flx4c5\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Processing image 1/4\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Saved temporary tensor to /tmp/tmpb2flx4c5/temp_image_0.pt\u001b[32m [repeated 48x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2603, ip=10.0.100.254)\u001b[0m Created temporary directory: /tmp/tmpwt_fefap\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Model loading (per batch) took: 0.85 seconds\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Current device: cpu\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Created temporary directory: /tmp/tmpd75116gs\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Processing image 1/4\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Saved temporary tensor to /tmp/tmpd75116gs/temp_image_0.pt\u001b[32m [repeated 64x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Created temporary directory: /tmp/tmplmwzqwms\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2603, ip=10.0.100.254)\u001b[0m Model loading (per batch) took: 0.89 seconds\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2603, ip=10.0.100.254)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2603, ip=10.0.100.254)\u001b[0m Current device: cpu\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2603, ip=10.0.100.254)\u001b[0m Created temporary directory: /tmp/tmp4tudzeyw\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2603, ip=10.0.100.254)\u001b[0m Processing image 3/4\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2603, ip=10.0.100.254)\u001b[0m Saved temporary tensor to /tmp/tmp4tudzeyw/temp_image_2.pt\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Created temporary directory: /tmp/tmpczfslytp\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0.00/230M [00:00<?, ?B/s]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            " 87%|████████▋ | 200M/230M [00:01<00:00, 215MB/s]\u001b[32m [repeated 28x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /home/ray/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 230M/230M [00:01<00:00, 217MB/s] ip=10.0.109.213)\u001b[0m \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Model loading (per batch) took: 2.18 seconds\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Current device: cpu\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Created temporary directory: /tmp/tmpscehwhs3\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Processing image 3/4\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Saved temporary tensor to /tmp/tmpscehwhs3/temp_image_2.pt\u001b[32m [repeated 34x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 230M/230M [00:01<00:00, 236MB/s] ip=10.0.93.34)\u001b[0m \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(MapBatches(inefficient_inference) pid=2689, ip=10.0.93.34)\u001b[0m Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /home/ray/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Created temporary directory: /tmp/tmppnkoooop\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Model loading (per batch) took: 0.82 seconds\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Current device: cpu\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2689, ip=10.0.93.34)\u001b[0m Created temporary directory: /tmp/tmp7573q6pc\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Processing image 2/4\u001b[32m [repeated 55x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Saved temporary tensor to /tmp/tmppnkoooop/temp_image_1.pt\u001b[32m [repeated 55x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2594, ip=10.0.99.160)\u001b[0m Created temporary directory: /tmp/tmpmjpwdblx\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Model loading (per batch) took: 0.83 seconds\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Current device: cpu\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Created temporary directory: /tmp/tmpqyl956m1\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Processing image 1/4\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2584, ip=10.0.109.213)\u001b[0m Saved temporary tensor to /tmp/tmpqyl956m1/temp_image_0.pt\u001b[32m [repeated 63x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2594, ip=10.0.99.160)\u001b[0m Created temporary directory: /tmp/tmpfzuvsogv\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Model loading (per batch) took: 0.84 seconds\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Current device: cpu\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Created temporary directory: /tmp/tmp287ltft6\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Processing image 1/4\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2679, ip=10.0.127.67)\u001b[0m Saved temporary tensor to /tmp/tmp287ltft6/temp_image_0.pt\u001b[32m [repeated 56x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /home/ray/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0.00/230M [00:00<?, ?B/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            " 88%|████████▊ | 202M/230M [00:00<00:00, 244MB/s]\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
            " 97%|█████████▋| 223M/230M [00:01<00:00, 232MB/s] ip=10.0.94.252)\u001b[0m \n",
            "100%|██████████| 230M/230M [00:01<00:00, 212MB/s] ip=10.0.94.252)\u001b[0m \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Model loading (per batch) took: 0.83 seconds\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Current device: cpu\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Created temporary directory: /tmp/tmpwusq9517\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2603, ip=10.0.100.254)\u001b[0m Processing image 2/4\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2603, ip=10.0.100.254)\u001b[0m Saved temporary tensor to /tmp/tmprinus5ii/temp_image_1.pt\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Created temporary directory: /tmp/tmppnremdgr\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2603, ip=10.0.100.254)\u001b[0m Created temporary directory: /tmp/tmp_efyljnj\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Model loading (per batch) took: 0.83 seconds\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Current device: cpu\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Created temporary directory: /tmp/tmpfwcz4l3c\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Processing image 1/4\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Saved temporary tensor to /tmp/tmpfwcz4l3c/temp_image_0.pt\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Model loading (per batch) took: 0.84 seconds\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Current device: cpu\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Created temporary directory: /tmp/tmpp5gxx94b\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Processing image 1/4\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2587, ip=10.0.94.252)\u001b[0m Saved temporary tensor to /tmp/tmpp5gxx94b/temp_image_0.pt\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2849, ip=10.0.104.3)\u001b[0m Created temporary directory: /tmp/tmphqkmxdpj\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2594, ip=10.0.99.160)\u001b[0m Model loading (per batch) took: 0.89 seconds\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2594, ip=10.0.99.160)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2594, ip=10.0.99.160)\u001b[0m Current device: cpu\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2594, ip=10.0.99.160)\u001b[0m Created temporary directory: /tmp/tmpvctul2b8\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Processing image 4/4\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Saved temporary tensor to /tmp/tmp5pawq5xe/temp_image_3.pt\u001b[32m [repeated 57x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Model loading (per batch) took: 0.83 seconds\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Current device: cpu\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Created temporary directory: /tmp/tmpo8bkic90\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Processing image 3/4\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Saved temporary tensor to /tmp/tmpo8bkic90/temp_image_2.pt\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Model loading (per batch) took: 0.85 seconds\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Current device: cpu\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Created temporary directory: /tmp/tmp_9z_o3ox\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Processing image 1/4\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2726, ip=10.0.116.84)\u001b[0m Saved temporary tensor to /tmp/tmp_9z_o3ox/temp_image_0.pt\u001b[32m [repeated 61x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2689, ip=10.0.93.34)\u001b[0m Model loading (per batch) took: 0.83 seconds\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2689, ip=10.0.93.34)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2689, ip=10.0.93.34)\u001b[0m Current device: cpu\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2689, ip=10.0.93.34)\u001b[0m Created temporary directory: /tmp/tmp0a1x6u2r\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2689, ip=10.0.93.34)\u001b[0m Processing image 1/4\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2689, ip=10.0.93.34)\u001b[0m Saved temporary tensor to /tmp/tmp0a1x6u2r/temp_image_0.pt\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Model loading (per batch) took: 0.98 seconds\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Current device: cpu\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Created temporary directory: /tmp/tmpl55el0c1\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Processing image 1/4\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Saved temporary tensor to /tmp/tmpl55el0c1/temp_image_0.pt\u001b[32m [repeated 60x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2681, ip=10.0.83.247)\u001b[0m Created temporary directory: /tmp/tmpfwurlrzk\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2689, ip=10.0.93.34)\u001b[0m Model loading (per batch) took: 0.87 seconds\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2689, ip=10.0.93.34)\u001b[0m Processing batch of 4 images...\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2689, ip=10.0.93.34)\u001b[0m Current device: cpu\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2689, ip=10.0.93.34)\u001b[0m Created temporary directory: /tmp/tmpdbotcpd3\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2689, ip=10.0.93.34)\u001b[0m Processing image 1/4\u001b[32m [repeated 62x across cluster]\u001b[0m\n",
            "\u001b[36m(MapBatches(inefficient_inference) pid=2689, ip=10.0.93.34)\u001b[0m Saved temporary tensor to /tmp/tmpdbotcpd3/temp_image_0.pt\u001b[32m [repeated 62x across cluster]\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-10 16:35:50,185\tINFO streaming_executor.py:279 -- ✔️  Dataset dataset_2_0 execution finished in 205.40 seconds\n"
          ]
        }
      ],
      "source": [
        "from typing import Dict, Any\n",
        "import torch\n",
        "from torchvision.models import ResNet152_Weights\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "weights = ResNet152_Weights.IMAGENET1K_V1\n",
        "\n",
        "# ============================================================================\n",
        "# MISTAKE 1: Model initialization at module level\n",
        "# ============================================================================\n",
        "# NEVER do this: model = models.resnet152(weights=weights)\n",
        "#\n",
        "# WHY THIS IS WRONG:\n",
        "# - When Ray serializes this function for distributed execution, it would try \n",
        "#   to serialize the entire model object and store it in the object store\n",
        "# - ResNet152 is ~230MB, so every worker would need to download this massive\n",
        "#   serialized object from the object store\n",
        "# - This causes huge memory overhead and network transfer costs\n",
        "# - Ray's object store would be unnecessarily bloated with duplicate models\n",
        "#\n",
        "# CORRECT APPROACH:\n",
        "# - Use a callable class with __init__ and __call__ methods\n",
        "# - Load the model once in __init__ (per worker)\n",
        "# - Reuse the model across all batches in __call__\n",
        "# ============================================================================\n",
        "\n",
        "def inefficient_inference(batch: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"INEFFICIENT: Loads model for every single batch.\n",
        "    \n",
        "    Anti-pattern demonstration - DO NOT use this approach in production!\n",
        "    This function intentionally shows bad practices to highlight optimization opportunities.\n",
        "    \n",
        "    Note: This example runs on CPU for classroom use. The antipatterns shown here\n",
        "    apply equally to GPU-based inference, where the performance differences would\n",
        "    be even more pronounced.\n",
        "    \n",
        "    Args:\n",
        "        batch: Dictionary containing 'image' key with array of images\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary with 'prediction' and 'image' arrays\n",
        "    \"\"\"\n",
        "    import time\n",
        "    import requests\n",
        "    import json\n",
        "    import tempfile\n",
        "    import os\n",
        "    \n",
        "    # ========================================================================\n",
        "    # MISTAKE 2: Model loading happens inside the batch processing function\n",
        "    # ========================================================================\n",
        "    # This is the MOST CRITICAL performance mistake in this code.\n",
        "    #\n",
        "    # WHY THIS IS WRONG:\n",
        "    # - The model gets loaded from scratch for EVERY SINGLE BATCH\n",
        "    # - ResNet152 has 60+ million parameters that need to be initialized\n",
        "    # - Loading weights from disk/network is extremely expensive (gigabytes)\n",
        "    # - With batch_size=4 and 1000 samples, this loads the model 250 times\n",
        "    #\n",
        "    # CORRECT APPROACH:\n",
        "    # - Use a callable class with __init__ and __call__ methods\n",
        "    # - Load the model once in __init__ (per worker)\n",
        "    # - Reuse the model across all batches in __call__\n",
        "    # ========================================================================\n",
        "    start_load = time.time()\n",
        "    \n",
        "    # Note: Using CPU for classroom environment\n",
        "    # In production with GPUs, you would use: torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "    model = models.resnet152(weights=weights).to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # ========================================================================\n",
        "    # MISTAKE 3: Transform pipeline recreated for every batch\n",
        "    # ========================================================================\n",
        "    # WHY THIS IS WRONG:\n",
        "    # - While less expensive than reloading the model, this still has overhead\n",
        "    # - Transform objects and their internal state get recreated repeatedly\n",
        "    # - ImageNet transforms include normalization parameters that are constants\n",
        "    # - Unnecessary object creation causes garbage collection pressure\n",
        "    #\n",
        "    # CORRECT APPROACH:\n",
        "    # - Create transforms once in __init__ method\n",
        "    # - Reuse the same transform pipeline for all batches\n",
        "    # ========================================================================\n",
        "    imagenet_transforms = weights.transforms()\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        imagenet_transforms\n",
        "    ])\n",
        "\n",
        "    load_time = time.time() - start_load\n",
        "    print(f\"Model loading (per batch) took: {load_time:.2f} seconds\")\n",
        "    \n",
        "    # ========================================================================\n",
        "    # MISTAKE 4: Excessive per-batch logging/printing\n",
        "    # ========================================================================\n",
        "    # WHY THIS IS WRONG:\n",
        "    # - Print statements in distributed tasks create massive log files\n",
        "    # - Each worker prints to stdout, creating I/O contention\n",
        "    # - Logs get scattered across different worker processes\n",
        "    # - With 1000 batches, you get 1000+ print statements flooding logs\n",
        "    # - Makes debugging harder (signal-to-noise ratio problems)\n",
        "    #\n",
        "    # CORRECT APPROACH:\n",
        "    # - Use proper logging with appropriate log levels\n",
        "    # - Log only errors and warnings during execution\n",
        "    # - Use Ray metrics/counters for monitoring\n",
        "    # - Sample logging (log every Nth batch, not every batch)\n",
        "    # ========================================================================\n",
        "    print(f\"Processing batch of {len(batch['image'])} images...\")\n",
        "    print(f\"Current device: {device}\")\n",
        "    \n",
        "    # ========================================================================\n",
        "    # MISTAKE 5: Synchronous network I/O inside inference function\n",
        "    # ========================================================================\n",
        "    # WHY THIS IS WRONG:\n",
        "    # - Making HTTP requests during inference blocks the entire batch\n",
        "    # - Network latency is orders of magnitude slower than inference\n",
        "    # - External services can fail, timeout, or rate-limit you\n",
        "    # - Creates hard dependency on external service availability\n",
        "    # - CPU sits idle while waiting for network responses\n",
        "    #\n",
        "    # CORRECT APPROACH:\n",
        "    # - Separate data processing from external I/O operations\n",
        "    # - Use async/batch APIs if external calls are necessary\n",
        "    # - Cache results from external services\n",
        "    # - Consider using Ray Data's read_* functions for data loading\n",
        "    # ========================================================================\n",
        "    # try:\n",
        "    #     # Simulating calling an external API for \"metadata\" (DON'T DO THIS!)\n",
        "    #     response = requests.get(\n",
        "    #         \"https://api.example.com/model-config\",\n",
        "    #         timeout=5\n",
        "    #     )\n",
        "    #     config = response.json()\n",
        "    #     print(f\"Retrieved config from API: {config}\")\n",
        "    # except Exception as e:\n",
        "    #     print(f\"API call failed (this is expected in this demo): {e}\")\n",
        "    #     config = {}\n",
        "    \n",
        "    # ========================================================================\n",
        "    # MISTAKE 6: Unnecessary data format conversions\n",
        "    # ========================================================================\n",
        "    # WHY THIS IS WRONG:\n",
        "    # - Converting between numpy, pandas, PyArrow, and torch repeatedly\n",
        "    # - Each conversion allocates new memory and copies data\n",
        "    # - Pandas DataFrame creation has significant overhead\n",
        "    # - Converting back and forth wastes CPU cycles\n",
        "    #\n",
        "    # CORRECT APPROACH:\n",
        "    # - Keep data in optimal format for your operations\n",
        "    # - For PyTorch: work with tensors directly\n",
        "    # - Minimize conversions; convert once at boundaries\n",
        "    # - Use zero-copy operations when possible\n",
        "    # ========================================================================\n",
        "    # Unnecessarily convert to pandas then back (DON'T DO THIS!)\n",
        "    df = pd.DataFrame(batch)\n",
        "    images_from_df = df[\"image\"].tolist()\n",
        "    \n",
        "    # ========================================================================\n",
        "    # MISTAKE 7: Creating temporary files during inference\n",
        "    # ========================================================================\n",
        "    # WHY THIS IS WRONG:\n",
        "    # - Disk I/O is much slower than memory operations\n",
        "    # - File creation/deletion creates filesystem overhead\n",
        "    # - Temporary files can fill disk space if not cleaned up\n",
        "    # - Multiple workers writing files simultaneously causes contention\n",
        "    #\n",
        "    # CORRECT APPROACH:\n",
        "    # - Keep all intermediate data in memory\n",
        "    # - Use numpy arrays or tensors for temporary data\n",
        "    # - Only write files for final outputs if necessary\n",
        "    # ========================================================================\n",
        "    temp_dir = tempfile.mkdtemp()\n",
        "    print(f\"Created temporary directory: {temp_dir}\")\n",
        "    \n",
        "    # MISTAKE 8: Processing images one-by-one instead of batched inference\n",
        "    predictions = []\n",
        "    confidence_scores = []\n",
        "\n",
        "    for idx, img in enumerate(images_from_df):\n",
        "        print(f\"Processing image {idx + 1}/{len(images_from_df)}\")\n",
        "        \n",
        "        # MISTAKE 9: Inefficient data transfer patterns\n",
        "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "        \n",
        "        # MISTAKE 10: Writing temporary files during inference loop\n",
        "        temp_file = os.path.join(temp_dir, f\"temp_image_{idx}.pt\")\n",
        "        torch.save(img_tensor, temp_file)\n",
        "        print(f\"Saved temporary tensor to {temp_file}\")\n",
        "        \n",
        "        # Run inference on a single image\n",
        "        with torch.no_grad():\n",
        "            prediction = model(img_tensor)\n",
        "            \n",
        "            # MISTAKE 11: Not using mixed precision on GPUs\n",
        "            # MISTAKE 12: Unnecessary device synchronization\n",
        "            predicted_classes = prediction.argmax(dim=1).detach().cpu()\n",
        "            predicted_label = weights.meta[\"categories\"][predicted_classes[0].item()]\n",
        "            \n",
        "            # Get confidence score\n",
        "            probs = torch.nn.functional.softmax(prediction, dim=1)\n",
        "            confidence = probs.max().detach().cpu().item()\n",
        "        \n",
        "        predictions.append(predicted_label)\n",
        "        confidence_scores.append(confidence)\n",
        "        \n",
        "        # Clean up temp file (but this still wasted time creating it!)\n",
        "        os.remove(temp_file)\n",
        "    \n",
        "    # MISTAKE 13: Not managing memory properly\n",
        "    # Clean up temporary directory\n",
        "    try:\n",
        "        os.rmdir(temp_dir)\n",
        "    except:\n",
        "        pass  # Directory might not be empty, but we don't care in this demo\n",
        "    \n",
        "    # MISTAKE 14: Returning inefficient data structures\n",
        "    # Return dictionary with equal-length arrays\n",
        "    return {\n",
        "        \"prediction\": predictions,\n",
        "        \"confidence\": confidence_scores,\n",
        "        \"image\": batch[\"image\"]\n",
        "    }\n",
        "\n",
        "# MISTAKE 15: Suboptimal resource configuration\n",
        "inefficient_results = dataset.map_batches(\n",
        "    inefficient_inference,\n",
        "    num_cpus=8,  # Too many CPUs reserved per task\n",
        "    batch_size=4,  # Too small for efficient processing\n",
        "    concurrency=4  # Too low for this cluster\n",
        ").take(1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"background-color: #e7f3ff; border-left: 4px solid #2196F3; padding: 12px; margin: 16px 0;\">\n",
        "<strong>Quick Reference:</strong> The most critical mistakes in Ray Data inference are initialization patterns (Mistakes 1-3) and batching strategies (Mistake 8). These alone can cause 10-100x performance differences.\n",
        "</div>\n",
        "\n",
        "## Mistake 1: Model initialization at module level\n",
        "\n",
        "**Why this is wrong:**\n",
        "- When Ray serializes the function for distributed execution, it tries to serialize the entire model object and store it in the object store\n",
        "- Large models (ResNet152 is ~230MB) cause every worker to download massive serialized objects\n",
        "- Causes huge memory overhead and network transfer costs\n",
        "- Ray's object store becomes unnecessarily bloated with duplicate models\n",
        "\n",
        "**Correct approach:**\n",
        "- Use a callable class with `__init__` and `__call__` methods\n",
        "- Load the model once in `__init__` (per worker)\n",
        "- Reuse the model across all batches in `__call__`\n",
        "\n",
        "```python\n",
        "# Wrong: Model loaded at module level\n",
        "model = torchvision.models.resnet152(pretrained=True)\n",
        "\n",
        "def process_batch(batch):\n",
        "    return model(batch[\"image\"])\n",
        "\n",
        "# Correct: Model loaded once per worker\n",
        "class ImageClassifier:\n",
        "    def __init__(self):\n",
        "        self.model = torchvision.models.resnet152(pretrained=True)\n",
        "        self.model.eval()\n",
        "    \n",
        "    def __call__(self, batch):\n",
        "        return self.model(batch[\"image\"])\n",
        "```\n",
        "\n",
        "## Mistake 2: Model loading inside the batch processing function\n",
        "\n",
        "**Why this is wrong:**\n",
        "- The model gets loaded from scratch for EVERY SINGLE BATCH\n",
        "- Models with millions of parameters need to be initialized repeatedly\n",
        "- Loading weights from disk/network is extremely expensive\n",
        "- With small batch sizes, you reload the model hundreds or thousands of times\n",
        "\n",
        "**Correct approach:**\n",
        "- Use a callable class with `__init__` and `__call__` methods\n",
        "- Load the model once in `__init__` (per worker)\n",
        "- Reuse the model across all batches in `__call__`\n",
        "\n",
        "```python\n",
        "# Wrong: Model reloaded for every batch\n",
        "def process_batch(batch):\n",
        "    model = torchvision.models.resnet152(pretrained=True)  # Loaded every time\n",
        "    model.eval()\n",
        "    return model(batch[\"image\"])\n",
        "\n",
        "# Correct: Model loaded once, reused for all batches\n",
        "class ImageClassifier:\n",
        "    def __init__(self):\n",
        "        self.model = torchvision.models.resnet152(pretrained=True)\n",
        "        self.model.eval()\n",
        "    \n",
        "    def __call__(self, batch):\n",
        "        return self.model(batch[\"image\"])\n",
        "```\n",
        "\n",
        "<div style=\"background-color: #fff3cd; border-left: 4px solid #ffc107; padding: 12px; margin: 16px 0;\">\n",
        "<strong>Performance Impact:</strong> Loading a ResNet152 model takes approximately 2-3 seconds. If you process 1,000 batches, Mistake 2 wastes 2,000-3,000 seconds (33-50 minutes) just reloading the same model repeatedly.\n",
        "</div>\n",
        "\n",
        "## Mistake 3: Transform pipeline recreated for every batch\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Transform objects and their internal state get recreated repeatedly\n",
        "- Normalization parameters and other constants are recomputed\n",
        "- Unnecessary object creation causes garbage collection pressure\n",
        "\n",
        "**Correct approach:**\n",
        "- Create transforms once in `__init__` method\n",
        "- Reuse the same transform pipeline for all batches\n",
        "\n",
        "## Mistake 4: Excessive per-batch logging/printing\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Print statements in distributed tasks create massive log files\n",
        "- Each worker prints to stdout, creating I/O contention\n",
        "- Logs get scattered across different worker processes\n",
        "- Makes debugging harder (signal-to-noise ratio problems)\n",
        "\n",
        "**Correct approach:**\n",
        "- Use proper logging with appropriate log levels\n",
        "- Log only errors and warnings during execution\n",
        "- Use Ray metrics/counters for monitoring\n",
        "- Sample logging (log every Nth batch, not every batch)\n",
        "\n",
        "## Mistake 5: Synchronous network I/O inside inference function\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Making HTTP requests during inference blocks the entire batch\n",
        "- Network latency is orders of magnitude slower than inference\n",
        "- External services can fail, timeout, or rate-limit you\n",
        "- Creates hard dependency on external service availability\n",
        "- Compute resources sit idle while waiting for network responses\n",
        "\n",
        "**Correct approach:**\n",
        "- Separate data processing from external I/O operations\n",
        "- Use async/batch APIs if external calls are necessary\n",
        "- Cache results from external services\n",
        "- Consider using Ray Data's `read_*` functions for data loading\n",
        "\n",
        "```python\n",
        "# Wrong: HTTP request during inference\n",
        "def process_batch(batch):\n",
        "    results = []\n",
        "    for image in batch[\"image\"]:\n",
        "        metadata = requests.get(f\"https://api.example.com/meta/{image.id}\")  # Blocks\n",
        "        result = model(image)\n",
        "        results.append(result)\n",
        "    return results\n",
        "\n",
        "# Correct: Preload metadata separately\n",
        "metadata_ds = ray.data.read_json(\"s3://bucket/metadata/\")\n",
        "image_ds = ray.data.read_images(\"s3://bucket/images/\")\n",
        "joined_ds = image_ds.zip(metadata_ds)\n",
        "```\n",
        "\n",
        "## Mistake 6: Unnecessary data format conversions\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Converting between numpy, pandas, PyArrow, and torch repeatedly\n",
        "- Each conversion allocates new memory and copies data\n",
        "- Pandas DataFrame creation has significant overhead\n",
        "- Converting back and forth wastes CPU cycles\n",
        "\n",
        "**Correct approach:**\n",
        "- Keep data in optimal format for your operations\n",
        "- For PyTorch: work with tensors directly\n",
        "- Minimize conversions; convert once at boundaries\n",
        "- Use zero-copy operations when possible\n",
        "\n",
        "<div style=\"background-color: #e8f5e9; border-left: 4px solid #4caf50; padding: 12px; margin: 16px 0;\">\n",
        "<strong>Pro Tip:</strong> Use <code>batch_format=\"numpy\"</code> in <code>map_batches()</code> to receive batches in the most efficient format for your operation. Ray Data handles the conversion once at the boundary.\n",
        "</div>\n",
        "\n",
        "## Mistake 7: Creating temporary files during inference\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Disk I/O is much slower than memory operations\n",
        "- File creation/deletion creates filesystem overhead\n",
        "- Temporary files can fill disk space if not cleaned up\n",
        "- Multiple workers writing files simultaneously causes contention\n",
        "\n",
        "**Correct approach:**\n",
        "- Keep all intermediate data in memory\n",
        "- Use numpy arrays or tensors for temporary data\n",
        "- Only write files for final outputs if necessary\n",
        "\n",
        "## Mistake 8: Processing images one-by-one instead of batched inference\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Neural networks are optimized for batch processing\n",
        "- Processing one image at a time prevents vectorization benefits\n",
        "- With GPUs: compute units sit idle (poor parallelization)\n",
        "- With CPUs: SIMD instructions and cache aren't utilized effectively\n",
        "- Each forward pass has overhead\n",
        "- Memory bandwidth is underutilized\n",
        "\n",
        "**Correct approach:**\n",
        "- Stack all images in the batch into a single tensor\n",
        "- Run one forward pass on the entire batch: `model(stacked_tensor)`\n",
        "- Let PyTorch parallelize across batch dimension\n",
        "\n",
        "```python\n",
        "# Wrong: Process images one-by-one\n",
        "def process_batch(batch):\n",
        "    results = []\n",
        "    for image in batch[\"image\"]:\n",
        "        result = self.model(image.unsqueeze(0))  # Single image forward pass\n",
        "        results.append(result)\n",
        "    return results\n",
        "\n",
        "# Correct: Batched inference\n",
        "def __call__(self, batch):\n",
        "    images = torch.stack([torch.tensor(img) for img in batch[\"image\"]])\n",
        "    results = self.model(images)  # Single batched forward pass\n",
        "    return {\"predictions\": results.cpu().numpy()}\n",
        "```\n",
        "\n",
        "## Mistake 9: Inefficient data transfer patterns\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Moving data to device (CPU or GPU) has overhead\n",
        "- Doing it per-image instead of per-batch multiplies overhead\n",
        "- Each `.to(device)` call can synchronize operations\n",
        "- Prevents overlapping compute and data movement\n",
        "\n",
        "**Correct approach:**\n",
        "- Transfer entire batch to device at once\n",
        "- For GPU: use `pin_memory=True` for faster transfers\n",
        "- For GPU: overlap data transfer with computation using streams\n",
        "\n",
        "## Mistake 10: Writing temporary files during inference loop\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Combines disk I/O overhead with loop iteration overhead\n",
        "- Creates many small files that stress filesystem metadata\n",
        "- Cleanup adds additional overhead\n",
        "\n",
        "**Correct approach:**\n",
        "- Keep all intermediate data in memory\n",
        "- Avoid writing files inside processing loops\n",
        "- Only persist final results if needed\n",
        "\n",
        "<div style=\"background-color: #fce4ec; border-left: 4px solid #e91e63; padding: 12px; margin: 16px 0;\">\n",
        "<strong>Memory Management:</strong> If you're concerned about memory usage, Ray Data automatically spills to disk using Arrow's memory-efficient format. You don't need to manually write temporary files.\n",
        "</div>\n",
        "\n",
        "## Mistake 11: Not using mixed precision on GPUs\n",
        "\n",
        "**Why this is wrong (GPU-specific):**\n",
        "- Modern GPUs (Volta, Turing, Ampere+) have specialized FP16 units\n",
        "- Running in FP32 doesn't utilize these specialized units\n",
        "- FP16 inference maintains accuracy for most vision models\n",
        "- Uses less GPU memory (can fit larger batches)\n",
        "\n",
        "**Correct approach (for GPU inference):**\n",
        "- Use `torch.cuda.amp.autocast()` for automatic mixed precision\n",
        "- Enables tensor cores on modern GPUs\n",
        "\n",
        "**Note:** Mixed precision is primarily beneficial for GPUs. For CPU inference, FP32 is typically fine.\n",
        "\n",
        "```python\n",
        "# GPU inference with mixed precision\n",
        "class ImageClassifier:\n",
        "    def __init__(self):\n",
        "        self.model = torchvision.models.resnet152(pretrained=True).cuda()\n",
        "        self.model.eval()\n",
        "    \n",
        "    def __call__(self, batch):\n",
        "        images = torch.stack([torch.tensor(img) for img in batch[\"image\"]]).cuda()\n",
        "        with torch.cuda.amp.autocast():  # Enable mixed precision\n",
        "            results = self.model(images)\n",
        "        return {\"predictions\": results.cpu().numpy()}\n",
        "```\n",
        "\n",
        "## Mistake 12: Unnecessary device synchronization\n",
        "\n",
        "**Why this is wrong:**\n",
        "- `.detach().cpu()` forces operations to complete before continuing\n",
        "- Synchronization prevents pipelining of operations\n",
        "- Transferring back to CPU per-image instead of per-batch adds overhead\n",
        "\n",
        "**Correct approach:**\n",
        "- Keep intermediate results on device until needed\n",
        "- Transfer back to CPU once for entire batch at the end\n",
        "- Let framework manage operation scheduling\n",
        "\n",
        "## Mistake 13: Not managing memory properly\n",
        "\n",
        "**Why this is wrong:**\n",
        "- PyTorch caches memory allocations for performance\n",
        "- Long-running jobs can accumulate fragmented memory\n",
        "- For GPU: manually clearing cache every batch is overkill and counterproductive\n",
        "- For CPU: Python garbage collector usually handles this\n",
        "\n",
        "**Correct approach:**\n",
        "- Let PyTorch manage memory automatically in most cases\n",
        "- For GPU: only clear cache if you see OOM errors\n",
        "- Clear between large operations, not every batch\n",
        "\n",
        "## Mistake 14: Returning inefficient data structures\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Returning Python lists instead of numpy arrays when possible\n",
        "- Lists have more overhead for Ray Data to process\n",
        "- Ray Data works best with numpy/PyArrow columnar formats\n",
        "\n",
        "**Correct approach:**\n",
        "- Return numpy arrays for numeric data\n",
        "- Use appropriate dtypes (don't return float64 if float32 works)\n",
        "\n",
        "```python\n",
        "# Wrong: Return Python lists\n",
        "def __call__(self, batch):\n",
        "    results = self.model(batch[\"image\"])\n",
        "    return {\"predictions\": results.tolist()}  # Converts to Python list\n",
        "\n",
        "# Correct: Return numpy arrays\n",
        "def __call__(self, batch):\n",
        "    results = self.model(batch[\"image\"])\n",
        "    return {\"predictions\": results.cpu().numpy()}  # Keep as numpy array\n",
        "```\n",
        "\n",
        "## Mistake 15: Suboptimal resource configuration\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Requesting too many CPUs per task prevents other tasks from running\n",
        "- Very small batch sizes don't utilize hardware efficiently\n",
        "- High concurrency compounds model reloading problems\n",
        "- Causes resource fragmentation and memory pressure\n",
        "\n",
        "**Correct approach:**\n",
        "- For CPU inference: set `num_cpus` based on model threading needs (usually 2-4)\n",
        "- For GPU inference: use `num_gpus=1` (or fractional: `num_gpus=0.25`)\n",
        "- Set `batch_size` based on available memory: typically 32-256\n",
        "- Set concurrency based on available resources:\n",
        "  - CPU: `num_cpus_available / num_cpus_per_task`\n",
        "  - GPU: number of available GPUs\n",
        "- Use `accelerator_type=\"A10G\"` or similar for specific GPU types in production\n",
        "\n",
        "<div style=\"background-color: #f3e5f5; border-left: 4px solid #9c27b0; padding: 12px; margin: 16px 0;\">\n",
        "<strong>Resource Configuration Example:</strong>\n",
        "<pre><code>ds.map_batches(\n",
        "    ImageClassifier,\n",
        "    batch_size=64,           # Process 64 images at once\n",
        "    num_gpus=1,              # 1 GPU per worker\n",
        "    concurrency=4,           # 4 workers if you have 4 GPUs\n",
        "    accelerator_type=\"A10G\"  # Request specific GPU type\n",
        ")</code></pre>\n",
        "</div>\n",
        "\n",
        "# Other common mistakes and antipatterns\n",
        "\n",
        "## Mistake 16: Not handling errors gracefully\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Letting one bad image crash entire batch/job\n",
        "- No error handling around individual image processing\n",
        "- Not leveraging Ray Data's error handling features\n",
        "\n",
        "**Correct approach:**\n",
        "- Use try-except around individual item processing\n",
        "- Set `DataContext.max_errored_blocks` to tolerate some failures\n",
        "- Log errors for debugging while continuing execution\n",
        "\n",
        "## Mistake 17: Using non-deterministic operations without setting seeds\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Makes debugging and reproduction impossible\n",
        "- Can cause flaky tests and inconsistent results\n",
        "- Different workers produce different results for same input\n",
        "\n",
        "**Correct approach:**\n",
        "- Set random seeds for Python, NumPy, and PyTorch\n",
        "- Use deterministic algorithms when available\n",
        "- Document any remaining sources of non-determinism\n",
        "\n",
        "## Mistake 18: Not considering data locality\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Reading data from remote storage repeatedly\n",
        "- Not using Ray Data's automatic data locality optimizations\n",
        "- Not colocating compute with data\n",
        "\n",
        "**Correct approach:**\n",
        "- Use Ray Data's built-in data sources that optimize locality\n",
        "- Cache intermediate results when appropriate\n",
        "- Let Ray schedule tasks close to data\n",
        "\n",
        "## Mistake 19: Ignoring batch format\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Not checking if batch is in numpy/pandas/pyarrow format\n",
        "- Assuming specific format without verification\n",
        "- Unnecessary conversions when batch is already in usable format\n",
        "\n",
        "**Correct approach:**\n",
        "- Use `batch_format` parameter in `map_batches`\n",
        "- Specify format that works best for your operations\n",
        "- Common formats: `\"numpy\"`, `\"pandas\"`, `\"pyarrow\"`\n",
        "\n",
        "## Mistake 20: Using wrong tensor dtypes\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Using float64 when float32 is sufficient\n",
        "- Not matching model's expected input dtype\n",
        "- Unnecessary precision wastes memory and compute\n",
        "\n",
        "**Correct approach:**\n",
        "- Use float32 for most deep learning operations\n",
        "- Match input dtype to model expectations\n",
        "- Only use higher precision when mathematically necessary\n",
        "\n",
        "## Mistake 21: Not using class-based inference pattern\n",
        "\n",
        "**Why this is wrong:**\n",
        "- Functions can't maintain state between batches\n",
        "- Can't initialize resources once and reuse them\n",
        "- No proper lifecycle management (setup/teardown)\n",
        "\n",
        "**Correct approach:**\n",
        "- Use callable classes with `__init__` and `__call__`\n",
        "- Initialize expensive resources (models, transforms) in `__init__`\n",
        "- Process batches in `__call__`\n",
        "- Optionally implement `__del__` for cleanup\n",
        "\n",
        "```python\n",
        "# Wrong: Function-based (can't maintain state)\n",
        "def inference_function(batch):\n",
        "    model = load_model()  # Reloaded every batch\n",
        "    return model(batch)\n",
        "\n",
        "# Correct: Class-based pattern\n",
        "class InferenceModel:\n",
        "    def __init__(self):\n",
        "        self.model = load_model()  # Loaded once\n",
        "        self.transform = create_transform()\n",
        "    \n",
        "    def __call__(self, batch):\n",
        "        return self.model(self.transform(batch))\n",
        "```\n",
        "\n",
        "<div style=\"background-color: #e0f7fa; border-left: 4px solid #00bcd4; padding: 12px; margin: 16px 0;\">\n",
        "<strong>Summary:</strong> The class-based inference pattern (Mistakes 1-3, 21) is the foundation of efficient Ray Data inference. Master this pattern first, then optimize batching (Mistake 8) and resource allocation (Mistake 15).\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fixed Version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-10 16:35:50,357\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_6_0\n",
            "2025-10-10 16:35:50,367\tINFO streaming_executor.py:159 -- Starting execution of Dataset dataset_6_0. Full logs are in /tmp/ray/session_2025-10-10_16-23-49_015346_2333/logs/ray-data\n",
            "2025-10-10 16:35:50,368\tINFO streaming_executor.py:160 -- Execution plan of Dataset dataset_6_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ListFiles] -> TaskPoolMapOperator[ReadFiles] -> LimitOperator[limit=1000] -> TaskPoolMapOperator[Map(preprocess_image)] -> ActorPoolMapOperator[MapBatches(InferenceWorker)]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running optimized Ray Data inference with stateful workers...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3394960cc9545768e9e437251f6ed9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Running 0: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "{\"asctime\":\"2025-10-10 16:35:50,422\",\"levelname\":\"E\",\"message\":\"Actor with class name: 'MapWorker(MapBatches(InferenceWorker))' and ID: '81e93d832395eb07fd426fb002000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\",\"filename\":\"core_worker.cc\",\"lineno\":2254}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc2b3b89d81148e69160701bcca9a19c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- ListFiles 1: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40cad6a757ef4192979867aeffdf9f86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- ReadFiles 2: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56467538b5694590ad89963fd9c49210",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- limit=1000 3: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47b46aad3d52426f9c22a75de2039a4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- Map(preprocess_image) 4: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95a4d81cac2e4a5b8f4bd90763ce8e01",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "- MapBatches(InferenceWorker) 5: 0.00 row [00:00, ? row/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(Map(preprocess_image) pid=2586, ip=10.0.83.124)\u001b[0m /tmp/ray/session_2025-10-10_16-23-49_015346_2333/runtime_resources/pip/3680f2510a97dceccb43369b34bd72d0ab26fa6c/virtualenv/lib/python3.12/site-packages/torchvision/transforms/functional.py:154: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "\u001b[36m(Map(preprocess_image) pid=2586, ip=10.0.83.124)\u001b[0m   img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
            "\u001b[36m(Map(preprocess_image) pid=4151, ip=10.0.94.252)\u001b[0m /tmp/ray/session_2025-10-10_16-23-49_015346_2333/runtime_resources/pip/3680f2510a97dceccb43369b34bd72d0ab26fa6c/virtualenv/lib/python3.12/site-packages/torchvision/transforms/functional.py:154: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "\u001b[36m(Map(preprocess_image) pid=4151, ip=10.0.94.252)\u001b[0m   img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
            "\u001b[36m(Map(preprocess_image) pid=4218, ip=10.0.94.252)\u001b[0m /tmp/ray/session_2025-10-10_16-23-49_015346_2333/runtime_resources/pip/3680f2510a97dceccb43369b34bd72d0ab26fa6c/virtualenv/lib/python3.12/site-packages/torchvision/transforms/functional.py:154: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "\u001b[36m(Map(preprocess_image) pid=4218, ip=10.0.94.252)\u001b[0m   img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n",
            "2025-10-10 16:36:20,713\tWARNING issue_detector_manager.py:58 -- \n",
            "\n",
            "Operator 'Map(preprocess_image)' uses 485.8MB of memory per task on\n",
            "average, but Ray only requests 0.0B per task at the start of the\n",
            "pipeline.\n",
            "\n",
            "To avoid out-of-memory errors, consider setting `memory=485.8MB` in\n",
            "the appropriate function or method call. (This might be unnecessary if\n",
            "the number of concurrent tasks is low.)\n",
            "\n",
            "To change the frequency of this warning, set\n",
            "`DataContext.get_current().issue_detectors_config.high_memory_detector_config.detection_time_interval_s`,\n",
            "or disable the warning by setting value to -1. (current value: 30)\n",
            "\n",
            "2025-10-10 16:36:20,714\tWARNING issue_detector_manager.py:67 -- To disable issue detection, run DataContext.get_current().issue_detectors_config.detectors = [].\n",
            "2025-10-10 16:36:22,857\tINFO streaming_executor.py:279 -- ✔️  Dataset dataset_6_0 execution finished in 32.49 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(autoscaler +1h15m28s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
            "\u001b[33m(raylet)\u001b[0m WARNING: 32 PYTHON worker processes have been started on node: 649a75ab4f03d0f79d9397c9d249bc0977d766b0eb9085dfc81526c2 with address: 10.0.127.67. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Cluster is starting.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [head] Attempting to add 1 node to the cluster (increasing from 0 to 1).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [8CPU-32GB] Attempting to add 10 nodes to the cluster (increasing from 0 to 10).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [8CPU-32GB|m5.2xlarge] [us-west-2b] [on-demand] Launched 10 instances.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [head|m5.2xlarge] [us-west-2b] [on-demand] Launched 1 instance.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Node launched (instance ID: i-031a5b1287cda591d, node IP: 10.0.124.207).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Pulling image for Ray container.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Pulled image for Ray container (image size: 3.0 GB), took 1.486s.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Created Ray container, took 134ms.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Started Ray container, took 78ms.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Executed 'init scripts' in container, took 104ms.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Executed 'optimize ray' in container, took 1.733s.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Executed 'ray start' in container, took 6.916s.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 0/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 3/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 4/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 7/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 8/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 10/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Cluster is running.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Cluster is terminating (reason: user action).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Cluster is terminated (reason: user action).\n",
            "\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Cluster is starting.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [head] Attempting to add 1 node to the cluster (increasing from 0 to 1).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [8CPU-32GB] Attempting to add 10 nodes to the cluster (increasing from 0 to 10).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [8CPU-32GB|m5.2xlarge] [us-west-2d] [on-demand] Launched 10 instances.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [head|m5.2xlarge] [us-west-2d] [on-demand] Launched 1 instance.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Node launched (instance ID: i-0f6d36eb5e5794734, node IP: 10.0.251.58).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Pulling image for Ray container.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Pulled image for Ray container (image size: 3.0 GB), took 1.346s.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Created Ray container, took 133ms.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Started Ray container, took 69ms.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Executed 'init scripts' in container, took 70ms.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Executed 'optimize ray' in container, took 1.674s.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [workspace snapshot] Successfully restored workspace.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Executed 'ray start' in container, took 7.049s.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 0/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 2/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 4/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 7/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 8/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 10/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Cluster is running.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Cluster is terminating (reason: auto-termination).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Cluster is terminated (reason: auto-termination).\n",
            "\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Cluster is starting.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [head] Attempting to add 1 node to the cluster (increasing from 0 to 1).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [8CPU-32GB] Attempting to add 10 nodes to the cluster (increasing from 0 to 10).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [head|m5.2xlarge] [us-west-2d] [on-demand] Launched 1 instance.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [8CPU-32GB|m5.2xlarge] [us-west-2d] [on-demand] Launched 10 instances.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Node launched (instance ID: i-00909e4bbcd888c6d, node IP: 10.0.195.54).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Pulling image for Ray container.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Pulled image for Ray container (image size: 3.0 GB), took 1.373s.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Created Ray container, took 131ms.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Started Ray container, took 80ms.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Executed 'init scripts' in container, took 99ms.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Executed 'optimize ray' in container, took 1.668s.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [workspace snapshot] Successfully restored workspace.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Executed 'ray start' in container, took 7.081s.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 0/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 3/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 6/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 7/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 9/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 10/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Cluster is running.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Cluster is terminating (reason: user action).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Cluster is terminated (reason: user action).\n",
            "\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Cluster is starting.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [8CPU-32GB] Attempting to add 10 nodes to the cluster (increasing from 0 to 10).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [head] Attempting to add 1 node to the cluster (increasing from 0 to 1).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [8CPU-32GB|m5.2xlarge] [us-west-2b] [on-demand] Launched 10 instances.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [autoscaler] [head|m5.2xlarge] [us-west-2b] [on-demand] Launched 1 instance.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Node launched (instance ID: i-0272bf0d515c548de, node IP: 10.0.71.116).\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Pulling image for Ray container.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Pulled image for Ray container (image size: 3.0 GB), took 1.514s.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Created Ray container, took 145ms.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Started Ray container, took 88ms.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Executed 'init scripts' in container, took 96ms.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Executed 'optimize ray' in container, took 1.773s.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [workspace snapshot] Successfully restored workspace.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m [head] Executed 'ray start' in container, took 7.233s.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 0/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 2/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 3/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 6/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 8/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 9/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Node Status: head: 1/1 ready, 8CPU-32GB: 10/10 ready\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Cluster is running.\n",
            "\u001b[36m(autoscaler +3h53m11s)\u001b[0m Cluster is recovering (reason: updating containers).\n",
            "\u001b[33m(raylet)\u001b[0m WARNING: 32 PYTHON worker processes have been started on node: 45eb4f9cbe98aac441206a556e4505c3153634633056153efe93760e with address: 10.0.83.247. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from typing import Dict, Any\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision.models import ResNet152_Weights\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "import ray.data\n",
        "\n",
        "# Check if GPU is available\n",
        "HAS_GPU = torch.cuda.is_available()\n",
        "\n",
        "# Read the dataset\n",
        "dataset = ray.data.read_images(\n",
        "    \"s3://anonymous@air-example-data-2/imagenette2/train/\",\n",
        "    mode=\"RGB\",\n",
        "    # Override num_blocks can help with parallelism\n",
        "    # override_num_blocks=100,\n",
        "    ray_remote_args={\"num_cpus\": 0.1},\n",
        ")\n",
        "\n",
        "\n",
        "def preprocess_image(row: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
        "    \"\"\"Preprocess a single image by applying transforms.\n",
        "    \n",
        "    Note: This function is kept lightweight and stateless. For more complex\n",
        "    preprocessing that requires initialization, consider using a class-based\n",
        "    approach similar to InferenceWorker.\n",
        "    \n",
        "    Args:\n",
        "        row: Dictionary containing 'image' key with numpy array\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary with transformed image as numpy array\n",
        "    \"\"\"\n",
        "    # ========================================================================\n",
        "    # ANTIPATTERN ADDRESSED: Transform defined inside function\n",
        "    # ========================================================================\n",
        "    # This recreates the transform for each image, which adds overhead.\n",
        "    # \n",
        "    # For this preprocessing step, we have a trade-off:\n",
        "    # - Option 1: Keep it simple with a function (current approach)\n",
        "    #   - Pros: Simple, works for lightweight transforms\n",
        "    #   - Cons: Recreates transform objects repeatedly\n",
        "    # \n",
        "    # - Option 2: Use a class-based approach (better for complex preprocessing)\n",
        "    #   - Pros: Initialize transforms once per worker\n",
        "    #   - Cons: More code, might be overkill for simple transforms\n",
        "    #\n",
        "    # For production with expensive preprocessing, use a class like InferenceWorker\n",
        "    # ========================================================================\n",
        "    weights = ResNet152_Weights.IMAGENET1K_V1\n",
        "    imagenet_transforms = weights.transforms()\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        imagenet_transforms\n",
        "    ])\n",
        "    \n",
        "    # Transform returns a tensor, convert back to numpy for Ray Data\n",
        "    transformed_tensor = transform(row[\"image\"])\n",
        "    \n",
        "    return {\n",
        "        \"transformed_image\": transformed_tensor.numpy(),\n",
        "    }\n",
        "\n",
        "\n",
        "class InferenceWorker:\n",
        "    \"\"\"Efficient inference worker using class-based pattern.\n",
        "    \n",
        "    This class demonstrates best practices for Ray Data batch inference:\n",
        "    - Model loaded once in __init__ (not per batch)\n",
        "    - Transforms initialized once in __init__\n",
        "    - Reuses resources across all batches in __call__\n",
        "    - Proper batched inference (not one-by-one)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize model and transforms once per worker.\n",
        "        \n",
        "        This method runs once when the actor is created, not for every batch.\n",
        "        All expensive initialization happens here.\n",
        "        \"\"\"\n",
        "        # ====================================================================\n",
        "        # BEST PRACTICE: Initialize model once in __init__\n",
        "        # ====================================================================\n",
        "        # The model is loaded once per worker and reused for all batches\n",
        "        # This avoids the expensive model loading overhead for each batch\n",
        "        # ====================================================================\n",
        "        self.weights = ResNet152_Weights.IMAGENET1K_V1\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = models.resnet152(weights=self.weights).to(self.device)\n",
        "        self.model.eval()\n",
        "        \n",
        "        # ====================================================================\n",
        "        # BEST PRACTICE: Initialize transforms once in __init__\n",
        "        # ====================================================================\n",
        "        # Transforms are created once and reused for all batches\n",
        "        # ====================================================================\n",
        "        imagenet_transforms = self.weights.transforms()\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            imagenet_transforms\n",
        "        ])\n",
        "\n",
        "    def __call__(self, batch: Dict[str, np.ndarray]) -> Dict[str, Any]:\n",
        "        \"\"\"Process a batch of images.\n",
        "        \n",
        "        This method is called for each batch. The model and transforms are\n",
        "        already loaded and ready to use.\n",
        "        \n",
        "        Args:\n",
        "            batch: Dictionary with 'transformed_image' key containing numpy array\n",
        "            \n",
        "        Returns:\n",
        "            Dictionary with predictions\n",
        "        \"\"\"\n",
        "        # ====================================================================\n",
        "        # BEST PRACTICE: Batched inference\n",
        "        # ====================================================================\n",
        "        # Process entire batch at once, not one image at a time\n",
        "        # This utilizes GPU/CPU parallelism and vectorization effectively\n",
        "        # ====================================================================\n",
        "        \n",
        "        # Convert the numpy array of images into a PyTorch tensor\n",
        "        # Shape: (batch_size, channels, height, width)\n",
        "        torch_batch = torch.from_numpy(batch[\"transformed_image\"]).to(self.device)\n",
        "        \n",
        "        # Run inference on the entire batch at once\n",
        "        with torch.no_grad():\n",
        "            # ================================================================\n",
        "            # BEST PRACTICE: Single forward pass for entire batch\n",
        "            # ================================================================\n",
        "            # One forward pass processes all images simultaneously\n",
        "            # Much more efficient than looping through images\n",
        "            # ================================================================\n",
        "            prediction = self.model(torch_batch)\n",
        "            \n",
        "            # Get predicted classes for all images in batch\n",
        "            # argmax(dim=1) gets the class with highest score for each image\n",
        "            predicted_classes = prediction.argmax(dim=1).detach().cpu()\n",
        "            \n",
        "            # Convert class indices to human-readable labels\n",
        "            predicted_labels = [\n",
        "                self.weights.meta[\"categories\"][i] for i in predicted_classes\n",
        "            ]\n",
        "            \n",
        "            # Optional: Get confidence scores\n",
        "            probabilities = torch.nn.functional.softmax(prediction, dim=1)\n",
        "            confidence_scores = probabilities.max(dim=1).values.detach().cpu().numpy()\n",
        "        \n",
        "        return {\n",
        "            \"predicted_label\": predicted_labels,\n",
        "            \"confidence\": confidence_scores.tolist(),\n",
        "        }\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# BEST PRACTICE: Proper resource configuration\n",
        "# ============================================================================\n",
        "# - Use class-based approach for stateful processing\n",
        "# - Set concurrency based on available GPUs/CPUs\n",
        "# - Use appropriate batch_size for memory and throughput\n",
        "# - Allocate resources (num_gpus, num_cpus) appropriately\n",
        "# ============================================================================\n",
        "\n",
        "inference_results = (\n",
        "    dataset\n",
        "    .limit(1000)\n",
        "    # Preprocess images before inference\n",
        "    # Using low num_cpus since this is lightweight\n",
        "    .map(preprocess_image, num_cpus=0.1)\n",
        "    # Run batched inference with class-based actors\n",
        "    .map_batches(\n",
        "        InferenceWorker,\n",
        "        concurrency=4 if HAS_GPU else 8,  # Fewer actors for GPU, more for CPU\n",
        "        num_gpus=1 if HAS_GPU else 0,  # Allocate GPU if available\n",
        "        num_cpus=1 if HAS_GPU else 4,  # Use more CPU cores if no GPU\n",
        "        batch_size=64 if HAS_GPU else 16,  # Larger batches for GPU\n",
        "        # Optional: Control batch format\n",
        "        # batch_format=\"numpy\" is default and works well here\n",
        "    )\n",
        ").take_all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Key Takeaways from Part 1\n",
        "\n",
        "You've learned the fundamentals of batch inference optimization:\n",
        "- Identified common anti-patterns that destroy performance\n",
        "- Understood why repeated model loading is problematic  \n",
        "- Implemented class-based actors for stateful model loading\n",
        "- Used proper resource allocation with `num_gpus` and `concurrency`\n",
        "- Learned CPU and GPU compatibility patterns\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "Now that you understand the fundamentals, you're ready to learn systematic optimization techniques.\n",
        "\n",
        "**[← Back to Overview](README.ipynb)** | **[Continue to Part 2: Advanced Optimization →](02-advanced-optimization.ipynb)**\n",
        "\n",
        "In Part 2, you'll learn:\n",
        "- Systematic decision frameworks for choosing optimization techniques\n",
        "- Multi-model ensemble inference patterns\n",
        "- Performance monitoring and diagnostics\n",
        "- Production deployment best practices\n",
        "\n",
        "**Or skip ahead to Part 3** for a deep dive into Ray Data's architecture:\n",
        "\n",
        "**[Jump to Part 3: Ray Data Architecture →](03-ray-data-architecture.ipynb)**\n",
        "\n",
        "In Part 3, you'll learn:\n",
        "- How streaming execution enables unlimited dataset processing\n",
        "- How blocks and memory management affect optimization\n",
        "- How operator fusion and backpressure work\n",
        "- How to calculate optimal parameters from architectural principles\n",
        "\n",
        "**[Return to overview](README.ipynb)** to see all available parts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
