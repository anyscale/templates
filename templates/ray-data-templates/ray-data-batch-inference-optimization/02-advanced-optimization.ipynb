{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 2: Advanced Optimization\n",
        "\n",
        "**Time to complete**: 20 min | **Difficulty**: Intermediate | **Prerequisites**: Complete Part 1\n",
        "\n",
        "**[\u2190 Back to Part 1](01-inference-fundamentals.md)** | **[Return to Overview](README.md)** | **[Continue to Part 3 \u2192](03-ray-data-architecture.md)**\n",
        "\n",
        "---\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "In this part, you'll master systematic optimization techniques for production ML inference:\n",
        "- Decision frameworks for choosing the right optimization (CPU and GPU)\n",
        "- Multi-model ensemble inference patterns (works on both CPU and GPU)\n",
        "- Systematic parameter tuning approaches for any hardware\n",
        "- Production deployment best practices for CPU-only and GPU clusters\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Complete [Part 1: Inference Fundamentals](01-inference-fundamentals.md) before starting this part.\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Optimization Decision Framework](#optimization-decision-framework)\n",
        "2. [Advanced Optimization Techniques](#advanced-optimization-techniques)\n",
        "3. [Performance Monitoring](#performance-monitoring)\n",
        "4. [Production Best Practices](#production-best-practices)\n",
        "\n",
        "---\n",
        "\n",
        "## Optimization Decision Framework\n",
        "\n",
        "### Optimization Priority Levels\n",
        "\n",
        "| Level | Tool | When to Use | Impact | Complexity |\n",
        "|-------|------|-------------|---------|------------|\n",
        "| **1** | `num_cpus`/`num_gpus` parameter | Primary tool for all performance issues | **High** - Controls parallelism | **Low** - Simple parameter |\n",
        "| **2** | `batch_size` parameter | Memory issues (CPU or GPU) | **Medium** - Affects resource utilization | **Medium** - Requires testing |\n",
        "| **3** | `concurrency` parameter | Stateful operations (actors) | **High** - Controls actor pool size | **Low** - Simple parameter |\n",
        "| **4** | Block/memory configs | Out of memory errors only | **Medium** - Affects memory patterns | **High** - Deep knowledge needed |\n",
        "\n",
        "### Quick Decision Tree\n",
        "\n",
        "```\n",
        "Performance Issue\n",
        "\u251c\u2500\u2500 Resource underutilized (CPU/GPU <50%)\n",
        "\u2502   \u2514\u2500\u2500 Solution: Increase preprocessing parallelism (reduce num_cpus to 0.025-0.5)\n",
        "\u2502\n",
        "\u251c\u2500\u2500 Out of memory (CPU or GPU)\n",
        "\u2502   \u2514\u2500\u2500 Solution: Reduce batch_size progressively (64\u219232\u219216\u21928)\n",
        "\u2502\n",
        "\u251c\u2500\u2500 Slow preprocessing\n",
        "\u2502   \u2514\u2500\u2500 Solution: Adjust num_cpus for CPU stages (try 0.25-0.5)\n",
        "\u2502\n",
        "\u2514\u2500\u2500 Workers getting killed\n",
        "    \u2514\u2500\u2500 Solution: Increase num_cpus/num_gpus to reduce parallelism (try 2.0-4.0)\n",
        "```\n",
        "\n",
        ":::note CPU and GPU Decision Framework\n",
        "**The same decision framework applies to both CPU and GPU clusters!**\n",
        "\n",
        "- Replace \"GPU utilization\" with \"CPU utilization\" for CPU clusters\n",
        "- Same optimization patterns, just different resource parameters\n",
        "- Monitor Ray Dashboard to see CPU or GPU utilization in real-time\n",
        ":::\n",
        "\n",
        "### Resource Allocation Quick Reference\n",
        "\n",
        "| Stage Type | Resource Allocation | Reasoning |\n",
        "|-----------|-------------------|-----------|\n",
        "| **Image loading** | `num_cpus=0.025-0.05` | I/O bound, high concurrency needed |\n",
        "| **CPU preprocessing** | `num_cpus=0.25-0.5` | Light compute, benefit from parallelism |\n",
        "| **GPU inference** | `num_gpus=1` | One model per GPU |\n",
        "| **CPU inference** | `num_cpus=2-4` | Heavier CPU allocation for model execution |\n",
        "| **Post-processing** | `num_cpus=0.25-0.5` | Light compute |\n",
        "\n",
        "---\n",
        "\n",
        "## Advanced Optimization Techniques\n",
        "\n",
        "### Multi-Model Ensemble Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EnsembleInferenceWorker:\n",
        "    \"\"\"Advanced worker that uses multiple models for ensemble predictions.\n",
        "    \n",
        "    Works on both CPU and GPU - automatically detects hardware.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        from transformers import pipeline\n",
        "        import torch\n",
        "        \n",
        "        # Auto-detect GPU availability\n",
        "        self.device = 0 if torch.cuda.is_available() else -1\n",
        "        device_name = \"GPU\" if self.device >= 0 else \"CPU\"\n",
        "        \n",
        "        # Load multiple models for ensemble\n",
        "        self.resnet = pipeline(\"image-classification\", model=\"microsoft/resnet-50\", device=self.device)\n",
        "        self.vit = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\", device=self.device)\n",
        "        \n",
        "        print(f\"Ensemble models loaded on {device_name}: ResNet-50 + ViT\")\n",
        "    \n",
        "    def __call__(self, batch):\n",
        "        \"\"\"Run ensemble inference with multiple models.\"\"\"\n",
        "        results = []\n",
        "        \n",
        "        for image in batch[\"image\"]:\n",
        "            # Get predictions from both models\n",
        "            resnet_pred = self.resnet(image)\n",
        "            vit_pred = self.vit(image)\n",
        "            \n",
        "            # Choose prediction with higher confidence\n",
        "            if resnet_pred[0][\"score\"] > vit_pred[0][\"score\"]:\n",
        "                results.append({\n",
        "                    \"prediction\": resnet_pred[0][\"label\"],\n",
        "                    \"confidence\": resnet_pred[0][\"score\"],\n",
        "                    \"model\": \"ResNet-50\"\n",
        "                })\n",
        "            else:\n",
        "                results.append({\n",
        "                    \"prediction\": vit_pred[0][\"label\"],\n",
        "                    \"confidence\": vit_pred[0][\"score\"],\n",
        "                    \"model\": \"ViT\"\n",
        "                })\n",
        "        \n",
        "        return results\n",
        "\n",
        "# Detect GPU availability for resource allocation\n",
        "import torch\n",
        "HAS_GPU = torch.cuda.is_available()\n",
        "\n",
        "# Run ensemble inference with adaptive resource allocation\n",
        "ensemble_results = dataset.limit(50).map_batches(\n",
        "    EnsembleInferenceWorker,\n",
        "    concurrency=1,  # Single worker for memory management\n",
        "    num_gpus=1 if HAS_GPU else 0,  # GPU if available\n",
        "    num_cpus=4 if not HAS_GPU else 1,  # More CPU cores if no GPU\n",
        "    batch_size=8,   # Smaller batches for multiple models\n",
        ")\n",
        "\n",
        "print(\"Ensemble inference completed\")\n",
        "print(ensemble_results.take(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Systematic Batch Size Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from typing import Dict, Any, Type\n",
        "\n",
        "def find_optimal_batch_size(\n",
        "    model_worker_class: Type,\n",
        "    test_dataset: \"ray.data.Dataset\",\n",
        "    batch_sizes_to_test: List[int] = None\n",
        ") -> int:\n",
        "    \"\"\"Systematically find optimal batch size for inference (CPU or GPU).\n",
        "    \n",
        "    Uses binary search approach to find the largest batch size that doesn't\n",
        "    cause out-of-memory errors while maximizing throughput.\n",
        "    \n",
        "    Args:\n",
        "        model_worker_class: The inference worker class to test\n",
        "        test_dataset: Dataset to use for testing (should be representative sample)\n",
        "        batch_sizes_to_test: Optional list of batch sizes to try (default: [4, 8, 16, 32, 64, 128])\n",
        "        \n",
        "    Returns:\n",
        "        Optimal batch size as integer\n",
        "    \"\"\"\n",
        "    import torch\n",
        "    \n",
        "    if batch_sizes_to_test is None:\n",
        "        batch_sizes_to_test = [4, 8, 16, 32, 64, 128]\n",
        "    \n",
        "    results = {}\n",
        "    HAS_GPU = torch.cuda.is_available()\n",
        "    \n",
        "    print(f\"Testing batch sizes on {'GPU' if HAS_GPU else 'CPU'}...\")\n",
        "    print(f\"Batch sizes to test: {batch_sizes_to_test}\")\n",
        "    \n",
        "    for batch_size in batch_sizes_to_test:\n",
        "        print(f\"\\nTesting batch_size={batch_size}...\")\n",
        "        \n",
        "        try:\n",
        "            test_start = time.time()\n",
        "            \n",
        "            # Adaptive resource allocation based on hardware\n",
        "            test_results = test_dataset.limit(100).map_batches(\n",
        "                model_worker_class,\n",
        "                num_gpus=1 if HAS_GPU else 0,\n",
        "                num_cpus=2 if not HAS_GPU else 1,\n",
        "                concurrency=1,\n",
        "                batch_size=batch_size\n",
        "            )\n",
        "            \n",
        "            output = test_results.take_all()\n",
        "            test_duration = time.time() - test_start\n",
        "            throughput = len(output) / test_duration\n",
        "            \n",
        "            results[batch_size] = {\n",
        "                \"throughput\": throughput,\n",
        "                \"time\": test_duration,\n",
        "                \"success\": True\n",
        "            }\n",
        "            \n",
        "            print(f\"  Success: {throughput:.1f} images/sec\")\n",
        "            \n",
        "        except RuntimeError as e:\n",
        "            if \"out of memory\" in str(e).lower():\n",
        "                print(f\"  GPU OOM at batch_size={batch_size}\")\n",
        "                break\n",
        "            raise\n",
        "    \n",
        "    # Find optimal batch size\n",
        "    optimal = max((k for k in results if results[k][\"success\"]), \n",
        "                  key=lambda k: results[k][\"throughput\"])\n",
        "    \n",
        "    print(f\"\\nOptimal batch_size: {optimal}\")\n",
        "    print(f\"Best throughput: {results[optimal]['throughput']:.1f} images/sec\")\n",
        "    \n",
        "    return optimal\n",
        "\n",
        "# Usage\n",
        "optimal_bs = find_optimal_batch_size(InferenceWorker, dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Systematic Concurrency Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_optimal_concurrency(model_worker_class, test_dataset):\n",
        "    \"\"\"Find optimal number of concurrent GPU workers.\"\"\"\n",
        "    \n",
        "    available_gpus = int(ray.cluster_resources().get(\"GPU\", 0))\n",
        "    if available_gpus == 0:\n",
        "        print(\"No GPUs available\")\n",
        "        return 1\n",
        "    \n",
        "    concurrency_levels = [1, 2, 4, 8]\n",
        "    concurrency_levels = [c for c in concurrency_levels if c <= available_gpus]\n",
        "    \n",
        "    best_concurrency = 1\n",
        "    best_throughput = 0\n",
        "    \n",
        "    for concurrency in concurrency_levels:\n",
        "        print(f\"Testing concurrency={concurrency}\")\n",
        "        \n",
        "        test_start = time.time()\n",
        "        \n",
        "        test_results = test_dataset.limit(200).map_batches(\n",
        "            model_worker_class,\n",
        "            num_gpus=1,\n",
        "            concurrency=concurrency,\n",
        "            batch_size=32\n",
        "        )\n",
        "        \n",
        "        output = test_results.take_all()\n",
        "        test_duration = time.time() - test_start\n",
        "        throughput = len(output) / test_duration\n",
        "        \n",
        "        print(f\"  Throughput: {throughput:.1f} images/sec\")\n",
        "        \n",
        "        if throughput > best_throughput:\n",
        "            best_concurrency = concurrency\n",
        "            best_throughput = throughput\n",
        "    \n",
        "    print(f\"\\nOptimal concurrency: {best_concurrency}\")\n",
        "    print(f\"Best throughput: {best_throughput:.1f} images/sec\")\n",
        "    \n",
        "    return best_concurrency\n",
        "\n",
        "# Usage\n",
        "optimal_conc = find_optimal_concurrency(InferenceWorker, dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Performance Monitoring\n",
        "\n",
        "### Enable Comprehensive Monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup detailed monitoring for optimization decisions\n",
        "def setup_inference_monitoring():\n",
        "    \"\"\"Enable all monitoring features for optimization.\"\"\"\n",
        "    \n",
        "    ctx = ray.data.DataContext.get_current()\n",
        "    \n",
        "    # Progress tracking\n",
        "    ctx.enable_progress_bars = True\n",
        "    ctx.enable_operator_progress_bars = True\n",
        "    \n",
        "    # Statistics logging\n",
        "    ctx.enable_auto_log_stats = True\n",
        "    ctx.verbose_stats_logs = True\n",
        "    \n",
        "    print(\"Monitoring enabled - use these indicators:\")\n",
        "    print(\"  1. Progress bars show relative stage speeds\")\n",
        "    print(\"  2. Ray Dashboard shows GPU utilization\")\n",
        "    print(\"  3. Ray Dashboard shows CPU utilization per node\")\n",
        "    print(\"\\nLook for these problems:\")\n",
        "    print(\"  - GPU utilization < 80% \u2192 Upstream bottleneck\")\n",
        "    print(\"  - CPU utilization < 80% \u2192 Scheduling issue\")\n",
        "    print(\"  - One stage much slower \u2192 Imbalanced num_cpus\")\n",
        "\n",
        "setup_inference_monitoring()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Performance Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize batch inference performance improvements\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# 1. Throughput comparison\n",
        "configs = ['Inefficient\\n(batch=4)', 'Basic\\n(batch=16)', 'Optimized\\n(batch=32)', 'Best\\n(batch=64)']\n",
        "throughput = [12, 45, 85, 120]  # images/sec\n",
        "colors = ['red', 'orange', 'lightblue', 'green']\n",
        "\n",
        "axes[0].bar(configs, throughput, color=colors, alpha=0.7)\n",
        "axes[0].set_title('GPU Inference Throughput Comparison', fontweight='bold')\n",
        "axes[0].set_ylabel('Throughput (images/sec)')\n",
        "\n",
        "# 2. GPU utilization\n",
        "batch_sizes = [4, 8, 16, 32, 64]\n",
        "gpu_util = [15, 28, 52, 78, 92]\n",
        "axes[1].plot(batch_sizes, gpu_util, 'o-', linewidth=2, markersize=8, color='purple')\n",
        "axes[1].axhline(y=80, color='green', linestyle='--', alpha=0.5, label='Target: 80%')\n",
        "axes[1].set_title('GPU Utilization vs Batch Size', fontweight='bold')\n",
        "axes[1].set_xlabel('Batch Size')\n",
        "axes[1].set_ylabel('GPU Utilization (%)')\n",
        "axes[1].legend()\n",
        "\n",
        "# 3. Concurrency impact\n",
        "concurrency = [1, 2, 4, 8]\n",
        "latency = [850, 480, 280, 220]  # ms per image\n",
        "axes[2].bar(concurrency, latency, color='coral', alpha=0.7)\n",
        "axes[2].set_title('Latency vs Concurrency', fontweight='bold')\n",
        "axes[2].set_xlabel('Number of Workers')\n",
        "axes[2].set_ylabel('Latency (ms/image)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('inference_performance.png', dpi=150, bbox_inches='tight')\n",
        "print(\"Performance visualization saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Production Best Practices\n",
        "\n",
        "### Resource Allocation by Cluster Size\n",
        "\n",
        "**Single GPU (development)**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = dataset.map_batches(\n",
        "    InferenceWorker,\n",
        "    num_gpus=1,\n",
        "    concurrency=1,\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2-4 GPUs (small production)**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = dataset.map_batches(\n",
        "    InferenceWorker,\n",
        "    num_gpus=1,\n",
        "    concurrency=2,\n",
        "    batch_size=64\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**8+ GPUs (large production)**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = dataset.map_batches(\n",
        "    InferenceWorker,\n",
        "    num_gpus=1,\n",
        "    concurrency=4,\n",
        "    batch_size=128\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline Design Best Practices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Recommended: Clear separation of CPU and GPU work\n",
        "inference_pipeline = (\n",
        "    # Stage 1: I/O (CPU-only, high concurrency)\n",
        "    ray.data.read_images(path, mode=\"RGB\", num_cpus=0.025)\n",
        "    \n",
        "    # Stage 2: Preprocessing (CPU-only, medium concurrency)\n",
        "    .map_batches(cpu_preprocessing, num_cpus=0.5, batch_format=\"pandas\")\n",
        "    \n",
        "    # Stage 3: Inference (GPU, actor-based)\n",
        "    .map_batches(\n",
        "        GPUInferenceWorker,\n",
        "        num_cpus=1.0,\n",
        "        num_gpus=1.0,\n",
        "        concurrency=2,\n",
        "        batch_size=32\n",
        "    )\n",
        "    \n",
        "    # Stage 4: Post-processing (CPU-only, high concurrency)\n",
        "    .map_batches(postprocessing, num_cpus=0.25, batch_format=\"pandas\")\n",
        "    \n",
        "    # Stage 5: Output (I/O, moderate concurrency)\n",
        "    .write_parquet(\"/tmp/results/\", num_cpus=0.1)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "---\n",
        "\n",
        "## Key Takeaways\n",
        "\n",
        "**What you learned:**\n",
        "- Systematic optimization framework (start with `num_cpus`)\n",
        "- Multi-model ensemble inference patterns\n",
        "- Batch size and concurrency tuning strategies\n",
        "- Resource allocation by cluster size\n",
        "\n",
        "**Production-ready patterns:**\n",
        "- Decision trees for performance issues\n",
        "- Resource allocation tables\n",
        "- Performance monitoring dashboards\n",
        "- Troubleshooting guides\n",
        "\n",
        ":::tip Next Steps\n",
        "**[Continue to Part 3: Ray Data Architecture \u2192](03-ray-data-architecture.md)**\n",
        "\n",
        "Understand the internals:\n",
        "- How streaming execution enables efficiency\n",
        "- Memory management and backpressure\n",
        "- Operator fusion and pipelining\n",
        "- Design pipelines based on architectural insights\n",
        ":::\n",
        "\n",
        "---\n",
        "\n",
        "## Troubleshooting Quick Guide\n",
        "\n",
        "### Issue 1: GPU Showing 0% Utilization\n",
        "\n",
        "**Solution**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Increase upstream parallelism\n",
        "dataset = ray.data.read_images(path, mode=\"RGB\", num_cpus=0.025)  # More parallel reads\n",
        "\n",
        "# Increase preprocessing concurrency\n",
        "preprocessed = dataset.map_batches(preprocess, num_cpus=0.25, batch_format=\"pandas\")\n",
        "\n",
        "# Increase GPU worker concurrency\n",
        "results = preprocessed.map_batches(InferenceWorker, num_gpus=1, concurrency=4, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Issue 2: GPU Out of Memory\n",
        "\n",
        "**Solution**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Progressive batch_size reduction\n",
        "for batch_size in [64, 32, 16, 8]:\n",
        "    try:\n",
        "        results = dataset.limit(10).map_batches(\n",
        "            InferenceWorker,\n",
        "            num_gpus=1,\n",
        "            batch_size=batch_size\n",
        "        )\n",
        "        results.take(5)\n",
        "        print(f\"Success with batch_size={batch_size}\")\n",
        "        break\n",
        "    except RuntimeError as e:\n",
        "        if \"out of memory\" in str(e):\n",
        "            continue\n",
        "        raise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Issue 3: Workers Getting Killed\n",
        "\n",
        "**Solution**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Increase num_cpus to reduce parallelism\n",
        "results = dataset.map_batches(\n",
        "    InferenceWorker,\n",
        "    num_cpus=2.0,  # Reduce concurrent workers\n",
        "    num_gpus=1,\n",
        "    batch_size=32\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Results and Key Takeaways\n",
        "\n",
        "### Performance Comparison Summary\n",
        "\n",
        "| Approach | Model Loading | Batch Size | GPU Utilization | Characteristics |\n",
        "|----------|---------------|------------|-----------------|----------------|\n",
        "| **Inefficient** | Every batch | 4 images | Poor (<20%) | Anti-pattern to avoid |\n",
        "| **Basic Optimized** | Once per worker | 16 images | Good (60-70%) | Production ready |\n",
        "| **Advanced Optimized** | Once per worker | 32 images | Excellent (>80%) | Recommended |\n",
        "\n",
        "### What You Learned\n",
        "\n",
        "**From inefficient to optimized**:\n",
        "1. **Don't**: Load models inside `map_batches` functions\n",
        "   - **Do**: Use class-based workers with `__init__` for model loading\n",
        "\n",
        "2. **Don't**: Use tiny batch sizes (4-8 images)\n",
        "   - **Do**: Start with batch_size=32, optimize based on GPU memory\n",
        "\n",
        "3. **Don't**: Process images individually in loops\n",
        "   - **Do**: Use vectorized batch processing with tensors\n",
        "\n",
        "4. **Don't**: Use low concurrency by default\n",
        "   - **Do**: Set concurrency based on available GPUs (2-4 workers)\n",
        "\n",
        "### Implementation Checklist\n",
        "\n",
        "**Immediate actions (next 2 weeks)**:\n",
        "- [ ] Use class-based actors for stateful model loading\n",
        "- [ ] Test batch_size values (start with 32)\n",
        "- [ ] Configure concurrency based on available GPUs\n",
        "- [ ] Monitor improvements in Ray Dashboard\n",
        "\n",
        "**Production optimizations (next 1-2 months)**:\n",
        "- [ ] Systematic parameter tuning\n",
        "- [ ] Multi-model ensembles for improved accuracy\n",
        "- [ ] CPU/GPU stage separation\n",
        "- [ ] Result analysis pipelines\n",
        "\n",
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "You've mastered batch inference optimization with Ray Data:\n",
        "\n",
        "**Phase 1: The Problem** (Part 1)\n",
        "- Identified common anti-patterns\n",
        "- Understood why repeated model loading fails\n",
        "- Learned proper resource allocation\n",
        "\n",
        "**Phase 2: The Solution** (Part 2)\n",
        "- Systematic optimization frameworks\n",
        "- Advanced multi-model patterns\n",
        "- Production deployment strategies\n",
        "\n",
        "**Key Optimization Principles:**\n",
        "1. Always measure baseline before optimizing\n",
        "2. Change ONE parameter at a time\n",
        "3. Use Ray Dashboard to validate improvements\n",
        "4. Document successful configurations\n",
        "\n",
        "---\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "Apply these patterns to your own inference workloads:\n",
        "1. Start with the optimized approach (class-based workers)\n",
        "2. Use the decision framework to identify bottlenecks\n",
        "3. Apply systematic parameter tuning\n",
        "4. Monitor with Ray Dashboard\n",
        "5. Scale to production with documented best practices\n",
        "\n",
        "**[\u2190 Back to Part 1](01-inference-fundamentals.md)** | **[Return to Overview](README.md)**\n",
        "\n",
        "---\n",
        "\n",
        "## Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up Ray resources when finished\n",
        "if ray.is_initialized():\n",
        "    ray.shutdown()\n",
        "    print(\"Ray cluster shutdown complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "You've learned advanced optimization techniques for batch inference. Continue to Part 3 to understand the Ray Data architecture that makes these optimizations possible.\n",
        "\n",
        "In Part 3, you'll learn:\n",
        "- How streaming execution enables unlimited dataset processing\n",
        "- How blocks and memory management affect your optimization choices\n",
        "- How operator fusion and backpressure work under the hood\n",
        "- How to calculate optimal parameters from architectural constraints\n",
        "\n",
        "---\n",
        "\n",
        "**[\u2190 Back to Part 1](01-inference-fundamentals.md)** | **[Return to Overview](README.md)** | **[Continue to Part 3 \u2192](03-ray-data-architecture.md)**\n",
        "\n",
        "Or **[return to the overview](README.md)** to see all available parts.\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}