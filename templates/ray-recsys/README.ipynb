{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8388dbd2",
   "metadata": {},
   "source": [
    "# Ray Train + Ray Data + DLRM + Criteo\n",
    "\n",
    "This report demonstrates training a DLRM model on the Criteo dataset using Ray Train and Ray Data. Compared to [the baseline](https://github.com/mlcommons/training/blob/master/recommendation_v2/torchrec_dlrm/dlrm_main.py), we achieve several improvements with a straightforward setup:\n",
    "\n",
    "* Process training data on-the-fly during training\n",
    "* Enable multi-node distributed training\n",
    "* Profile the program using Ray Data metrics and GPU profiler\n",
    "* Implement checkpointing with fault tolerance\n",
    "\n",
    "\n",
    "## Workspace Requirements\n",
    "\n",
    "* To demonstrate Rayâ€™s capability to support heterogeneous clusters, we use a setup consisting of two g5.12xlarge nodes and two r7i.12xlarge nodes.\n",
    "\n",
    "### Note\n",
    "\n",
    "The original model requires A100 GPUs to run. To enable execution on A10 GPUs, we manually reduced the embedding table size. This adjustment may lead to a degradation in model quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a034711c",
   "metadata": {},
   "source": [
    "## Import the Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd92599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note: we reduce the embedding table size to make it able to run in A10 GPUs.\n",
    "from configs import RecsysConfig\n",
    "import os\n",
    "\n",
    "recsys_config = RecsysConfig()\n",
    "# We use 2 g5.12xlarge nodes\n",
    "recsys_config.num_workers = 8\n",
    "recsys_config.train_step_limit = 5000\n",
    "\n",
    "# Enable Ray Train V2\n",
    "os.environ['RAY_TRAIN_V2_ENABLED'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7248762",
   "metadata": {},
   "source": [
    "## Ray Data for Criteo Dataset\n",
    "\n",
    "Instead of processing the training data offline, we process it on-the-fly and overlap with training. This approach includes several steps:\n",
    "\n",
    "* Load the feature mapping table into the [object store](https://docs.ray.io/en/latest/ray-core/key-concepts.html#objects). The benefit of the object store is that processes on the same node can share memory efficiently.\n",
    "* Start the Ray Data pipeline, which:\n",
    "    * Reads the raw training data\n",
    "    * Fills missing data\n",
    "    * Looks up the feature mapping table to transform categorical features into feature IDs\n",
    "    * Concatenates and normalizes the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4b9f58",
   "metadata": {},
   "source": [
    "#### Lazily Load the Feature Mapping Table into the Object Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e60c610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from typing import Dict\n",
    "from criteo import read_feature_mapping_table, DEFAULT_CAT_NAMES\n",
    "\n",
    "def build_categorical_to_feature_mapping_refs() -> Dict[str, ray.ObjectRef]:\n",
    "    return {\n",
    "        cat_feature: read_feature_mapping_table.remote(cat_feature) for cat_feature in DEFAULT_CAT_NAMES\n",
    "    }\n",
    "\n",
    "# After running this, the task `read_feature_mapping_table` will run in the background.\n",
    "categorical_to_feature_mapping_refs = build_categorical_to_feature_mapping_refs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5274a67",
   "metadata": {},
   "source": [
    "#### Build the Ray Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2de75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "import pyarrow.csv\n",
    "from criteo import TRAIN_DATASET_PATH, VAL_DATASET_PATH, DEFAULT_COLUMN_NAMES, fill_missing, map_features_to_indices, concat_and_normalize_dense_features\n",
    "from typing import Tuple\n",
    "\n",
    "def get_ray_dataset(path: str) -> ray.data.Dataset:\n",
    "    categorical_to_feature_mapping_refs = build_categorical_to_feature_mapping_refs()\n",
    "    dataset_path = path\n",
    "    ds = ray.data.read_csv(\n",
    "        dataset_path,\n",
    "        read_options=pyarrow.csv.ReadOptions(column_names=DEFAULT_COLUMN_NAMES),\n",
    "        parse_options=pyarrow.csv.ParseOptions(delimiter=\"\\t\"),\n",
    "        ray_remote_args={\n",
    "            # reading is memory intensive\n",
    "            'memory': 800 * 1024 * 1024,  # 800 MB\n",
    "        },\n",
    "        shuffle=(\n",
    "            \"files\"\n",
    "        ),  # coarse file-level shuffle\n",
    "    )\n",
    "    ds = ds.map_batches(fill_missing)\n",
    "    ds = ds.map_batches(map_features_to_indices, fn_kwargs={\"categorical_to_feature_mapping_refs\": categorical_to_feature_mapping_refs})\n",
    "    ds = ds.map_batches(concat_and_normalize_dense_features)\n",
    "    return ds\n",
    "\n",
    "train_dataset = get_ray_dataset(TRAIN_DATASET_PATH)\n",
    "val_dataset = get_ray_dataset(VAL_DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ac4f47",
   "metadata": {},
   "source": [
    "## Set Up Model and Build Train Function\n",
    "\n",
    "To integrate the [TorchRec implementation](https://github.com/facebookresearch/dlrm/blob/main/torchrec_dlrm/dlrm_main.py) with Ray Train, minor modifications are required:\n",
    "\n",
    "* Call `ray.train.get_dataset_shard('train')` to obtain the dataloader\n",
    "* Use Ray Train APIs to fetch ranks and world sizes\n",
    "\n",
    "Check [TorchRecWrapper](torchrec_wrapper.py) for implementation details.\n",
    "\n",
    "Note: We need to initialize TorchRecWrapper inside the training function, where the training worker has completed initialization.\n",
    "\n",
    "Within the training loop, we enable fault tolerance using checkpoints provided by Ray Train.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe9032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchrec_wrapper import train_loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d72924f-2346-401b-9d5b-4bada216788d",
   "metadata": {},
   "source": [
    "## Define TorchTrainer and Start Training\n",
    "\n",
    "We define the `TorchTrainer` and run `fit()`. Key points to note:\n",
    "\n",
    "* By configuring `scaling_config.num_workers`, we can easily enable multi-node distributed training. In this notebook, we use 2 g5.12xlarge nodes, providing 8 GPUs in total.\n",
    "* Setting `{\"KINETO_USE_DAEMON\": \"1\", \"KINETO_DAEMON_INIT_DELAY_S\": \"5\"}` according to [GPU profiling guidelines](https://docs.anyscale.com/monitoring/workload-debugging/profiling-tools) enables easy profiling of GPU events on any worker.\n",
    "* The remaining CPUs are allocated for Ray Data processing.\n",
    "\n",
    "We will run 5000 iterations and evaluate every 1000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3adcc9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import ScalingConfig, RunConfig, CheckpointConfig, FailureConfig\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "scaling_config = ScalingConfig(\n",
    "    num_workers=recsys_config.num_workers,\n",
    "    # reserve CPUs to the training workers can make the training more stable.\n",
    "    resources_per_worker={\"GPU\": 1, \"CPU\": 1},\n",
    "    use_gpu=True,\n",
    ")\n",
    "\n",
    "config_dict = {}\n",
    "for attr in dir(recsys_config):\n",
    "    if not attr.startswith('_'):\n",
    "        value = getattr(recsys_config, attr)\n",
    "        if not callable(value):\n",
    "            config_dict[attr] = value\n",
    "\n",
    "logger.info(f\"Starting Ray training with {recsys_config.num_workers} workers\")\n",
    "logger.info(f\"Training configuration: {config_dict}\")\n",
    "\n",
    "# Create TorchTrainer\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop,\n",
    "    train_loop_config=config_dict,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=RunConfig(\n",
    "        failure_config=FailureConfig(max_failures=2),\n",
    "        worker_runtime_env={'env_vars': {\"KINETO_USE_DAEMON\": \"1\", \"KINETO_DAEMON_INIT_DELAY_S\": \"5\"}},\n",
    "        checkpoint_config=CheckpointConfig(\n",
    "            num_to_keep=1,\n",
    "        ),\n",
    "        storage_path=recsys_config.checkpoint_dir,\n",
    "    ),\n",
    "    datasets={\n",
    "        \"train\": train_dataset,\n",
    "        \"val\": val_dataset,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Run training\n",
    "logger.info(\"Starting distributed training...\")\n",
    "result = trainer.fit()\n",
    "\n",
    "logger.info(\"Training completed successfully!\")\n",
    "logger.info(f\"Final metrics: {result.metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13566c5",
   "metadata": {},
   "source": [
    "You can see how the workloads are distributed across GPU and CPU machines.\n",
    "\n",
    "![running_progress](./images/running_progress.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9082394a",
   "metadata": {},
   "source": [
    "## Ray Data Metrics\n",
    "\n",
    "Ray Data metrics dashboards provide numerous useful tools for understanding the training pipeline.\n",
    "\n",
    "For example, `Iteration Blocked Time` is a valuable metric for identifying data loading bottlenecks. If this value consistently increases over time, it indicates that the model is frequently waiting for data, suggesting that the training pipeline is bottlenecked by data loading.\n",
    "\n",
    "![example](./images/data_metrics.png)\n",
    "\n",
    "## GPU Profiling\n",
    "\n",
    "If you set the environment variables `\"KINETO_USE_DAEMON\": \"1\", \"KINETO_DAEMON_INIT_DELAY_S\": \"5\"`, you can profile GPU metrics with one click.\n",
    "\n",
    "![gpu profiling](./images/gpu_profiling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d14874c",
   "metadata": {},
   "source": [
    "## Model Quality\n",
    "\n",
    "We achieve comparable training loss and validation performance to the baseline. The training loss curve appears spiky due to the presence of numerous sparse features in the model.\n",
    "\n",
    "![wandb_curve](./images/model_quality.png)\n",
    "\n",
    "## Throughput Benchmark\n",
    "\n",
    "We compare the baseline and Ray Train versions under several conditions:\n",
    "\n",
    "* Baseline (torchrun), single p4d, processed numpy data took 7 minutes to download locally. Throughput: 1,020k\n",
    "* Ray Train, single p4d, training data processed on-the-fly: data loading becomes the bottleneck. Throughput: 220k\n",
    "* Ray Train, single p4d + 1 r7i, throughput: 800k\n",
    "* Ray Train, single p4d + 2 r7i, throughput: 925k\n",
    "\n",
    "From the benchmarks, we can observe:\n",
    "\n",
    "* The task is data-loading bounded, and adding more CPU machines can mitigate this bottleneck. This demonstrates the strength of Ray Train.\n",
    "\n",
    "## Multi-node Scalability with EFA\n",
    "\n",
    "By following [Cluster-level EFA configuration](https://docs.anyscale.com/configuration/compute/aws#cluster-level-efa-configuration), we can enable EFA on the Anyscale platform, which is critical for multi-node training.\n",
    "\n",
    "We conduct two sets of experiments on `p3dn.24xlarge` machines.\n",
    "\n",
    "### Without EFA\n",
    "\n",
    "The throughput on 2 nodes is worse than on 1 node.\n",
    "\n",
    "![wandb_curve](./images/no_efa.png)\n",
    "\n",
    "### With EFA\n",
    "\n",
    "With EFA enabled, we observe clear scalability as the number of nodes increases.\n",
    "\n",
    "![wandb_curve](./images/with_efa.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
