{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Ray Train\n",
    "\n",
    "This notebook will walk you through the basics of distributed training with Ray Train and PyTorch.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b> Here is the roadmap for this notebook:</b>\n",
    "\n",
    "<ul>\n",
    "    <li><b>Part 1:</b> Single GPU PyTorch</li>\n",
    "    <li><b>Part 2:</b> Migrating the model to Ray Train</li>\n",
    "    <li><b>Part 3:</b> Migrating the dataset to Ray Train</li>\n",
    "    <li><b>Part 4:</b> Reporting metrics and checkpoints</li>\n",
    "    <li><b>Part 5:</b> Launching a training job</li>\n",
    "    <li><b>Part 6:</b> Accessing training results</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os   \n",
    "import tempfile\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import csv\n",
    "import torchmetrics\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "\n",
    "import ray\n",
    "from ray.train import ScalingConfig, RunConfig\n",
    "from ray.train.torch import TorchTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Single GPU PyTorch\n",
    "\n",
    "We will start by fitting our own `ResNet18` model to the `MNIST` dataset.\n",
    "\n",
    "Here is a diagram visualizing the single GPU training process:\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-ai-libraries/diagrams/single_gpu_pytorch_v3.png\" width=\"800\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first start by defining how to build and load our model on a single GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_resnet18():\n",
    "    model = resnet18(num_classes=10)\n",
    "    model.conv1 = torch.nn.Conv2d(\n",
    "        in_channels=1, # grayscale MNIST images\n",
    "        out_channels=64,\n",
    "        kernel_size=(7, 7),\n",
    "        stride=(2, 2),\n",
    "        padding=(3, 3),\n",
    "        bias=False,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model_torch() -> torch.nn.Module:\n",
    "    model = build_resnet18()\n",
    "    # Move to the single GPU device\n",
    "    model.to(\"cuda\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also define a data loader to load our data in batches and apply transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_torch(batch_size: int) -> DataLoader:\n",
    "    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "    train_data = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compute and report metrics via a simple print statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_metrics_torch(loss: torch.Tensor, accuracy: torch.Tensor, epoch: int) -> None:\n",
    "    metrics = {\"loss\": loss.item(), \"epoch\": epoch, \"accuracy\": accuracy.item()}\n",
    "    print(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the checkpoint we will make use of a local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint_and_metrics_torch(metrics: dict[str, float], model: torch.nn.Module, local_path: str) -> None:\n",
    "    # Save the metrics\n",
    "    with open(os.path.join(local_path, \"metrics.csv\"), \"a\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(metrics.values())\n",
    "\n",
    "    # Save the model\n",
    "    checkpoint_path = os.path.join(local_path, \"model.pt\")\n",
    "    torch.save(model.state_dict(), checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together into a training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_torch(num_epochs: int = 2, batch_size: int = 128, local_path: str = \"./checkpoints\"):\n",
    "    # Model, Loss, Optimizer\n",
    "    criterion = CrossEntropyLoss()\n",
    "    model = load_model_torch()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    # Initialize the metric \n",
    "    acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(\"cuda\")\n",
    "\n",
    "    # Load the data loader\n",
    "    data_loader = data_loader_torch(batch_size=batch_size)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels in data_loader:\n",
    "            # Move the data to the GPU\n",
    "            images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the metric\n",
    "            acc(outputs, labels)\n",
    "        \n",
    "        # Report the metrics\n",
    "        metrics = report_metrics_torch(loss=loss, accuracy=acc.compute(), epoch=epoch)\n",
    "        \n",
    "        # Reset the metric\n",
    "        acc.reset()\n",
    "\n",
    "        # Save the checkpoint and metrics\n",
    "        Path(local_path).mkdir(parents=True, exist_ok=True)\n",
    "        save_checkpoint_and_metrics_torch(metrics=metrics, model=model, local_path=local_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can schedule the training loop on a single GPU using Ray Core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now(datetime.UTC).strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "local_path = f\"/mnt/cluster_storage/single_gpu_mnist/torch_{timestamp}/\"\n",
    "\n",
    "train_loop_torch(\n",
    "    num_epochs=2, \n",
    "    local_path=local_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the produced checkpoints and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l {local_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(\n",
    "    os.path.join(local_path, \"metrics.csv\"),\n",
    "    header=None,\n",
    "    names=[\"loss\", \"epoch\", \"accuracy\"],\n",
    ")\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Data Parallel Training with Ray Train and PyTorch\n",
    "\n",
    "Let's now consider the case where we have a very large dataset of images that would take a long time to train on a single GPU. \n",
    "\n",
    "We would now like to scale this training job to run on multiple GPUs. \n",
    "\n",
    "Here is a diagram visualizing the desired distributed data-parallel training process:\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-ai-libraries/diagrams/multi_gpu_pytorch_v3.png\" width=\"1000\" >\n",
    "\n",
    "\n",
    "Let's see how we can achieve this data-parallel training with Ray Train and PyTorch.\n",
    "\n",
    "Here are the steps we will go through:\n",
    "- Migrating the model to Ray Train\n",
    "- Migrating the dataset to Ray Train\n",
    "- Reporting metrics and checkpoints\n",
    "- Launching a training job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Migrating the model to Ray Train\n",
    "\n",
    "Use the `ray.train.torch.prepare_model()` utility function to:\n",
    "\n",
    "- Automatically move your model to the correct device.\n",
    "- Wrap it in pytorch's `DistributedDataParallel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_ray_train() -> torch.nn.Module:\n",
    "    model = resnet18(num_classes=10)\n",
    "    model.conv1 = torch.nn.Conv2d(\n",
    "        1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
    "    )\n",
    "    model = ray.train.torch.prepare_model(model) # Instead of model = model.to(\"cuda\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Migrating the dataset to Ray Train\n",
    "\n",
    "Use the `ray.train.torch.prepare_data_loader()` utility function, which:\n",
    "\n",
    "- Adds a DistributedSampler to your DataLoader.\n",
    "- Automatically moves the batches to the right device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader_ray_train(batch_size: int) -> DataLoader:\n",
    "    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "    train_data = MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    # Add DistributedSampler to the DataLoader\n",
    "    train_loader = ray.train.torch.prepare_data_loader(train_loader)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b> Note</b> that this step isn’t necessary if you are integrating your Ray Train implementaiton with Ray Data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reporting checkpoints and metrics\n",
    "To monitor progress, you can report intermediate metrics and checkpoints using the `ray.train.report` utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics_ray_train(\n",
    "    loss: torch.Tensor, accuracy: torch.Tensor, epoch: int\n",
    ") -> None:\n",
    "    metrics = {\"loss\": loss.item(), \"accuracy\": accuracy.item(), \"epoch\": epoch}\n",
    "    if ray.train.get_context().get_world_rank() == 0:\n",
    "        print(metrics)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def save_checkpoint_and_metrics_ray_train(\n",
    "    model: torch.nn.Module, metrics: dict[str, float]\n",
    ") -> None:\n",
    "    with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "        torch.save(\n",
    "            model.module.state_dict(),  # note the .module to unwrap the DistributedDataParallel\n",
    "            os.path.join(temp_checkpoint_dir, \"model.pt\"),\n",
    "        )\n",
    "        ray.train.report(  # use ray.train.report to save the metrics and checkpoint\n",
    "            metrics,  # train.report will only save worker rank 0's metrics\n",
    "            checkpoint=ray.train.Checkpoint.from_directory(temp_checkpoint_dir),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the lifecycle of a checkpoint from being created using a local path to being uploaded to persistent storage.\n",
    "\n",
    "<img src=\"https://docs.ray.io/en/latest/_images/checkpoint_lifecycle.png\" width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given it is the same model across all workers, we can instead only build the checkpoint on worker of rank 0. Note that we will still need to call `ray.train.report` on all workers to ensure that the training loop is synchronized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint_and_metrics_ray_train(\n",
    "    model: torch.nn.Module, metrics: dict[str, float]\n",
    ") -> None:\n",
    "    with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "        checkpoint = None\n",
    "        if ray.train.get_context().get_world_rank() == 0:\n",
    "            torch.save(\n",
    "                model.module.state_dict(), os.path.join(temp_checkpoint_dir, \"model.pt\")\n",
    "            )\n",
    "            checkpoint = ray.train.Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "\n",
    "        ray.train.report(\n",
    "            metrics,\n",
    "            checkpoint=checkpoint,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Launching a training job\n",
    "\n",
    "Here is the desired data-parallel training diagram, but now using Ray Train.\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-ai-libraries/diagrams/multi_gpu_pytorch_annotated_v4.png\" width=\"1000\" >\n",
    "\n",
    "### Build a training loop\n",
    "\n",
    "Let's tie everything together into a single training loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_loop_ray_train(config: dict):  # pass in hyperparameters in config\n",
    "    criterion = CrossEntropyLoss()\n",
    "    model = load_model_ray_train() # model is now wrapped in DistributedDataParallel\n",
    "    optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "    \n",
    "    # Calculate the batch size for each worker\n",
    "    global_batch_size = config[\"global_batch_size\"]\n",
    "    batch_size = global_batch_size // ray.train.get_context().get_world_size()\n",
    "    data_loader = data_loader_ray_train(batch_size=batch_size) # data loader now has a DistributedSampler\n",
    "    \n",
    "    acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(model.device)\n",
    "\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        # Ensure data is on the correct device\n",
    "        data_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "        for images, labels in data_loader: # images, labels are now sharded across the workers\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward() # gradients are accumulated across the workers\n",
    "            optimizer.step()\n",
    "            acc(outputs, labels) # accuracy is computed across the workers\n",
    "\n",
    "        metrics = print_metrics_ray_train(loss, acc.compute(), epoch) # accuracy is aggregated across the workers\n",
    "        save_checkpoint_and_metrics_ray_train(model, metrics)\n",
    "        acc.reset() # reset the accuracy metric for the next epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Configure scale and GPUs\n",
    "Outside of your training function, create a ScalingConfig object to configure:\n",
    "\n",
    "- `num_workers`: The number of distributed training worker processes.\n",
    "- `use_gpu`: Whether each worker should use a GPU (or CPU).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_config = ScalingConfig(num_workers=2, use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a high-level architecture of how Ray Train works:\n",
    "\n",
    "<img src=\"https://docs.ray.io/en/latest/_images/overview.png\" width=600>\n",
    "\n",
    "Here are some key points:\n",
    "- The scaling config specifies the number of training workers.\n",
    "- A trainer actor process is launched that oversees the training workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure persistent storage\n",
    "Create a `RunConfig` object to specify the path where results (including checkpoints and artifacts) will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_path = \"/mnt/cluster_storage/ray-summit-2024-training/\"\n",
    "print(storage_path)  \n",
    "run_config = RunConfig(storage_path=storage_path, name=\"distributed-mnist-resnet18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Launch a training job\n",
    "\n",
    "We can now launch a distributed training job with a `TorchTrainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TorchTrainer(\n",
    "    train_loop_ray_train,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    "    train_loop_config={\"num_epochs\": 2, \"global_batch_size\": 128},\n",
    ")\n",
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access training results\n",
    "After training completes, a `Result` object is returned which contains information about the training run, including the metrics and checkpoints reported during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the metrics produced by the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.metrics_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take the latest checkpoint and load it to inspect the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = result.checkpoint\n",
    "with ckpt.as_directory() as ckpt_dir:\n",
    "    model_path = os.path.join(ckpt_dir, \"model.pt\")\n",
    "    loaded_model = build_resnet18()\n",
    "    state_dict = torch.load(model_path, map_location=torch.device('cpu'), weights_only=True)\n",
    "    loaded_model.load_state_dict(state_dict)\n",
    "    loaded_model.eval()\n",
    "\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "### Activity: Update the training loop to compute AUROC\n",
    "\n",
    "1. Update the training loop `train_loop_ray_train` to compute the AUROC metric.\n",
    "2. Update the `print_metrics_ray_train` function to include the AUROC metric.\n",
    "3. Save the AUROC metric in the `save_checkpoint_and_metrics_ray_train` function.\n",
    "\n",
    "Use the following code snippets to guide you:\n",
    "\n",
    "```python\n",
    "# Hint: Update the print function to include AUROC\n",
    "def print_metrics_ray_train(...):\n",
    "    ...\n",
    "\n",
    "def train_loop_ray_train(config):\n",
    "    # Hint: Update the training loop to compute AUROC\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_ray_train,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    "    train_loop_config={\"num_epochs\": 2, \"global_batch_size\": 128},\n",
    ")\n",
    "result = trainer.fit()\n",
    "result.metrics_dataframe\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary> Click here to see the solution </summary>\n",
    "\n",
    "```python\n",
    "def print_metrics_ray_train(loss, accuracy, auroc):\n",
    "    metrics = {\n",
    "        \"loss\": loss.item(),\n",
    "        \"accuracy\": accuracy.item(),\n",
    "        \"auroc\": auroc.item(),\n",
    "    }\n",
    "    if ray.train.get_context().get_world_rank() == 0:\n",
    "        print(\n",
    "            f\"Loss: {loss.item()}, Accuracy: {accuracy.item()}, AUROC: {auroc.item()}\"\n",
    "        )\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def train_loop_ray_train(config):\n",
    "    criterion = CrossEntropyLoss()\n",
    "    model = load_model_ray_train()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    global_batch_size = config[\"global_batch_size\"]\n",
    "    batch_size = global_batch_size // ray.train.get_context().get_world_size()\n",
    "    data_loader = data_loader_ray_train(batch_size=batch_size)\n",
    "\n",
    "    acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(model.device)\n",
    "    # Add AUROC metric\n",
    "    auroc = torchmetrics.AUROC(task=\"multiclass\", num_classes=10).to(model.device)\n",
    "\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        data_loader.sampler.set_epoch(epoch)\n",
    "\n",
    "        for images, labels in data_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            acc(outputs, labels)\n",
    "            auroc(outputs, labels)\n",
    "\n",
    "        metrics = print_metrics_ray_train(\n",
    "            loss, acc.compute(), auroc.compute()\n",
    "        )\n",
    "        save_checkpoint_and_metrics_ray_train(model, metrics)\n",
    "        acc.reset()\n",
    "        auroc.reset()\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_ray_train,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=run_config,\n",
    "    train_loop_config={\"num_epochs\": 2, \"global_batch_size\": 128},\n",
    ")\n",
    "result = trainer.fit()\n",
    "print(result.metrics_dataframe)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup \n",
    "!rm -rf /mnt/cluster_storage/single_gpu_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orphan": true,
  "vscode": {
   "interpreter": {
    "hash": "a8c1140d108077f4faeb76b2438f85e4ed675f93d004359552883616a1acd54c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
