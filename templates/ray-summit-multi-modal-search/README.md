# Reinventing Multi-Modal Search with LLMs and Large Scale Data Processing

Traditional search systems often struggle with handling unstructured data, especially non-text data like images. In this workshop, you'll learn how to enhance legacy search systems using generative and embedding models for richer data representation.

You will build a scalable multi-modal data indexing pipeline and a hybrid search backend using Anyscale and MongoDB. The training will cover practical applications of Ray Data for scalable batch inference, Ray Serve for deploying and scaling the search application, vLLM for integrating large language models and MongoDB Atlas for both lexical and vector search.

By the end of this session, you'll have the skills to implement advanced AI tooling for creating a scalable and efficient search system capable of handling diverse data types in enterprise applications.

## Prerequisites:
- Familiarity with large scale data processing.
- Prior experience with Ray Data or Ray Serve is not required, but participants with some experience in these frameworks will have an advantage in understanding the more advanced topics that will be covered in the training.
- Intermediate-level experience with Python.

## Ray Libraries:
- Ray Data
- Ray Serve