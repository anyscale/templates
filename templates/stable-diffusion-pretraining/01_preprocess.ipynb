{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalable data preprocessing pipeline for Stable Diffusion\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/stable-diffusion/preprocessing_architecture_v4.jpeg\" width=\"900px\">\n",
    "\n",
    "The preceding architecture diagram illustrates the data preprocessing pipeline for Stable Diffusion. \n",
    "\n",
    "Ray Data loads the data from a remote storage system, then streams the data through two processing main stages:\n",
    "1. **Transformation**\n",
    "   1. Cropping and normalizing images.\n",
    "   2. Tokenizing the text captions using a CLIP tokenizer.\n",
    "2. **Encoding**\n",
    "   1. Compressing images into a latent space using a VAE encoder.\n",
    "   2. Generating text embeddings using a CLIP model.\n",
    "\n",
    "This notebook executes a fully self-contained module, `preprocess.py`, that processes a small subset of the full 2 billion dataset to demonstrate the workload. You can parameterize the same module code to process the full dataset. The \"Scale to 2 billion images\" section below for a summarizes the necessary changes for read the full dataset.\n",
    "\n",
    "Run the following cell to perform the data preprocessing. The script loads the data, transforms it, and encodes the output. After the cell executes, view the two sample visualized inputs along with their corresponding outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/preprocess.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the preprocessing.py implementation, refer to our [Definitive Guide on Processing 2 Billion Images for Stable Diffusion Model Training](https://www.anyscale.com/blog/processing-2-billion-images-for-stable-diffusion-model-training-definitive-guides-with-ray-series) for a detailed breakdown of the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Running production-scale data preprocessing\n",
    "\n",
    "If you're looking to scale your Stable Diffusion pre-training and potenitally use your own custom data, we're here to help ðŸ™Œ !\n",
    "\n",
    "ðŸ‘‰ **[Check out this link](https://forms.gle/9aDkqAqobBctxxMa8) so we can assist you**.\n",
    "\n",
    "In case you would like to get an idea of the changes needed to scale the `preprocess.py` script to the full dataset, below is a table that provides approximate guidance on the changes you need to make:\n",
    "\n",
    "| Step | Change | Description |\n",
    "| --- | --- | --- |\n",
    "| 1 | Raw Data Path | Change to point to the full dataset |\n",
    "| 2 | Data Loading Workers | Increase from 1 to 192 CPUs |\n",
    "| 3 | Transformation Workers | Increase from 1 to 192 CPUs |\n",
    "| 4 | Batch Size | Use 120 for 256x256 images and 40 for 512x512 images |\n",
    "| 5 | Encoding Workers | Increase from 0 to 48 A10-G GPUs |\n",
    "| 6 | Output Path | Change to a permanent remote storage location |\n",
    "| 7 | Run Process | Run as an Anyscale Job |\n",
    "\n",
    "In terms of infrastructure, you would provision 48 instances of g5.2xlarge instances for the entire process or use Anyscale's autoscaling capabilities to scale up and down as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd-template-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
