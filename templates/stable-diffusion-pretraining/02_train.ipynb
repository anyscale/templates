{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalable model training pipeline for Stable Diffusion\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/stable-diffusion/training_architecture_v3.jpeg\" width=700px />\n",
    "\n",
    "The preceding architecture diagram illustrates the model training process for Stable Diffusion. \n",
    "\n",
    "The training stage primarily consists of three steps:\n",
    "\n",
    "1. **Load the preprocessed data**: Load preprocessed data to feed the model.\n",
    "2. **Build a Stable Diffusion model**: Use a network architecture called a U-Net to build the model.\n",
    "3. **Run the scalable training procedure**: Scale the base model from the previous step with Ray Train to enable running on a GPU compute cluster. \n",
    "\t  \n",
    "This notebook executes a fully self-contained module, `train.py`, that processes a small subset of the full 2 billion dataset on a small U-Net model to demonstrate the workload. You can parameterize the same module code to train over the full dataset. The **Running production-scale model training** section below summarizes the necessary changes to scale the workload.\n",
    "\n",
    "Run the following cell to perform the model training. The script loads the data, builds the model, and runs Ray to train and checkpoint the model. After the cell executes, view the generated model checkpoint files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Running production-scale model training\n",
    "\n",
    "If you're looking to scale your Stable Diffusion pre-training and potenitally use your own custom data, we're here to help ðŸ™Œ !\n",
    "\n",
    "ðŸ‘‰ **[Check out this link](https://forms.gle/9aDkqAqobBctxxMa8) so we can assist you**.\n",
    "\n",
    "\n",
    "In case you would like to get an idea of the changes needed to scale the `train.py` script to the full dataset, below is a table that provides approximate guidance on the changes you need to make:\n",
    "\n",
    "| Step | Change | Action |\n",
    "| --- | --- | --- |\n",
    "| 1 | Change the processed training and validation data paths | Point to the full dataset |\n",
    "| 2 | Change the number of data loading workers | Change from 1 to 64 CPUs to load the data |\n",
    "| 2 | Change the number of training workers | Change from 1 A10G GPU to 32 A100-80 GB GPUs to run the training |\n",
    "| 4 | Change the batch size | Use 128 for a resolution of 256x256 images and 32 for a resolution of 512x512 images |\n",
    "| 5 | Update the model config | Use the full U-Net model |\n",
    "| 6 | Set `FSDP` as the distributed training strategy | Configure it to run in `SHARD_GRAD_OP` mode |\n",
    "| 7 | Change the output path | Change to the desired remote storage output path  |\n",
    "| 8 | Run the process script as an Anyscale Job | Submit a job instead of running in a notebook |\n",
    "| 9 | Run the first phase of training | Use resolution 256x256 for a total of 550,000 steps |\n",
    "| 10 | Run the second phase of training | Use resolution 512x512 for a total of 850,000 steps loading the checkpoint from the first phase |\n",
    "\n",
    "\n",
    "In terms of infrastructure, you would provision 4 `p4de.24xlarge` instances for the entire process or use Anyscale's autoscaling capabilities to scale up and down as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
