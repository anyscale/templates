{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93741bbd-1f44-4950-8097-2d5af7618c90",
   "metadata": {},
   "source": [
    "# Quickstart: Stable diffusion pre-training\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/stable-diffusion/end_to_end_architecture_v6.jpeg\" width=\"1000px\">\n",
    "\n",
    "Above is the reference architecture for Stable Diffusion pre-training\n",
    "with Ray and Anyscale. You can view how to implement the architecture by\n",
    "checking the provided python scripts. You can run interactive notebooks\n",
    "to guide you through the major steps in the process.\n",
    "\n",
    "Hereâ€™s what you can achieve with this reference implementation:\n",
    "\n",
    "-   Pre-train the Stable Diffusion v2 model on a massive dataset of ~2\n",
    "    billion images for less than \\$40,000.\n",
    "-   Eliminate preprocessing bottlenecks with Ray Data and improve\n",
    "    training throughput by 30%.\n",
    "-   Benefit from system and algorithm optimizations to reduce training\n",
    "    costs by 3x compared to baseline methods.\n",
    "\n",
    "To view a detailed benchmarking and explanation of our reference implementation, check out our [blog post here](https://www.anyscale.com/blog/stable-diffusion-pre-training)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd246722",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Interactive notebooks\n",
    "\n",
    "Dive into these interactive notebooks to see how you can implement\n",
    "Stable Diffusion v2 pre-training on Anyscale:\n",
    "\n",
    "| Notebook                                                                             | Description                                                                                                                               | Input                                | Output                               | Time to complete  |\n",
    "|---------------|---------------|---------------|---------------|---------------|\n",
    "| preprocessing.ipynb                                         | Run a scalable data pipeline to process image and text data for Stable Diffusion pre-training.                                            | Image and caption data               | Image latents and caption embeddings | ðŸ•™ 5 minutes |\n",
    "| training.ipynb                                                   | Initiate a scalable training pipeline to efficiently produce Stable Diffusion v2 models.                                                  | Image latents and caption embeddings | Trained model                        | ðŸ•™ 5 minutes |\n",
    "| online_preprocessing_and_training.ipynb | Create and run a scalable online processing and training pipeline for more complex training scenarios running on heterogeneous resources. | Image and caption data               | Trained model                        | ðŸ•™ 5 minutes |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef7c1f3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Want to pre-train with custom data? ðŸ“ˆ\n",
    "\n",
    "If youâ€™re looking to scale your Stable Diffusion pre-training with\n",
    "custom data, weâ€™re here to help ðŸ™Œ !\n",
    "\n",
    "ðŸ‘‰ **[Check out this link](https://forms.gle/9aDkqAqobBctxxMa8) so we\n",
    "can assist you**.\n",
    "\n",
    "## Key benefits of using Anyscale\n",
    "\n",
    "With Anyscale, you can significantly improve your pre-training setup,\n",
    "given Anyscaleâ€™s unique features like:\n",
    "\n",
    "-   **Heterogeneous Compute**: Easily scale your training across\n",
    "    different machines, GPUs, and accelerators.\n",
    "-   **Cost Efficient**: Use automatic on-demand to spot instances\n",
    "    switching and fast nodes startup to lower compute costs.\n",
    "-   **Smooth DevEx**: Develop in VSCode, monitor hardware usage in real\n",
    "    time, and move from development to production seamlessly.\n",
    "\n",
    "## Detailed cost analysis\n",
    "\n",
    "For those who love the details, hereâ€™s a deep dive into our costs for\n",
    "pre-training Stable Diffusion v2. We reduced training costs by 3x\n",
    "compared to baseline methods.\n",
    "\n",
    "| Parameter           | Value                                                                                                      |\n",
    "|------------------------------------|------------------------------------|\n",
    "| Instance Type       | p4de.24xlarge                                                                                              |\n",
    "| Cloud Provider      | AWS (us-west-2)                                                                                            |\n",
    "| GPU Type            | A100-80G                                                                                                   |\n",
    "| Global Batch Size   | 4096                                                                                                       |\n",
    "| Training Procedure  | Phase 1: 1,126,400,000 samples at resolution 256x256; Phase 2: 1,740,800,000 samples at resolution 512x512 |\n",
    "| Total A100 Hours    | 13,165                                                                                                     |\n",
    "| Total Training Cost | \\$39,511 (1-yr reservation instances) \\$67,405 (on-demand instances)                                       |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
