{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f815e4-caab-4315-964b-851cd49aa1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.train import ScalingConfig, RunConfig, Checkpoint\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from ray.train.torch import TorchTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07afb184-3fad-441f-91fe-39db5ebd1d10",
   "metadata": {},
   "source": [
    "# Train a Basic PyTorch Model with Ray Train + Ray Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2308f83d-67b0-4dd8-8b7b-3ca9e602a6c2",
   "metadata": {},
   "source": [
    "We'll start with the NYC taxicab data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c3322-db4c-4c4b-8bad-10eb2c82099c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = ray.data.read_parquet(\"s3://anonymous@anyscale-training-data/intro-to-ray-air/nyc_taxi_2021.parquet\", \n",
    "                                columns=['passenger_count', 'trip_distance', 'fare_amount', 'trip_duration','hour','day_of_week','is_big_tip'])\n",
    "\n",
    "dataset.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8ffce-1c2d-4f86-a910-ef1a5d7ebf56",
   "metadata": {
    "tags": []
   },
   "source": [
    "In order to feed this data to typical model fitting APIs, we need to collect the predictors into a vector. We may want to stack these into batches represented by matrices.\n",
    "\n",
    "> Note: we could do this within the per-worker training function itself, converting each batch of data close to where we consume it for training. In many cases, though, that would violate separation of concerns and make it hard to change and reuse the data processing logic.\n",
    "\n",
    "We're going to demonstrate how to do this with Ray Data because\n",
    "1. we might want to do other transformations or feature preprocessing in a data-only pipeline\n",
    "1. it provides better separation of concerns and reuse\n",
    "1. it allows us to better benefit from Ray's granular resource and scheduling capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e005fa32-9214-4c7b-a934-509b39c86129",
   "metadata": {},
   "source": [
    "Map batches receives and returns a dict by default.\n",
    "\n",
    "An easy way to design the batch logic is to take a batch from the dataset and write code that works correctly for that batch; then we'll wrap it in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d62ee80-f724-4b49-a667-0c350b6c6495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = dataset.take_batch(5)\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421a75a-2079-47ee-84b1-e518568717c4",
   "metadata": {},
   "source": [
    "Let's move our logic into a function and check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ca6b12-84e3-490f-b1ec-cc8826009eab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_vectorize(batch):\n",
    "    return { 'vectors' : np.vstack(list(batch.values()), dtype=np.float32).transpose() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9123348-7b98-41df-a7c0-0942dba3def3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = dataset.map_batches(batch_vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719d66b-2ae8-4a71-9bf6-d836521e4179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds.take_batch(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5542805-3e18-4a37-bfe9-0e45287f702d",
   "metadata": {},
   "source": [
    "Looks good. Next we'll prepare a per-worker training function\n",
    "* Start with standard PyTorch code (model, loss, optimizer, loop)\n",
    "* use `ray.train.torch.prepare_model` to wrap the model for distributed training\n",
    "* use `get_dataset_shard` to obtain a source for data batches\n",
    "    * if we want to implement validation (or anything else) we can pass additional datasets in the same way\n",
    "    * the batchs from `iter_torch_batches` will be dictionaries ... with Torch Tensors as the values\n",
    "* supply arbitrary small values via `train_loop_config`\n",
    "* create checkpoints and call `train.report`\n",
    "    * we can use the logic we like to decide on checkpointing (typically only from one worker and only every *n* epochs)\n",
    "    * we must call `train.report` from each worker (even if that worker is not checkpointing or reporting any stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed208277-4995-44ad-abe0-29f275cacd68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_func(config):\n",
    "    from ray.train import get_dataset_shard\n",
    "\n",
    "    # simple multilayer perceptron model\n",
    "    \n",
    "    D_in = 6\n",
    "    H1 = config[\"H1_width\"] # example config params\n",
    "    H2 = config[\"H2_width\"]\n",
    "    D_out = 1\n",
    "    \n",
    "    model = torch.nn.Sequential(\n",
    "      torch.nn.Linear(D_in, H1), \n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.Linear(H1, H2), \n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.Linear(H2, D_out)\n",
    "    )\n",
    "    \n",
    "    criterion = BCEWithLogitsLoss()\n",
    "    optimizer = Adam(model.parameters())\n",
    "\n",
    "    # Prepare model\n",
    "\n",
    "    model = ray.train.torch.prepare_model(model)\n",
    "\n",
    "    # Get and local data shard stream and generate batch iterator\n",
    "    \n",
    "    train_sh = get_dataset_shard(\"train\")\n",
    "    training = train_sh.iter_torch_batches(batch_size=65536, dtypes=torch.float)\n",
    "    \n",
    "    # Simple torch training loop\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        for batch in training:\n",
    "            features = batch['vectors'][:,:-1]\n",
    "            targets = batch['vectors'][:,-1,None]\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Report (with metrics) and checkpoint\n",
    "\n",
    "        with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "            checkpoint = None\n",
    "\n",
    "            # In standard DDP training, where the model is the same across all ranks,\n",
    "            # only the global rank 0 worker needs to save and report the checkpoint\n",
    "            if ray.train.get_context().get_world_rank() == 0:\n",
    "                torch.save(\n",
    "                    model.module.state_dict(),  # NOTE: Unwrap the model.\n",
    "                    os.path.join(temp_checkpoint_dir, \"model.pt\"),\n",
    "                )\n",
    "                checkpoint = Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "\n",
    "            ray.train.report({'loss': loss.item()}, checkpoint=checkpoint)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b085066b-df9b-492f-86f2-26d2658bc4af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaling_config = ScalingConfig(num_workers=2, use_gpu=True)\n",
    "\n",
    "trainer = TorchTrainer(train_func, \n",
    "                       scaling_config=scaling_config, \n",
    "                       run_config=ray.train.RunConfig(storage_path='/mnt/cluster_storage'),\n",
    "                       datasets={\"train\": train_ds},\n",
    "                       train_loop_config={\"H1_width\": 10, \"H2_width\": 5})\n",
    "\n",
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddae890-57b0-49d6-aadc-8d234c31652d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07abc8-94e7-498b-813e-c3bab0c7ca0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
