{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87b86b-8af9-4075-9107-29d4fbadbdef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diffusers import AutoPipelineForText2Image\n",
    "from transformers import pipeline\n",
    "from transformers.utils import logging\n",
    "import numpy as np\n",
    "import random\n",
    "import ray\n",
    "import torch\n",
    "logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf2f3c9-d304-45fa-8dfa-c1bd2212a93c",
   "metadata": {},
   "source": [
    "First, we need to get all of our data in some common location where the whole cluster can see it. This might be a blob store, NFS, database, etc.\n",
    "\n",
    "Anyscale offers `/mnt/cluster_storage` as a NFS path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ff6260-3303-4da1-9624-b399c0100c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! cp *.csv /mnt/cluster_storage/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22045eb-ec5c-438f-a66b-a9382ec81e6f",
   "metadata": {},
   "source": [
    "Ray Data's `read_xxxx` methods (see I/O in Ray Docs for all the available formats and data sources) get us scalable, parallel reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8dacd2-871f-4fa7-a164-1c653778d10b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "animals = ray.data.read_csv('/mnt/cluster_storage/animals.csv')\n",
    "\n",
    "animals.take_batch(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43dd7f2-39f9-4d7d-af3d-a30b3fbce1a3",
   "metadata": {},
   "source": [
    "Batches of records are represented as Python dicts where the keys correspond to the dataset column names and the values are a vectorized type -- usually a NumPy Array -- of values containing one value for each record in the batch.\n",
    "\n",
    "Ray Data contains methods for basic data transformation and allow modification of dataset schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2fc3c2-d042-4853-a815-7e73b7bb111c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "animals.rename_columns({'animal' : 'prompt'}).take_batch(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8c9812-e194-4a1e-a250-fa1e492db439",
   "metadata": {},
   "source": [
    "Stateful tranformation of datasets -- in this example, AI inference where the state is the image gen model -- is done with the following pattern.\n",
    "\n",
    "1. Define a Python class (which Ray will later instantiate across the cluster as one more actor instances to do the processing)\n",
    "1. Use Dataset's `map_batches` API to tell Ray to send batches of data to the `__call__` method in the actors instances\n",
    "    1. `map_batches` allows us to specify resource requirements, actor pool size, batch size, and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2eed92-11c5-4d8a-b452-e4123f87ec05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageGen():\n",
    "    def __init__(self):\n",
    "        self.pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
    "        \n",
    "    def gen_image(self, prompts):\n",
    "        return self.pipe(prompt=list(prompts), num_inference_steps=1, guidance_scale=0.0).images\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        batch['image'] = self.gen_image(batch['prompt'])\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba51c5-80d7-484f-a974-8602ddf9058b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "animals_images = animals.repartition(2).rename_columns({'animal' : 'prompt'}).map_batches(ImageGen, num_gpus=1, concurrency=2, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17c3274-3975-4a24-b12a-a27225ba154c",
   "metadata": {},
   "source": [
    "Ray Datasets employ *lazy evaluation* for improved performance, so we can use APIs like `take_batch`, `take`, or `show` to trigger execution for development and testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e0e5c-34c7-4743-ac35-6826b079863d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples = animals_images.take_batch(3)\n",
    "\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef0e113-70df-4a56-9975-c083a6a37aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples['image'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e024d8-31ec-49c0-a691-ff0397ac335d",
   "metadata": {},
   "source": [
    "## Lab: Generate and write all output to storage as parquet data\n",
    "\n",
    "Instructions/hints:\n",
    "\n",
    "1. Start with the Ray Dataset you'd like to write\n",
    "1. Check https://docs.ray.io/en/latest/data/api/input_output.html to find a suitable write API\n",
    "1. Remember to write to a *shared* file location, such as `/mnt/cluster_storage`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f86a1d-76c2-4b17-8ae7-6493b5419058",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary> Click to see solution </summary>\n",
    "\n",
    "```python\n",
    "animals_images.write_parquet('/mnt/cluster_storage/animals_images.parquet/')\n",
    "```\n",
    "</details>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee81801-d0a7-465e-934e-4770078d6dbd",
   "metadata": {},
   "source": [
    "## Load and join details for each prompt\n",
    "\n",
    "Ray Data supports a number of high-performance JOIN APIs: https://docs.ray.io/en/latest/data/joining-data.html\n",
    "\n",
    "We can use a JOIN to connect our animal records with a detailed prompt refinement unique to that record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb868767-38e3-4a0c-a7bc-b3f294edbece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outfits = ray.data.read_csv('/mnt/cluster_storage/outfits.csv')\n",
    "\n",
    "outfits.take_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ec501-638f-411e-a300-c2eb00827eea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "animals_outfits = animals.join(outfits, 'inner', 1).repartition(8)\n",
    "\n",
    "animals_outfits.take_batch(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376f9e81-30fc-443c-861c-eb652a421e23",
   "metadata": {},
   "source": [
    "We can add custom logic to combine and expand the image gen prompt using another call to `map_batches`\n",
    "\n",
    "In this pattern, since the transformation is stateless and lightweight, we can define it as a Python function (which takes and returns a batch of records) and then use a simplified call to `map_batches` where Ray will autoscale the number of scheduled tasks in order to keep the best throughput for our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157b347-6ba4-4851-9eba-82239ed4ff61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expand_prompt(batch):\n",
    "    batch['prompt'] = batch['animal'] + ' wearing a ' + batch['outfit']\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3105e53e-dead-4e7d-a376-abe3c66a957a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "animals_outfits.map_batches(expand_prompt).take_batch(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9ece41-5407-4680-83f2-b9af10f9eff7",
   "metadata": {},
   "source": [
    "We can combine the prompt expansion operation with the image gen operation to produce a new set of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f69b2-da3f-42d0-ba16-df088149b4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dressed_animals = animals_outfits.map_batches(expand_prompt).map_batches(ImageGen, batch_size=16, concurrency=2, num_gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c15171-d92d-464d-929f-e09d0758bdf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples = dressed_animals.take_batch(3)\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f37544-d29a-43c8-a7e1-71ca0a0563e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples['prompt'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2837fc0-4167-4a15-9008-414096f78e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples['image'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf35723-e7ef-4fed-98a7-06e7ee405402",
   "metadata": {},
   "source": [
    "## Lab: generate images for the input prompts and write the images to a folder\n",
    "\n",
    "> Hint 1: Use `dataset.write_images(...)`\n",
    ">\n",
    "> Hint 2: To use `dataset.write_images(...)`, the images will need to be NumPy arrays (instead of PIL Image objects). You can use `np.array(my_pil_image)` to do that conversion. Use that API along with `map_batches` to convert all of your images prior to calling `write_images`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23e653-e245-4bcb-8479-828fbbe9ef22",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary> Click to see solution </summary>\n",
    "\n",
    "```python\n",
    "def image_to_array(batch):\n",
    "    batch['image'] = [np.array(i) for i in batch['image']]\n",
    "    return batch\n",
    "    \n",
    "animals_images.map_batches(image_to_array).write_images('/mnt/cluster_storage/animals_images/', 'image')\n",
    "```\n",
    "\n",
    "</details>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
