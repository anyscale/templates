{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a327f2",
   "metadata": {},
   "source": [
    "# Ray Tasks Advanced Patterns: Building Distributed Applications\n",
    "\n",
    "© 2025, Anyscale. All Rights Reserved\n",
    "\n",
    "This notebook goes through some advanced patterns with Ray Tasks, the fundamental building block of Ray that enables distributed computing.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b> Here is the roadmap for this notebook </b>\n",
    "\n",
    "<ol>\n",
    "  <li>Error handling and task retries</li>\n",
    "  <li>Task runtime environments</li>\n",
    "  <li>Resource allocation and management</li>\n",
    "  <li>Pipeline data processing and waiting for results</li>\n",
    "  <li>Ray generators</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd37367",
   "metadata": {},
   "source": [
    "**Imports**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30318fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ray\n",
    "import requests\n",
    "import ray.runtime_context\n",
    "from ray import tune\n",
    "from ray.util.scheduling_strategies import NodeAffinitySchedulingStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bbdbd2",
   "metadata": {},
   "source": [
    "## 1. Error handling and task retries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b6c5d4",
   "metadata": {},
   "source": [
    "### 1.1. Understanding exception types\n",
    "\n",
    "Let's consider two types of exceptions:\n",
    "1. **System errors**: Worker node dies, out of memory, network issues\n",
    "2. **Application-level errors**: Python exceptions in your code (ValueError, TypeError, etc.)\n",
    "\n",
    "Ray will automatically **retry system errors in tasks up to 3 times** if it fails due to a system error (e.g., a worker node dies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76fcc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def sys_flaky_square(x: int, prob: float) -> int:\n",
    "    if random.random() < prob:\n",
    "        raise sys.exit(1)\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd92409",
   "metadata": {},
   "source": [
    "Let's run the flaky task a few times, we should see some retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2208d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.get([sys_flaky_square.remote(x=4, prob=0.2) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dffcc12",
   "metadata": {},
   "source": [
    "### 1.2. Handling application exceptions\n",
    "\n",
    "Below task won't be retried by default because it's an application failure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df95ff3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def incorrect_square(x: int, prob: float) -> int:\n",
    "    if random.random() < prob:\n",
    "        raise ValueError(\"Random failure\")\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7648ba",
   "metadata": {},
   "source": [
    "If we run for enough times, we will see failures given application errors are not retried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5268149",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ray.get([incorrect_square.remote(x=4, prob=0.5) for _ in range(10)])\n",
    "except ray.exceptions.RayTaskError as e:\n",
    "    print(f\"Task failed with: {e}\")\n",
    "    print(f\"Original exception: {e.cause}\")  # Access underlying exception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565c90a0",
   "metadata": {},
   "source": [
    "**Exception propagation:**\n",
    "- Exceptions in tasks are wrapped in `RayTaskError`\n",
    "- The original exception is available via `.cause` attribute\n",
    "- `ray.get()` will raise the exception\n",
    "- ObjectRefs remain valid, but getting them raises the exception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1464b5",
   "metadata": {},
   "source": [
    "### 1.3. Configuring retries\n",
    "\n",
    "Ray lets you specify how to handle retries when an exception is encountered:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8013fcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(retry_exceptions=[ValueError])\n",
    "def correct_square(x: int, prob: float) -> int:\n",
    "    if random.random() < prob:\n",
    "        raise ValueError(\"Random failure\")\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac9129",
   "metadata": {},
   "source": [
    "Note we did not have to re-define the remote function, instead we can create an updated version using `.options`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e670d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_square_mod = correct_square.options(\n",
    "    retry_exceptions=[ValueError],\n",
    "    max_retries=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd63de16",
   "metadata": {},
   "source": [
    "Let's try it out:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704a1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    outputs = ray.get([correct_square_mod.remote(x=4, prob=0.5) for _ in range(10)])\n",
    "except ray.exceptions.RayTaskError:\n",
    "    print(\"At least one of the tasks failed after all retries\")\n",
    "else:\n",
    "    print(f\"\\nSuccess! Results: {outputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f71983",
   "metadata": {},
   "source": [
    "### 1.4. Idempotency: Critical for reliable retries\n",
    "\n",
    "**⚠️ WARNING:** Only retry tasks that are **idempotent** (can be safely run multiple times).\n",
    "\n",
    "**❌ Non-idempotent (dangerous to retry):**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18729bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(retry_exceptions=[ValueError])\n",
    "def append_to_file(data):\n",
    "    with open(\"/tmp/data.txt\", \"a\") as f:\n",
    "        f.write(data)  # Will duplicate data on retry!\n",
    "    if random.random() < 0.5:\n",
    "        raise ValueError(\"Simulated failure\")\n",
    "    return \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a076f98",
   "metadata": {},
   "source": [
    "**If this task fails and retries:**\n",
    "1. First attempt: Writes \"hello\" → fails\n",
    "2. Retry: Writes \"hello\" again → file now has \"hellohello\"\n",
    "\n",
    "**✅ Idempotent (safe to retry):**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5fe54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(retry_exceptions=[ValueError])\n",
    "def write_to_file_safe(data, unique_id):\n",
    "    filename = f\"data_{unique_id}.txt\"\n",
    "    with open(filename, \"w\") as f:  # Overwrites on retry\n",
    "        f.write(data)\n",
    "    if random.random() < 0.5:\n",
    "        raise ValueError(\"Simulated failure\")\n",
    "    return \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd11888b",
   "metadata": {},
   "source": [
    "**Other idempotent operations:**\n",
    "- Reading from database\n",
    "- GET requests (not POST/PUT/DELETE)\n",
    "- Mathematical computations\n",
    "- Overwriting files (not appending)\n",
    "\n",
    "**Non-idempotent operations to avoid retrying:**\n",
    "- Appending to files/databases\n",
    "- Sending emails/notifications\n",
    "- Charging credit cards\n",
    "- Incrementing counters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fd0778",
   "metadata": {},
   "source": [
    "### 1.5. Task timeouts and cancellation\n",
    "\n",
    "Sometimes you want to set a maximum execution time or cancel tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02804e3",
   "metadata": {},
   "source": [
    "#### Setting timeouts with ray.get()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f9258",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def slow_task():\n",
    "    time.sleep(100)\n",
    "    return \"done\"\n",
    "\n",
    "ref = slow_task.remote()\n",
    "\n",
    "try:\n",
    "    result = ray.get(ref, timeout=5)  # Wait max 5 seconds\n",
    "except ray.exceptions.GetTimeoutError:\n",
    "    print(\"Task took too long!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52001d0a",
   "metadata": {},
   "source": [
    "#### Cancelling tasks\n",
    "\n",
    "Ray provides the functionality to cancel tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1822ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def long_running_task(duration):\n",
    "    time.sleep(duration)\n",
    "    return \"completed\"\n",
    "\n",
    "refs = [long_running_task.remote(10) for _ in range(5)]\n",
    "\n",
    "# Cancel all tasks\n",
    "for ref in refs:\n",
    "    ray.cancel(\n",
    "        ref,\n",
    "        force=False,\n",
    "        recursive=True\n",
    "    )\n",
    "\n",
    "# Verify task is cancelled\n",
    "try:\n",
    "    ray.get(refs[0])\n",
    "except ray.exceptions.TaskCancelledError:\n",
    "    print(\"Task was cancelled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3986f4eb",
   "metadata": {},
   "source": [
    "**Expected behavior**\n",
    "\n",
    "Here is the expected behavior\n",
    "* When `force=False` a KeyboardInterrupt is raised in Python\n",
    "* When `force=True`, ray will force-kill the worker process running task (does not apply for actors)\n",
    "\n",
    "If `recursive=True`, all the child Tasks and Actor Tasks are cancelled. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c2ac4b",
   "metadata": {},
   "source": [
    "**Important notes about cancellation:**\n",
    "- Cancellation is best-effort, not guaranteed\n",
    "- Task might complete before cancellation takes effect\n",
    "- Dependent tasks are also cancelled\n",
    "- Use for cleanup, not critical functionality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b698c1",
   "metadata": {},
   "source": [
    "## 2. Task runtime environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b851455d",
   "metadata": {},
   "source": [
    "A runtime environment defines dependencies such as files, packages, and environment variables needed for a Python script to run.\n",
    "\n",
    "- **Runtime Environment Management**:\n",
    "  - Managed by a `RuntimeEnvAgent` gRPC server on each node.\n",
    "  - The `RuntimeEnvAgent` fate-shares with the raylet, simplifying the failure model and ensuring it is a core component for task and actor scheduling.\n",
    "\n",
    "- **Environment Creation**:\n",
    "  - Triggered by the raylet via a gRPC request to the `RuntimeEnvAgent` when a task or actor requires a runtime environment.\n",
    "  - May involve:\n",
    "    - Installing packages using `pip install`.\n",
    "    - Setting environment variables for Ray worker processes.\n",
    "    - Activating conda environments with `conda activate`.\n",
    "    - Downloading files from remote cloud storage.\n",
    "\n",
    "- **Resource Caching**:\n",
    "  - Runtime environment resources, such as downloaded files and installed conda environments, are cached on each node.\n",
    "  - The cache allows sharing of resources between different tasks, actors, and jobs.\n",
    "  - When the cache size limit is exceeded, resources not currently in use are deleted to free up space.\n",
    "\n",
    "Here is a diagram showcasing the above concepts:\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-core/runtime_env.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2fb2ce",
   "metadata": {},
   "source": [
    "### 2.1. Setting environment variables\n",
    "\n",
    "For example, we can set an environment variable:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c90c4a8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "@ray.remote(runtime_env={\"env_vars\": {\"my_custom_env\": \"prod\"}})\n",
    "def f():\n",
    "    env = os.environ[\"my_custom_env\"]\n",
    "    return f\"My custom env is {env}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b86c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.get(f.remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f62fb",
   "metadata": {},
   "source": [
    "### 2.2. Installing pip dependencies\n",
    "\n",
    "This will perform pip installation at runtime and setting up the worker process to execute the task appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f506cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(runtime_env={\"pip\": [\"requests\", \"pandas==1.5.0\"]})\n",
    "def fetch_data(url):\n",
    "    return requests.get(url).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c3e2ab",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "pip dependencies add overhead to first task startup but are cached afterwards; for frequently used dependencies, bake them into your cluster image instead.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c298a63",
   "metadata": {},
   "source": [
    "### 2.3. Working directory\n",
    "\n",
    "Files can also be fetched from remote storage at runtime and made available in the worker processe's working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d0f7e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "@ray.remote(runtime_env={\"working_dir\": \"s3://my-bucket/project/my_directory.zip\"})\n",
    "def load_config():\n",
    "    with open(\"config.yaml\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1eeaed",
   "metadata": {},
   "source": [
    "## 3. Resource allocation and management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5202394c",
   "metadata": {},
   "source": [
    "### 3.1. Understanding logical vs physical resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b6da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=1)  # Ray reserves 1 CPU slot for scheduling\n",
    "def cpu_intensive_task():\n",
    "    # Ray sets OMP_NUM_THREADS=1 to match num_cpus\n",
    "    return np.dot(large_matrix_a, large_matrix_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5209db04",
   "metadata": {},
   "source": [
    "**Key points:**\n",
    "- `num_cpus` is a scheduling hint, not a hard limit\n",
    "- Ray automatically sets `OMP_NUM_THREADS` to match `num_cpus` to prevent oversubscription\n",
    "\n",
    "You can override this if needed (may cause oversubscription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c1700",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=1)\n",
    "def mm(n: int = 4000):\n",
    "    return np.dot(np.random.rand(n, n), np.random.rand(n, n))\n",
    "\n",
    "# Override to use 8 threads (caution: may oversubscribe)\n",
    "ray.get(mm.options(runtime_env={\"env_vars\": {\"OMP_NUM_THREADS\": \"8\"}}).remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fdcd2c",
   "metadata": {},
   "source": [
    "Note assigning \"GPU\" resources to a task, Ray will automatically set the `CUDA_VISIBLE_DEVICES` env var within the worker to limit it to specific GPU ids.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "Learn more about <strong><a href=\"https://docs.ray.io/en/latest/ray-core/scheduling/resources.html#physical-resources-and-logical-resources\" target=\"_blank\">physical resources and logical resources</a></strong>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d6269",
   "metadata": {},
   "source": [
    "### 3.2. Fractional resources for I/O-bound tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028f1541",
   "metadata": {},
   "source": [
    "Ray supports **fractional CPU requests** to enable efficient oversubscription of I/O-bound tasks.\n",
    "\n",
    "**When to use fractional CPUs:**\n",
    "\n",
    "Tasks that spend most of their time waiting (not computing) can share CPU slots:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moderately I/O-bound: Some computation, some I/O\n",
    "@ray.remote(num_cpus=0.5)  # Allow 2 tasks per CPU core\n",
    "def download_and_parse(url):\n",
    "    data = requests.get(url).text\n",
    "    return process_file(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3017ee",
   "metadata": {},
   "source": [
    "**Benefits:**\n",
    "- **Higher throughput**: Run more tasks concurrently when they're waiting on I/O\n",
    "- **Better resource utilization**: Don't waste CPU cores on tasks that are mostly idle\n",
    "- **Cost efficiency**: Process more work on the same hardware\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Note:** Don't abuse fractional resources and fall into the anti-pattern of launching too many small tasks. Instead, batch work and leverage multi-threading within tasks when possible.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ea732",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Fractional resources include support for <strong><a href=\"https://docs.ray.io/en/latest/ray-core/scheduling/accelerators.html#fractional-accelerators\" target=\"_blank\">multiple accelerators</a></strong>, allowing users to load multiple smaller models onto a single GPU. Learn more about <strong><a href=\"https://docs.ray.io/en/latest/ray-core/scheduling/resources.html#fractional-resource-requirements\" target=\"_blank\">fractional resource requirements</a></strong>.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e47ccf",
   "metadata": {},
   "source": [
    "### 3.3. Resource availability and cluster inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c204f6",
   "metadata": {},
   "source": [
    "Ray's scheduler matches tasks to nodes based on **resource requirements** like CPUs, GPUs, memory, or custom resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe87c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=2, num_gpus=1)\n",
    "def train_model(data):\n",
    "    return model.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe404fcd",
   "metadata": {},
   "source": [
    "**Inspecting cluster resources** returns total resources across the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f39196",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383f5696",
   "metadata": {},
   "source": [
    "**Inspecting available resources** returns currently unreserved resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632ff517",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.available_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31271485",
   "metadata": {},
   "source": [
    "### 3.4. Resource management and autoscaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60ea767",
   "metadata": {},
   "source": [
    "Ray's **Global Control Service (GCS)** orchestrates cluster-wide resource management and autoscaling:\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-core/resource_management_autoscaling.svg\" width=\"700\">\n",
    "\n",
    "**The resource synchronization loop:**\n",
    "\n",
    "1. **Raylets report usage**: Each raylet sends its resource usage to the GCS every ~100ms\n",
    "2. **GCS broadcasts state**: GCS pushes the global resource view back to all raylets every ~100ms  \n",
    "3. **Autoscaler reconciles**: The autoscaler queries the GCS for cluster load and:\n",
    "   - Adds nodes when demand exceeds available capacity\n",
    "   - Removes idle nodes to reduce costs\n",
    "\n",
    "**Example:** If 10 tasks need `num_gpus=1` but only 4 GPUs exist, the autoscaler provisions additional GPU nodes to meet demand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3a7df",
   "metadata": {},
   "source": [
    "## 4. Pipeline data processing and waiting for results\n",
    "\n",
    "After launching a number of tasks, you may want to know which ones have finished executing without blocking on all of them. This could be achieved by `ray.wait()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75d930b",
   "metadata": {},
   "source": [
    "### 4.1. Understanding ray.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e5921f",
   "metadata": {},
   "source": [
    "`ray.wait()` is a powerful primitive for building pipelines and managing task completion.\n",
    "\n",
    "Given a sample remote function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def remote_fn(x):\n",
    "    time.sleep(random.uniform(2, 10))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf43add",
   "metadata": {},
   "source": [
    "Unlike `ray.get`, which blocks until all tasks are complete, `ray.wait` allows you to wait for a specified number of tasks to finish and returns two lists: one with the completed tasks and another with the pending tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417405ea",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "refs = [remote_fn.remote(i) for i in range(10)]\n",
    "\n",
    "ready, not_ready = ray.wait(\n",
    "    refs,\n",
    "    num_returns=1,      # Number of references to wait for\n",
    "    timeout=None,       # Max time to wait for (seconds)\n",
    "    fetch_local=True    # Whether to fetch objects to the local node or not\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a687a1f4",
   "metadata": {},
   "source": [
    "Let's inspect the ready refs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b0bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1590395b",
   "metadata": {},
   "source": [
    "**Returns:**\n",
    "- `ready`: List of ObjectRefs that are ready\n",
    "- `not_ready`: List of ObjectRefs still pending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a616d86",
   "metadata": {},
   "source": [
    "### 4.2. Pipeline pattern with ray.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c19e01e",
   "metadata": {},
   "source": [
    "| <img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/ray-core/pipeline-data-processing.png\" width=\"400px\" loading=\"lazy\">                                                                               |\n",
    "| :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| \n",
    "(top panel) Execution timeline when using ray.get() to wait for all results before calling process results. \n",
    "(bottom panel) Execution timeline when using ray.wait() to process results as soon as they become available. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85df844",
   "metadata": {},
   "source": [
    "Here are functions to match the above diagram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf7578",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def do_some_work(x: int) -> int:\n",
    "    time.sleep(x)  # varying execution time based on input\n",
    "    return x\n",
    "\n",
    "@ray.remote\n",
    "def process_incremental(result: int) -> int:\n",
    "    time.sleep(1)\n",
    "    return result * 2\n",
    "\n",
    "@ray.remote\n",
    "def process_results(result_refs: list) -> list:\n",
    "    results = ray.get(result_refs)  # need to call ray.get explicitly for containers\n",
    "    out = []\n",
    "    for result in results:\n",
    "        time.sleep(1)\n",
    "        out.append(result * 2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe14b78",
   "metadata": {},
   "source": [
    "This is the **naive approach:** block until all tasks are complete and then process the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e3f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [2, 3, 1, 4]\n",
    "start = time.time()\n",
    "data_list = [do_some_work.remote(x) for x in inputs]\n",
    "output = ray.get(process_results.remote(data_list))\n",
    "print(\"duration =\", time.time() - start, \"\\nresult = \", output)\n",
    "# Duration: ~8 seconds (4s max task + 4s processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0938ae2d",
   "metadata": {},
   "source": [
    "This is the **pipelined** approach: process items as soon as they become available\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "result_ids = [do_some_work.remote(x) for x in inputs]\n",
    "refs = []\n",
    "while len(result_ids):\n",
    "    done_id, result_ids = ray.wait(result_ids, num_returns=1)\n",
    "    print(done_id)\n",
    "    refs.append(process_incremental.remote(done_id[0]))\n",
    "output = ray.get(refs)\n",
    "print(\"duration =\", time.time() - start, \"\\nresult = \", output)\n",
    "# Duration: ~5 seconds (overlapping ~4s computation and 1s processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77db1c9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Read more about the <strong><a href=\"https://docs.ray.io/en/latest/ray-core/tips-for-first-time.html#tip-4-pipeline-data-processing\" target=\"_blank\">pipeline data processing</a></strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bac785",
   "metadata": {},
   "source": [
    "## 5. Ray generators\n",
    "\n",
    "[Ray Generators](https://docs.ray.io/en/latest/ray-core/ray-generator.html) are a way to make use of the python generator pattern to generate data.\n",
    "\n",
    "They are useful for:\n",
    "- Reducing worker heap memory usage **by** avoiding building up a large in-memory collection\n",
    "- Reducing object store memory usage **by** allowing for garbage collection of objects that are processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9556cf",
   "metadata": {},
   "source": [
    "### 5.1. Why use Ray Generators?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22678a74",
   "metadata": {},
   "source": [
    "**Problem with regular tasks:**\n",
    "Memory intensive tasks will cause pressure on both the worker process heap and shared object store memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee679686",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_returns=2)\n",
    "def produce_large_dataset():\n",
    "    task_id = ray.runtime_context.get_runtime_context().get_task_id()\n",
    "    # Creates all data in memory at once\n",
    "    results = []\n",
    "    for i in range(100):\n",
    "        results.append(np.random.rand(1024**2))  # Each object is ~8MiB (64 bit * 1024)\n",
    "    return results, task_id  # ~800iMB in memory!\n",
    "\n",
    "# High memory pressure\n",
    "ref, task_id_ref = produce_large_dataset.remote()\n",
    "task_id = ray.get(task_id_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1314dbfb",
   "metadata": {},
   "source": [
    "Let's see the objects ties to this task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ray list objects --filter TASK_STATUS!=NIL --filter TYPE=DRIVER --filter OBJECT_ID={task_id}01000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399c2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup\n",
    "%xdel ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b8148",
   "metadata": {},
   "source": [
    "**Solution with generators:**\n",
    "\n",
    "Avoid memory build up in the task, and start generating blocks or partitions as soon as they are available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3646e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def produce_large_dataset():\n",
    "    # Yields one object at a time\n",
    "    for i in range(100):\n",
    "        yield np.random.rand(1024**2)  # Only ~8MB at a time\n",
    "\n",
    "@ray.remote\n",
    "def process(result):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# Process streaming\n",
    "for obj_ref in produce_large_dataset.remote():\n",
    "    process.remote(obj_ref)\n",
    "    # Previous objects can be garbage collected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cc87a6",
   "metadata": {},
   "source": [
    "### 5.2. Python generator recap\n",
    "\n",
    "Let's start with a sample python generator function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adda18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_function():\n",
    "    for i in range(10):\n",
    "        time.sleep(1)\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292c23cb",
   "metadata": {},
   "source": [
    "Here is how we can iterate over the generator function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f0037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in generator_function():\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9405619",
   "metadata": {},
   "source": [
    "### 5.3. Converting to Ray generator\n",
    "\n",
    "Converting into a Ray generator function is straightforward - simply decorate with `@ray.remote`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482659e6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def generator_function():\n",
    "    for i in range(10):\n",
    "        time.sleep(1)\n",
    "        yield i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b936f9c",
   "metadata": {},
   "source": [
    "Now instead of yielding the value we get back object references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b1e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj_ref in generator_function.remote():\n",
    "    print(obj_ref)  # Prints ObjectRef\n",
    "\n",
    "result = ray.get(obj_ref)\n",
    "print(result)  # Prints actual value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3589d54d",
   "metadata": {},
   "source": [
    "### 5.4. Memory usage comparison\n",
    "\n",
    "See the below script which shows the memory consumption when running with and without a generator:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c728b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "!RAY_DEDUP_LOGS=0 python scripts/ray_generator_object_store_diff.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7016245",
   "metadata": {},
   "source": [
    "### 5.5. Key differences from Python generators\n",
    "\n",
    "Unlike python generators, Ray generators:\n",
    "- **Don't pause execution** - i.e. they don't require `__next__` to be called to yield the next element\n",
    "- **Don't support all APIs** like `send` and `throw`\n",
    "\n",
    "Given that Ray **eagerly executes** a generator task to completion **regardless** of whether the caller is polling the partial results or not, it might lead to **object store spilling.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def455cb",
   "metadata": {},
   "source": [
    "### 5.6. When to use Ray Generators\n",
    "\n",
    "**✅ Use Ray Generators when:**\n",
    "- Processing large datasets that don't fit in memory\n",
    "- Streaming results from long-running computations\n",
    "- Building data pipelines with multiple stages\n",
    "- You want incremental results (don't wait for everything)\n",
    "\n",
    "**❌ Don't use Ray Generators when:**\n",
    "- You need random access to results\n",
    "- You need the full result set at once"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
