{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d53536c5",
   "metadata": {},
   "source": [
    "## Observability\n",
    "\n",
    "Ray Serve provides a rich set of observability tools to help you understand the behavior of your service.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<b>Here is the roadmap for this notebook:</b>\n",
    "\n",
    "<ol>\n",
    "    <li>Metrics</li>\n",
    "    <li>Logs</li>\n",
    "    <li>Health Checks</li>\n",
    "    <li>Alerts</li>\n",
    "    <li>Tracing</li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "**Imports**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4316028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "from ray import serve\n",
    "from ray.serve import metrics\n",
    "from starlette.requests import Request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d4599f",
   "metadata": {},
   "source": [
    "## 1. Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f38cc",
   "metadata": {},
   "source": [
    "Ray Serve provides the following metrics:\n",
    "\n",
    "- **Throughput metrics:**\n",
    "    - Queries per second (QPS)\n",
    "    - Error QPS\n",
    "    - Error by error code QPS\n",
    "\n",
    "Shown are the throughput metrics for the MNIST application.\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/throughput_per_application.png\" alt=\"Ray Serve Metrics\" width=\"800\">\n",
    "\n",
    "- **Latency metrics:**\n",
    "    - P50, P90, P99 latencies\n",
    "\n",
    "Shown are the latency metrics for the MNIST application.\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/latency_per_application.png\" alt=\"Ray Serve Latency Metrics\" width=\"800\">\n",
    "\n",
    "- **Latency and throughput metrics are available at different levels of granularity:**\n",
    "    - Per-application metrics\n",
    "    - Per-deployment metrics\n",
    "    - Per-replica metrics\n",
    "\n",
    "Shown are the latency metrics on the deployment level.\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/latency_per_deployment.png\" alt=\"Ray Serve Latency Metrics\" width=\"800\">\n",
    "\n",
    "- **Deployment-specific metrics:**\n",
    "    - Number of replicas\n",
    "    - Queue size (TODO - explain which queue)\n",
    "\n",
    "Shown are the number of replicas and queue size for the MNIST application.\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/replicas_per_deployment.png\" alt=\"Ray Serve Deployment Metrics\" width=\"400\">\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/queue_size_per_deploymnet.png\" alt=\"Ray Serve Deployment Metrics\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e1c086",
   "metadata": {},
   "source": [
    "### Define custom metrics\n",
    "\n",
    "It is a good practice to define custom metrics to track the performance of your application.\n",
    "\n",
    "To do so, use `serve.metrics`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9b3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(num_replicas=2)\n",
    "class MyDeployment:\n",
    "    def __init__(self):\n",
    "        self.my_counter = metrics.Counter(\n",
    "            \"my_counter\",\n",
    "            description=(\"The number of odd-numbered requests to this deployment.\"),\n",
    "            tag_keys=(\"model\",),\n",
    "        )\n",
    "        self.my_counter.set_default_tags({\"model\": \"123\"})\n",
    "\n",
    "    async def __call__(self):\n",
    "        self.my_counter.inc()\n",
    "\n",
    "\n",
    "my_deployment = MyDeployment.bind()\n",
    "serve.run(my_deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f2edbb",
   "metadata": {},
   "source": [
    "We can then send requests to the deployment and see the custom metric in action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd7688",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "while time.time() - start < 120:\n",
    "    requests.get(\"http://localhost:8000/\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7831685",
   "metadata": {},
   "source": [
    "Here is how the custom metric looks like in the Anyscale dashboard.\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/custom_metric.png\" alt=\"Ray Serve Custom Metric\" width=\"500\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946421ec",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note:**\n",
    "\n",
    "Prometheus scrapes metrics at regular intervals. This is why we don't see the counter incrementing in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0542234c",
   "metadata": {},
   "source": [
    "Configuring a shorter scrape interval will improve the resolution of the metrics but will also increase the load on the server.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's clean up\n",
    "!serve shutdown -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e8888",
   "metadata": {},
   "source": [
    "## 2. Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad70c50",
   "metadata": {},
   "source": [
    "To understand system-level behavior and to surface application-level details during runtime, you can leverage Ray Serve's logging.\n",
    "\n",
    "**Implementation:**\n",
    "- Uses Python's standard logging module\n",
    "- Logger name is \"ray.serve\"\n",
    "\n",
    "**Log Output Locations:**\n",
    "- Logs are sent to stderr\n",
    "- Logs are written to disk at `/tmp/ray/session_latest/logs/serve/`\n",
    "\n",
    "**Types of Logs Captured:**\n",
    "- System-level logs (from Serve controller and proxy)\n",
    "- Access logs\n",
    "- Custom user logs from deployment replicas\n",
    "\n",
    "**Development Environment Behavior:**\n",
    "- Logs are streamed to the driver Ray program\n",
    "- Driver program can be either:\n",
    "    - Python script calling serve.run()\n",
    "    - serve run CLI command\n",
    "\n",
    "Here is how to use logging in a deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d22d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment()\n",
    "class SayHelloDefaultLogging:\n",
    "    async def __call__(self):\n",
    "        logger = logging.getLogger(\"ray.serve\")\n",
    "        logger.info(\"hello world\")\n",
    "\n",
    "\n",
    "serve.run(SayHelloDefaultLogging.bind())\n",
    "\n",
    "resp = requests.get(\"http://localhost:8000/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba9aaf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Note:**\n",
    "Given Ray Serve uses Python's standard logging module, aggressive logging inside your application will incur a performance penalty. Use logging levels to control the verbosity of your logs and to avoid this penalty when running in production.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ecfad",
   "metadata": {},
   "source": [
    "### Logging Configuration\n",
    "\n",
    "Here are the common configurations for logging.\n",
    "\n",
    "- `enable_access_log`: Access logs are injected by default into Replica and Proxy logs. By default, it is `True`.\n",
    "- `log_level`: Set the log level. By default, it is `INFO`.\n",
    "- `encoding`: Set the encoding of the log file. By default, it is `JSON`.\n",
    "\n",
    "You can set the logging configuration:\n",
    "- At the deployment level\n",
    "- At the serve instance level\n",
    "\n",
    "Both programmatically or via a configuration file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(logging_config={\"log_level\": \"DEBUG\"})\n",
    "class SayHelloDebugLogging:\n",
    "    async def __call__(self):\n",
    "        logger = logging.getLogger(\"ray.serve\")\n",
    "        logger.debug(\"hello world\")\n",
    "\n",
    "\n",
    "serve.run(\n",
    "    SayHelloDebugLogging.bind(),\n",
    "    logging_config={\n",
    "        \"encoding\": \"JSON\",\n",
    "        \"log_level\": \"INFO\",\n",
    "        \"enable_access_log\": False,\n",
    "    },\n",
    ")\n",
    "\n",
    "resp = requests.get(\"http://localhost:8000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78208b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's clean up\n",
    "!serve shutdown -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d1b52a",
   "metadata": {},
   "source": [
    "## 3. Health Checks\n",
    "You can configure health checks for your deployments to help detect when a replica is unhealthy.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Best practice** If a Replica is using a stateful resource like a database, it is important to check the health of the resource periodically.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d936363",
   "metadata": {},
   "source": [
    "Here is an example that simulates a replica that relies on a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfa6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db(con_url): \n",
    "    # Simulate a database connection\n",
    "    time.sleep(1)\n",
    "    return f\"Connected to {con_url}\"\n",
    "\n",
    "# write a status file\n",
    "path =  Path(\"/mnt/cluster_storage/db_status.txt\")\n",
    "path.write_text(\"alive\")\n",
    "\n",
    "# check status of connection\n",
    "def is_alive(db):\n",
    "    with open(path, \"r\") as file:\n",
    "        status = file.read()\n",
    "    return status == \"alive\"\n",
    "\n",
    "@serve.deployment\n",
    "class DataFetcher:\n",
    "    def __init__(self, con_url):\n",
    "        self.db = connect_to_db(con_url)\n",
    "    def __call__(self, request: Request):\n",
    "        return \"ok\"\n",
    "    def check_health(self): # implement health check\n",
    "        if not is_alive(self.db):\n",
    "            raise Exception(\"Database connection lost\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2487817e",
   "metadata": {},
   "source": [
    "We run the deployment and expect the health check to pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9e88e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_handle = serve.run(DataFetcher.bind(\"db_url\"), name=\"data-fetcher\", blocking=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128291a",
   "metadata": {},
   "source": [
    "We can simulate a database connection failure by modifying the status file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b406a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path.write_text(\"dead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e3039",
   "metadata": {},
   "source": [
    "Observe the following key log lines\n",
    "\n",
    "```\n",
    "2025-09-26 18:01:45,513 WARNING Health check for Replica(id='f4yawq8r', deployment='DataFetcher', app='data-fetcher') failed: mray::ServeReplica:data-fetcher:DataFetcher.check_health() (pid=2634, ip=10.0.43.216, actor_id=7b2a9e3a4039907963dc2cb208000000, repr=<ray.serve._private.replica.ServeReplica:data-fetcher:DataFetcher object at 0x7f79addc2810>) ...\n",
    "2025-09-26 18:01:54,722 WARNING Health check for Replica(id='f4yawq8r', deployment='DataFetcher', app='data-fetcher') failed: mray::ServeReplica:data-fetcher:DataFetcher.check_health() (pid=2634, ip=10.0.43.216, actor_id=7b2a9e3a4039907963dc2cb208000000, repr=<ray.serve._private.replica.ServeReplica:data-fetcher:DataFetcher object at 0x7f79addc2810>) ...\n",
    "2025-09-26 18:02:04,364 WARNING Health check for Replica(id='f4yawq8r', deployment='DataFetcher', app='data-fetcher') failed: mray::ServeReplica:data-fetcher:DataFetcher.check_health() (pid=2634, ip=10.0.43.216, actor_id=7b2a9e3a4039907963dc2cb208000000, repr=<ray.serve._private.replica.ServeReplica:data-fetcher:DataFetcher object at 0x7f79addc2810>) ...\n",
    "2025-09-26 18:02:04,364 WARNING Replica Replica(id='f4yawq8r', deployment='DataFetcher', app='data-fetcher') failed the health check 3 times in a row, marking it unhealthy.\n",
    "2025-09-26 18:02:04,365 WARNING Replica Replica(id='f4yawq8r', deployment='DataFetcher', app='data-fetcher') failed health check, stopping it.\n",
    "2025-09-26 18:02:04,365 INFO Stopping Replica(id='f4yawq8r', deployment='DataFetcher', app='data-fetcher') (currently ReplicaState.RUNNING).\n",
    "2025-09-26 18:02:04,367 INFO Adding 1 replica to Deployment(name='DataFetcher', app='data-fetcher').\n",
    "```\n",
    "\n",
    "As expected, the health check was triggered and the replica was replaced.\n",
    "\n",
    "Given the health check will continue to fail, the replica will be replaced again and again. We shutdown the serve application to avoid endless retries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcf9b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "serve.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70950fff",
   "metadata": {},
   "source": [
    "## 4. Alerts\n",
    "\n",
    "Ray integrates with Prometheus and Grafana for an enhanced observability experience. For alerts, the common route is to rely on Grafana alerting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c739a04d",
   "metadata": {},
   "source": [
    "**Alert Types:**\n",
    "Grafana [can alert](https://grafana.com/docs/grafana/v7.5/alerting/) based on:\n",
    "- Metric values\n",
    "- Rate of change\n",
    "- Metric absence\n",
    "\n",
    "**Notification Options:**\n",
    "- Supports multiple [notification channels](https://grafana.com/docs/grafana/v7.5/alerting/notifications/#add-a-notification-channel) (Slack, PagerDuty, etc.)\n",
    "- Email support planned for future\n",
    "- Configurable through notification channels\n",
    "\n",
    "**Documentation:** Full setup details available in Grafana's [official documentation](https://grafana.com/docs/grafana/v7.5/alerting/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e69eaa",
   "metadata": {},
   "source": [
    "## 5. Tracing\n",
    "\n",
    "To perform end-to-end distributed tracing of requests, you can use the Anyscale Tracing integration.\n",
    "\n",
    "See the [tracing guide](https://docs.anyscale.com/monitoring/tracing/) for details."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
