{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecec7a8f",
   "metadata": {},
   "source": [
    "## Autoscaling\n",
    "\n",
    "This notebook is an overview of how to configure autoscaling in Ray Serve.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b> Here is the roadmap of this notebook:</b>\n",
    "<ol>\n",
    "  <li> Scaling across the stack</li>\n",
    "  <li> Manual Scaling in Ray Serve</li>\n",
    "  <li> Autoscaling Basic Configuration in Ray Serve</li>\n",
    "  <li> Tuning autoscaling in Ray Serve</li>\n",
    "  <li> Finetuning of autoscaling in Ray Serve</li>\n",
    "  <li> Custom Autoscaling (Coming Soon)</li>\n",
    "</ol>\n",
    "\n",
    "</div>\n",
    "\n",
    "**imports**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09174feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from ray import serve\n",
    "from ray.serve.config import AutoscalingConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7464546d",
   "metadata": {},
   "source": [
    "## 1. Scaling Across the Stack\n",
    "\n",
    "Below is a diagram that illustrates the scaling across the stack.\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/scaling_across_the_stack.png\" width=\"800\">\n",
    "\n",
    "Here are the steps in the scaling process:\n",
    "\n",
    "1. **Ray Serve Controller Monitoring**  \n",
    "   The Ray Serve controller controls scaling decisions\n",
    "\n",
    "2. **Scaling Decision**  \n",
    "   Based on this comparison, it decides whether to scale up or down the number of Serve replicas (actors).\n",
    "\n",
    "3. **Replica Creation Requests**  \n",
    "   If scaling up, the controller submits pending requests to create new actors to handle increased traffic.\n",
    "\n",
    "4. **Ray Cluster Autoscaler Response**  \n",
    "   These pending actor requests create unmet resource demands. The Ray Cluster Autoscaler detects this and attempts to provision additional Ray nodes to fulfill the need.\n",
    "\n",
    "5. **Kubernetes Layer (if applicable)**  \n",
    "   When running on Kubernetes, each Ray node is scheduled as a Kubernetes Pod. To launch more Pods, the Kubernetes scheduler must find available capacity.\n",
    "\n",
    "6. **Kubernetes Cluster Autoscaler**  \n",
    "   If there isn’t enough capacity (e.g., insufficient nodes), the Kubernetes Cluster Autoscaler attempts to scale the underlying infrastructure by adding nodes to the appropriate node group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be4c98",
   "metadata": {},
   "source": [
    "## 2. Manual Scaling in Ray Serve\n",
    "\n",
    "Before jumping into autoscaling, which is more complex, the other option to consider is manual scaling. You can increase the number of replicas by setting a higher value for `num_replicas` in **the deployment options** through **in-place updates**.\n",
    "\n",
    "By default, `num_replicas` is 1. Increasing the number of replicas will horizontally scale out your deployment and improve latency and throughput for increased levels of traffic.\n",
    "\n",
    "```yaml\n",
    "# Deploy with a single replica\n",
    "deployments:\n",
    "- name: Model\n",
    "  num_replicas: 1\n",
    "\n",
    "# Scale up to 10 replicas\n",
    "deployments:\n",
    "- name: Model\n",
    "  num_replicas: 10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7d616",
   "metadata": {},
   "source": [
    "## 3. Autoscaling in Ray Serve\n",
    "\n",
    "Ray Serve automatically changes the number of replicas based on traffic.\n",
    "\n",
    "Here is a diagram that illustrates how replicas communicate with the controller to report metrics for autoscaling.\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-serve-deep-dive/serve-autoscaling-replica-reporting.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ff482d",
   "metadata": {},
   "source": [
    "### 1. Target Ongoing Requests\n",
    "- **Meaning**: Average active requests per replica.\n",
    "- **Config**: `target_ongoing_requests` (default = 2)\n",
    "- **How it works**:\n",
    "  - Compare total ongoing requests to `target_ongoing_requests * num_replicas`.\n",
    "  - Ratio < 1 → scale **down**\n",
    "  - Ratio > 1 → scale **up**\n",
    "- **Example**: Ratio = 2 → doubles the replicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f5c4aa",
   "metadata": {},
   "source": [
    "### 2. Maximum Ongoing Requests\n",
    "- **Meaning**: Max number of requests a replica can handle at once.\n",
    "- **Config**: `max_ongoing_requests` (default = 5)\n",
    "- **Purpose**:\n",
    "  - Handles spikes safely.\n",
    "  - Keeps replicas stable if requests vary in length.\n",
    "- **Tip**: Set ~20–50% higher than `target_ongoing_requests`.\n",
    "  - Too low → slows throughput.\n",
    "  - Too high → overloads replicas.\n",
    "  - Just right → balances performance.\n",
    "\n",
    "Here is the same diagram as above now showcasing how the default autoscaling policy works.\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-serve-deep-dive/serve_replica_queue_length_autoscaling_policy.png\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ac49d",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Define a service that takes 60 seconds to process each request. With `target_ongoing_requests=1`, Ray Serve will scale up when more than 1 request per replica is processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54859890",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(\n",
    "    autoscaling_config=AutoscalingConfig(\n",
    "        target_ongoing_requests=1,\n",
    "        min_replicas=1,\n",
    "        max_replicas=2,\n",
    "    )\n",
    ")\n",
    "class SlowService:\n",
    "    def run(self, id: int):\n",
    "        time.sleep(60)  # purposefully sync and blocking\n",
    "        print(f\"got request {id}\")\n",
    "        return f\"Done {id}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bdf963",
   "metadata": {},
   "source": [
    "Deploy the service. Initially, there will be 1 replica.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06a69ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = serve.run(SlowService.bind())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e602bf3",
   "metadata": {},
   "source": [
    "Send 2 requests simultaneously. Since both arrive while processing, Ray Serve detects 2 ongoing requests > target of 1, triggering scale-up to 2 replicas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905af12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send 2 ongoing requests to replica\n",
    "result1 = handle.run.remote(1)\n",
    "result2 = handle.run.remote(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a82b0c",
   "metadata": {},
   "source": [
    "## 4. Tuning Autoscaling in Ray Serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de6677a",
   "metadata": {},
   "source": [
    "#### Step 1: Baseline Testing with a Single Replica\n",
    "\n",
    "**Goal**: Determine optimal `target_ongoing_requests` for your workload\n",
    "\n",
    "1. **Setup**: Deploy with a single replica and autoscaling disabled\n",
    "   ```python\n",
    "   @serve.deployment(num_replicas=1)\n",
    "   class MyDeployment:\n",
    "       ...\n",
    "   ```\n",
    "   Note set `max_ongoing_requests` to a large number to avoid queueing at the caller. \n",
    "\n",
    "2. **Benchmark Process**:\n",
    "   - Start with low query-per-second (QPS) rate\n",
    "   - Gradually increase load until you hit your latency SLA (e.g., P99 < 500ms)\n",
    "   - Monitor replica queue length using Ray Dashboard or metrics\n",
    "\n",
    "3. **Key Metrics to Track**:\n",
    "   - **Ongoing requests per replica** when latency is acceptable\n",
    "   - **Request processing time** (average and P99)\n",
    "   - **Throughput** (requests/second at SLA limit)\n",
    "\n",
    "4. **Calculate Target Settings**:\n",
    "\n",
    "Example: If replica handles 20 requests well before hitting latency SLA, then set:\n",
    "- `target_ongoing_requests` ~= 16  # Use 80% of max capacity\n",
    "- `max_ongoing_requests` ~= 24  # 1.2-1.5x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf65e6",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Take a look at `examples/autoscaling`\n",
    "\n",
    "1. `resnet50_model.py` contains our model deployment that we are attempting to autoscale\n",
    "2. `locustfile.py` is how we have configured locust to send concurrent requests by spawning additional users\n",
    "3. `benchmark.yaml` is how we have configured the deployment for benchmarking purposes.\n",
    "\n",
    "**Key Benchmarking Configuration:**\n",
    "- `max_ongoing_requests: 10000` - Set artificially high to avoid queueing during benchmarking\n",
    "- `min_replicas: 1` and `max_replicas: 1` - Benchmark against a single replica to measure its capacity\n",
    "\n",
    "**Observation from Load Testing:**\n",
    "\n",
    "After running the benchmark and inspecting the Serve deployment dashboard, we observe a clear relationship between ongoing requests and latency:\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-serve-deep-dive/load_test_ongoing_requests.png\" width=\"1000\">\n",
    "\n",
    "**Key Finding:** P90 latency starts to exceed 500ms when there are approximately **6 ongoing requests** per replica.\n",
    "\n",
    "**Recommended Configuration:**\n",
    "\n",
    "Based on this observation, we should configure autoscaling as follows:\n",
    "\n",
    "- **`target_ongoing_requests: 4`** - Set at ~67% of the capacity threshold (6 requests) to maintain headroom\n",
    "- **`max_ongoing_requests: 6`** - Set at ~1.5x the threshold to allow brief bursts while triggering backpressure if sustained\n",
    "\n",
    "This configuration ensures:\n",
    "- Replicas operate below their latency threshold under normal load\n",
    "- The autoscaler adds replicas before latency degrades\n",
    "- Brief traffic spikes are handled without immediately rejecting requests "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b767de1b",
   "metadata": {},
   "source": [
    "## 5. Finetuning of autoscaling in Ray Serve\n",
    "\n",
    "You can adjust how quickly and smoothly Ray Serve reacts to changes in traffic using these settings:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fe1250",
   "metadata": {},
   "source": [
    "#### 1. Controller Responsiveness\n",
    "\n",
    "* **Upscale Delay** (`upscale_delay_s`, default = 30s)\n",
    "  How long Serve waits before adding replicas.\n",
    "\n",
    "  * If traffic stays **above** the target for this duration, Serve adds replicas.\n",
    "  * Use a **smaller** delay for fast reaction to traffic spikes.\n",
    "  * Example: For bursty workloads, set `upscale_delay_s` to a lower value (like 5–10s).\n",
    "\n",
    "* **Downscale Delay** (`downscale_delay_s`, default = 600s)\n",
    "  How long Serve waits before removing replicas.\n",
    "\n",
    "  * If traffic stays **below** the target for this duration, Serve removes replicas.\n",
    "  * Use a **larger** delay for apps that start slowly or have unpredictable traffic, to avoid scaling down too soon.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299f67d1",
   "metadata": {},
   "source": [
    "#### 2. Metrics Window and Update Frequency\n",
    "\n",
    "* **Look Back Period** (`look_back_period_s`, default = 30s)\n",
    "  The time window over which Serve averages ongoing requests per replica.\n",
    "\n",
    "* **Metrics Interval** (`metrics_interval_s`, default = 10s)\n",
    "  How often each replica reports metrics to the autoscaler.\n",
    "\n",
    "  * The autoscaler only makes decisions when it gets new data.\n",
    "  * Keep `metrics_interval_s` **≤** `upscale_delay_s` and `downscale_delay_s`.\n",
    "  * Example: If `upscale_delay_s = 3` but `metrics_interval_s = 10`, scaling up can only happen every ~10 seconds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11d5d1b",
   "metadata": {},
   "source": [
    "#### 3. Scale Adjustment Sensitivity\n",
    "\n",
    "* **Upscaling Factor** (`upscaling_factor`, default = 1.0)\n",
    "  Controls how aggressively to scale up.\n",
    "\n",
    "  * Increase it (>1) for faster scale-ups when traffic surges.\n",
    "  * Acts like a “gain” that amplifies the scaling response.\n",
    "\n",
    "* **Downscaling Factor** (`downscaling_factor`, default = 1.0)\n",
    "  Controls how aggressively to scale down.\n",
    "\n",
    "  * Decrease it (<1) to make downscaling slower and more conservative.\n",
    "  * Useful if you want to avoid frequent scale-down/scale-up cycles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b88b6",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Configure fast upscaling for bursty traffic. Note: `look_back_period_s` and `metrics_interval_s` should be ≤ `upscale_delay_s` to ensure timely metric collection and decision-making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93959d1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "@serve.deployment(\n",
    "    autoscaling_config=AutoscalingConfig(\n",
    "        target_ongoing_requests=2,\n",
    "        min_replicas=1,\n",
    "        max_replicas=5,\n",
    "        upscale_delay_s=5,\n",
    "        downscale_delay_s=60,\n",
    "        look_back_period_s=5,\n",
    "        metrics_interval_s=2,\n",
    "        upscaling_factor=1.5,\n",
    "    )\n",
    ")\n",
    "class BurstyService:\n",
    "    def run(self, id: int):\n",
    "        time.sleep(60)\n",
    "        return f\"Done {id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b9d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = serve.run(BurstyService.bind())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be2133",
   "metadata": {},
   "source": [
    "Send a burst of 10 requests. With fast upscaling, replicas are added quickly (after 5s) rather than the default 30s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [handle.run.remote(i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ebcd65",
   "metadata": {},
   "source": [
    "#### Step 2: Load Testing with Realistic Traffic\n",
    "\n",
    "**Goal**: Validate and finetune autoscaling behavior under production-like conditions\n",
    "\n",
    "1. **Create test scenarios** that mimic your production traffic\n",
    "   - **Steady ramp-up**: Gradual increase from min to max load\n",
    "   - **Traffic spikes**: Sudden 2-5x increase in QPS\n",
    "   - **Sustained high load**: Run at peak for 10-15 minutes\n",
    "   - **Scale-down**: Drop traffic to trigger downscaling\n",
    "\n",
    "2. **Monitor During Tests**:\n",
    "   - **Latency degradation** during scale-up transitions\n",
    "   - **Time to scale**: How long until new replicas handle traffic (typically 30-60s)\n",
    "   - **Request rejections**: Check for 503 errors or BackPressureErrors\n",
    "   - **Replica utilization**: Ensure load distributes evenly\n",
    "\n",
    "3. **Common Issues & Fixes**:\n",
    "\n",
    "| Symptom | Likely Cause |\n",
    "|---------|--------------|\n",
    "| Frequent request rejections | `max_ongoing_requests` too low | \n",
    "| Slow scale-up | `upscale_delay_s` too high | \n",
    "| Replica thrashing (up/down) | Traffic at boundary due to drastic delay values `upscale_delay_s` and `downscale_delay_s` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7d7b7b",
   "metadata": {},
   "source": [
    "## 6. Custom Autoscaling (Coming Soon)\n",
    "\n",
    "Ray Serve is introducing custom autoscaling capabilities that go beyond the default queue-depth policy, allowing you to implement domain-specific scaling logic tailored to your application's needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcb4075",
   "metadata": {},
   "source": [
    "### Key Capabilities\n",
    "\n",
    "**1. Custom Metrics Collection**\n",
    "- **Prometheus Integration**: Scrape external metrics (CPU, GPU memory, latency) from Prometheus\n",
    "- **Code-Based Metrics**: Export custom metrics from your deployments\n",
    "- Metrics are aggregated over configurable time windows and made available to your scaling policy\n",
    "\n",
    "**2. Deployment-Level Custom Policies**\n",
    "- Write Python functions that receive an `AutoscalingContext` with current replicas, metrics, and constraints\n",
    "- Implement custom logic (e.g., scale based on GPU memory, latency percentiles, or business KPIs)\n",
    "- Return target replica count and optional state to persist across policy invocations\n",
    "\n",
    "**3. Application-Level Policies (Joint Scaling)**\n",
    "- Coordinate scaling decisions across multiple deployments in an application\n",
    "- Useful for maintaining ratios between services (e.g., app1 scales 2x faster than app2)\n",
    "- Policy receives context for all deployments and returns scaling decisions for each\n",
    "\n",
    "**4. External Scaler Integration**\n",
    "- REST API endpoints allow third-party systems (Kubernetes HPA, custom monitors) to control scaling\n",
    "- `POST /api/v1/applications/{app}/deployments/{dep}/scale` to set target replicas\n",
    "- `GET /api/v1/applications/{app}/deployments/{dep}/status` to query current state\n",
    "- Optional webhook registration for scale events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e29348",
   "metadata": {},
   "source": [
    "### Example Use Cases\n",
    "\n",
    "- **GPU Memory-Aware**: Scale based on GPU memory utilization instead of request count\n",
    "- **LLM KV-Cache Aware**: Scale when KV-cache utilization exceeds thresholds\n",
    "- **Multi-Deployment Coordination**: Scale app1 and app2 services proportionally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8eaaff",
   "metadata": {},
   "source": [
    "### Backward Compatibility\n",
    "\n",
    "All existing autoscaling configurations continue to work. If you don't specify a custom `policy`, Serve uses the default replica queue-length based algorithm with `target_ongoing_requests`.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "**Note:** Custom autoscaling is currently in development. Check this [Ray Serve issue](https://github.com/ray-project/ray/issues/41135) for availability and updates.\n",
    "\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "split_at_heading": true
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
