{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecec7a8f",
   "metadata": {},
   "source": [
    "## Autoscaling\n",
    "\n",
    "This notebook is an overview of how to configure autoscaling in Ray Serve.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b> Here is the roadmap of this notebook:</b>\n",
    "<ul>\n",
    "<li> Scaling across the stack</li>\n",
    "<li> Manual Scaling in Ray Serve</li>\n",
    "<li> Autoscaling Basic Configuration in Ray Serve</li>\n",
    "<li> Autoscaling Advanced Configuration in Ray Serve</li>\n",
    "<li> Tuning autoscaling in Ray Serve</li>\n",
    "</ul>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7464546d",
   "metadata": {},
   "source": [
    "## 1. Scaling Across the Stack\n",
    "\n",
    "Below is a diagram that illustrates the scaling across the stack.\n",
    "\n",
    "<img src=\"https://anyscale-public-materials.s3.us-west-2.amazonaws.com/ray-serve/scaling_across_the_stack.png\" width=\"800\">\n",
    "\n",
    "Here are the steps in the scaling process:\n",
    "\n",
    "1. **Ray Serve Controller Monitoring**  \n",
    "   The Ray Serve controller controls scaling decisions\n",
    "\n",
    "2. **Scaling Decision**  \n",
    "   Based on this comparison, it decides whether to scale up or down the number of Serve replicas (actors).\n",
    "\n",
    "3. **Replica Creation Requests**  \n",
    "   If scaling up, the controller submits pending requests to create new actors to handle increased traffic.\n",
    "\n",
    "4. **Ray Cluster Autoscaler Response**  \n",
    "   These pending actor requests create unmet resource demands. The Ray Cluster Autoscaler detects this and attempts to provision additional Ray nodes to fulfill the need.\n",
    "\n",
    "5. **Kubernetes Layer (if applicable)**  \n",
    "   When running on Kubernetes, each Ray node is scheduled as a Kubernetes Pod. To launch more Pods, the Kubernetes scheduler must find available capacity.\n",
    "\n",
    "6. **Kubernetes Cluster Autoscaler**  \n",
    "   If there isn’t enough capacity (e.g., insufficient nodes), the Kubernetes Cluster Autoscaler attempts to scale the underlying infrastructure by adding nodes to the appropriate node group.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be4c98",
   "metadata": {},
   "source": [
    "## 2. Manual Scaling in Ray Serve\n",
    "\n",
    "Before jumping into autoscaling, which is more complex, the other option to consider is manual scaling. You can increase the number of replicas by setting a higher value for `num_replicas` in **the deployment options** through **in-place updates**.\n",
    "\n",
    "By default, `num_replicas` is 1. Increasing the number of replicas will horizontally scale out your deployment and improve latency and throughput for increased levels of traffic.\n",
    "\n",
    "```yaml\n",
    "# Deploy with a single replica\n",
    "deployments:\n",
    "- name: Model\n",
    "  num_replicas: 1\n",
    "\n",
    "# Scale up to 10 replicas\n",
    "deployments:\n",
    "- name: Model\n",
    "  num_replicas: 10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f5c4aa",
   "metadata": {},
   "source": [
    "## 3. Autoscaling in Ray Serve\n",
    "\n",
    "Ray Serve automatically changes the number of replicas based on traffic.\n",
    "\n",
    "### 1. Target Ongoing Requests\n",
    "- **Meaning**: Average active requests per replica.\n",
    "- **Config**: `target_ongoing_requests` (default = 2)\n",
    "- **How it works**:\n",
    "  - Compare total ongoing requests to `target_ongoing_requests * num_replicas`.\n",
    "  - Ratio < 1 → scale **down**\n",
    "  - Ratio > 1 → scale **up**\n",
    "- **Example**: Ratio = 2 → doubles the replicas.\n",
    "\n",
    "### 2. Maximum Ongoing Requests\n",
    "- **Meaning**: Max number of requests a replica can handle at once.\n",
    "- **Config**: `max_ongoing_requests` (default = 5)\n",
    "- **Purpose**:\n",
    "  - Handles spikes safely.\n",
    "  - Keeps replicas stable if requests vary in length.\n",
    "- **Tip**: Set ~20–50% higher than `target_ongoing_requests`.\n",
    "  - Too low → slows throughput.\n",
    "  - Too high → overloads replicas.\n",
    "  - Just right → balances performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de6677a",
   "metadata": {},
   "source": [
    "### Tuning Autoscaling in Ray Serve\n",
    "\n",
    "#### Step 1: Baseline Testing with a Single Replica\n",
    "\n",
    "**Goal**: Determine optimal `target_ongoing_requests` for your workload\n",
    "\n",
    "1. **Setup**: Deploy with a single replica and autoscaling disabled\n",
    "   ```python\n",
    "   @serve.deployment(num_replicas=1)\n",
    "   class MyDeployment:\n",
    "       ...\n",
    "   ```\n",
    "   Note set `max_ongoing_requests` to a large number to avoid queueing at the caller. \n",
    "\n",
    "2. **Benchmark Process**:\n",
    "   - Start with low query-per-second (QPS) rate\n",
    "   - Gradually increase load until you hit your latency SLA (e.g., P99 < 500ms)\n",
    "   - Monitor replica queue length using Ray Dashboard or metrics\n",
    "\n",
    "3. **Key Metrics to Track**:\n",
    "   - **Ongoing requests per replica** when latency is acceptable\n",
    "   - **Request processing time** (average and P99)\n",
    "   - **Throughput** (requests/second at SLA limit)\n",
    "\n",
    "4. **Calculate Target Settings**:\n",
    "\n",
    "Example: If replica handles 20 requests well before hitting latency SLA, then set:\n",
    "- `target_ongoing_requests` ~= 16  # Use 80% of max capacity\n",
    "- `max_ongoing_requests` ~= 24  # 1.2-1.5x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf65e6",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "Take a look at `examples/autoscaling`\n",
    "\n",
    "1. `resnet50_model.py` contains our model deployment that we are attempting to autoscale\n",
    "2. `locustfile.py` is how we have configured locust to send concurrent requests by spawning additional users\n",
    "3. `benchmark.yaml` is how we have configured the deployment for benchmarking purposes.\n",
    "\n",
    "\n",
    "Inspecting the serve deployment dashboard we can see latency worsening with an increase in the number ofongoing requests. In this exampele, we choose 6 replicas as the cutoff value at which P90 latency starts to exceed 500 ms.\n",
    "\n",
    "<img src=\"https://anyscale-materials.s3.us-west-2.amazonaws.com/ray-serve-deep-dive/load_test_ongoing_requests.png\" width=\"1000\">\n",
    "\n",
    "\n",
    "Base on the above, a value of 4 ongoing requests would be ideal for this model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11d5d1b",
   "metadata": {},
   "source": [
    "### Fine-Tuning Autoscaling in Ray Serve\n",
    "\n",
    "You can adjust how quickly and smoothly Ray Serve reacts to changes in traffic using these settings:\n",
    "\n",
    "#### 1. Controller Responsiveness\n",
    "\n",
    "* **Upscale Delay** (`upscale_delay_s`, default = 30s)\n",
    "  How long Serve waits before adding replicas.\n",
    "\n",
    "  * If traffic stays **above** the target for this duration, Serve adds replicas.\n",
    "  * Use a **smaller** delay for fast reaction to traffic spikes.\n",
    "  * Example: For bursty workloads, set `upscale_delay_s` to a lower value (like 5–10s).\n",
    "\n",
    "* **Downscale Delay** (`downscale_delay_s`, default = 600s)\n",
    "  How long Serve waits before removing replicas.\n",
    "\n",
    "  * If traffic stays **below** the target for this duration, Serve removes replicas.\n",
    "  * Use a **larger** delay for apps that start slowly or have unpredictable traffic, to avoid scaling down too soon.\n",
    "\n",
    "\n",
    "\n",
    "#### 2. Metrics Window and Update Frequency\n",
    "\n",
    "* **Look Back Period** (`look_back_period_s`, default = 30s)\n",
    "  The time window over which Serve averages ongoing requests per replica.\n",
    "\n",
    "* **Metrics Interval** (`metrics_interval_s`, default = 10s)\n",
    "  How often each replica reports metrics to the autoscaler.\n",
    "\n",
    "  * The autoscaler only makes decisions when it gets new data.\n",
    "  * Keep `metrics_interval_s` **≤** `upscale_delay_s` and `downscale_delay_s`.\n",
    "  * Example: If `upscale_delay_s = 3` but `metrics_interval_s = 10`, scaling up can only happen every ~10 seconds.\n",
    "\n",
    "\n",
    "\n",
    "#### 3. Scale Adjustment Sensitivity\n",
    "\n",
    "* **Upscaling Factor** (`upscaling_factor`, default = 1.0)\n",
    "  Controls how aggressively to scale up.\n",
    "\n",
    "  * Increase it (>1) for faster scale-ups when traffic surges.\n",
    "  * Acts like a “gain” that amplifies the scaling response.\n",
    "\n",
    "* **Downscaling Factor** (`downscaling_factor`, default = 1.0)\n",
    "  Controls how aggressively to scale down.\n",
    "\n",
    "  * Decrease it (<1) to make downscaling slower and more conservative.\n",
    "  * Useful if you want to avoid frequent scale-down/scale-up cycles.\n",
    "\n",
    "\n",
    "\n",
    "Would you like me to make a **one-line cheat sheet** version next (good for quick recall during study)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ebcd65",
   "metadata": {},
   "source": [
    "#### Step 2: Load Testing with Realistic Traffic\n",
    "\n",
    "**Goal**: Validate and finetune autoscaling behavior under production-like conditions\n",
    "\n",
    "1. **Create test scenarios** that mimic your production traffic\n",
    "   - **Steady ramp-up**: Gradual increase from min to max load\n",
    "   - **Traffic spikes**: Sudden 2-5x increase in QPS\n",
    "   - **Sustained high load**: Run at peak for 10-15 minutes\n",
    "   - **Scale-down**: Drop traffic to trigger downscaling\n",
    "\n",
    "2. **Monitor During Tests**:\n",
    "   - **Latency degradation** during scale-up transitions\n",
    "   - **Time to scale**: How long until new replicas handle traffic (typically 30-60s)\n",
    "   - **Request rejections**: Check for 503 errors or BackPressureErrors\n",
    "   - **Replica utilization**: Ensure load distributes evenly\n",
    "\n",
    "3. **Common Issues & Fixes**:\n",
    "\n",
    "| Symptom | Likely Cause |\n",
    "|---------|--------------|\n",
    "| Frequent request rejections | `max_ongoing_requests` too low | \n",
    "| Slow scale-up | `upscale_delay_s` too high | \n",
    "| Replica thrashing (up/down) | Traffic at boundary due to drastic delay values `upscale_delay_s` and `downscale_delay_s` |\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
