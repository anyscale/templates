{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "697d98e0",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: linear-gradient(90deg, #0f2027 0%, #2c5364 100%);\n",
    "    padding: 32px 0 32px 0;\n",
    "    border-radius: 15px;\n",
    "    text-align: center;\n",
    "    margin-bottom: 30px;\n",
    "\">\n",
    "  <h1 style=\"color: #fff; letter-spacing: 2px; font-size: 2.7rem; margin: 0; font-weight: 800;\">\n",
    "    Building Scalable AI with Ray\n",
    "  </h1>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95730699",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #0f2027; background: linear-gradient(90deg, #43cea2 0%, #185a9d 100%); padding: 12px 0; border-radius: 8px; text-align:center; font-size: 2rem; letter-spacing: 1px;\">\n",
    "   <span style=\"color: #fff;\">Introduction</span> \n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a80dfe",
   "metadata": {},
   "source": [
    "## What is Ray ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c14712",
   "metadata": {},
   "source": [
    "- **Open-source project** under PyTorch Foundation\n",
    "- **Open-source distributed scheduler** for stateless tasks & stateful actors  \n",
    "- **Key features:** task graphs, resource-aware, fast data transfer, GPU/custom resources  \n",
    "- **Infra:** in-memory object store, fault-tolerant design  \n",
    "- **Ecosystem:** Data, Train, Tune, Serve, RLlib  \n",
    "- **User-friendly Python APIs**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8208cf49",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/img01.png\" alt=\"Intro to Ray\" width=\"70%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00711d2",
   "metadata": {},
   "source": [
    "| Concept | What It Is | Why It Matters (The Problem It Solves) |\n",
    "| :--- | :--- | :--- |\n",
    "| **`@ray.remote`** | A decorator to mark Python code for parallel execution. | The magic switch to turn a normal function or class into a distributed building block. |\n",
    "| **Task** | A remote, stateless function call. | **Problem:** My code is slow because it only uses one core. A Task lets you run a function on any available core. |\n",
    "| **Actor** | A remote, stateful class instance. | **Problem:** My parallel tasks need to share and update a common state (like a counter or a model). |\n",
    "| **`.remote()`** | The syntax used to execute a Task or an Actor method. | The command to \"send this work to the Ray cluster\" instead of running it here. |\n",
    "| **`ObjectRef`** | A \"future\" or a \"receipt\" for a result being computed. | The placeholder you get back instantly after calling `.remote()`, allowing your code to continue without waiting. |\n",
    "| **`ray.get()`** | The command to retrieve the actual result from an `ObjectRef`. | **Problem:** My parallel work has been sent out; now I need the final answers back. |\n",
    "| **`ray.put()`** | A command to place a large object into shared memory. | **Problem:** Sending the same large dataset (e.g., a big model) to every task is slow and wasteful. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96db0c1f",
   "metadata": {},
   "source": [
    "## Ray `Task`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2286f25",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/img02.png\" alt=\"Ray Task\" width=\"70%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87061e44",
   "metadata": {},
   "source": [
    "#### Example of a sequential process (`without Ray`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb13c19",
   "metadata": {},
   "source": [
    "Let's `run` it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd849397",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python code/sequential_process.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41569a2a",
   "metadata": {},
   "source": [
    "#### Example of the same process but using `Ray Task`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d197a745",
   "metadata": {},
   "source": [
    "Let's `run` it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6615b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python code/parallel_process.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f7c676",
   "metadata": {},
   "source": [
    "## Ray `Actors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code\n",
    "\n",
    "Code(\"code/ray_actor.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd23761b",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/ray_actors.jpg\" alt=\"actors\" width=\"80%\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff3ea8b",
   "metadata": {},
   "source": [
    "Let's `run` it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96937aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python code/ray_actor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9d07df",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #0f2027; background: linear-gradient(90deg, #43cea2 0%, #185a9d 100%); padding: 12px 0; border-radius: 8px; text-align:center; font-size: 2rem; letter-spacing: 1px;\">\n",
    "   <span style=\"color: #fff;\">Introduction to Ray Data</span> \n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01b0edb",
   "metadata": {},
   "source": [
    "## Streaming execution\n",
    "\n",
    "Ray Data processes large datasets efficiently using a streaming model, which works with **blocks** as the basic units of data.\n",
    "\n",
    "This approach replaces traditional bulk processing, where the entire dataset and intermediate results had to fit in the cluster's memory.\n",
    "\n",
    "For example:\n",
    "\n",
    "Here is a batch inference pipeline with a bulk processing approach.\n",
    "\n",
    "<div align=\"center\"><img src=\"assets/img04.png\" alt=\"DP\" width=\"80%\"></div>\n",
    "\n",
    "Note how:\n",
    "- Execution is performed in stages\n",
    "- The entire dataset can be repartitioned across stage boundaries\n",
    "\n",
    "In contrast, here is the same batch inference pipeline with Ray Data's streaming model.\n",
    "\n",
    "<div align=\"center\"><img src=\"assets/img05.png\" alt=\"DP with Ray\" width=\"80%\"></div>\n",
    "\n",
    "Note how:\n",
    "- Execution across stages of the pipeline is performed in parallel (i.e pipeline parallelism)\n",
    "- Data is passed incrementally without blocking the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc1d3e9",
   "metadata": {},
   "source": [
    "### Dataset and blocks\n",
    "\n",
    "A Ray Dataset defines a data loading and processing pipeline.\n",
    "\n",
    "When either \"materialized\" or \"consumed\", a Ray Dataset manifests as a distributed collection of blocks stored in the Ray Object Store.\n",
    "\n",
    "Let's start by creating a materialized Ray Dataset to inspect its underlying blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b473925",
   "metadata": {},
   "source": [
    "### Dataset and blocks\n",
    "\n",
    "A Ray Dataset defines a data loading and processing pipeline.\n",
    "\n",
    "When either \"materialized\" or \"consumed\", a Ray Dataset manifests as a distributed collection of blocks stored in the Ray Object Store.\n",
    "\n",
    "Let's start by creating a materialized Ray Dataset to inspect its underlying blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059a9dc9",
   "metadata": {},
   "source": [
    "### `Step 1`: List the existing objects before executing the code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d424856f",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/img07.png\" alt=\"DP\" width=\"70%\"></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0816a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ray list objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e625e3f",
   "metadata": {},
   "source": [
    "As expected, there are no objects created yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048ee0f",
   "metadata": {},
   "source": [
    "### `Step 2`: Prepare some data\n",
    "\n",
    "Let's build a parquet dataset given a target in-memory size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b116c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import ray\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f5ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "size_mb = 64\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": np.random.rand(size_mb * 1024**2 // 8).astype(np.float64),\n",
    "    }\n",
    ")\n",
    "\n",
    "memory_usage = (df.memory_usage(deep=True) / 1024**2).sum() # in MiB\n",
    "print(f\"Memory usage: {memory_usage} MiB\")\n",
    "\n",
    "# Write the dataframe to a parquet file \n",
    "df.to_parquet(\"/mnt/cluster_storage/data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2aea08",
   "metadata": {},
   "source": [
    "Let's inspect the parquet file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240ccd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh /mnt/cluster_storage/data.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e154aa4d",
   "metadata": {},
   "source": [
    "### `Step 3`: Create a materialized dataset\n",
    "\n",
    "Let's create a `Dataset` from the parquet file using `read_parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9784ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ray.data.read_parquet(\"/mnt/cluster_storage/data.parquet\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a7279",
   "metadata": {},
   "source": [
    "Let's materialize the `Dataset` using `materialize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4981a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_materialized = ds.materialize() \n",
    "ds_materialized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e165b",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/img09.png\" alt=\"DP\" width=\"70%\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a8f431",
   "metadata": {},
   "source": [
    "### `Step 4`: List the objects again\n",
    "\n",
    "We can see an object with a size of ~64 MiB has been created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0609335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ray list objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d863a0",
   "metadata": {},
   "source": [
    "Note that we can verify the object was indeed generated by a Ray Data task by following the `CALL_SITE` of the object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bdb1e0",
   "metadata": {},
   "source": [
    "### `Step 5`: Inspect the blocks\n",
    "\n",
    "Instead of browsing through all the objects in the object store, we can directly fetch the blocks of a materialized dataset using Ray Data.\n",
    "\n",
    "It turns out that we can iterate over the blocks of a dataset using `iter_internal_ref_bundles`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9ff96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ref_bundle in ds_materialized.iter_internal_ref_bundles():\n",
    "    print(ref_bundle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0849b56",
   "metadata": {},
   "source": [
    "A reference bundle `RefBundle` is simply a bundle of:\n",
    "- a reference to the block\n",
    "- metadata about the block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7259c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_ref, block_metadata = ref_bundle.blocks[0]\n",
    "block_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e557407",
   "metadata": {},
   "source": [
    "We can check the `Block size` as well. \n",
    "\n",
    "Ray Data bounds block sizes to avoid excessive communication overhead and prevent out-of-memory errors.\n",
    "\n",
    "- Small blocks are good for latency and more streamed execution\n",
    "- Large blocks reduce scheduler and communication overhead.\n",
    "- The default range attempts to make a good tradeoff for most jobs.\n",
    "\n",
    "Here are the default values that Ray Data uses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249f2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_block_size = ray.data.DatasetContext.get_current().target_max_block_size / 1024**2 # in MiB\n",
    "min_block_size = ray.data.DatasetContext.get_current().target_min_block_size / 1024**2 # in MiB\n",
    "\n",
    "print(f\"Max block size: {max_block_size} MiB\")\n",
    "print(f\"Min block size: {min_block_size} MiB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b98251",
   "metadata": {},
   "source": [
    "A block is the basic unit of data that Ray Data stores in the object store and transfers over the network. \n",
    "\n",
    "Each block contains a disjoint subset of rows, and Ray Data loads and transforms these blocks in a distributed manner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b412bb",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/img03.png\" alt=\"Ray Data\" width=\"80%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bde3cfc",
   "metadata": {},
   "source": [
    "To fetch the block, we can use `ray.get`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b3317",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = ray.get(block_ref)\n",
    "block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc43e788",
   "metadata": {},
   "source": [
    "Ray Data stores blocks as either pandas Dataframes or pyarrow Tables. In this case, when materializing from a `read_parquet`, the block is a pyarrow Table.\n",
    "\n",
    "<!-- TODO - figure out adding info below: -->\n",
    "<!-- Note, that regardless of the data type that Ray Data uses to store the block, Ray Data will convert the block to the required batch format when batching the data and transforming it. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7dd552",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(block)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7ffc9e",
   "metadata": {},
   "source": [
    "In this case, the block contains the same data as the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "block.shape, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac63f69e",
   "metadata": {},
   "source": [
    "let's clean up references to the objects we created so Ray can garbage collect them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9307c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel block\n",
    "%xdel block_ref\n",
    "%xdel ds\n",
    "%xdel ds_materialized\n",
    "%xdel ref_bundle\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d289dc",
   "metadata": {},
   "source": [
    "We can see that the object has been garbage collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb3d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ray list objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ddbfcd",
   "metadata": {},
   "source": [
    "\n",
    "<h2 style=\"color: #0f2027; background: linear-gradient(90deg, #43cea2 0%, #185a9d 100%); padding: 12px 0; border-radius: 8px; text-align:center; font-size: 2rem; letter-spacing: 1px;\">\n",
    "   <span style=\"color: #fff;\">What are we going to build today ?</span> \n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170fcd5b",
   "metadata": {},
   "source": [
    "* Scalable data ingestion (`Batch image generation`)\n",
    "* Transforming data using Ray Data pipelines and operators\n",
    "* Scalable batch inference processing with accelerators\n",
    "* Joining Ray Datasets and apply data transformation to joined columns\n",
    "* Integrating scalable LLM inference and fractional resource scheduling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a329b0",
   "metadata": {},
   "source": [
    "## Scenario\n",
    "\n",
    "We have a dataset of image prompts (in our example, animals) and another dataset with enhanced detail information for each record (in the demo, clothing the animal will wear).\n",
    "\n",
    "Our end goal is to combine the prompts and details, then use a LLM to enhance to prompts further, employ an image gen model to create corresponding images, and produce batch output to storage.\n",
    "\n",
    "### Ray Data motivation\n",
    "\n",
    "It's pretty easy to write a Python script to manipulate strings and use models directly from Huggingface with code like the following:\n",
    "\n",
    "```python\n",
    "# Load some model\n",
    "pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
    "# Perform the inference\n",
    "image = pipe(\"A cinematic shot of a racoon wearing an italian priest robe.\", num_inference_steps=1, guidance_scale=0.0).images[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff70e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7717d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1f392e8",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/img06.png\" alt=\"RD\" width=\"80%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc0cfd5",
   "metadata": {},
   "source": [
    "But we want to build a scalable data+AI processing pipeline. To do that, we want to ...\n",
    "\n",
    "* leverage a scale-out cluster with multiple GPUs\n",
    "* read data using as much of our cluster as is useful (parallel read)\n",
    "* work with the data in chunks large enough to get benefits of scale (i.e., not suffer from excessive overhead relative to the number of records)\n",
    "    * but also small enough to allow for flexible scheduling as it flows through our pipeline -- we don't want an enormous chunk to hold up processing, require excessive disk or network I/O, etc.\n",
    "* assign work to, e.g., CPU nodes where GPU is not required; or to smaller, cheaper GPUs where large ones are not required\n",
    "* adjust batching to optimize GPU use even when ideal batch size may be different for different operations\n",
    "* handle arbitrarily large datasets by leveraging a streaming execution model\n",
    "* minimize I/O costs by, e.g., fusing operations where possible\n",
    "* produce predictable flow by managing backpressure (i.e., ensuring data doesn't \"pile up\" in between pipeline stages)\n",
    "* optimize via lazy execution and flexible logical + physical planners\n",
    "\n",
    "Ray Data is designed to address these requirements, allowing us to orchestrate at scale while still straightforward Python / Huggingface code we're used to.\n",
    "\n",
    "### Agenda and steps for incremental implementation\n",
    "\n",
    "1. Locate our datasets in shared storage\n",
    "2. Read records using Ray Data and learn how to perform basic transformations\n",
    "3. Generate images across multiple GPU nodes\n",
    "4. Lab activity: generate images and store all of our prompts and outputs as parquet data\n",
    "5. Join animal records against clothing outfit details to build a bigger prompt and generate enhanced images\n",
    "6. Lab activity: generate and export just the images as PNG files\n",
    "7. Leverage a LLM to further enhance the prompts, adding seasonal content and generate images from the full pipeline\n",
    "8. Lab activity: parameterize the LLM-based component so see how Ray Data supports separation of concerns\n",
    "9. Wrapup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a6fe71",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #0f2027; background: linear-gradient(90deg, #43cea2 0%, #185a9d 100%); padding: 12px 0; border-radius: 8px; text-align:center; font-size: 2rem; letter-spacing: 1px;\">\n",
    "   <span style=\"color: #fff;\">Let's get started! </span> \n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b06316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoPipelineForText2Image\n",
    "from transformers import pipeline\n",
    "from transformers.utils import logging\n",
    "import numpy as np\n",
    "import random\n",
    "import ray\n",
    "import torch\n",
    "logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1ef2e7",
   "metadata": {},
   "source": [
    "## `Step 0`: Defining the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8ec307",
   "metadata": {},
   "source": [
    "First, we need to get all of our data in some common location where the whole cluster can see it. This might be a blob store, NFS, database, etc.\n",
    "\n",
    "Anyscale offers `/mnt/cluster_storage` as a NFS path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fdd518",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/animals.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbec006",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp data/animals.csv /mnt/cluster_storage/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d490c6",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/img09.png\" alt=\"DP\" width=\"70%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a65003",
   "metadata": {},
   "source": [
    "## `Step 1`: Read the data using `Ray Data`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da84a989",
   "metadata": {},
   "source": [
    "Ray Data's `read_xxxx` methods (see I/O in Ray Docs for all the available formats and data sources) get us scalable, parallel reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a59c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ray.data.read_csv('/mnt/cluster_storage/animals.csv')\n",
    "animals.take_batch(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a087bb",
   "metadata": {},
   "source": [
    "We can rename column, like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.rename_columns({'animal' : 'prompt'}) \\\n",
    "       .take_batch(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3168343",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/step2.png\" alt=\"Step2\" width=\"70%\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddebbd1",
   "metadata": {},
   "source": [
    "## `Step 2` : Generate Image "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477f09d0",
   "metadata": {},
   "source": [
    "We dont want to simply do this and process sequentially\n",
    "\n",
    "```python\n",
    "# Load some model\n",
    "pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
    "# Perform the inference\n",
    "image = pipe(\"A cinematic shot of a racoon wearing an italian priest robe.\", num_inference_steps=1, guidance_scale=0.0).images[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b38ef8",
   "metadata": {},
   "source": [
    "Stateful tranformation of datasets -- in this example, `AI inference where the state` is the image gen model (`ImageGen`) -- is done with the following pattern.\n",
    "\n",
    "1. Define a Python class (which Ray will later instantiate across the cluster as one more actor instances to do the processing)\n",
    "2. Use Dataset's `map_batches` API to tell Ray to send batches of data to the `__call__` method in the actors instances\n",
    "    - `map_batches` allows us to specify resource requirements, actor pool size, batch size, and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageGen():\n",
    "    def __init__(self):\n",
    "        self.pipe = AutoPipelineForText2Image.from_pretrained(\"stabilityai/sdxl-turbo\", torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
    "        \n",
    "    def gen_image(self, prompts):\n",
    "        return self.pipe(prompt=list(prompts), num_inference_steps=1, guidance_scale=0.0).images\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        batch['image'] = self.gen_image(batch['prompt'])\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599c2353",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_images = animals.repartition(2) \\\n",
    "                        .rename_columns({'animal' : 'prompt'}) \\\n",
    "                        .map_batches(ImageGen, \n",
    "                                     num_gpus=1, \n",
    "                                     compute=ray.data.ActorPoolStrategy(size=2), \n",
    "                                     batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db949bdc",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/step3.png\" alt=\"Step3\" width=\"70%\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c522fefe",
   "metadata": {},
   "source": [
    "Ray Datasets employ *lazy evaluation* for improved performance, so we can use APIs like `take_batch`, `take`, or `show` to trigger execution for development and testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6d2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = animals_images.take_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d8460",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/img10.png\" alt=\"Step3\" width=\"70%\"></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26319e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(examples['prompt'][0])\n",
    "examples['image'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8539e4",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/step4.png\" alt=\"Step4\" width=\"70%\"></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48342bc1",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: 2px solid #4F8EF7; background: #F3F8FF; border-radius: 10px; padding: 18px; margin: 18px 0;\">\n",
    "<h2 style=\"color: #25396f; margin-top: 0;\">üìù <span style=\"color:#3971CC;\">Lab:</span> Generate and Write All Output to Storage as <span style=\"color: #C678DD;\">Parquet</span> Data</h2>\n",
    "\n",
    "<ul style=\"font-size: 1.1em;\">\n",
    "  <li><b>Start</b> with the <span style=\"color: #A9A9A9;\">Ray Dataset</span> you'd like to write.</li>\n",
    "  <li><b>Check</b> the <a href=\"https://docs.ray.io/en/latest/data/api/input_output.html\" target=\"_blank\" style=\"color: #3971CC;\">Ray Data Write API docs</a> to find a suitable <code>write</code> API.</li>\n",
    "  <li><b>Remember</b> to write to a <span style=\"color: #228B22;\">shared file location</span>, such as <code style=\"color: #228B22;\">/mnt/cluster_storage</code>.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c49f94",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "<details>\n",
    "    <summary style=\"font-size: 1.5em; color: ;\"><b> Solution</b></summary>\n",
    " \n",
    " ```python\n",
    " animals_images.write_parquet('/mnt/cluster_storage/animals_images.parquet/')\n",
    " ```\n",
    "\n",
    "<div align=\"center\"><img src=\"assets/step5.png\" alt=\"Step5\" width=\"70%\"></div>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70a0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f6eeae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24af9c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29819f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9324c11b",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/Part1_done.png\" alt=\"Intro to Ray\" width=\"70%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50435406",
   "metadata": {},
   "source": [
    "## `Step 3`: Improving the `prompt` using `JOIN`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736b1c91",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/Part2.png\" alt=\"Part2\" width=\"70%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be542a1f",
   "metadata": {},
   "source": [
    "Ray Data supports a number of high-performance JOIN APIs.  \n",
    "You can learn more here:  [Ray Data Join API Documentation](https://docs.ray.io/en/latest/data/joining-data.html)\n",
    "\n",
    "We can use a `JOIN` to connect our `animal` records with a detailed prompt refinement unique to that record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9922c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp data/outfits.csv /mnt/cluster_storage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1852cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head /mnt/cluster_storage/outfits.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565cc4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfits = ray.data.read_csv('/mnt/cluster_storage/outfits.csv')\n",
    "outfits.take_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6937aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "animals_outfits = animals.join(outfits, 'inner', 1) \\\n",
    "                         .repartition(8)\n",
    "\n",
    "animals_outfits.take_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495beabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the prompt to include the outfit\n",
    "def expand_prompt(batch):\n",
    "    batch['prompt'] = batch['animal'] + ' wearing a ' + batch['outfit']\n",
    "    return batch\n",
    "\n",
    "# Generate images for the dressed animals\n",
    "dressed_animals = animals_outfits.map_batches(expand_prompt) \\\n",
    "                                 .map_batches(ImageGen, \n",
    "                                              batch_size=16, \n",
    "                                              compute=ray.data.ActorPoolStrategy(size=2), \n",
    "                                              num_gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b039015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the first 3 records\n",
    "examples = dressed_animals.take_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3efd002",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecf3a37",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/img11.png\" alt=\"Ray Task\" width=\"70%\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d32a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(examples['prompt'][0])\n",
    "examples['image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3105272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43b20a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0aeb52d",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/step4_task.png\" alt=\"Ray Task\" width=\"70%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f037304",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #4F8EF7; background: #F3F8FF; border-radius: 10px; padding: 18px; margin: 18px 0;\">\n",
    "<h2 style=\"color: #25396f; margin-top: 0;\">üìù <span style=\"color:#3971CC;\">Lab:</span> Generate Images for Input Prompts &amp; Write Them to a Folder</h2>\n",
    "\n",
    "<ul style=\"font-size: 1.1em;\">\n",
    "  <li><b>Convert</b> the image column to NumPy arrays using <code>np.array(my_pil_image)</code> together with <code>map_batches</code>.</li>\n",
    "  <li><b>Use</b> <code>dataset.write_images(...)</code> to write the NumPy image arrays to a folder of your choice (e.g., <code>/mnt/cluster_storage/generated_images/</code>).</li>\n",
    "  <li><b>Check</b> the <a href=\"https://docs.ray.io/en/latest/data/api/input_output.html#ray.data.Dataset.write_images\" target=\"_blank\" style=\"color: #3971CC;\">Ray Data Write Images API Docs</a> for details.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb6385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d4723",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"font-size: 1.5em; color: ;\"><b> Solution</b></summary>\n",
    " \n",
    " ```python\n",
    "    def image_to_array(batch):\n",
    "        batch['image'] = [np.array(i) for i in batch['image']]\n",
    "        return batch\n",
    "        \n",
    "    dressed_animals.map_batches(image_to_array) \\\n",
    "                   .write_images('/mnt/cluster_storage/animals_images/', 'image')\n",
    " ```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ced0f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4578d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8440890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639a94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396d212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12247dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b9923f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "059636d0",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/Part2_done.png\" alt=\"Intro to Ray\" width=\"70%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e727ddf1",
   "metadata": {},
   "source": [
    "## `Step 4` :  Enhance pipeline with `LLM` generated prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5db94a",
   "metadata": {},
   "source": [
    "We can leverage a LLM to create more varied and detailed image prompts -- as well as add dynamism like a seasonal element -- by adding a LLM batch inference step to the pipeline.\n",
    "\n",
    "To implement this operation, we'll\n",
    "1. Create a Python class to encasulate the logic and data transformtion\n",
    "1. Use `map_batches` to route batches of data from our Ray Dataset through this transformation operation\n",
    "1. Demonstrate Ray's support for fractional resource allocation, so that we can schedule 4 GPU-dependent operator instances with only 2 GPUs\n",
    "1. Demonstrate the decoupling of operator batch sizes from each other (as well as from Dataset block size) to optimally use our models and GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e2bb04",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/Part3.png\" alt=\"Intro to Ray\" width=\"70%\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba788c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Enhancer():\n",
    "    def __init__(self):\n",
    "        self.pipe = pipeline(\"text-generation\", model=\"Qwen/Qwen2.5-0.5B-Instruct\", device='cuda')\n",
    "        \n",
    "    def chat(self, prompts):\n",
    "        messages = []\n",
    "        for p in prompts:\n",
    "            season = random.choice(['winter', 'spring', 'summer', 'fall'])\n",
    "                                   \n",
    "            message = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\" +\n",
    "                        \"Enhance the image description with two short elements corresponding to the \" + season + \n",
    "                        \"season. Keep animal wearing clothing and retain image medium information (like photo or painting). Return new description only, no intro.\"},\n",
    "                        {\"role\": \"user\", \"content\": p }]\n",
    "            messages.append(message)\n",
    "        return [out[0]['generated_text'][-1]['content'] for out in self.pipe(messages, max_new_tokens=200, batch_size=2)]\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        batch['prompt'] = self.chat(batch['prompt'])\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a5533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_images = animals_outfits.map_batches(expand_prompt) \\\n",
    "                                 .map_batches(Enhancer, batch_size=4, compute=ray.data.ActorPoolStrategy(size=2), num_gpus=0.6) \\\n",
    "                                 .map_batches(ImageGen, batch_size=8, compute=ray.data.ActorPoolStrategy(size=2), num_gpus=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95296924",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = seasonal_images.take_batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75402f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(examples['prompt'][2])\n",
    "examples['image'][2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d99b03f",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/Part3_done.png\" alt=\"Intro to Ray\" width=\"70%\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd0184",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #4F8EF7; background: #F3F8FF; border-radius: 10px; padding: 18px; margin: 18px 0;\">\n",
    "<h2 style=\"color: #25396f; margin-top: 0;\">üìù <span style=\"color:#3971CC;\">Modify the <code>Enhancer</code> class and <code>seasonal_images</code> pipeline for parametrization</span></h2>\n",
    "\n",
    "<ul style=\"font-size: 1.1em;\">\n",
    "  <li>Use variables contaioning the model name and the name of the dataset column containing the prompt as below</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhancer_model = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "prompt_column = \"prompt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c5b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try your code here: updated Enhancer class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dd00a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try your code here: updated pipelineto generate seasonal_images Ray dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86324d",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"font-size: 1.5em; color: ;\"><b> Solution</b></summary>\n",
    " \n",
    " ```python\n",
    "    # try your code here: updated Enhancer class\n",
    "    class Enhancer():\n",
    "        def __init__(self, model_name, prompt_column_name):\n",
    "            self.pipe = pipeline(\"text-generation\", model=model_name, device='cuda')\n",
    "            self.prompt_column_name = prompt_column_name\n",
    "            \n",
    "        def chat(self, prompts):\n",
    "            messages = []\n",
    "            for p in prompts:\n",
    "                season = random.choice(['winter', 'spring', 'summer', 'fall'])\n",
    "                                    \n",
    "                message = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\" +\n",
    "                            \"Enhance the image description with two short elements corresponding to the \" + season + \n",
    "                            \"season. Keep animal wearing clothing and retain image medium information (like photo or painting). Return new description only, no intro.\"},\n",
    "                            {\"role\": \"user\", \"content\": p }]\n",
    "                messages.append(message)\n",
    "            return [out[0]['generated_text'][-1]['content'] for out in self.pipe(messages, max_new_tokens=200, batch_size=2)]\n",
    "        \n",
    "        def __call__(self, batch):\n",
    "            batch[self.prompt_column_name] = self.chat(batch[self.prompt_column_name])\n",
    "            return batch\n",
    "\n",
    "\n",
    "    # try your code here: updated pipelineto generate seasonal_images Ray dataset\n",
    "    seasonal_images = animals_outfits.map_batches(expand_prompt) \\\n",
    "                        .map_batches(Enhancer, batch_size=4, compute=ray.data.ActorPoolStrategy(size=2), num_gpus=0.6, fn_constructor_args=[enhancer_model, prompt_column]) \\\n",
    "                        .map_batches(ImageGen, batch_size=8, compute=ray.data.ActorPoolStrategy(size=2), num_gpus=0.4)\n",
    " ```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a16b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try your code here: updated Enhancer class\n",
    "class Enhancer():\n",
    "    def __init__(self, model_name, prompt_column_name):\n",
    "        self.pipe = pipeline(\"text-generation\", model=model_name, device='cuda')\n",
    "        self.prompt_column_name = prompt_column_name\n",
    "        \n",
    "    def chat(self, prompts):\n",
    "        messages = []\n",
    "        for p in prompts:\n",
    "            season = random.choice(['winter', 'spring', 'summer', 'fall'])\n",
    "                                   \n",
    "            message = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\" +\n",
    "                        \"Enhance the image description with two short elements corresponding to the \" + season + \n",
    "                        \"season. Keep animal wearing clothing and retain image medium information (like photo or painting). Return new description only, no intro.\"},\n",
    "                        {\"role\": \"user\", \"content\": p }]\n",
    "            messages.append(message)\n",
    "        return [out[0]['generated_text'][-1]['content'] for out in self.pipe(messages, max_new_tokens=200, batch_size=2)]\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        batch[self.prompt_column_name] = self.chat(batch[self.prompt_column_name])\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a22f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try your code here: updated pipelineto generate seasonal_images Ray dataset\n",
    "seasonal_images = animals_outfits.map_batches(expand_prompt) \\\n",
    "                    .map_batches(Enhancer, batch_size=4, compute=ray.data.ActorPoolStrategy(size=2), num_gpus=0.6, fn_constructor_args=[enhancer_model, prompt_column]) \\\n",
    "                    .map_batches(ImageGen, batch_size=8, compute=ray.data.ActorPoolStrategy(size=2), num_gpus=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f34026",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = seasonal_images.take_batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5256341",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(examples['prompt'][1])\n",
    "examples['image'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8398b70c",
   "metadata": {},
   "source": [
    "<h2 style=\"color: #0f2027; background: linear-gradient(90deg, #43cea2 0%, #185a9d 100%); padding: 12px 0; border-radius: 8px; text-align:center; font-size: 2rem; letter-spacing: 1px;\">\n",
    "   <span style=\"color: #fff;\">Thank You!</span> \n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00880ff2",
   "metadata": {},
   "source": [
    "<div align=\"center\"><img src=\"assets/LI.png\" alt=\"Intro to Ray\" width=\"50%\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92015cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
